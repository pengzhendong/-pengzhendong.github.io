<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Randy&#39;s Notes</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://pengzhendong.cn/"/>
  <updated>2019-04-08T03:23:21.000Z</updated>
  <id>https://pengzhendong.cn/</id>
  
  <author>
    <name>Randy Peng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java 基础总结</title>
    <link href="https://pengzhendong.cn/2019/04/08/java-basis/"/>
    <id>https://pengzhendong.cn/2019/04/08/java-basis/</id>
    <published>2019-04-08T02:36:03.000Z</published>
    <updated>2019-04-08T03:23:21.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>五月份就该去实习了，趁着这一个多月无所事事，正好学着刷一下 LeetCode。一直以来算法相关内容都是弱点，本科的《数据结构与算法》学得也不是很好。大三暑假为了保研曾经刷过一段时间 poj，不太会总结，纯粹就是瞎刷。由于没有什么方向保研后就又放弃了，最近在慕课网上找了一套视频学习，发现效果很好。</p><a id="more"></a><p>视频链接：<a href="https://coding.imooc.com/class/82.html" target="_blank" rel="noopener">玩转算法面试</a>，刚刷完数组、查找表和链表，就在阿里巴巴的实习面试中排上用场了。由于 LeetCode 题目太多，无法每道题都写一篇博客，视频中推荐的题目就直接丢 <a href="https://github.com/pengzhendong/LeetCode" target="_blank" rel="noopener">Github</a> 了。在刷题过程中对 Java 的传值有些疑惑，顺便记录一下。</p><h2 id="基础类型">基础类型</h2><p>Java 一共有八种基础类型：<code>byte</code>/8、<code>char</code>/16、<code>short</code>/16、<code>int</code>/32、<code>float</code>/32、<code>long</code>/64、<code>double</code>/64 和 boolean/~。前七种类型的占用的<strong>位数</strong>明确给出，而 boolean 类型没有给出精确的定义，因为其在编译之后都使用 int 数据类型来代替，而 boolean 数组将会被编码成 byte 数组，因此 boolean 单独使用占 32 位，在数组中占 8 位。</p><p>Java 的八种基础类型对应八种包裹类型：<code>Byte</code>、 <code>Character</code>、<code>Short</code>、<code>Integer</code>、<code>Float</code>、<code>Long</code>、 <code>Double</code> 和 <code>Boolean</code>。这些包裹类型内部有一个对应类型的变量 <code>value</code> 用于保存数值。包裹类型会自动拆箱和装箱，即在计算数值时包裹类型会自动拆箱转为基础类型进行计算，当基础类型传入包裹类型时，又会自动包装成包裹类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer num = <span class="number">1</span>;     <span class="comment">// 装箱</span></span><br><span class="line"><span class="keyword">int</span> x = num;         <span class="comment">// 拆箱</span></span><br></pre></td></tr></table></figure><h2 id="存储区域">存储区域</h2><p>Java 有六大存储区域：</p><ul><li><p>寄存器：在处理器内部而不是内存中，速度最快，但是在 Java 中无法直接控制，也感受不到。</p></li><li><p>栈：存放八种基本类型、数组的引用和对象的引用（即数组和对象在堆内存中的首地址）。当在一段代码块定义一个变量时，就在栈中为这个变量分配内存空间，当该变量退出该作用域后，会自动释放掉为该变量所分配的内存空间。</p></li><li><p>堆：存放由 <code>new</code> 创建的数组和对象。在堆中产生了一个数组或对象后，在栈中定义一个特殊的变量，让栈中这个变量的取值等于数组或对象在堆内存中的首地址，栈中的这个变量就成了数组或对象的引用变量。引用变量就相当于是为数组或对象起的一个名称，以后就可以在程序中使用栈中的引用变量来访问堆中的数组或对象。<code>new</code> 一个数组则会返回其在堆中的首地址，将其赋值给栈中的变量 <code>nums</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span>[] nums = <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;<span class="number">1</span>, <span class="number">2</span>&#125;;</span><br></pre></td></tr></table></figure></li><li><p>静态存储区：又叫方法区，顾名思义包含的是 <code>static</code> 修饰的静态变量，即程序运行时一直存在的数据。</p></li><li><p>常量存储区：<code>static final</code> 修饰的常量值通常直接存放在程序代码内部，即在编译时被确定，并被保存在已编译的 .class 文件中的一些数据。</p></li><li><p>非 RAM 存储区：硬盘等。</p></li></ul><h2 id="缓存池">缓存池</h2><p>包裹类型的 value 被声明为 <code>final</code>，表示 value 初始化后无法重新赋值，即包裹类型内部没有改变 value 的方法。因此在自增等操作的时候，变量会指向新的对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer num = <span class="number">1</span>;</span><br><span class="line">num += <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>以上代码会被编译成：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer localInteger = Integer.valueOf(<span class="number">1</span>);</span><br><span class="line">localInteger = Integer.valueOf(localInteger.intValue() + <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>即会取出 num 的值加一，然后再返回一个新的对象。可是 <code>Integer.valueOf()</code> 和 <code>new Integer()</code> 有什么关系呢？通过查看其源代码可知：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Integer <span class="title">valueOf</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)</span><br><span class="line">        <span class="keyword">return</span> IntegerCache.cache[i + (-IntegerCache.low)];</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Integer(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原来除了 <code>Float</code> 和 <code>Double</code>，Java 为其他包裹类型提供了缓存池。 <code>Integer</code> 内部维护了一个 <code>IntegerCache</code> 静态类，这个类又维护了一个 <code>static final Integer</code> 数组（默认范围为：[-128, 127]，可配置），如果缓存池中有这个值对于的对象则直接返回，否则 <code>new</code> 一个返回（不会加入缓存池）。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Integer num1 = Integer.valueOf(<span class="number">1</span>);</span><br><span class="line">Integer num2 = <span class="keyword">new</span> Integer(<span class="number">1</span>);</span><br><span class="line">Integer num3 = Integer.valueOf(<span class="number">128</span>);</span><br></pre></td></tr></table></figure><p>如果通过反射机制修改对象的 value，那么指向这个对象的其它变量也会改变。下面代码中初始化了两个变量，编译后它们会通过 <code>valueOf()</code> 去缓存池中获取对应的对象，通过反射机制修改了 value 的值，缓存池中对象的值也会改变，最后导致 val 的值改变：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Integer num = <span class="number">1</span>;</span><br><span class="line">        Integer val = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = Integer.class.getDeclaredField(<span class="string">"value"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            field.set(num, <span class="number">2</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其他类型对应的缓冲池如下：</p><ul><li>Boolean: true &amp; false</li><li>Byte: 所有 byte 值</li><li>Short: [-128, 127]</li><li>Character: [, ]</li></ul><h2 id="string">String</h2><p>除了上述类型，<code>String</code> 类型也被声明为 <code>final</code>，因此它也不可继承。在 Java 8 中，<code>String</code> 内部使用 <code>char</code> 存储数据，在 Java 9 之后则改用 <code>byte</code> 数组，同时使用变量 <code>coder</code> 来标记使用了哪种编码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span>, <span class="title">Comparable</span>&lt;<span class="title">String</span>&gt;, <span class="title">CharSequence</span> </span>&#123;</span><br><span class="line">    <span class="comment">/** The value is used for character storage. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] value;</span><br><span class="line">    <span class="comment">/** The identifier of the encoding used to encode the bytes in &#123;<span class="doctag">@code</span> value&#125;. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span> coder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>value 被声明为 <code>final</code>，因此 value 数组初始化以后就不能再指向其他数组，即 <code>String</code> 类的内部没有改变 value 数组的方法。同样可以使用反射机制修改 <code>String</code> 的值，需要注意的是，当调用 <code>hashCode()</code> 一次以后就会保存哈希值，再次调用则不会重新计算：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h = hash;</span><br><span class="line">    <span class="keyword">if</span> (h == <span class="number">0</span> &amp;&amp; value.lenght &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        hash = h = isLatin1() ? StringLatin1.hashCode(value)</span><br><span class="line">          : StringUTF16.hashCode(value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面代码中 <code>addressOf(Object o)</code> 会将对象的引用转化成一个长整型地址；在主函数中定义了一个字符串 "Hello"，输出其地址和哈希值，用反射机制修改其内容为 "World" 后再次输出地址和哈希值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"><span class="keyword">import</span> sun.misc.Unsafe;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Unsafe unsafe;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = Unsafe.class.getDeclaredField(<span class="string">"theUnsafe"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            unsafe = (Unsafe) field.get(<span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">addressOf</span><span class="params">(Object o)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Object[] array = <span class="keyword">new</span> Object[] &#123; o &#125;;</span><br><span class="line">        <span class="keyword">long</span> baseOffset = unsafe.arrayBaseOffset(Object[].class);</span><br><span class="line">        <span class="keyword">int</span> addressSize = unsafe.addressSize();</span><br><span class="line">        <span class="keyword">long</span> objectAddress;</span><br><span class="line">        <span class="keyword">switch</span> (addressSize) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">4</span>:</span><br><span class="line">                objectAddress = unsafe.getInt(array, baseOffset);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">8</span>:</span><br><span class="line">                objectAddress = unsafe.getLong(array, baseOffset);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">"Unsupported address size: "</span> + addressSize);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (objectAddress);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String str = <span class="string">"Hello"</span>;</span><br><span class="line">        System.out.println(<span class="string">"Address: "</span> + addressOf(str) + <span class="string">" Value: "</span> + str + <span class="string">" HashCode: "</span> + str.hashCode());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = String.class.getDeclaredField(<span class="string">"value"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            field.set(str, <span class="string">"World"</span>.getBytes());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"Address: "</span> + addressOf(str) + <span class="string">" Value: "</span> + str + <span class="string">" HashCode: "</span> + str.hashCode());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终输出结果为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Address: 2353254184 Value: Hello HashCode: 69609650</span><br><span class="line">Address: 2353254184 Value: World HashCode: 69609650</span><br></pre></td></tr></table></figure><p>可以看到只有字符串内容发生改变，而地址和哈希值都有发生变化。大部分情况下都是根据哈希值来识别一个字符串，所以反射修改字符串内容属于非常危险的操作！</p><h3 id="string-常量池">String 常量池</h3><p>String 常量池保存着所有字符串字面量 (literal strings)，即在编译时期就确定的字面量，还可以使用 <code>intern()</code> 方法将字符串添加到常量池中。</p><blockquote><p>When the intern method is invoked, if the pool already contains a string equal to this {<span class="citation" data-cites="code">@code</span> String} object as determined by the {<span class="citation" data-cites="link">@link</span> #equals(Object)} method, then the string from the pool is returned. Otherwise, this {<span class="citation" data-cites="code">@code</span> String} is added to the pool and a reference to this {<span class="citation" data-cites="code">@code</span> String} object is returned.</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String str1 = <span class="string">"Hello"</span>;<span class="comment">// 字面量赋值，"Hello" 为字面量</span></span><br><span class="line">String str2 = <span class="string">"Hel"</span> + <span class="string">"lo"</span>;<span class="comment">// 在编译阶段优化成 String str2 = "Hello";</span></span><br><span class="line">String str3 = <span class="keyword">new</span> String(<span class="string">"World"</span>);<span class="comment">// new 创建对象，"World" 为字面量</span></span><br><span class="line">String str4 = str2.intern();<span class="comment">// 将 str2 的内容加入常量池，并且返回其在常量池中的引用</span></span><br></pre></td></tr></table></figure><p>在类加载阶段会将所有字面量加入常量池，即常量池中有 "Hello" 和 "World"。编译阶段 "Hel" + "lo" 会被优化成 "Hello"，因此 str1 和 str2 指向常量池中同一个字符串；str3 会根据字面量 "World" 的内容在堆中重新创建一个对象，<code>String</code> 的构造函数如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(String original)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.val = original.value;</span><br><span class="line">    <span class="keyword">this</span>.hash = original.hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然在堆中重新构造了一个对象，但是并没有复制 value 数组的内容，而是指向同一个 <code>byte</code> 数组；将 str3 的内容加入常量池，常量池中有 "World"，所以直接返回其在常量池中的引用给 str4。</p><h2 id="传值">传值</h2><p>Java 与 C/C++ 最大的不同就是 Java 无法操作指针，上面的 <code>addressOf(Object o)</code> 函数也只能将一个对象的地址转化成长整型地址，并不能获取基本类型的地址。因此 Java Pass By Value，即传的都是值，只不过这个值有可能是对象的引用。</p><h3 id="基础类型-1">基础类型</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">changeInt</span><span class="params">(<span class="keyword">int</span> value)</span> </span>&#123; value += <span class="number">1</span>; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line">    changInt(num);</span><br><span class="line">    System.out.println(num);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 <code>changeInt()</code> 的时候会将参数 num 拷贝一份，因此不会影响主函数中的 num 变量，即为值传递。</p><h3 id="包裹类型-string">包裹类型 &amp; String</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">changeStr</span><span class="params">(String value)</span> </span>&#123; value += <span class="string">"World"</span>; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String str = <span class="string">"Hello"</span>;</span><br><span class="line">    changStr(str);</span><br><span class="line">    System.out.println(str);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 <code>changeStr()</code> 的时候会将参数 str （即常量池中 "Hello" 的地址）拷贝一份，因此 value 变量和 str 变量同样指向常量池中的 "Hello"。由于 <code>String</code> 不可变，对字符串进行拼接不会对原有字符串产生变动，而是直接生成一个新的字符串 "HelloWorld"，返回其地址给 value 变量。因此不会影响主函数中的 str 变量，所以也是值传递。</p><h3 id="容器类型">容器类型</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">changeList</span><span class="params">(List&lt;Integer&gt; value)</span> </span>&#123; value.add(<span class="number">1</span>); &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    List&lt;Integer&gt; list = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    changeList(list);</span><br><span class="line">    System.out.println(str);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 <code>changeList()</code> 的时候会将参数 list （即堆中新建的 <code>LinkedList</code> 的地址）拷贝一份，因此 value 变量和 list 变量同样指向堆中的 <code>LinkedList</code>。因此在 <code>changeList()</code> 函数中对 value 的操作会影响主函数中的 list 变量，所以虽然是值传递（传的是 <code>LinkedList</code> 的地址），也可以认为传递的是引用。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;五月份就该去实习了，趁着这一个多月无所事事，正好学着刷一下 LeetCode。一直以来算法相关内容都是弱点，本科的《数据结构与算法》学得也不是很好。大三暑假为了保研曾经刷过一段时间 poj，不太会总结，纯粹就是瞎刷。由于没有什么方向保研后就又放弃了，最近在慕课网上找了一套视频学习，发现效果很好。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://pengzhendong.cn/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>风格迁移</title>
    <link href="https://pengzhendong.cn/2019/01/14/neural-style-transfer/"/>
    <id>https://pengzhendong.cn/2019/01/14/neural-style-transfer/</id>
    <published>2019-01-14T08:16:19.000Z</published>
    <updated>2019-01-14T10:42:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>我觉得卷积神经网络最神奇的应用就是风格迁移！大部分应用的思想都相差无几，重点就是如何构造损失函数，将我们的目标用损失函数的方式表示，让模型按照指定的方向去学习。</p><a id="more"></a><h2 id="可视化">可视化</h2><p>在学习风格迁移之前，首先了解一下卷积神经网络的可视化。训练好的 CNN 模型的隐藏层中的每一个滤波器对应一种特征，每一个滤波器与输入的图像进行卷积运算后经过激活层。如果输入的图像具有该滤波器对应的特征，那么经过激活层后就会被激活，即输出特征图对应的数值大于 0。可视化过程涉及到反卷积和反池化，具体过程可参考 Visualizing and Understanding Convolutional Networks [2]。<a href="https://github.com/yosinski/deep-visualization-toolbox" target="_blank" rel="noopener">DeepVis Toolbox</a> 是一个开源的可视化工具，可视化结果如下图所示：</p><p><img src="/2019/01/14/neural-style-transfer/example_bvlc-googlenet_bus.png"></p><p>图中可视化的是 GoogleNet，输入为一张公交车的图像，每个小方块表示一个滤波器。将滤波器反卷积和反池化回原图像，结果如左下角所示。</p><h2 id="风格迁移">风格迁移</h2><p>给定一张内容图像 C 和一张风格图像 S，风格迁移模型生成一张具有 C 的内容和 S 的风格图像 G。如下图所示：</p><p><img src="/2019/01/14/neural-style-transfer/perspolis_vangogh.png"></p><h3 id="迁移学习">迁移学习</h3><p>风格迁移任务中，需要提取图像的内容特征和风格特征，然后根据特征生成图像（初始化为一张随机噪声图）。通过构造损失函数，令模型学习生成的图像 G 具有 C 的内容和 S 的风格，训练完毕后给定任意两张图像都能生成它们的风格迁移图像。实验使用了迁移学习提取图像特征，首先在 ImageNet 上预训练了一个用于分类的 VGG-19 网络，然后直接应用过来提取图像特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = load_vgg_model(<span class="string">"pretrained-model/imagenet-vgg-verydeep-19.mat"</span>)</span><br></pre></td></tr></table></figure><p>使用 <code>tf.assign</code> 函数为模型输入数据，获取模型中间隐藏层的输出如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model[<span class="string">"input"</span>].assign(image)</span><br><span class="line">sess.run(model[<span class="string">"conv4_2"</span>])</span><br></pre></td></tr></table></figure><h3 id="代价函数">代价函数</h3><p>风格迁移的代价函数分为两部分：内容代价函数 <span class="math inline">\(J_{content}(C,G)\)</span> 和风格代价函数 <span class="math inline">\(J_{style}(S,G)\)</span>。完整的代价函数为： <span class="math display">\[J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)\]</span></p><p>其中 <span class="math inline">\(\alpha\)</span> 和 <span class="math inline">\(\beta\)</span> 是超参数，代码实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_cost</span><span class="params">(J_content, J_style, alpha = <span class="number">10</span>, beta = <span class="number">40</span>)</span>:</span></span><br><span class="line">    J = alpha * J_content + beta * J_style</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J</span><br></pre></td></tr></table></figure><h4 id="内容代价函数">内容代价函数</h4><p>由可视化可知，通常浅层的滤波器提取的特征都是一些简单的特征，例如边角和纹理；比较深的、靠近全连接层的滤波器提取的特征就比较高级，例如一些复杂的纹理或者对象的类别。因此我们需要将比较中间的卷积层的输出作为图像的内容特征，假设选择的层数为 <span class="math inline">\(l\)</span>，图像 C 经过该层激活函数后的输出为 <span class="math inline">\(a^{[l](C)}\)</span>，为了表示方便，后续内容将省略层数，用 <span class="math inline">\(a^{(C)}\)</span> 表示图像 C 的内容特征，同时后续内容实验会测试不同 <span class="math inline">\(l\)</span> 取值的影响。</p><p>那么如何衡量生成的图像 G 和 C 之间的内容匹配了多少？内容代价函数比较简单，就是计算 C 和 G 的内容特征图每个像素点的差异，然后进行归一化。计算公式如下所示： <span class="math display">\[J_{content}(C,G) =  \frac{1}{4 \times n_H \times n_W \times n_C}\sum _{ \text{all entries}} (a^{(C)} - a^{(G)})^2\]</span> 其中 <span class="math inline">\(n_H\)</span>、<span class="math inline">\(n_W\)</span> 和 <span class="math inline">\(n_C\)</span> 分别表示特征图的高、宽和通道数。为了<strong>便于理解</strong>，将 3 维的特征图展开成两维，如下所示：</p><p><img src="/2019/01/14/neural-style-transfer/reshape_loss.png"></p><p>由于 <code>reshape</code> 只是修改维度，而不改变填充顺序，因此需要先使用 <code>transpose</code> 对矩阵进行转置。使用 Tensorflow 实现内容代码函数分为以下三个步骤：</p><ol type="1"><li>获取图像维度</li><li>展开 <span class="math inline">\(a_C\)</span> 和 <span class="math inline">\(a_G\)</span></li><li>计算内容损失</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_content_cost</span><span class="params">(a_C, a_G)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from a_G (≈1 line)</span></span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    <span class="comment"># Reshape a_C and a_G (≈2 lines)</span></span><br><span class="line">    a_C_unrolled = tf.reshape(tf.transpose(a_C, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]), [n_C, n_H * n_W, m])</span><br><span class="line">    a_G_unrolled = tf.reshape(tf.transpose(a_G, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]), [n_C, n_H * n_W, m])</span><br><span class="line">    <span class="comment"># compute the cost with tensorflow (≈1 line)</span></span><br><span class="line">    J_content = (<span class="number">1</span>/ (<span class="number">4</span>* n_H * n_W * n_C)) * tf.reduce_sum(tf.pow((a_G_unrolled - a_C_unrolled), <span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J_content</span><br></pre></td></tr></table></figure><p>计算过程中展开和不展开并不会影响矩阵元素之间的计算，而且 <code>transpose</code> 函数默认的参数 <code>perm</code> 可以省略。</p><h4 id="风格代价函数">风格代价函数</h4><p>图像的风格定义为 <span class="math inline">\(l\)</span> 层中各个通道之间激活项的相关系数，即风格矩阵（也叫 Gram 矩阵）。这里有个小问题就是风格矩阵用 <span class="math inline">\(G\)</span> 表示，生成的图像也是用 <span class="math inline">\(G\)</span> 表示。</p><h5 id="gram-矩阵">Gram 矩阵</h5><p>给定展开成两维的特征图矩阵，其由 <span class="math inline">\(n_C\)</span> 个横向量<span class="math inline">\((v_{1},\dots ,v_{n_H\times n_W})\)</span> 组成。根据定义，Gram 矩阵中每个元素的值 <span class="math inline">\({\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j}) }\)</span>，即 <span class="math inline">\(G_{ij}\)</span> 衡量滤波器 <span class="math inline">\(i\)</span> 的激活值 <span class="math inline">\(v_i\)</span> 和滤波器 <span class="math inline">\(j\)</span> 的激活值 <span class="math inline">\(v_j\)</span> 的相似性，如下图所示：</p><p><img src="/2019/01/14/neural-style-transfer/NST_GM.png"></p><p>输出的 Gram 矩阵的维度为 <span class="math inline">\((n_C, n_C)\)</span>，值得注意的是 <span class="math inline">\(G_{ii} = v_{i}^T v_{i}\)</span> 衡量的是图像中滤波器 <span class="math inline">\(i\)</span> 对应的特征的活跃性。假设 <span class="math inline">\(i\)</span> 对应水平纹理，<span class="math inline">\(G_{ii}\)</span> 的值越大就表示图像中水平纹理越多。通过计算各种特征之间的 <span class="math inline">\(G_{ij}\)</span> 即这些特征同时出现的可能性，就可以衡量一张图像的风格。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(A)</span>:</span></span><br><span class="line">    GA = tf.matmul(A, tf.transpose(A))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> GA</span><br></pre></td></tr></table></figure><h5 id="风格代价">风格代价</h5><p>我们的目标是最小化风格图像 S 和生成图像 G 之间的 Gram 矩阵的距离，这里只考虑第 <span class="math inline">\(l\)</span> 个隐藏层的风格（考虑的层数越多，风格越相似），其对应的风格代价计算公式如下所示： <span class="math display">\[J_{style}^{[l]}(S,G)=\frac{1}{4\times {n_C}^2\times (n_H\times n_W)^2}\sum _{i=1}^{n_C}\sum_{j=1}^{n_C}(G^{(S)}\_{ij}-G^{(G)}\_{ij})^2\]</span> 计算过程分为四个步骤：</p><ol type="1"><li>获取风格矩阵的维度</li><li>展开 <span class="math inline">\(a_S\)</span> 和 <span class="math inline">\(a_G\)</span></li><li>计算 S 和 G 的风格矩阵</li><li>计算风格代价</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_layer_style_cost</span><span class="params">(a_S, a_G)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from a_G (≈1 line)</span></span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Reshape the images to have them of shape (n_H*n_W, n_C) (≈2 lines)</span></span><br><span class="line">    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]))</span><br><span class="line">    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Computing gram_matrices for both images S and G (≈2 lines)</span></span><br><span class="line">    GS = gram_matrix(a_S)</span><br><span class="line">    GG = gram_matrix(a_G)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Computing the loss (≈1 line)</span></span><br><span class="line">    J_style_layer = (<span class="number">1.</span>/(<span class="number">4</span> * n_C**<span class="number">2</span> * (n_H*n_W)**<span class="number">2</span>)) * tf.reduce_sum(tf.pow((GS - GG), <span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J_style_layer</span><br></pre></td></tr></table></figure><h5 id="风格权值">风格权值</h5><p>综合考虑每个隐藏层的风格会令实验效果更好，因此对每个隐藏层的风格代价一个权值，进行加权平均：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">STYLE_LAYERS = [</span><br><span class="line">    (<span class="string">'conv1_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv2_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv3_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv4_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv5_1'</span>, <span class="number">0.2</span>)]</span><br></pre></td></tr></table></figure><p>整体的风格代价函数为： <span class="math display">\[J_{style}(S,G) = \sum_{l} \lambda^{[l]} J^{[l]}_{style}(S,G)\]</span> 其中 <span class="math inline">\(\lambda^{[l]}\)</span> 就是给定的 <code>STYLE_LAYERS[l]</code>。代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_style_cost</span><span class="params">(model, STYLE_LAYERS)</span>:</span></span><br><span class="line">    <span class="comment"># initialize the overall style cost</span></span><br><span class="line">    J_style = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> layer_name, coeff <span class="keyword">in</span> STYLE_LAYERS:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select the output tensor of the currently selected layer</span></span><br><span class="line">        out = model[layer_name]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out</span></span><br><span class="line">        a_S = sess.run(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that when we run the session, this will be the activations drawn from the appropriate layer, with G as input.</span></span><br><span class="line">        a_G = out</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute style_cost for the current layer</span></span><br><span class="line">        J_style_layer = compute_layer_style_cost(a_S, a_G)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add coeff * J_style_layer of this layer to overall style cost</span></span><br><span class="line">        J_style += coeff * J_style_layer</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> J_style</span><br></pre></td></tr></table></figure><p>在循环中 <code>a_S</code> 和 <code>a_G</code> 都是选择同一隐藏层的激活值，但是前者使用了 <code>sess.run</code> 而后者没有。因此后续需要将生成的图像 G 作为输入，然后运行对话才可以得到具体 <code>a_G</code> 的值。</p><h3 id="解决优化问题">解决优化问题</h3><p>最后需要结合上述代码，实现风格迁移。实验分为以下几个步骤：</p><ol type="1"><li><p>创建交互式会话</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reset the graph</span></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="comment"># Start interactive session</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure></li><li><p>载入 VGG19 模型、内容图像和风格图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = load_vgg_model(<span class="string">"pretrained-model/imagenet-vgg-verydeep-19.mat"</span>)</span><br><span class="line"></span><br><span class="line">content_image = scipy.misc.imread(<span class="string">"images/louvre_small.jpg"</span>)</span><br><span class="line">content_image = reshape_and_normalize_image(content_image)</span><br><span class="line">style_image = scipy.misc.imread(<span class="string">"images/monet.jpg"</span>)</span><br><span class="line">style_image = reshape_and_normalize_image(style_image)</span><br></pre></td></tr></table></figure></li><li><p>随机初始化生成图像（通过对内容图像添加大量噪声而不是完全随机，可以让生成的图像内容快速匹配）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">generated_image = generate_noise_image(content_image)</span><br><span class="line">imshow(generated_image[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></li><li><p>构建 Tensorflow 图模型</p><ul><li><p>通过 VGG19 模型运行内容图像，计算内容代价</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Assign the content image to be the input of the VGG model.  </span></span><br><span class="line">sess.run(model[<span class="string">'input'</span>].assign(content_image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select the output tensor of layer conv4_2</span></span><br><span class="line">out = model[<span class="string">'conv4_2'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a_C to be the hidden layer activation from the layer we have selected</span></span><br><span class="line">a_C = sess.run(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that when we run the session, this will be the activations drawn from the appropriate layer, with G as input.</span></span><br><span class="line">a_G = out</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the content cost</span></span><br><span class="line">J_content = compute_content_cost(a_C, a_G)</span><br></pre></td></tr></table></figure></li><li><p>通过 VGG19 模型运行风格图像，计算风格代价</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Assign the input of the model to be the "style" image </span></span><br><span class="line">sess.run(model[<span class="string">'input'</span>].assign(style_image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the style cost</span></span><br><span class="line">J_style = compute_style_cost(model, STYLE_LAYERS)</span><br></pre></td></tr></table></figure></li><li><p>计算整体代价、定义优化器和学习率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">J = total_cost(J_content, J_style, alpha = <span class="number">10</span>, beta = <span class="number">40</span>)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(<span class="number">2.0</span>)</span><br><span class="line">train_step = optimizer.minimize(J)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>初始化图模型，迭代输入<strong>生成的图像</strong>，更新生成的图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_nn</span><span class="params">(sess, input_image, num_iterations = <span class="number">200</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize global variables (you need to run the session on the initializer)</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the noisy input image (initial generated image) through the model. Use assign().</span></span><br><span class="line">    sess.run(model[<span class="string">'input'</span>].assign(input_image))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        <span class="comment"># Run the session on the train_step to minimize the total cost</span></span><br><span class="line">        sess.run(train_step)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the generated image by running the session on the current model['input']</span></span><br><span class="line">        generated_image = sess.run(model[<span class="string">'input'</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print every 20 iteration.</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            Jt, Jc, Js = sess.run([J, J_content, J_style])</span><br><span class="line">            print(<span class="string">"Iteration "</span> + str(i) + <span class="string">" :"</span>)</span><br><span class="line">            print(<span class="string">"total cost = "</span> + str(Jt))</span><br><span class="line">            print(<span class="string">"content cost = "</span> + str(Jc))</span><br><span class="line">            print(<span class="string">"style cost = "</span> + str(Js))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># save current generated image in the "/output" directory</span></span><br><span class="line">            save_image(<span class="string">"output/"</span> + str(i) + <span class="string">".png"</span>, generated_image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># save last generated image</span></span><br><span class="line">    save_image(<span class="string">'output/generated_image.jpg'</span>, generated_image)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> generated_image</span><br></pre></td></tr></table></figure></li></ol><p>运行模型 <code>model_nn(sess, generated_image)</code> 后即可得到保存在输出文件夹中的生成图像，实验为了节省时间直接设定好了所有超参数，例如风格权值 <code>STYLE_LAYERS</code>、迭代的次数和 <span class="math inline">\((\alpha, \beta)\)</span>。</p><h2 id="总结">总结</h2><p>深度学习具有各种各样的模型，这次实验是首次对图像的像素值进行更新优化而不是权值，由于不需要手动实现反向传播所以不算很难，但是还需要多了解 Tensorflow 的文档。收获比较大的就是将直观感觉用数学语言描述出来，即如何表示一张图像的内容和风格！然后才能设计合适的代价函数，让模型学习出我们想要的内容。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Matthew D Zeiler, Rob Fergus, (2013). Visualizing and Understanding Convolutional Networks(https://arxiv.org/abs/1311.2901)</li><li>Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style (<a href="https://arxiv.org/abs/1508.06576" class="uri" target="_blank" rel="noopener">https://arxiv.org/abs/1508.06576</a>)</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;我觉得卷积神经网络最神奇的应用就是风格迁移！大部分应用的思想都相差无几，重点就是如何构造损失函数，将我们的目标用损失函数的方式表示，让模型按照指定的方向去学习。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>人脸识别</title>
    <link href="https://pengzhendong.cn/2019/01/12/face-recognition/"/>
    <id>https://pengzhendong.cn/2019/01/12/face-recognition/</id>
    <published>2019-01-12T07:53:03.000Z</published>
    <updated>2019-01-12T10:26:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>人脸识别这部分内容的实验 idea 主要来自于 FaceNet，其中还有部分来自 DeepFace。网络结构没有什么特殊的地方，主要是其损失函数的构造。</p><a id="more"></a><h2 id="人脸识别">人脸识别</h2><p>人脸识别问题通常分为两类：</p><ul><li>人脸验证：例如苹果的 Face ID 技术，判断当前人脸是否为机主，这就是 1:1 匹配问题。</li><li>人脸识别：例如有些公司的门禁，判断当前人脸是否为公司员工，这就是 1:K 匹配问题。</li></ul><p>FaceNet [2] 神经网络可以将一张人脸图像编码成一个 128 维的向量，然后通过比较两个向量来判断是否属于同一个人。实验内容主要分为三部分：</p><ol type="1"><li>实现三重损失函数</li><li>使用预训练的模型将人脸图像编码成 128 维向量</li><li>使用上述编码来进行人脸验证和人脸识别</li></ol><p>首先需要引入各种 package 和导入数据集，虽然在深度学习领域没有统一的标准，但是为了方便，这里使用的图像数据集是 "channels first" 的，即维度为 <span class="math inline">\((m, n_C, n_H, n_W)\)</span>。</p><h3 id="人脸验证">人脸验证</h3><p>人脸验证问题就是给定两张人脸图像，判断他们是否是同一个人。最简单的方法就是计算每个像素的差异，然后给定一个阈值，差异超过这个阈值就不是同一个人，但是如果同一个人在不同亮度下或者不同角度下照片的差异通常很大。因此需要对图像进行编码后分析而不是简单对像素进行分析，即使用神经网络提取图像特征进行对比。</p><h3 id="编码人脸">编码人脸</h3><p>实验使用 FaceNet 提取人脸特征，这个 ConvNet 网络的架构是 Inception 模型，模型细节可以参考 <a href="https://github.com/pengzhendong/DeepLearning/blob/master/4.%20Convolutional%20Neural%20Networks/Week%204/Face%20Recognition/inception_blocks.py" target="_blank" rel="noopener">inception_blocks.py</a>。输入模型的图像尺寸为 <span class="math inline">\(96\times 96\)</span>，即输入维度为 <span class="math inline">\((m, n_C, n_H, n_W) = (m, 3, 96, 96)\)</span>，输出为 <span class="math inline">\((m, 128)\)</span>。通过计算两个向量之间的距离，就可以判断对应的两张人脸图像是否属于同一个人。</p><p><img src="/2019/01/12/face-recognition/distance_kiank.png"></p><p>如果编码足够好，即模型提取人脸的特征足够好，那么对于同一个人的不同照片，最后计算的距离应该很小；对于不同人脸，计算出的距离应该很大。FaceNet 在训练过程中使用的三重损失函数就可以保证这个模型提取的特征足够好。</p><h4 id="三重损失">三重损失</h4><p>三重损失的思想是最小化不同人脸的编码距离，最大化同一个人脸的编码距离。给定一张图像 <span class="math inline">\(x\)</span>，定义其编码为 <span class="math inline">\(f(x)\)</span>，函数 <span class="math inline">\(f\)</span> 即神经网络计算的功能。给定三元组图像 <span class="math inline">\((A, P, N)\)</span>，其中：</p><ul><li>A: Anchor 图像，即人脸图像</li><li>P: Positive 图像，与 Anchor 图像为同一个人</li><li>N: Negative 图像，与 Anchor 图像不是同一个人</li></ul><p>对于训练集中的第 <span class="math inline">\(i\)</span> 个样本 <span class="math inline">\((A^{(i)}, P^{(i)}, N^{(i)})\)</span>，有： <span class="math display">\[\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 + \alpha &lt; \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2\]</span> 其中参数 <span class="math inline">\(\alpha\)</span> 是为了避免对于所有的图像，模型都编码为 0，这里手动设置为 0.2。因此可以构造三重代价函数： <span class="math display">\[\mathcal{J} = \sum^{N}_{i=1} max\large( \small \underbrace{\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2}_\text{(1)} - \underbrace{\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2}_\text{(2)} + \alpha, 0 \large )\]</span> 通常还会对编码进行归一化，即令 <span class="math inline">\(\mid \mid f(img)\mid \mid_2=1\)</span>。实现上述代价函数分为四个步骤：</p><ol type="1"><li>计算 A 和 P 编码的距离：<span class="math inline">\(\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2\)</span></li><li>计算 A 和 N 编码的距离：<span class="math inline">\(\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2\)</span></li><li>对于每个三元组样本，计算损失函数：<span class="math inline">\(\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid - \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2 + \alpha\)</span></li><li>计算代价函数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(y_true, y_pred, alpha = <span class="number">0.2</span>)</span>:</span></span><br><span class="line">    anchor, positive, negative = y_pred[<span class="number">0</span>], y_pred[<span class="number">1</span>], y_pred[<span class="number">2</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Compute the (encoding) distance between the anchor and the positive</span></span><br><span class="line">    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)))</span><br><span class="line">    <span class="comment"># Step 2: Compute the (encoding) distance between the anchor and the negative</span></span><br><span class="line">    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)))</span><br><span class="line">    <span class="comment"># Step 3: subtract the two previous distances and add alpha.</span></span><br><span class="line">    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</span><br><span class="line">    <span class="comment"># Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.</span></span><br><span class="line">    loss = tf.maximum(tf.reduce_mean(basic_loss), <span class="number">0.0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h2 id="载入预训练模型">载入预训练模型</h2><p>训练 FaceNet 的过程就是最小化三重损失，由于 FaceNet 在训练的时候需要大量数据和时间，因此实验直接给了一个预训练的 ConvNet 模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FRmodel = faceRecoModel(input_shape=(<span class="number">3</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br><span class="line">FRmodel.compile(optimizer = <span class="string">'adam'</span>, loss = triplet_loss, metrics = [<span class="string">'accuracy'</span>])</span><br><span class="line">load_weights_from_FaceNet(FRmodel)</span><br></pre></td></tr></table></figure><p>以下为模型在三个人的人脸图像上计算的编码距离，距离越小表示为同一个人的概率越大。</p><h2 id="模型应用">模型应用</h2><p>例如构建一个人脸验证系统，用户输入姓名，然后系统拍摄人脸，判断该用户是否是姓名对应那个人。与人脸识别不同的是，人脸识别系统不需要提供姓名，直接拍摄人脸，然后判断数据库中是否有该用户。</p><h3 id="人脸验证-1">人脸验证</h3><p>首先往数据库中存入数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">database = &#123;&#125;</span><br><span class="line">database[<span class="string">"danielle"</span>] = img_to_encoding(<span class="string">"images/danielle.png"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"younes"</span>] = img_to_encoding(<span class="string">"images/younes.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"tian"</span>] = img_to_encoding(<span class="string">"images/tian.jpg"</span>, FRmodel)</span><br></pre></td></tr></table></figure><p>实现验证过程主要分为以下几个步骤：</p><ol type="1"><li>计算人脸图像的编码</li><li>计算该编码与数据库中<font color="red"><strong>指定</strong></font>的编码的距离</li><li>差异小于阈值 0.7 即判断为同一个人</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verify</span><span class="params">(image_path, identity, database, model)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)</span></span><br><span class="line">    encoding = img_to_encoding(image_path, model)</span><br><span class="line">    <span class="comment"># Step 2: Compute distance with identity's image (≈ 1 line)</span></span><br><span class="line">    dist = np.linalg.norm(encoding-database[identity])</span><br><span class="line">    <span class="comment"># Step 3: Return True if dist &lt; 0.7 (≈ 3 lines)</span></span><br><span class="line">    <span class="keyword">if</span> dist &lt; <span class="number">0.7</span>:</span><br><span class="line">        print(<span class="string">"It's "</span> + str(identity) + <span class="string">", welcome home!"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"It's not "</span> + str(identity) + <span class="string">", please go away"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h3 id="人脸识别-1">人脸识别</h3><p>人脸识别和人脸验证的区别就是人脸验证需要提供其他信息，然后只需要判断用户是否为信息指定的那个人；人脸识别不需要提供其他信息，但是需要和数据库中所有数据进行比较，判断是否属于其中任何一个人。实现识别过程主要分为以下几个步骤：</p><ol type="1"><li><p>计算人脸图像的编码（目标编码）</p></li><li><p>找到数据库中与目标编码距离最小的编码</p><ul><li>初始化 <code>min_dist</code> 为一个比较大的值，用于存储最小的距离</li><li>遍历数据库中所有编码<ul><li>计算编码与目标编码的距离</li><li>如果距离小于 <code>min_dist</code>，记录新的距离和该编码对应的信息</li></ul></li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">who_is_it</span><span class="params">(image_path, database, model)</span>:</span></span><br><span class="line">    <span class="comment">## Step 1: Compute the target "encoding" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)</span></span><br><span class="line">    encoding = img_to_encoding(image_path, model)</span><br><span class="line">    <span class="comment">## Step 2: Find the closest encoding ##</span></span><br><span class="line">    <span class="comment"># Initialize "min_dist" to a large value, say 100 (≈1 line)</span></span><br><span class="line">    min_dist = <span class="number">100</span></span><br><span class="line">    <span class="comment"># Loop over the database dictionary's names and encodings.</span></span><br><span class="line">    <span class="keyword">for</span> (name, db_enc) <span class="keyword">in</span> database.items():</span><br><span class="line">        <span class="comment"># Compute L2 distance between the target "encoding" and the current "emb" from the database. (≈ 1 line)</span></span><br><span class="line">        dist = np.linalg.norm(encoding-db_enc)</span><br><span class="line">        <span class="comment"># If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)</span></span><br><span class="line">        <span class="keyword">if</span> dist &lt; min_dist:</span><br><span class="line">            min_dist = dist</span><br><span class="line">            identity = name</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> min_dist &gt; <span class="number">0.7</span>:</span><br><span class="line">        print(<span class="string">"Not in the database."</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"it's "</span> + str(identity) + <span class="string">", the distance is "</span> + str(min_dist))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> min_dist, identity</span><br></pre></td></tr></table></figure><p>通过对数据集的扩增，例如提供同一个用户在不同光照下照片等等可以提高系统的准确率；通过对图像的处理，例如裁剪图像只保留人脸等等可以提高系统的鲁棒性。</p><h2 id="总结">总结</h2><p>人脸验证是 1:1 匹配问题，只需要对比一张人脸图像；而人脸识别就比较难，1:K 匹配问题需要比较数据库中所有的人脸。最小化三重损失得到的网络可以有效提取人脸的特征。同样的编码既可以用来进行人脸验证，也可以用来进行人脸识别。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). <a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank" rel="noopener">FaceNet: A Unified Embedding for Face Recognition and Clustering</a></li><li>Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). <a href="https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf" target="_blank" rel="noopener">DeepFace: Closing the gap to human-level performance in face verification</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;人脸识别这部分内容的实验 idea 主要来自于 FaceNet，其中还有部分来自 DeepFace。网络结构没有什么特殊的地方，主要是其损失函数的构造。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>自动驾驶</title>
    <link href="https://pengzhendong.cn/2019/01/08/autonomous-driving/"/>
    <id>https://pengzhendong.cn/2019/01/08/autonomous-driving/</id>
    <published>2019-01-08T13:50:00.000Z</published>
    <updated>2019-01-08T15:26:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>最近在看《梁实秋读书与做人》，开始感受到了时间的宝贵，究竟如何才能掌握尚未逝去的时光呢？同时也尝试了刷一刷 LeetCode，毕竟这是每一个计算机从业者的基本功，不能再浑浑噩噩了。论文还是没有结果，在一个博士的指导下投了 B 刊，也是不能松懈，继续折腾吧！正好自己又有了一点小想法，可是为什么我的想法总是这么难实现呢？每一篇博客的前言都是被用来吐槽的，吐槽最近的生活与科研。空闲之余继续学习深度学习，这一节的内容是使用 YOLO 算法实现“自动驾驶”，其实是对摄像头拍摄的视频中的每一帧进行目标检测。</p><a id="more"></a><h2 id="目标检测">目标检测</h2><p>这部分内容属于自动驾驶的一个模块，即车辆检测。通常自动驾驶需要给汽车安装一个摄像头，对前方路况进行拍摄，我们需要检测前方有无车辆以及车辆的位置信息，以供其它模块避开车辆。</p><p><img src="/2019/01/08/autonomous-driving/box_label.png"></p><p>这里使用 YOLO 算法进行目标检测，一共有 80 个类别，即 <span class="math inline">\(c\)</span> 的取值为 <span class="math inline">\([1, 80]\)</span> 或者是一个 80 维的独热向量，这两种表示在实验中都会使用，哪个方便用哪个。由于 YOLO 训练比较耗时，因此主要是了解 YOLO 算法的原理，最后实验会提供预训练好的模型。</p><h2 id="yolo">YOLO</h2><p>YOLO (You Only Look Once) 算法在目标检测领域比较受欢迎，因为它的准确率比较高而且可以做到实时检测。这个算法只需要前向传播一次即可做出预测，在非极大值抑制后即可输出识别的目标和其位置信息。而前面介绍的 RCNN 系列算法则是需要先提取图像的感兴趣区域，再对这些区域进行分析，即需要“看”两次。</p><h3 id="模型">模型</h3><ul><li>输入：一个批次的三通道图像，其 shape 为 <span class="math inline">\((m, 608, 608, 3)\)</span></li><li>输出：一个列表，列表中每个元素为一个 6 维向量 <span class="math inline">\((p_c, b_x, b_y, b_h, b_w, c)\)</span>；如果使用独热向量则是 85 维向量。</li></ul><p>实验使用 5 个锚框，因此 YOLO 的结构为：IMAGE (m, 608, 608, 3) -&gt; DEEP CNN -&gt; ENCODING (m, 19, 19, 5, 85)，如下图所示：</p><p><img src="/2019/01/08/autonomous-driving/architecture.png"></p><p>如果目标的中心在网格中，该网格就需要检测到该目标。由于使用了 5 个锚框，所以输出的 <span class="math inline">\(19\times 19\)</span> 网格中的每一个网格对应 5 个边界框，即输出的维度为 <span class="math inline">\((19, 19, 5, 85)\)</span>。将最后两个维度拉平得 <span class="math inline">\((19, 19, 425)\)</span>，如下图所示：</p><p><img src="/2019/01/08/autonomous-driving/flatten.png"></p><p>对于网格中的每一个锚框，我们需要计算其中分类为每一个类别的概率，如下图所示：</p><p><img src="/2019/01/08/autonomous-driving/probability_extraction.png"></p><p>图中 <span class="math inline">\(p_c\)</span> 为包含待检测目标的概率，<span class="math inline">\(c_n\)</span> 为属于第 <span class="math inline">\(n\)</span> 个类别的概率。因此 <span class="math inline">\(p_cc_n\)</span> 为锚框中包含第 <span class="math inline">\(n\)</span> 类目标的概率，最后取概率最大的一类作为该锚框的预测结果。由于一个网格对应 5 个锚框，最后再对这 5 个锚框的输出取最大值作为该网格的预测结果，即一个网格只保留一个锚框，该锚框对应一个类别的物体。有两种方法可以对算法进行可视化：对网格上色和绘制出每个网格对应的边界框。两种方式如下图所示：</p><p><img src="/2019/01/08/autonomous-driving/proba_anchor.png"></p><p>即使取了最大值，但是输出的边界框还是很多。因此还可以对其进行过滤：</p><ul><li>去除得分比较低的边界框（阈值过滤），得分低表示边界框不敢肯定其中检测到的目标</li><li>对于重叠内容比较多的边界框，只保留其中一个（非极大值抑制）</li></ul><h3 id="阈值过滤">阈值过滤</h3><p>设定阈值，过滤掉得分低于阈值的边界框。模型输出的维度为 <span class="math inline">\(19\times 19\times 5\times 85\)</span>，每个 85 维的向量对应一个边界框，因此可以将模型的输出分为以下三部分：</p><ul><li><code>box_confidence</code>: 维度为 <span class="math inline">\((19 \times 19, 5, 1)\)</span> 的张量，对应所有边界框的 <span class="math inline">\(p_c\)</span></li><li><code>boxes</code>: 维度为 <span class="math inline">\((19 \times 19, 5, 4)\)</span> 的张量，对应所有边界框的位置信息 <span class="math inline">\((b_x, b_y, b_h, b_w)\)</span></li><li><code>box_class_probs</code>: 维度为 <span class="math inline">\((19 \times 19, 5, 80)\)</span> 的张量，对应检测到的目标的类别的概率 <span class="math inline">\((c_1, c_2, ... c_{80})\)</span></li></ul><p>实现阈值过滤包含以下四个步骤：</p><ol type="1"><li><p>计算每个边界框包含的具体类别目标的概率 <span class="math inline">\(p_cc_n\)</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(<span class="number">19</span>*<span class="number">19</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">b = np.random.randn(<span class="number">19</span>*<span class="number">19</span>, <span class="number">5</span>, <span class="number">80</span>)</span><br><span class="line">c = a * b <span class="comment"># shape of c will be (19*19, 5, 80)</span></span><br></pre></td></tr></table></figure></li><li><p>对于每一个边界框，找到最大的得分 <code>box_class_scores</code> 与其对应类别的索引 <code>box_classes</code></p></li><li><p>根据阈值创建 mask 矩阵。如 <code>([0.9, 0.3, 0.4, 0.5, 0.1] &lt; 0.4</code> 返回 <code>[False, True, False, False, True]</code></p></li><li><p>将 mask 矩阵应用到 <code>box_class_scores</code> 和 <code>box_classes</code> 中即可过滤出超过阈值的边界框</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_filter_boxes</span><span class="params">(box_confidence, boxes, box_class_probs, threshold = <span class="number">.6</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Compute box scores</span></span><br><span class="line">    box_scores = np.multiply(box_confidence, box_class_probs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score</span></span><br><span class="line">    box_classes = K.argmax(box_scores, axis=<span class="number">-1</span>)</span><br><span class="line">    box_class_scores = K.max(box_scores, axis=<span class="number">-1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Create a filtering mask based on "box_class_scores" by using "threshold". The mask should have the</span></span><br><span class="line">    <span class="comment"># same dimension as box_class_scores, and be True for the boxes you want to keep (with probability &gt;= threshold)</span></span><br><span class="line">    filtering_mask = K.greater_equal(box_class_scores, threshold)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 4: Apply the mask to scores, boxes and classes</span></span><br><span class="line">    scores = tf.boolean_mask(box_class_scores, filtering_mask)</span><br><span class="line">    boxes = tf.boolean_mask(boxes, filtering_mask)</span><br><span class="line">    classes = tf.boolean_mask(box_classes, filtering_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores, boxes, classes</span><br></pre></td></tr></table></figure><h3 id="非极大值抑制">非极大值抑制</h3><p>阈值过滤后，还是会有很多边界框。它们框住同一个目标，因此 <span class="math inline">\(p_cc_n\)</span> 都会大于阈值，我们可以使用非极大值抑制来保留一个边界框，如下图所示：</p><p><img src="/2019/01/08/autonomous-driving/non-max-suppression.png"></p><p>上图中模型预测出三个车，但是属于同一辆车，非极大值抑制可以保留最准确的一个边界框，即概率最大的一个。非极大值抑制中有一个很重要的概念叫<strong>交并比 IoU</strong>(Intersection over Union)，其原理如下图所示：</p><p><img src="/2019/01/08/autonomous-driving/iou.png"></p><p>实验给定的边界框位置信息为左上角和右下角：(x1, y1, x2, y2)。即边界框的高为 (y2 - y1)，宽为 (x2 - x1)；图像的左上角为 (0, 0)，右上角为 (1, 0)，右下角为 (1, 1)。给定两个边界框，还需要找到交并后的坐标：</p><ul><li><code>xi1</code>: 两个边界框 x1 的最大值</li><li><code>yi1</code>: 两个边界框 y1 的最大值</li><li><code>xi2</code>: 两个边界框 x2 的最小值</li><li><code>yi2</code>: 两个边界框 y2 的最小值</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iou</span><span class="params">(box1, box2)</span>:</span></span><br><span class="line">    <span class="comment"># Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1 and box2. Calculate its Area.</span></span><br><span class="line">    xi1 = max(box1[<span class="number">0</span>], box2[<span class="number">0</span>])</span><br><span class="line">    yi1 = max(box1[<span class="number">1</span>], box2[<span class="number">1</span>])</span><br><span class="line">    xi2 = min(box1[<span class="number">2</span>], box2[<span class="number">2</span>])</span><br><span class="line">    yi2 = min(box1[<span class="number">3</span>], box2[<span class="number">3</span>])</span><br><span class="line">    inter_area = (xi2 - xi1)*(yi2 - yi1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)</span></span><br><span class="line">    box1_area = (box1[<span class="number">3</span>] - box1[<span class="number">1</span>])*(box1[<span class="number">2</span>]- box1[<span class="number">0</span>])</span><br><span class="line">    box2_area = (box2[<span class="number">3</span>] - box2[<span class="number">1</span>])*(box2[<span class="number">2</span>]- box2[<span class="number">0</span>])</span><br><span class="line">    union_area = (box1_area + box2_area) - inter_area</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute the IoU</span></span><br><span class="line">    iou = inter_area / union_area</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure><p>实现非极大值抑制分为三个步骤：</p><ol type="1"><li><p>将所有边界框按照得分排序，选择最高分的边界框</p></li><li><p>遍历其余的边界框，计算得分最高的边界框与这些边界框的交并比。如果交并比大于阈值 <code>iou_threshold</code>，则删除这些边界框</p></li><li><p>迭代以上过程，直到处理完毕所有的边界框</p></li></ol><p>Tensorflow 内置函数实现了非极大值抑制，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_non_max_suppression</span><span class="params">(scores, boxes, classes, max_boxes = <span class="number">10</span>, iou_threshold = <span class="number">0.5</span>)</span>:</span></span><br><span class="line">    max_boxes_tensor = K.variable(max_boxes, dtype=<span class="string">'int32'</span>)     <span class="comment"># tensor to be used in tf.image.non_max_suppression()</span></span><br><span class="line">    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) <span class="comment"># initialize variable max_boxes_tensor</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep</span></span><br><span class="line">    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use K.gather() to select only nms_indices from scores, boxes and classes</span></span><br><span class="line">    scores = K.gather(scores, nms_indices)</span><br><span class="line">    boxes = K.gather(boxes, nms_indices)</span><br><span class="line">    classes = K.gather(classes, nms_indices)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores, boxes, classes</span><br></pre></td></tr></table></figure><h3 id="合并过滤器">合并过滤器</h3><p>将以上两种过滤器合并为 <code>yolo_filter_boxes</code>；深度 CNN 输出的 <span class="math inline">\(19\times 19\times 5\times 85\)</span> 维向量，即 YOLO 的编码 <code>yolo_outputs</code>。由于过滤器需要的位置信息不同，需要将 (x, y, w, h) 转化为 (x1, y1, x2, y2)。如果测试集的图像尺寸与训练集不一致，例需要将其扩展到图像大小的测试集上，例如图像大小为 (720, 1280) 。实验提供这些功能的接口，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_eval</span><span class="params">(yolo_outputs, image_shape = <span class="params">(<span class="number">720.</span>, <span class="number">1280.</span>)</span>, max_boxes=<span class="number">10</span>, score_threshold=<span class="number">.6</span>, iou_threshold=<span class="number">.5</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve outputs of the YOLO model (≈1 line)</span></span><br><span class="line">    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert boxes to be ready for filtering functions </span></span><br><span class="line">    boxes = yolo_boxes_to_corners(box_xy, box_wh)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line)</span></span><br><span class="line">    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Scale boxes back to original image shape.</span></span><br><span class="line">    boxes = scale_boxes(boxes, image_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use one of the functions you've implemented to perform Non-max suppression with a threshold of iou_threshold (≈1 line)</span></span><br><span class="line">    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes = max_boxes, iou_threshold = iou_threshold)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores, boxes, classes</span><br></pre></td></tr></table></figure><h2 id="测试">测试</h2><p>在图像大小为 (720, 1280) 的测试集上测试预训练的模型，由于需要检测 80 种类别并且使用 5 个锚框，因此需要先载入这些信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line">class_names = read_classes(<span class="string">"model_data/coco_classes.txt"</span>)</span><br><span class="line">anchors = read_anchors(<span class="string">"model_data/yolo_anchors.txt"</span>)</span><br><span class="line">image_shape = (<span class="number">720.</span>, <span class="number">1280.</span>)</span><br><span class="line"></span><br><span class="line">yolo_model = load_model(<span class="string">"model_data/yolo.h5"</span>)</span><br></pre></td></tr></table></figure><p>该模型的输出维度为 (m, 608, 608, 3))，输出维度为 (m, 19, 19, 5, 85)。将输出转化为过滤器的输入所需的维度，继而对边界框进行过滤：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))</span><br><span class="line">scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)</span><br></pre></td></tr></table></figure><h3 id="运行图">运行图</h3><p>目前为止，我们已经创建了一个 (sess) 图，主要包含以下三部分内容：</p><ol type="1"><li><code>yolo_model</code>: 输入为 yolo_model.input，输出为 yolo_model.output</li><li><code>yolo_head</code>: 输入为 yolo_model.output，输出为 yolo_outputs</li><li><code>yolo_eval</code>: 过滤函数，输入为 yolo_outputs，输出为预测结果 scores, boxes 和 classes</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(sess, image_file)</span>:</span></span><br><span class="line">    <span class="comment"># Preprocess your image</span></span><br><span class="line">    image, image_data = preprocess_image(<span class="string">"images/"</span> + image_file, model_image_size = (<span class="number">608</span>, <span class="number">608</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run the session with the correct tensors and choose the correct placeholders in the feed_dict.</span></span><br><span class="line">    <span class="comment"># You'll need to use feed_dict=&#123;yolo_model.input: ... , K.learning_phase(): 0&#125;)</span></span><br><span class="line">    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict=&#123;yolo_model.input: image_data, K.learning_phase(): <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print predictions info</span></span><br><span class="line">    print(<span class="string">'Found &#123;&#125; boxes for &#123;&#125;'</span>.format(len(out_boxes), image_file))</span><br><span class="line">    <span class="comment"># Generate colors for drawing bounding boxes.</span></span><br><span class="line">    colors = generate_colors(class_names)</span><br><span class="line">    <span class="comment"># Draw bounding boxes on the image file</span></span><br><span class="line">    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)</span><br><span class="line">    <span class="comment"># Save the predicted bounding box on the image</span></span><br><span class="line">    image.save(os.path.join(<span class="string">"out"</span>, image_file), quality=<span class="number">90</span>)</span><br><span class="line">    <span class="comment"># Display the results in the notebook</span></span><br><span class="line">    output_image = scipy.misc.imread(os.path.join(<span class="string">"out"</span>, image_file))</span><br><span class="line">    imshow(output_image)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out_scores, out_boxes, out_classes</span><br></pre></td></tr></table></figure><p><code>preprocess_image</code> 函数返回的 image 用于绘制边界框。在测试图像种运行结果如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_scores, out_boxes, out_classes = predict(sess, <span class="string">"test.jpg"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Found 7 boxes <span class="keyword">for</span> test.jpg</span><br><span class="line">car 0.60 (925, 285) (1045, 374)</span><br><span class="line">car 0.66 (706, 279) (786, 350)</span><br><span class="line">bus 0.67 (5, 266) (220, 407)</span><br><span class="line">car 0.70 (947, 324) (1280, 705)</span><br><span class="line">car 0.74 (159, 303) (346, 440)</span><br><span class="line">car 0.80 (761, 282) (942, 412)</span><br><span class="line">car 0.89 (367, 300) (745, 648)</span><br></pre></td></tr></table></figure><p><img src="/2019/01/08/autonomous-driving/output.png"></p><h2 id="总结">总结</h2><p>YOLO 是目前目标检测领域最快最准确的算法，其直接在整张图像上运行 CNN 网络，输出 <span class="math inline">\(19\times 19\times 5\times 85\)</span> 的向量。这个输出的编码可以看成是一个 <span class="math inline">\(19\times 19\)</span> 的网格，每个网格对应 5 个边界框。然后使用非极大值抑制对边界框进行过滤，得到最后的结果。这种直接对图像运行 CNN 得到输出的形式，只需要一趟即可得到结果，不像 RCNN 需要先提取感兴趣的区域。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - <a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">You Only Look Once: Unified, Real-Time Object Detection</a> (2015)</li><li>Joseph Redmon, Ali Farhadi - <a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">YOLO9000: Better, Faster, Stronger</a> (2016)</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在看《梁实秋读书与做人》，开始感受到了时间的宝贵，究竟如何才能掌握尚未逝去的时光呢？同时也尝试了刷一刷 LeetCode，毕竟这是每一个计算机从业者的基本功，不能再浑浑噩噩了。论文还是没有结果，在一个博士的指导下投了 B 刊，也是不能松懈，继续折腾吧！正好自己又有了一点小想法，可是为什么我的想法总是这么难实现呢？每一篇博客的前言都是被用来吐槽的，吐槽最近的生活与科研。空闲之余继续学习深度学习，这一节的内容是使用 YOLO 算法实现“自动驾驶”，其实是对摄像头拍摄的视频中的每一帧进行目标检测。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>目标检测</title>
    <link href="https://pengzhendong.cn/2018/12/19/object-detection/"/>
    <id>https://pengzhendong.cn/2018/12/19/object-detection/</id>
    <published>2018-12-19T08:16:29.000Z</published>
    <updated>2018-12-19T10:02:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>最近看了几篇关于漏洞检测的文章，将图像处理领域中的目标检测的思想运用到软件的漏洞检测中。话是这么说，但是通篇看下来，其实和目标检测关系并不大，说到底还是对代码行进行分类，判断是否有漏洞。借着这个机会，正好总结一些深度学习课程中的目标检测。</p><a id="more"></a><h2 id="概念">概念</h2><p>在学习目标检测之前首先来了解一下计算机视觉领域中的一些方向和概念，分别是图像分类、定位、语义分割、目标检测和实例分割。</p><ul><li><p>图像分类</p><p>图像分类指用事先确定好的类别来描述图片，例如二分类判断一张图片中是否有猫或者多分类判断图片中手势表示的数字，前面实验中的任务就是图像分类。经典的网络模型就是 LeNet、AlexNet 和 VGG 等等。</p></li><li><p>分类 + 定位</p><p>定位任务不仅要识别出图像中的目标是什么，还要给出其在图像中的位置信息。通常用一个矩形框把识别的目标框出来（有时候也有多个<strong>固定数量</strong>的目标），而我们通常采用两种方式在图像中表示一个矩形框：</p><ol type="1"><li>(x1, y1, x2, y2)： 即给出矩形框左上角和右下角的坐标；</li><li>(x, y, w, h)：即给出矩形框的中心坐标和矩形框的长宽。</li></ol></li><li><p>目标检测</p><p>一幅图像中有多个目标而且目标的<strong>数量不固定</strong>，检测任务要尽可能多的将图像中的目标用矩形框定位出来，相当于对多个目标的定位。目标检测在计算机视觉领域中占据了核心地位，后面的实验也是围绕着目标检测展开。</p></li><li><p>语义分割</p><p>语义分割也叫语义场景标注，是对图像中所有像素进行分类，和目标检测任务不同的是同一个类别的不同实例不需要分割出来。例如图像中有多只猫，那么这些组成猫的像素就都分为同一类。</p></li><li><p>实例分割</p><p>实例分割要求更严格，相对于目标检测来说不再是用矩形框框出目标，相对于语义分割来说不再是对像素进行简单分类。而是要从像素层面上将目标和背景完全分离出来，分割的结果往往是找出目标的轮廓线。</p></li></ul><h2 id="目标定位">目标定位</h2><p>目标定位不仅关注特定目标的类别信息，还要求获得这一目标的位置信息。假设需要定位三类物体，网络最后则输出一个 8 维的向量，第一维表示图像中存在需要定位的目标的概率；第二到第五维表示目标的位置（中心和长宽）；最后三维则表示目标的类别。在训练的过程中，如果第一维为 0 则可以忽略其他维度，即损失函数与其他维度无关。可以对不同的维度使用不同的损失函数，例如对离散的分类结果使用交叉熵损失，对位置信息使用回归损失。</p><h3 id="landmark-定位">Landmark 定位</h3><p>除了对目标进行分类和定位之外，我们还可以对目标的关键特征点（Landmark）进行定位，即已知固定数量的目标，给出每个目标的位置。例如人脸识别，可以对人脸的一部分特征点的坐标进行定位检测，并且标记出来，如下图所示：</p><p><img src="/2018/12/19/object-detection/face.png"></p><p>该模型一共检测人脸 64 处特征点，加上是否是人脸的标志位，输出标签一共有 128+1 个值，通过检测人脸特征点可以进行情绪分类或者对脸部进行瘦脸美颜。除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示：</p><p><img src="/2018/12/19/object-detection/gesture.png"></p><h2 id="目标检测">目标检测</h2><p>目标检测的一种简单方法是滑动窗口算法，这种算法训练了一个 CNN 分类模型，只不过训练集的图像尺寸较小，尽量仅包含相应目标。模型训练完成后，在测试图片上选择大小适宜的窗口、合适的步长，进行从左到右、从上到下的滑动。每个窗口区域都输入之前训练好的模型进行识别判断。若判断有目标，则此窗口即为目标区域；若判断没有目标，则此窗口为非目标区域。不同大小的窗口如下图所示：</p><p><img src="/2018/12/19/object-detection/windows.png"></p><p>滑动窗口算法原理简单，但是滑动窗口的大小和步长都需要人为直观设定。滑动窗口过小或过大，步长过大均会降低目标检测正确率。而且每次滑动窗区域都要进行一次 CNN 网络计算，如果滑动窗口和步长较小，整个目标检测算法运行时间会很长。</p><h3 id="滑动窗口的卷积实现">滑动窗口的卷积实现</h3><p>窗口在滑动动过程中，其框中的像素会输入到模型中进行卷积运算。由于窗口之间重复的内容比较多，因此会有大量的重复运算。而使用卷积的方式实现滑动窗口算法则可以提高网络的运行速度，节约重复运算成本。</p><p>单个滑动窗口区域进入 CNN 网络模型进行识别判断时，模型包含全连接层。如果滤波器的大小和输入的图像一致，那么卷积层的操作过程就相当于全连接层，因此我们可以将全连接层转变成为卷积层，如下图所示：</p><p><img src="/2018/12/19/object-detection/1.png"></p><p>全连接层参数个数为 <span class="math inline">\((5\times 5\times 16)\times 400\)</span>，使用卷积层替换后一共需要 400 个 <span class="math inline">\(5\times 5\times 16\)</span> 的滤波器。参数个数与全连接层一样，输出也一样。那么卷积实现如何能够节约重复运算成本呢？我们逆向地去思考一下，一个窗口区域图像的目标检测如上图所示，那么一张完整的图像的目标检测呢？假设一张图像在滑动窗口的过程中一共产生 4 个区域，全连接层的形式就只能判断 4 次；而使用卷积实现的方式我们就可以输入整张图像，然后输出 <span class="math inline">\(2\times 2\)</span> 个 4 维向量，即只需要运行模型一次。如下图所示：</p><p><img src="/2018/12/19/object-detection/2.png"></p><p>窗口的大小为 <span class="math inline">\(14\times 14\)</span>，最后输出一个 4 维的向量。一张大一点的图像 <span class="math inline">\(16\times 16\)</span>，步长为 2，滑动窗口可以产生 4 个区域，因此通过模型可以输出一个 <span class="math inline">\(2\times 2\)</span> 的 4 维向量；一张更大的图像 <span class="math inline">\(28\times 28\)</span>，步长为 2，滑动窗口可以产生 64 个区域，模型输出一个 <span class="math inline">\(8\times 8\)</span> 的 4 维向量。因此通过卷积的形式实现滑动窗口算法，可以有效利用卷积的特点减少区域内容的重复计算，提高网络的运行速度，节约重复运算成本。</p><h3 id="边界框预测">边界框预测</h3><p>卷积方式实现的滑动窗口算法，使得在预测时计算的效率大大提高。但是其存在的问题是：不能输出最精准的边界框（Bounding Box）。如图所示，滑动窗口算法产生的滑窗（蓝色）不能完全涵盖目标，即不能输出精确的边界框。</p><p><img src="/2018/12/19/object-detection/bounding.png"></p><h4 id="交并比">交并比</h4><p>交并比（Intersection over Union，简称 IoU）通过计算两个边界框的交集和并集的比来评价对象检测算法，也就是上图中红框和蓝框的交集和并集之比。在目标检测任务中，通常约定交并比大于等于 0.5 就说检测正确。如果两个框完全重合，那么交并比就为 1。</p><h4 id="选择性搜索算法">选择性搜索算法</h4><p>如果暴力枚举各种各样的滑窗参数（大小和步长），那么也可以找到精确的边界框，但是这样时间开销比较大。那么应该如何优化呢？有人提出使用<strong>提议区域的方法</strong>（Region proposal method）创建目标检测的兴趣区域（Regions of Interest，简称 RoI），例如一张图像选 2000 个 RoI，这些区域之间可以互相重叠或者包含，然后再直接对这些区域进行识别判断。</p><p><strong>选择性搜索</strong>（Selective Search，简称 SS）[2] 算法就是一种提议区域的方法，它的主要观点是图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。首先，对输入图像进行分割算法产生许多小的子区域。其次，根据这些子区域之间相似性（相似性标准主要有颜色、纹理、大小等等）进行区域合并，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做外切矩形，生成 RoI。</p><p>基于以上思路，人们提出了区域卷积神经网络（Region-based CNN 或 Regions with CNN features，简称 R-CNN）[3]。下面将简单介绍 R-CNN 和它的一系列改进方法：Fast R-CNN [4]、Faster R-CNN [5] 以及掩码 R-CNN（Mask R-CNN）[6]，效果更好的 YOLO(You Only Look Once) [7] 算法将结合着课程实验介绍和实现。</p><h3 id="r-cnn">R-CNN</h3><p>目标检测 <span class="math inline">\(k\)</span> 种类别的 R-CNN 主要分为以下四个步骤：</p><ol type="1"><li>对输入图像使用 SS 来选取大约 2000 个高质量的 RoI 。这些区域通常是在多个尺度下选取的，并具有不同的形状和大小，每个区域将被标注类别和真实边界框；</li><li>选取一个预训练的卷积神经网络，对模型进行微调使其分类数为 <span class="math inline">\(k+1\)</span>。将每个 RoI 裁剪缩放为网络需要的输入尺寸，并通过 CNN 前向传播计算和保存 RoI 的特征；</li><li>将每个 RoI 的特征连同其标注的类别作为一个样本，训练 <span class="math inline">\(k\)</span> 个 SVM 对目标分类。其中每个 SVM 用来判断样本是否属于某一个类别；</li><li>将每个 RoI 的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框。</li></ol><p>这个模型和我在自己论文中的思想有一定的相似性，都是单独训练几个模型：用于特征提取的模型和用于分类的模型。模型思路比较简单但是实现比较麻烦，这里值得注意的就是回归模型预测真实边界框，通过 SS 算法得到的边界框可能还不够精确。R-CNN 的主要性能瓶颈在于需要对每个 RoI 独立提取特征。由于这些区域通常有大量重叠，独立的特征提取会导致大量的重复计算。</p><h3 id="fast-r-cnn">Fast R-CNN</h3><p>为了使 R-CNN 更快，Girshick 提出了 Fast R-CNN。一个主要改进在于只对整个图像做卷积神经网络的前向计算；其次三个独立模型合并为了一个联合训练框架并共享计算结果（end-to-end 的形式）。它的主要计算步骤如下：</p><ol type="1"><li>与 R-CNN 相比，Fast R-CNN 用来提取特征的 CNN 的输入是整个图像，而且这个网络通常会参与训练，即更新模型参数；</li><li>SS 在原图像上生成 <span class="math inline">\(n\)</span> 个 RoI，这些形状各异的区域需要映射到 CNN 的输出上；</li><li>将映射后的区域输入全连接层的时候需要固定的形状，与 R-CNN 裁剪缩放操作不同的是，Fast R-CNN 引入 RoI 池化层，将 CNN 输出的特征图和 SS 输出的 RoI 作为输入，提取 RoI 固定形状的特征；</li><li>通过全连接层将输出形状变换为 <span class="math inline">\(n×d\)</span>，其中 <span class="math inline">\(d\)</span> 为隐藏层节点个数；</li><li>类别预测时，将全连接层的输出的形状再变换为 <span class="math inline">\(n×q\)</span> 并使用 softmax 回归（q 为类别个数）。边界框预测时，将全连接层的输出的形状再变换为 <span class="math inline">\(n×4\)</span> 。也就是说，我们为每个 RoI 预测类别和边界框。</li></ol><p>Fast R-CNN 中提出的 RoI 池化层对每个区域的输出形状是可以直接指定的，例如指定每个区域输出的高和宽为 <span class="math inline">\((2, 2)\)</span>。假设某一 RoI 的高和宽为 <span class="math inline">\((5, 7)\)</span>，该窗口将被划分为形状为 <span class="math inline">\((2, 2)\)</span> 的子窗口网格，且每个子窗口的大小大约为 <span class="math inline">\((5/2)×(7/2)\)</span>。任一子窗口的高和宽要取整，其中的最大元素作为该子窗口的输出。因此，RoI 池化层可从形状各异的 RoI 中提取出形状相同的特征。</p><h3 id="faster-r-cnn">Faster R-CNN</h3><p>Fast R-CNN 存在的瓶颈是 SS，通常需要生成很多 RoI。Faster R-CNN 提出将 SS 替换成区域提议网络（Region Proposal Network，简称 RPN），通过训练的方式来获得只与检测目标类别有关的高质量区域，从而减少提议区域的生成数量，并保证目标检测的精度。</p><p>与 Fast R-CNN 相比，只有生成 RoI 的方法从 SS 变成了 RPN 而其他部分均保持不变。RPN 和最后的分类器的损失函数都是由两部分组成：分类的损失和边界框的回归损失。只不过 RPN 只需要进行二分类，即分析窗口中内容为目标还是背景，而不需要判断目标的类别。</p><p>文章使用了两种 CNN 来提取特征：Zeiler and Fergus（简称 ZF）网络和 Simonyan and Zisserman 网络（即 VGG-16）。前者输出的特征图为 256 通道，后者输出的特征图为 512 通道，以下内容均基于 VGG-16 网络作为卷积层。首先将输入 VGG-16 网络的图像缩放成 <span class="math inline">\(800\times 600\)</span>，网络下采样后 16 倍后输出的特征图大小为 <span class="math inline">\(50\times 37\times 512\)</span>，然后将其输入 RPN 网络提取感兴趣区域。</p><h4 id="rpn">RPN</h4><p>特征图中一共有 <span class="math inline">\(50\times 37\)</span> 个 512 维的向量，每一个 512 维特征向量都对应原图在卷积过程中滑窗产生的区域，如<a href="#滑动窗口的卷积实现">滑动窗口的卷积实现</a>所示。 相当于是将大小为 <span class="math inline">\(800\times 600\)</span> 的图像分割成 <span class="math inline">\(50\times 37\)</span> 个大小一样的区域，由于 VGG-16 卷积层的步长不等于滤波器的大小，因此这些区域之间有重叠但是覆盖了整张图像，最后 VGG-16 为每个区域提取了一个 512 维的特征向量，RPN 网络就是要找到每个区域中目标的边界框。</p><h5 id="锚框">锚框</h5><blockquote><p>以每个像素为中心生成多个大小和宽高比（aspect ratio）不同的边界框，这些边界框被称为锚框（anchor box）。</p></blockquote><p>如果多个待检测目标的中心在同一个区域内，我们首先根据数据集手工对原图上每一个区域生成各种各样形状和大小的锚框，保证锚框可以框住所有种类的目标。作者为每个区域手动指定了 <span class="math inline">\(k=9\)</span> 种不同大小和比例的锚框。</p><p>一共有 <span class="math inline">\(50\times 37\times 9=16650\)</span> 个锚框，基本上覆盖了所有可能出现的目标。这些人工指定锚框的内容大部分只有背景而且也很难精确地框中目标，给定一张人工标注好的图像，任何一个生成的锚框如果和人工标注的目标的边界框之间的 IoU &gt; 0.7，就可以认为该锚框的真实标签为前景并且得到其真实的边界框；IoU &lt; 0.3 则认为该锚框的真实标签为背景；其余的不参与训练。得到了锚框的真实标签，我们就可以对其进行训练，因此一个区域需要输出 <span class="math inline">\(2k\)</span> 个分数来进行二分类和 <span class="math inline">\(4k\)</span> 个值来进行边界框回归。</p><h5 id="提议区域">提议区域</h5><p>模型训练完毕后，我们就可以使用模型的前向传播部分对新的数据进行处理，步骤如下所示：</p><ol type="1"><li>输入新的特征图，生成锚框，对所有的锚框进行边界框回归和分类；</li><li>对所有的锚框按照其为前景的分数进行排序，取前 6000 个；</li><li>对回归后的锚框进行处理，例如去除过长度或者宽度过小的锚框；</li><li>进行非极大值抑制，然后再次对所有的锚框按照其为前景的分数进行排序，取前 300 个作为提议区域输出。</li></ol><h5 id="非极大值抑制">非极大值抑制</h5><p>在对锚框进行边界框回归后，对于同一个目标，可能有多个边界框与其对应，于是我们就要用到非极大值抑制，来抑制那些冗余的框，其过程如下所示：</p><ol type="1"><li>将所有框的得分排序，选中最高分及其对应的框，例如上图中 0.9；</li><li>遍历其余的框，如果和当前最高分框的 IoU 大于一定阈值（通常取 0.5），我们就将框删除，例如上图中 0.6;</li><li>从未处理的框中继续选一个得分最高的，例如上图中 0.8，重复上述过程。</li></ol><p>RPN 作为 Faster R-CNN 的一部分，是和整个模型一起训练得到的。即 Faster R-CNN 的目标函数既包括目标检测中的类别和边界框预测，也包括 RPN 中锚框的二元类别和边界框预测。最终 RPN 能够学习到如何生成高质量的RoI，从而在减少 RoI 数量的情况下也能保证目标检测的精度。</p><h3 id="mask-r-cnn">Mask R-CNN</h3><p>如果训练数据还标注了每个目标在图像上的像素级位置，那么 Mask R-CNN 能有效利用这些详尽的标注信息进一步提升目标检测的精度，例如进行实例分割，在每一个像素上都表示出来目标所属的具体类别。</p><p>Mask R-CNN 在 Faster R-CNN 的基础上做了修改，引入一个全卷积网络。即增加了一个分支，用于输出一个二值掩膜，如下图所示，最后输出一个 80 通道的 <span class="math inline">\(14\times 14\)</span> 的二值矩阵，分别表示是否 80 个分类中的某一类。</p><h4 id="roialign">RoIAlign</h4><p>RoI 池化层有两个步骤会产生区域不匹配的问题，假设 CNN 下采样倍数为 32，原图中 RoI 的大小为 <span class="math inline">\(665\times 665\)</span>，经过网络后对应的区域大小为 <span class="math inline">\(\frac{665}{32}\times \frac{665}{32}\)</span>，向下取整会产生区域不匹配问题，即映射回原图大小不一致；将 RoI 的特征图输入全连接网络之前需要固定形状，在划分 bins （对应图中的 sections）的时候如果无法整除也需要向下取整，再次产生区域不匹配的问题，对于目标检测比较小的目标、语义分割和实例分割任务影响就会比较大。因此作者提出了 RoIAlign，全程可以使用浮点数操作，不存在取整过程。假设原图大小为 <span class="math inline">\(800\times 800\)</span>，RoIAlign 的步骤如下所示：</p><p><img src="/2018/12/19/object-detection/5WG68S.jpg"></p><ol type="1"><li>计算 RoI 在特征图中的边长，不取整，即边长为 <span class="math inline">\(\frac{665}{32}=20.78\)</span>；</li><li>假设输入全连接网络的特征为 <span class="math inline">\(7\times 7\)</span>，每个 bin 的大小不取整，即边长为 <span class="math inline">\(\frac{20.78}{7}=2.97\)</span>；</li><li>RoI 池化层得到的 bin 的边长是整数，然后输出整数。而 RoIAlign 需要对区域采样，例如采样点数为 4，用须线把 bin 平均分成 4 份，每一份取中心点位置的像素，即 <font color="red">x</font> 处的像素值；</li><li>每个 <font color="red">x</font> 处的像素值为其最邻近的四个值通过双线性插值得到。</li></ol><h5 id="双线性差值">双线性差值</h5><p>数值分析这门课学得最熟的也就是插值法了，首先是线性插值，给定 <span class="math inline">\((x_0, y_0)\)</span> 和 <span class="math inline">\((x_1, y_1)\)</span>，估计 <span class="math inline">\([x_0, x_1]\)</span> 区间内某一位置 <span class="math inline">\(x\)</span> 在直线上的 <span class="math inline">\(y\)</span> 值： <span class="math display">\[y = \frac{x_1 - x}{x_1 - x_0}y_0 +\frac{x - x_0}{x_1 - x_0}y_1\]</span> 双线性插值就是相继在两个坐标轴上做线性差值，先分别对 <font color="red">x</font> 上方两个像素值和下方的两个像素值在 <span class="math inline">\(x\)</span> 轴上进行线性插值得到 <span class="math inline">\(R_1\)</span> 和 <span class="math inline">\(R_2\)</span>，再由 <span class="math inline">\(R_1\)</span> 和 <span class="math inline">\(R_2\)</span> 在 $y $ 轴上进行线性插值得到最终结果。</p><h2 id="总结">总结</h2><p>粗略学习了以下 R-CNN 以及一些列的改进，首先是 R-CNN 使用选择性搜索算法，先找出一些边界框再分别输入 CNN，避免了滑动窗口算法边界框不准确的问题；其次是 Fast R-CNN 将整张图片输入 CNN 提取特征后再把边界框映射过去，避免了 R-CNN 再分析边界框的过程中重复运算的问题；然后是 Faster R-CNN 直接在网络里面学习找出高质量的边界框，避免了 Fast R-CNN 中选择性搜索算法盲目找边界框；最后是 Mask R-CNN 改进了 RoI 池化层，避免了 Faster R-CNN 中区域不匹配的问题，同时添加了一个分支用于掩码预测每一个像素的分类，最后可以做到语义分割和实例分割。</p><p>以上图片来自于《动手学深度学习》，发现这是大神李沐写的，该花点时间好好提升一下自己的代码水平了。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Van de Sande K E A, Uijlings J R R, Gevers T, et al. Segmentation as selective search for object recognition[C]//Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 2011: 1879-1886.</li><li>R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR, 2014.</li><li>Girshick, R. (2015). Fast r-cnn. arXiv preprint arXiv:1504.08083.</li><li>Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).</li><li>He, K., Gkioxari, G., Doll á r, P., &amp; Girshick, R. (2017, October). Mask R-CNN. In Computer Vision (ICCV), 2017 IEEE International Conference on (pp. 2980-2988). IEEE.</li><li>Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 779-788.</li><li>J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015. 1, 3, 6</li><li>《动手学深度学习》. http://zh.diveintodeeplearning.org/index.html</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;最近看了几篇关于漏洞检测的文章，将图像处理领域中的目标检测的思想运用到软件的漏洞检测中。话是这么说，但是通篇看下来，其实和目标检测关系并不大，说到底还是对代码行进行分类，判断是否有漏洞。借着这个机会，正好总结一些深度学习课程中的目标检测。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>残差网络 ResNet</title>
    <link href="https://pengzhendong.cn/2018/12/12/resnet/"/>
    <id>https://pengzhendong.cn/2018/12/12/resnet/</id>
    <published>2018-12-12T08:55:03.000Z</published>
    <updated>2018-12-12T09:42:48.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>稳稳地被拒了，现在再回顾自己写的内容，发现确实有不少地方似懂非懂的，特别是调用了别人代码的地方。继续我的 deeplearning 总结吧！由于实验中有 ResNet 的实现，所以将它单独作为一篇总结。</p><a id="more"></a><h2 id="深度神经网络的问题">深度神经网络的问题</h2><p>神经网络越深拟合能力就越强，也可以学到不同级别抽象的特征，但是太深就会导致梯度消失等问题，阻碍了网络的收敛。这个问题前面也介绍过，通常是通过标准初始化层和中间的标准化层来解决。这样虽然可以让网络收敛，但是准确度会随着网络的加深而变得饱和，然后退化，一个 20 层和一个 56 层的网络的训练误差和测试误差如下图所示：</p><p><img src="/2018/12/12/resnet/vanishing_grad_kiank.png"></p><h2 id="残差网络-resnet">残差网络 ResNet</h2><p>ResNet[2] 的主要思想就是通过远跳连接（也叫捷径连接）来解决网络过深的问题，远跳连接允许在反向传播的时候，梯度直接传播给更前面的层，结构如下图所示：</p><p><img src="/2018/12/12/resnet/skip_connection_kiank.png"></p><p>左图为普通的神经网络块的传输，其前向传播的计算步骤为： <span class="math display">\[z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}\]</span></p><p><span class="math display">\[a^{[l+1]}=g(z^{[l+1]})\]</span></p><p><span class="math display">\[z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}\]</span></p><p><span class="math display">\[a^{[l+2]}=g(z^{[l+2]})\]</span></p><p>右图为一个残差块，通过增加了一个恒等映射，把当前输出不添加任何参数直接传给下一层网络。残差块的堆叠可以构建非常深的网络，其前向传播的计算步骤只有最后一步与上述步骤不同： <span class="math display">\[a^{[l+2]}=g(z^{[l+2]}+a^{[l]})\]</span></p><h3 id="resnet-原理">ResNet 原理</h3><p>残差网络看起来似乎同容易理解，但是还要理解为什么有了它就不怕增加网络的深度了。假设网络中均使用 ReLU 激活函数且最后的输出 <span class="math inline">\(a\geq 0\)</span>，则： <span class="math display">\[a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})\]</span> 如果我们使用 L2 正则化项或者权重衰减，那么就可以压缩 <span class="math inline">\(W\)</span> 和 <span class="math inline">\(b\)</span> 的值，进而使网络的拟合能力逼近于更浅的网络。例如当 <span class="math inline">\(W^{[l+2]}=0\)</span> 和 <span class="math inline">\(b^{[l+2]}=0\)</span> 时，有： <span class="math display">\[a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}\]</span> 所以在增加了残差块后更深的网络的性能也并不逊色于没有增加残差块简单的网络，尽管增加了网络的深度，但是并不会影响网络的性能。同时如果增加的网络结构能够学习到一些有用的信息，那么就会提升网络的性能。</p><h2 id="代码实现">代码实现</h2><p>实验同样是用 Keras 来实现，首先需要载入需要用到的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> layer_utils</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> resnets_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> imshow</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line">K.set_image_data_format(<span class="string">'channels_last'</span>)</span><br><span class="line">K.set_learning_phase(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="残差块">残差块</h3><p>同时由于结构 <span class="math inline">\(a^{[l+2]}=g(z^{[l+2]}+a^{[l]})\)</span>，ResNet 在设计中使用了很多 Same 卷积来保持图像大小相同。在通道不一致的时候，对增加的通道可以用 0 填充或者使用线性投影来保证维度一致（<span class="math inline">\(1\times 1\)</span> 滤波器）。因此残差块分为两种 Identity block 和 Convolutional block，前者维度一致，后者在捷径上添加了一个卷积层用来调节输出的维度。</p><h4 id="identity-block">Identity Block</h4><p>实验实现的 Identity block 远跳了两层，同时使用了批标准化来加速网络的训练过程，结构如下图所示：</p><p><img src="/2018/12/12/resnet/idblock3_kiank.png"></p><p>实现以上残差块的步骤如下所示：</p><ol type="1"><li>主路径的第一部分<ul><li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_1\)</span> 大小为 (1, 1) 和步长为 (1, 1)，valid 卷积并且命名为 <code>conv_name_base + '2a'</code>；</li><li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '2a'</code>；</li><li>使用 ReLU 激活函数，不需要命名并且没有超参数。</li></ul></li><li>主路径的第二部分<ul><li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_2\)</span> 大小为 <span class="math inline">\((f, f)\)</span> 和步长为 (1, 1)，same 卷积并且命名为 <code>conv_name_base + '2b'</code>；</li><li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '2b'</code>；</li><li>使用 ReLU 激活函数。</li></ul></li><li>主路径的第三部分<ul><li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_3\)</span> 大小为 (1, 1)​ 和步长为 (1, 1)，same 卷积并且命名为 <code>conv_name_base + '2c'</code>；</li><li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '2c'</code>；</li></ul></li><li>最后一步<ul><li>输入需要加上远跳连接；</li><li>使用 ReLU 激活函数。</li></ul></li></ol><p>因此一共有三个卷积层，对应三组滤波器，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_block</span><span class="params">(X, f, filters, stage, block)</span>:</span></span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the input value. You'll need this later to add back to the main path. </span></span><br><span class="line">    X_shortcut = X</span><br><span class="line"></span><br><span class="line">    <span class="comment"># First component of main path</span></span><br><span class="line">    X = Conv2D(filters=F1, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2a'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2a'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, name=conv_name_base + <span class="string">'2b'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2b'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(filters=F3, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2c'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2c'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><h4 id="convolutional-block">Convolutional Block</h4><p>在输入和输出维度不匹配的时候可以 Convolutional block，与 Identity block 的不同之处就在于在捷径上也有一个卷积层，其结构如下图所示：</p><p><img src="/2018/12/12/resnet/convblock_kiank.png"></p><p>捷径上的卷积层可以用来调节 <span class="math inline">\(x\)</span> 的大小和通道数，调节通道数即上面提到的线性映射。实现步骤如下所示：</p><ol type="1"><li>主路径的第一、二和三部分和 Identity block 一致</li><li>捷径<ul><li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_3\)</span> 大小为 (1, 1)​ 和步长为 <span class="math inline">\((s, s)\)</span>，same 卷积并且命名为 <code>conv_name_base + '1'</code>。需要注意的是用的滤波器和主路径第三部分的滤波器一样，只是步长不一样，此处只是为了调节 <span class="math inline">\(x\)</span> 的形状；</li><li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '1'</code>；</li></ul></li><li>最后一步<ul><li>将捷径的输出添加到主路径上；</li><li>使用 ReLU 激活函数。</li></ul></li></ol><p>因此一共有四个卷积层，对应三组滤波器，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolutional_block</span><span class="params">(X, f, filters, stage, block, s=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the input value</span></span><br><span class="line">    X_shortcut = X</span><br><span class="line"></span><br><span class="line">    <span class="comment">##### MAIN PATH #####</span></span><br><span class="line">    <span class="comment"># First component of main path </span></span><br><span class="line">    X = Conv2D(filters=F1, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(s, s), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2a'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2a'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, name=conv_name_base + <span class="string">'2b'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2b'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(filters=F3, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2c'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2c'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">##### SHORTCUT PATH #### (≈2 lines)</span></span><br><span class="line">    X_shortcut = Conv2D(filters=F3, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(s, s), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'1'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X_shortcut)</span><br><span class="line">    X_shortcut = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'1'</span>)(X_shortcut)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><h3 id="构建-resnet-模型">构建 ResNet 模型</h3><p>50 层的 ResNet-50 网络结构一共分为 5 个阶段（stage），如下图所示：</p><p><img src="/2018/12/12/resnet/resnet_kiank.png"></p><p>ResNet-50 模型的细节为：</p><ul><li>零填充的大小为 (3, 3)</li><li>阶段一：<ul><li>二维卷积使用 64 个大小为 (7, 7) 步长为 (2, 2) 的滤波器，命名为 <code>conv1</code>；</li><li>批标准化应用于通道的维度；</li><li>最大池化窗口大小为 (3, 3)，步长为 (2, 2)。</li></ul></li><li>阶段二：<ul><li>Convolutional block 使用的三组滤波器的数量分别为 [64, 64, 256]，f=3，s=1，块被命名为 <code>a</code>；</li><li>两个 Identity block 使用的三组滤波器的数量分别为 [64, 64, 256]，f=3，块被命名为 <code>b</code> 和 <code>c</code>。</li></ul></li><li>阶段三：<ul><li>Convolutional block 使用的三组滤波器的数量分别为 [128, 128, 512]，f=3，s=2，块被命名为 <code>a</code>；</li><li>三个 Identity block 使用的三组滤波器的数量分别为 [128, 128, 512]，f=3，块被命名为 <code>b</code>、<code>c</code> 和 <code>d</code>。</li></ul></li><li>阶段四：<ul><li>Convolutional block 使用的三组滤波器的数量分别为 [256, 256, 1024]，f=3，s=2，块被命名为 <code>a</code>；</li><li>五个 Identity block 使用的三组滤波器的数量分别为 [256, 256, 1024]，f=3，块被命名为 <code>b</code>、<code>c</code>、<code>d</code>、<code>e</code> 和 <code>f</code>。</li></ul></li><li>阶段五：<ul><li>Convolutional block 使用的三组滤波器的数量分别为 [512, 512, 2048]，f=3，s=2，块被命名为 <code>a</code>；</li><li>两个 Identity block 使用的三组滤波器的数量分别为 [512, 512, 2048]，f=3，块被命名为 <code>b</code> 和 <code>c</code>。</li></ul></li><li>二维平均池化层使用的窗口大小为 (2, 2)，命名为 <code>avg_pool</code></li><li>变平</li><li>全连接（Dense）层将 input 的神经元节点数降为类别数，用于 Softmax 分类，命名为 <code>'fc' + str(classes)</code></li></ul><p>代码实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ResNet50</span><span class="params">(input_shape=<span class="params">(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span>, classes=<span class="number">6</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Define the input as a tensor with shape input_shape</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero-Padding</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 1</span></span><br><span class="line">    X = Conv2D(<span class="number">64</span>, (<span class="number">7</span>, <span class="number">7</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'conv1'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=<span class="string">'bn_conv1'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    X = MaxPooling2D((<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 2</span></span><br><span class="line">    X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'a'</span>, s=<span class="number">1</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'c'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 3 (≈4 lines)</span></span><br><span class="line">    X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'a'</span>, s=<span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'c'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'d'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 4 (≈6 lines)</span></span><br><span class="line">    X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'a'</span>, s=<span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'c'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'d'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'e'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'f'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 5 (≈3 lines)</span></span><br><span class="line">    X = X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'a'</span>, s=<span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'c'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AVGPOOL (≈1 line). Use "X = AveragePooling2D(...)(X)"</span></span><br><span class="line">    X = AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># output layer</span></span><br><span class="line">    X = Flatten()(X)</span><br><span class="line">    X = Dense(classes, activation=<span class="string">'softmax'</span>, name=<span class="string">'fc'</span> + str(classes), kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create model</span></span><br><span class="line">    model = Model(inputs=X_input, outputs=X, name=<span class="string">'ResNet50'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>编译训练模型，用于前面实验的手势分类，这是一个六分类的问题，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model = ResNet50(input_shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>), classes=<span class="number">6</span>)</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize image vectors</span></span><br><span class="line">X_train = X_train_orig / <span class="number">255.</span></span><br><span class="line">X_test = X_test_orig / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert training and test labels to one hot matrices</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line">model.fit(X_train, Y_train, epochs = <span class="number">2</span>, batch_size = <span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">preds = model.evaluate(X_test, Y_test)</span><br><span class="line">print(<span class="string">"Loss = "</span> + str(preds[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"Test Accuracy = "</span> + str(preds[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>运行两个 epoch 就到使测试的准确率达到 87%，最后可以使用 <code>model.summary()</code> 查看模型概况和使用以下代码绘制模型图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_model(model, to_file=<span class="string">'model.png'</span>)</span><br><span class="line">SVG(model_to_dot(model).create(prog=<span class="string">'dot'</span>, format=<span class="string">'svg'</span>))</span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>残差网络中的远跳连接解决了深度网络存在梯度消失等问题。为了解决输入和输出维度不匹配，作者提出了两种残差块，一种通过在捷径上使用卷积层调节输出的维度。最后就是将这些块堆叠起来形成深度残差网络。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;稳稳地被拒了，现在再回顾自己写的内容，发现确实有不少地方似懂非懂的，特别是调用了别人代码的地方。继续我的 deeplearning 总结吧！由于实验中有 ResNet 的实现，所以将它单独作为一篇总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>深度卷积网络探究</title>
    <link href="https://pengzhendong.cn/2018/12/10/deep-convnet-probe/"/>
    <id>https://pengzhendong.cn/2018/12/10/deep-convnet-probe/</id>
    <published>2018-12-10T07:30:00.000Z</published>
    <updated>2018-12-10T10:46:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>自己给自己加个油！还有两周多的内容就结束了，慢慢学了快一年了，博客写写停停，也算是坚持下来了。这一周的内容是深度卷积网络的实例探究，介绍了好些个经典的模型，慢慢扩展吧！</p><a id="more"></a><h2 id="卷积神经网络">卷积神经网络</h2><p>比较经典的卷积神经网络有：LeNet-5、AlexNet 和 VGGNet，下面将简单介绍这三种网络。随着网络的加深则带来梯度消失、梯度爆炸和参数过多等问题，最后介绍 <span class="math inline">\(1\times 1\)</span> 滤波器和谷歌的 Inception 网络，下一篇博客再结合着实验介绍残差网络 ResNet。</p><h3 id="lenet-5">LeNet-5</h3><p>LeNet-5 是卷积神经网络中比较适合入门的网络结构，也是年代比较久远的网络，由于采用的滤波器都是 <span class="math inline">\(5\times 5\)</span> 的，因此叫 LeNet-5。它在 1998年 由 Yann LeCuu 等人在论文 "Gradient-Based Learning Applied to Document Recognition"[2] 中提出，用于解决 mnist 数据集的字符识别问题，网络结构比较简单，如下图所示：</p><p><img src="/2018/12/10/deep-convnet-probe/LeNet-5.png"></p><p>LeNet-5 除了输入层以外由 7 层网络构成：</p><ol type="1"><li><p>卷积层 Conv1：</p><p>输入为 <span class="math inline">\(32\times 32\)</span> 的灰度图，本层使用 6 个 <span class="math inline">\(5\times 5\)</span> 的滤波器，步长为 1，当时人们并不适用零填充，也就是使用 valid 卷积，因此输出结果为 <span class="math inline">\(28\times 28\times 6\)</span>；</p></li><li><p>池化层 Pool1：</p><p>虽然现在我们可能用最大池化更多一些，但是在这篇论文写成的那个年代，人们更喜欢使用平均池化。本层使用大小为 <span class="math inline">\(2\times 2\)</span> 的滤波器，步长为 2，因此图像的宽度和高度都会缩小一半，输出结果为 <span class="math inline">\(14\times 14\times 6\)</span>；</p></li><li><p>卷积层 Conv2：</p><p>输入为 <span class="math inline">\(14\times 14\times 6\)</span>，本层使用 16 个大小为 <span class="math inline">\(5\times 5\)</span> 的滤波器，步长为 1，输出结果为 <span class="math inline">\(10\times 10\times 16\)</span>；</p></li><li><p>池化层 Pool2：</p><p>同样是 <span class="math inline">\(2\times 2\)</span> 的滤波器做步长为 2 的平均池化，输出结果为 <span class="math inline">\(5\times 5\times 16\)</span>；</p></li><li><p>全连接层 FC1：</p><p>上一层变平后的 400 个神经元作为输入，本层包含 120 个神经元；</p></li><li><p>全连接层 FC2：</p><p>本层包含 84 个神经元。</p></li></ol><p>最后还可以加一个节点来预测输出，例如使用 softmax 来进行多分类，当时 LeNet-5 网络在输出层使用的是一种现在已经很少用到的分类器 Guassian Connection，LeNet-5 和上一个实验中的网络结构基本一致。只不过当时人们普遍使用的激活函数是 sigmod 函数和 tanh 函数，而不是 ReLU 函数。模型用的正是这两种激活函数，池化层后用的是 sigmoid 函数。</p><h3 id="alexnet">AlexNet</h3><p>AlexNet[3] 由 2012 年 ImageNet 竞赛冠军获得者 Alex Krizhevsky 设计，网络结构如下图所示：</p><p><img src="/2018/12/10/deep-convnet-probe/AlexNet.png"></p><p>AlexNet 中首次提出了局部响应归一化技术 LRN（Local Response Normalization，虽然被证明在 AlexNet 中作用不大，现在很少使用），在激活、池化后用来防止过拟合，其操作是对附近通道（附近取多少通道由参数 <code>local_size</code> 决定）上同一个位置的像素值进行归一化，因此不改变图像尺寸大小。虽然文章中的输入的图像是 <span class="math inline">\(224\times 224 \times 3\)</span>，但是根据公式可知 <span class="math inline">\(227\times 227\times 3\)</span> 的图像才能得到后面的结果。网络一共包含 5 个卷积层（5 个激活层、3 个池化层、2 个局部响应归一化层）和 3 个全连接层：</p><ol type="1"><li><p>卷积层 Conv1：</p><ul><li>输入：<span class="math inline">\(227\times 227\times 3\)</span>；</li><li>卷积层：96 个大小为 <span class="math inline">\(11\times 11\times 3\)</span> 的滤波器，步长为 4，valid卷积，输出结果为 <span class="math inline">\(55\times 55\times 96\)</span>；</li><li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(55\times 55\times 96\)</span>；</li><li>池化层：最大（重叠）池化，大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器，步长为 2，输出结果为 <span class="math inline">\(27\times 27\times 96\)</span>；</li><li>局部响应归一化层：local_size 为 5，输出结果为 <span class="math inline">\(27\times 27\times 96\)</span>。</li></ul></li><li><p>卷积层 Conv2：</p><ul><li>输入：<span class="math inline">\(27\times 27\times 96\)</span>；</li><li>卷积层：256 个大小为 <span class="math inline">\(5\times 5\times 96\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(27\times 27\times 256\)</span>；</li><li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(27\times 27\times 256\)</span>；</li><li>池化层：最大池化，大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器，步长为 2，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>；</li><li>局部响应归一化层：local_size 为 5，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>。</li></ul></li><li><p>卷积层 Conv3：</p><ul><li>输入：<span class="math inline">\(13\times 13\times 256\)</span>；</li><li>卷积层：384 个大小为 <span class="math inline">\(3\times 3\times 256\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>；</li><li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>。</li></ul></li><li><p>卷积层 Conv4：</p><ul><li>输入：<span class="math inline">\(13\times 13\times 384\)</span>；</li><li>卷积层：384 个大小为 <span class="math inline">\(3\times 3\times 384\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>；</li><li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>。</li></ul></li><li><p>卷积层 Conv5：</p><ul><li>输入：<span class="math inline">\(13\times 13\times384\)</span>；</li><li>卷积层：256 个大小为 <span class="math inline">\(3\times 3\times 384\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>；</li><li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>；</li><li>池化层：最大池化，大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器，步长为 2，输出结果为 <span class="math inline">\(6\times 6\times 256\)</span>。</li></ul></li><li><p>全连接层 FC6：</p><ul><li>输入：$6=9216 $;</li><li>神经元：4096 个神经元，输出为 <span class="math inline">\(4096\times 1\)</span>；</li><li>Dropout：概率为 50%，输出为 <span class="math inline">\(4096\times 1\)</span>。</li></ul></li><li><p>全连接层 FC7：</p><ul><li>输入：<span class="math inline">\(4096\times 1\)</span>;</li><li>神经元：4096 个神经元，输出为 <span class="math inline">\(4096\times 1\)</span>；</li><li>Dropout：概率为 50%，输出为 <span class="math inline">\(4096\times 1\)</span>。</li></ul></li><li><p>全连接层 FC8：</p><ul><li>输入：<span class="math inline">\(4096\times 1\)</span>;</li><li>神经元：1000 个神经元，输出为 <span class="math inline">\(1000\times 1\)</span>，即 1000 中分类的概率。</li></ul></li></ol><p>AlexNet 和之前的网络相比，它有以下几点特定：</p><ul><li>使用了数据增广的方法，即对数据集中的图像进行水平翻转、随机裁剪、平移变换、颜色、光照、对比度变换。或者按照 RGB 三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做 PCA Jittering（抖动）；</li><li>首次应用了 Dropout 有效防止过拟合；</li><li>使用 ReLU 代替传统的 sigmoid 和 tanh 函数；</li><li>使用了局部响应归一化，虽然这一作用有争议；</li><li>使用了重叠池化，减小过拟合；</li><li>多 GPU 并行训练，将网络分成两部分训练，提高了训练速度，整个网络大约有 6000 万个参数。</li></ul><h3 id="vgg">VGG</h3><p>VGG 网络出自 "Very Deep Convolutional Networks for Large-Scale Image Recognition"[4]，作者一共实验了 A、A-LRN、B、C、D 和 E 六种网络结构，根据网络的层数可以分类为 VGG-11、VGG-13、VGG-16 和 VGG-19。这六种网络结构的详情如下表所示，其中 conv3-512 表示该层使用 512 个大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器：</p><p><img src="/2018/12/10/deep-convnet-probe/VGG.png"></p><p>VGG 在 AlexNet 基础上对深度神经网络在深度和宽度上做了更多深入的研究，业界普遍认为更深的网络具有比浅网络更强的表达能力，更能刻画现实和完成更复杂的任务。通常 VGG 指的就是上表中网络结构 D。</p><p>VGG 与 AlexNet 相比，具有如下改进几点：</p><ul><li>作者实验发现深度网络中 LRN 的作用并不明显，于是去掉了 LRN 层；</li><li>VGG 用 <span class="math inline">\(3\times 3\)</span> 的滤波器，相比较于 AlexNet 中 <span class="math inline">\(11\times 11\)</span> 的滤波器，参数量更少；</li><li>池化层使用 <span class="math inline">\(2\times 2\)</span> 的滤波器也比 AlexNet 的 <span class="math inline">\(3\times 3\)</span> 滤波器小。</li></ul><p>VGG 主要采用增加卷积层的方法来加深网络，结果发现深度越深，网络学习能力越好，分类能力越强。为了更好的探究深度对网络的影响，必须要解决参数量的问题，作者分析认为 <span class="math inline">\(3\times 3\)</span> 的滤波器足以捕捉到横、竖以及斜对角像素的变化，使用大卷积核会带来参数量的爆炸不说，而且图像中会存在一些部分被多次卷积，可能会给特征提取带来困难。</p><h3 id="network-in-network">Network in Network</h3><p>传统的卷积层只是将前一层的特征进行了线性组合，然后经过一个非线性激活提取的特征就是低度非线性的。在<a href="2018/05/19/Neuron-network/#神经网络模型">单隐层神经网络</a>中我们知道，虽然单隐层神经网络几乎可以拟合任意函数，但是需要特别多神经元节点。类似的，传统的 CNN 就会使用大量的滤波器尽可能的提取更多的特征，这就会导致网络结构复杂和参数空间巨大。</p><h4 id="times-1-滤波器"><span class="math inline">\(1\times 1\)</span> 滤波器</h4><p>对于单通道的图像，<span class="math inline">\(1\times 1\)</span> 的滤波器可能没什么用，相当于让图像上的每一个像素值都乘以一个数。但是对于多通道的图像，这个操作实现的就是多个通道的线性组合，类似于全连接神经网络，可以起到降维或者升维（滤波器个数大于原图像通道数）的作用，从而减少运算量。举个比较形象的例子就是 RGB 图像转灰度图 <code>rgb2gray</code>，通过对三个通道的像素值的线性组合得到单通道的灰度图，只不过 <code>rgb2gray</code> 中使用的滤波器也是人工设置的，而且只有一个滤波器。</p><p>如下图所示，使用大小为 <span class="math inline">\(5\times 5\times 192\)</span> 的滤波器对 <span class="math inline">\(28\times 28\times 192\)</span> 的输入进行滤波，如果希望输出结果为 <span class="math inline">\(28\times 28\times 32\)</span>，那么就需要 32 个滤波器进行 Same 卷积。运算次数虽然和输入图像的大小无关，但是和输入图像的通道有关，通道越大和滤波器越大则运算次数越大，运算次数为 <span class="math inline">\((28\times 28\times 32)\times(5\times 5\times 192)\)</span>，大概需要 1.2 亿次。而先使用 <span class="math inline">\(1\times 1\)</span> 小滤波器压缩通道后再在小通道的图像使用大滤波器就可以解决这个问题，运算次数为： <span class="math display">\[(28\times 28\times 16)\times(1\times 1\times 192)+(28\times 28\times 32)\times(5\times 5\times 16)\]</span> 大概只需要 1204 万次运算，计算量是原来的十分之一左右。多个 <span class="math inline">\(1\times 1\)</span> 的滤波器配合激活函数还可以实现对原图像的多通道做非线性的组合，可以减少需要的滤波器的个数进而实现参数的减少化。这个思想来自于 Network in Network 中的多层感知卷积层 Mlpconv layer。</p><h4 id="多层感知卷积层">多层感知卷积层</h4><p>在 Network in Network[5] 中，作者在卷积后使用一个微小的神经网络（主要是多层感知器）对提取的特征进行进一步抽象。因为传统的卷积层只是一个线性的过程，即使层次比较深的网络层也只是对于浅层网络层学习到的特征进行整合。因此，在对特征进行高层次整合之前，进行进一步的抽象是必要的，即使用微网络进行进一步的抽象，这也是该文章名字的由来。网络的结构如下图所示：</p><p><img src="/2018/12/10/deep-convnet-probe/Network%20in%20Network.png"></p><p>假设这是一个 384 种类别的分类问题。在第一层网络中，输入为 <span class="math inline">\(224\times 224\times 3\)</span> 的图像，首先使用 96 个 <span class="math inline">\(11\times 11\times 3\)</span> 的滤波器进行卷积，每计算一个<strong>局部</strong>后可以得到一个 96 维的向量；然后将其输入一个多层感知机（图中第一列为输入层，第二列为隐藏层），本例子中隐藏层神经元节点数等于输入层的神经元节点数（一共有 <span class="math inline">\(96\times 96\)</span> 个参数），最后输出一张 <span class="math inline">\(55\times 55\times 96\)</span> 的图像。</p><p>这里的多层感知机就等同于 <span class="math inline">\(1\times 1\)</span> 滤波器，对特征进一步抽象，进而非线性激活函数不需要太多神经元节点就可以拟合处很复杂的函数，多添加几层隐藏层就相当于多进行几次 <span class="math inline">\(1\times 1\)</span> 卷积。感知机中隐藏层的神经元节点个数就相当于 <span class="math inline">\(1\times 1\)</span> 滤波器的个数，可以这个数来减少模型的参数。</p><h4 id="全局池化">全局池化</h4><p>作者还用全局平均池化取代网络的全连接层，避免全连接层参数过多而且容易过拟合。全局池化就是滤波器大小和原图像一致，因此每张大小为 <span class="math inline">\(W\times H\times C\)</span> 的图像，池化后的输出为 <span class="math inline">\(1\times 1\times C\)</span>。对大小为 <span class="math inline">\(13\times 13\times 384\)</span> 的图像进行全局平均池化就是每个通道的像素值求平均，最后得到一个 384 维的向量。</p><p>上图中最后一个多层感知机的隐藏层神经元节点数等于分类的类别数，主要是为了在全局平均池化的时候每一个通道（特征图）能够对应于一个输出类别，让模型的解释性更强，最后输入到 384 中分类的 Softmax 层中。</p><h3 id="googlenet">GoogLeNet</h3><p>GoogLeNet 是谷歌团队在 2014 年的 ILSVRC 比赛中使用的网络，这个名字也是为了向 LeNet 致敬。谷歌团队在 Going deeper with convolutions[6] 中提出 Inception 这种网络结构，也就是用 Inception 模块组成的网络都叫 Inception 网络，最后他们在比赛中使用的那个 22 层的 Inception 网络就叫 GoogLeNet，网络结构可以点击<a href="https://randy-1251769892.cos.ap-beijing.myqcloud.com/GoogLeNet.pdf" target="_blank" rel="noopener">查看全图</a>，由于模型的层数比较多，就不再一一介绍。下面重点介绍一下文章中提出的 Inception 模块的思想。</p><h4 id="inception">Inception</h4><p>Inception （盗梦空间）这个名字来自于电影名字是因为其中有一句台词：</p><blockquote><p>We need to go deeper</p></blockquote><p>文章指出提高深度神经网络性能最直接的方法是增大网络规模：增加网络层数和增加各层神经元数量。但是在样本较少的情况下，参数越多越容易导致网络过拟合；而且需要的计算资源会直线上升。根据 Hebbian 原理，解决这两个问题的根本途径是将全连接改成稀疏连接，例如 Dropout 就是随机使神经元失活，进而让连接变得稀疏。但是由于实际运算过程中都是基于矩阵优化的，因此很难减少运算的时间，所以目前视觉领域的机器学习系统仅仅是利用卷积的空域稀疏性。</p><p>Inception 结构的主要思想是找到网络的最优稀疏的结构，也就是说不需要人为决定使用哪个滤波器或者是否需要池化，而是由网络自行确定这些参数，给网络添加这些参数的所有可能值后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些滤波器组合。后来 <span class="math inline">\(1\times 1\)</span> 滤波器广泛使用后，就被应用到了 Inception 模块中。理解了 Inception 模块就能理解 Inception 网络，无非是很多个 Inception 模块组成了网络。自从 Inception 模块诞生以来，经过研究者们的不断发展而衍生了许多新的版本。比如 Inception V2、V3 和 V4，还有一个版本引入了跳跃连接的方法，即 ResNet 中防止梯度消失和梯度爆炸的思想。</p><h2 id="总结">总结</h2><p>了解了卷积神经网络的发展历程，感觉还是很有意思的。人们提出了很多想法，无非就是为了让模型更复杂又不能出现过拟合，或者让模型运算得更快一点，总之百变不离其中，就是提取特征。但是整体感觉下来好像还是缺点什么，或许就是这种数据科学确实没有一个很标准的答案吧！同时还是默默期待哪一天会出现这个时代的牛顿，给所有一切很自然的东西一个公式或者定理吧。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.</li><li>Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems. 2012.</li><li>Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</li><li>Lin M, Chen Q, Yan S. Network in network[J]. arXiv preprint arXiv:1312.4400, 2013.</li><li>Szegedy C, Liu W, Jia Y, et al. c[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 1-9.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;自己给自己加个油！还有两周多的内容就结束了，慢慢学了快一年了，博客写写停停，也算是坚持下来了。这一周的内容是深度卷积网络的实例探究，介绍了好些个经典的模型，慢慢扩展吧！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络应用</title>
    <link href="https://pengzhendong.cn/2018/12/05/convnet-application/"/>
    <id>https://pengzhendong.cn/2018/12/05/convnet-application/</id>
    <published>2018-12-05T03:16:44.000Z</published>
    <updated>2018-12-05T07:45:07.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>写了两周基金申请报告也是醉了，说什么基金申请下来后我们出国交流就不用钱啦！多么拙劣的谎言，我只想中一篇论文达到毕业要求，然后去实习就行。今天又吐槽我说我晚上出勤不够，您真不愧是大学城最努力的老师。这都还没毕业，实验室的同学们都已经过上了公务员那种朝九晚五的生活。继续学习卷积神经网络，看看怎么用 Tensorflow 实现多分类问题。</p><a id="more"></a><h2 id="tensorflow-模型">Tensorflow 模型</h2><p>这个实验的要求是对手势进行识别，分析图片中的手势表示的是哪个数字（0~6）。手势图像如下所示：</p><p><img src="/2018/12/05/convnet-application/SIGNS.png"></p><p>首先载入需要用到的包和数据集，对数据进行简单的预处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line"><span class="keyword">from</span> cnn_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line">conv_layers = &#123;&#125;</span><br></pre></td></tr></table></figure><h3 id="创建-placeholders">创建 placeholders</h3><p>需要给数据创建 placeholders，在运行 session 的时候就可以喂入数据。使用 <code>None</code> 作为 batch size，这样就可以在后面的时候比较灵活地设置小批量的大小：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span><span class="params">(n_H0, n_W0, n_C0, n_y)</span>:</span></span><br><span class="line">    X = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_H0, n_W0, n_C0])</span><br><span class="line">    Y = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_y])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure><h3 id="初始化参数">初始化参数</h3><p>网络为两层卷积神经网络，分别初始化每一层的权值 <span class="math inline">\(W1\)</span> 和 <span class="math inline">\(W2\)</span>，也就是滤波器 。其中 <span class="math inline">\(W1\)</span> 包含 8 个大小为 4 的 3 通道滤波器，<span class="math inline">\(W2\)</span> 包含 16 个大小为 2 的 8 通道滤波器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">()</span>:</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    W1 = tf.get_variable(<span class="string">"W1"</span>, [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    W2 = tf.get_variable(<span class="string">"W2"</span>, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">16</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">"W1"</span>: W1, <span class="string">"W2"</span>: W2&#125;</span><br></pre></td></tr></table></figure><h3 id="前向传播">前向传播</h3><p>在 Tensorflow 中，提供了以下函数可以用来快速构建卷积神经网络：</p><ul><li><code>tf.nn.conv2d(X, W1, strides=[1,s,s,1], padding='SAME')</code>：给定输入 <span class="math inline">\(X\)</span> 和一组滤波器 <span class="math inline">\(W1\)</span>，该函数回使用 <span class="math inline">\(W1\)</span> 中的滤波器和 <span class="math inline">\(X\)</span> 进行卷积运算，第三个参数指定了 <span class="math inline">\(X\)</span> 每个维度的卷积步长。</li><li><code>tf.nn.max_pool(A, ksize=[1,f,f,1], strides=[1,s,s,1], padding='SAME')</code>：给定输入 A，滤波器大小为 f，使用最大池化进行运算。</li><li><code>tf.nn.relu(Z1)</code>：对 Z1 中的每个元素进行 ReLU 运算。</li><li><code>tf.contrib.layers.flatten(P)</code>：给定输入 P，将其变平（flatten）成一维向量。如果 P 中包含 batch-size 则变成形状为 [batch_size, k] 的张量。</li><li><code>tf.contrib.layers.fully_connected(F, num_outputs)</code>：给定变平的输入，返回全连接神经网络层计算的输出，该层自动初始化权值。</li></ul><p>卷积神经网络的前向传播主要流程为：<code>CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</code>，每一层的参数配置如下所示：</p><ol type="1"><li>Conv2D：步长为 1，零填充为 SAME 卷积；</li><li>ReLU；</li><li>Max pool：滤波器大小为 8，步长为 8；</li><li>Conv2D：卷积步长为 1，零填充为 SAME 卷积；</li><li>ReLU；</li><li>Max pool：滤波器尺大小为 4，步长为 4</li><li>将前面的输出变平（flatten）；</li><li>FULLYCONNECTED (全连接) 层：此处不需要使用 softmax 函数，在 Tensorflow 中，softmax 和代价函数被写成了一个单独的函数，所以可以直接在全连接层的输出上计算代价。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary "parameters" </span></span><br><span class="line">    W1 = parameters[<span class="string">'W1'</span>]</span><br><span class="line">    W2 = parameters[<span class="string">'W2'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># CONV2D: stride of 1, padding 'SAME'</span></span><br><span class="line">    Z1 = tf.nn.conv2d(X, W1, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A1 = tf.nn.relu(Z1)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 8x8, stride 8, padding 'SAME'</span></span><br><span class="line">    P1 = tf.nn.max_pool(A1, ksize = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># CONV2D: filters W2, stride 1, padding 'SAME'</span></span><br><span class="line">    Z2 = tf.nn.conv2d(P1, W2, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A2 = tf.nn.relu(Z2)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 4x4, stride 4, padding 'SAME'</span></span><br><span class="line">    P2 = tf.nn.max_pool(A2, ksize = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># FLATTEN</span></span><br><span class="line">    P = tf.contrib.layers.flatten(P2)</span><br><span class="line">    <span class="comment"># FULLY-CONNECTED without non-linear activation function (not not call softmax).</span></span><br><span class="line">    <span class="comment"># 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" </span></span><br><span class="line">    Z3 = tf.contrib.layers.fully_connected(P, <span class="number">6</span>, activation_fn=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure><h3 id="计算代价">计算代价</h3><ul><li><code>tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y)</code>：计算 softmax 交叉损失，该函数包含了 softmax 函数。</li><li><code>tf.reduce_mean</code>：计算张量每个维度的均值，用来计算整体的代价。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(Z3, Y)</span>:</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><h3 id="模型">模型</h3><p>整体的模型包含以上几个步骤，最后需要创建优化器，然后运行 session 迭代数据集 num_epochs 次，在每个最小批量上运行优化器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X_train, Y_train, X_test, Y_test, learning_rate=<span class="number">0.009</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          num_epochs=<span class="number">100</span>, minibatch_size=<span class="number">64</span>, print_cost=True)</span>:</span></span><br><span class="line">    ops.reset_default_graph()                         <span class="comment"># to be able to rerun the model without overwriting tf variables</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             <span class="comment"># to keep results consistent (tensorflow seed)</span></span><br><span class="line">    seed = <span class="number">3</span>                                          <span class="comment"># to keep results consistent (numpy seed)</span></span><br><span class="line">    (m, n_H0, n_W0, n_C0) = X_train.shape             </span><br><span class="line">    n_y = Y_train.shape[<span class="number">1</span>]                            </span><br><span class="line">    costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Placeholders of the correct shape</span></span><br><span class="line">    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagation: Build the forward propagation in the tensorflow graph</span></span><br><span class="line">    Z3 = forward_propagation(X, parameters)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Cost function: Add cost function to tensorflow graph</span></span><br><span class="line">    cost = compute_cost(Z3, Y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize all the variables globally</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># Start the session to compute the tensorflow graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run the initialization</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Do the training loop</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line"></span><br><span class="line">            minibatch_cost = <span class="number">0.</span></span><br><span class="line">            num_minibatches = int(m / minibatch_size) <span class="comment"># number of minibatches of size minibatch_size in the train set</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Select a minibatch</span></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                <span class="comment"># IMPORTANT: The line that runs the graph on a minibatch.</span></span><br><span class="line">                <span class="comment"># Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).</span></span><br><span class="line">                _ , temp_cost = sess.run([optimizer, cost], feed_dict=&#123;X:minibatch_X, Y:minibatch_Y&#125;)</span><br><span class="line">                </span><br><span class="line">                minibatch_cost += temp_cost / num_minibatches</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Print the cost every epoch</span></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after epoch %i: %f"</span> % (epoch, minibatch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(minibatch_cost)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        predict_op = tf.argmax(Z3, <span class="number">1</span>)</span><br><span class="line">        correct_prediction = tf.equal(predict_op, tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">        print(accuracy)</span><br><span class="line">        train_accuracy = accuracy.eval(&#123;X: X_train, Y: Y_train&#125;)</span><br><span class="line">        test_accuracy = accuracy.eval(&#123;X: X_test, Y: Y_test&#125;)</span><br><span class="line">        print(<span class="string">"Train Accuracy:"</span>, train_accuracy)</span><br><span class="line">        print(<span class="string">"Test Accuracy:"</span>, test_accuracy)</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> train_accuracy, test_accuracy, parameters</span><br></pre></td></tr></table></figure><p>运行以下代码，将模型训练 100 个 epoch，同时每 5 个 epoch 输出模型的代价：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_, _, parameters = model(X_train, Y_train, X_test, Y_test)</span><br></pre></td></tr></table></figure><p><img src="/2018/12/05/convnet-application/output.png"></p><p>最后模型在训练集上的准确度能达到 94%，在测试集上能达到 78%。模型的方差比较高，还可以继续调节超参数和使用正则项提高模型的性能。</p><h2 id="总结">总结</h2><p>投出去的论文的实验也是用 Tensorflow 实现的，Tensorflow 确实强大，但是如果不是很熟悉就想用还是有点难，当时遇到一些小问题都得花半天时间解决，看来还需要多学习一下，多看看文档。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;写了两周基金申请报告也是醉了，说什么基金申请下来后我们出国交流就不用钱啦！多么拙劣的谎言，我只想中一篇论文达到毕业要求，然后去实习就行。今天又吐槽我说我晚上出勤不够，您真不愧是大学城最努力的老师。这都还没毕业，实验室的同学们都已经过上了公务员那种朝九晚五的生活。继续学习卷积神经网络，看看怎么用 Tensorflow 实现多分类问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络</title>
    <link href="https://pengzhendong.cn/2018/12/03/convolutional-neural-networks/"/>
    <id>https://pengzhendong.cn/2018/12/03/convolutional-neural-networks/</id>
    <published>2018-12-03T05:16:18.000Z</published>
    <updated>2018-12-03T07:16:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>“如果我们要建成一个更好的世界，我们必须有从头做起的勇气”，我差的很远，最近没什么效率，总是不想改开题报告和论文，只能看看书和学学深度学习。读研以前对未来的那种憧憬也没了，我现在的想法就是赶紧毕业，找一个工程师的岗位，在实践中成长吧！学术搞不来！</p><a id="more"></a><h2 id="卷积神经网络">卷积神经网络</h2><p>平常我们使用神经网络的时候，输入的特征的维度一般不会很大，但是如果需要处理图片，例如一张 <span class="math inline">\(1000\times 1000\)</span> 像素的三通道图，那么就会有三百万个输入。如果下一层神经元的节点数为 1000，那么就需要三十亿个参数！很难处理这么多的参数，而且也很难有足够多的数据来保证模型不会过拟合，因此就需要卷积运算。</p><p>卷积神经网络的思想就是检测图像左上角的特征检测器也适用于图像的右下角，图像的分布通常差不多，参数通过移动卷积核达到共享的效果。卷积神经网络的原理就是把卷积的滤波器（算子）当成参数来学习，而不是用固定的 Sobel 算子或者其他人工定义的算子。需要注意的是，在深度学习领域，卷积神经网络中实际的操作是相关操作，即省略了滤波器翻转的过程，不过这影响并不大，因此人们还是把它叫做卷积神经网络。</p><p><strong>符号定义：</strong></p><ul><li><span class="math inline">\([l]\)</span> 表示第 <span class="math inline">\(l\)</span> 层，例如 <span class="math inline">\(W^{[5]}\)</span> 是第五层的参数</li><li><span class="math inline">\((i)\)</span> 表示第 <span class="math inline">\(i\)</span> 个样本，例如 <span class="math inline">\(x^{(i)}\)</span> 是第 <span class="math inline">\(i\)</span> 个训练样本</li><li><span class="math inline">\(i\)</span> 表示向量的第 <span class="math inline">\(i\)</span> 维，例如 <span class="math inline">\(a^{[l]}_i\)</span> 是第 <span class="math inline">\(l\)</span> 层的激活向量得第 <span class="math inline">\(i\)</span> 维</li><li><span class="math inline">\(n^{[l]}_H, n^{[l]}_W\)</span> 和 <span class="math inline">\(n^{[l]}_C\)</span> 分别表示第 <span class="math inline">\(l\)</span> 层的高、宽和通道数</li><li><span class="math inline">\(n^{[l]}_{H_{prev}}, n^{[l]}_{W_{prev}}\)</span> 和 <span class="math inline">\(n^{[l]}_{C_{prev}}\)</span> 分别表示第 <span class="math inline">\(l\)</span> 层的的上一层高、宽和通道数，即 <span class="math inline">\(n^{[l-1]}_H, n^{[l-1]}_W\)</span> 和 <span class="math inline">\(n^{[l-1]}_C\)</span></li></ul><h3 id="卷积">卷积</h3><p>对于一张 <span class="math inline">\(n\times n\)</span> 的图片和尺寸为 <span class="math inline">\(f\times f\)</span> 的滤波器，对于步长为 1 的卷积神经网络，卷积后的图片大小是： <span class="math display">\[n\times n * f\times f \rightarrow (n-f+1)\times (n-f+1)\]</span> 多通道图像的滤波器的通道数要和图像的一致，通道数为 <span class="math inline">\(n_C\)</span> 的立体卷积输出的图像大小为： <span class="math display">\[n\times n\times n_C * f\times f\times n_C \rightarrow (n-f+1)\times (n-f+1)\]</span></p><h4 id="零填充">零填充</h4><p>没有零填充的叫 <strong>Valid 卷积</strong>，由于网络的层数可能会比较多，经过卷积之后的图片就会越来越小，所以需要对图片的进行零填充。</p><p><img src="/2018/12/03/convolutional-neural-networks/PAD.png"></p><p>如果填充使得输出和原图一样大，就叫 <strong>Same 卷积</strong>，假设进行了 <span class="math inline">\(p\)</span> 次零填充，有： <span class="math display">\[n+2p-f+1=n\]</span> 解得 <span class="math inline">\(p=\frac{f-1}{2}\)</span>。对数据集中的图像进行零填充的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_pad</span><span class="params">(X, pad)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    X -- (m, n_H, n_W, n_C) representing a batch of m images</span></span><br><span class="line"><span class="string">    pad -- integer</span></span><br><span class="line"><span class="string">    X_pad -- (m, n_H + 2*pad, n_W + 2*pad, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    X_pad = np.pad(X, ((<span class="number">0</span>,<span class="number">0</span>), (pad,pad), (pad,pad), (<span class="number">0</span>,<span class="number">0</span>)), <span class="string">'constant'</span>, constant_values = (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X_pad</span><br></pre></td></tr></table></figure><h4 id="步长">步长</h4><p>卷积神经网络中还有一个参数叫做步长（stride），也就是滤波器移动的步长 <span class="math inline">\(s\)</span>，卷积后的图片大小是： <span class="math display">\[n\times n * f\times f \rightarrow (\lfloor\frac{n+2p-f}{s}+1\rfloor)\times (\lfloor\frac{n+2p-f}{s}+1\rfloor)\]</span></p><p>对于后面所有内容，如果两个维度上的数值相等，则只记一个维度。例如 <span class="math inline">\(f\times f\)</span> 的滤波器，则说是大小为 <span class="math inline">\(f\)</span> 的滤波器；两个维度上的步长为 <span class="math inline">\(1\times 1\)</span>，则说是步长为 1。</p><h3 id="单层卷积神经网络">单层卷积神经网络</h3><p>步长为 1 的立体 valid 卷积输出的图像是单通道图像，代表图像的某一种特征，可以使用多个提取图像多种特征。在卷积神经网络中，得到输出后通常还需要进行激活函数操作，即加上偏置后经过 ReLU 函数，最后才叠在一起 。假设原图像为 <span class="math inline">\(I\)</span>，对于第 <span class="math inline">\(i\)</span> 个滤波器 <span class="math inline">\(f_i\)</span>， 输出图像的第 <span class="math inline">\(i\)</span> 个通道 <span class="math inline">\(O_i\)</span> 为：</p><p><span class="math display">\[O_i=ReLU(I* f_i+b_i)\]</span> 卷积神经网络的动态视频如下所示：</p><center><video width="620" height="440" controls><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/conv_kiank.mp4" type="video/mp4">Your browser does not support the video tag. </video></center><h4 id="代码">代码</h4><p>在计算卷积的过程中，每次从图像中选出一部分与滤波器进行加权求和，然后加上偏置。代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_single_step</span><span class="params">(a_slice_prev, W, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    a_slice_prev -- (f, f, n_C_prev) slice of input data</span></span><br><span class="line"><span class="string">    W -- (f, f, n_C_prev) Weight parameters contained in a window</span></span><br><span class="line"><span class="string">    b -- (1, 1, 1) Bias parameters contained in a window</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Element-wise product between a_slice and W. Do not add the bias yet.</span></span><br><span class="line">    s = np.multiply(a_slice_prev, W)</span><br><span class="line">    <span class="comment"># Sum over all entries of the volume s.</span></span><br><span class="line">    Z = np.sum(s)</span><br><span class="line">    <span class="comment"># Add bias b to Z. Cast b to a float() so that Z results in a scalar value.</span></span><br><span class="line">    Z = Z + b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z</span><br></pre></td></tr></table></figure><p>那么如何从图像中选出一部分呢？需要对选出的部分图像进行定义，定义其水平和竖直的起点和终点。如下图所示：</p><p><img src="/2018/12/03/convolutional-neural-networks/vert_horiz_kiank.png"></p><p>根据前面的定义，卷积输出的大小为： <span class="math display">\[n_H = \lfloor \frac{n_{H_{prev}} - f + 2 \times pad}{stride} \rfloor +1\]</span></p><p><span class="math display">\[n_W = \lfloor \frac{n_{W_{prev}} - f + 2 \times pad}{stride} \rfloor +1\]</span></p><p>全部的前向卷积过程的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_forward</span><span class="params">(A_prev, W, b, hparameters)</span>:</span>    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape (≈1 line)  </span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from W's shape (≈1 line)</span></span><br><span class="line">    (f, f, n_C_prev, n_C) = W.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve information from "hparameters" (≈2 lines)</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    pad = hparameters[<span class="string">'pad'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)</span></span><br><span class="line">    n_H = int((n_H_prev - f + <span class="number">2</span> * pad) / stride) + <span class="number">1</span></span><br><span class="line">    n_W = int((n_W_prev - f + <span class="number">2</span> * pad) / stride) + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the output volume Z with zeros. (≈1 line)</span></span><br><span class="line">    Z = np.zeros((m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create A_prev_pad by padding A_prev</span></span><br><span class="line">    A_prev_pad = zero_pad(A_prev, pad)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                               <span class="comment"># loop over the batch of training examples</span></span><br><span class="line">        a_prev_pad = A_prev_pad[i,:,:,:]                               <span class="comment"># Select ith training example's padded activation</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                           <span class="comment"># loop over vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):                       <span class="comment"># loop over horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):                   <span class="comment"># loop over channels (= #filters) of the output volume</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)</span></span><br><span class="line">                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)</span></span><br><span class="line">                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c], b[:,:,:,c])</span><br><span class="line">                                        </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(Z.shape == (m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save information in "cache" for the backprop</span></span><br><span class="line">    cache = (A_prev, W, b, hparameters)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Z, cache</span><br></pre></td></tr></table></figure><p>最后还需要对输出进行激活函数操作：<code>A[i, h, w, c] = activation(Z[i, h, w, c])</code>。</p><h4 id="参数">参数</h4><p>假设有 10 个 <span class="math inline">\(3\times 3\times 3\)</span> 的滤波器，那么单层卷积神经网络有多少参数呢？每个滤波器对应 <span class="math inline">\(3\times 3\times 3+1=28\)</span> 个参数，其中 <span class="math inline">\(3\times 3\times 3\)</span> 表示滤波器中的数值，1 表示滤波器的偏置项。因此 10 个滤波器就一共有 <span class="math inline">\(28\times 10=280\)</span> 个参数，不管图像的大小是多少都不会改变参数的个数。</p><h3 id="池化层">池化层</h3><p>在卷积层之后通常还有池化层，其目的是为了缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。其实池化层就是属于非线性空间滤波中的统计排序滤波器。该层一共有两个参数 <span class="math inline">\(f\)</span> 和 <span class="math inline">\(s\)</span>，分别表示滤波器的大小和步长，如果 <span class="math inline">\(f=s\)</span> 则是正常池化，如果 <span class="math inline">\(s&gt;f\)</span> 则是重叠池化（Overlapping），重叠池化有避免过拟合的作用。<span class="math inline">\(f=s=2\)</span> 的最大池化如下图所示：</p><p><img src="/2018/12/03/convolutional-neural-networks/max_pool.png"></p><p>由于池化层两个参数都是超参数，不需要训练，因此卷积层和池化层一起通常算一层。类似于卷积层，池化层的输出的图像大小为： <span class="math display">\[n_H = \lfloor \frac{n_{H_{prev}} - f}{stride} \rfloor +1\]</span></p><p><span class="math display">\[n_W = \lfloor \frac{n_{W_{prev}} - f}{stride} \rfloor +1\]</span></p><p><span class="math display">\[n_C = n_{C_{prev}}\]</span></p><p>类似于卷积层，池化层的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_forward</span><span class="params">(A_prev, hparameters, mode = <span class="string">"max"</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from the input shape</span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve hyperparameters from "hparameters"</span></span><br><span class="line">    f = hparameters[<span class="string">"f"</span>]</span><br><span class="line">    stride = hparameters[<span class="string">"stride"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the dimensions of the output</span></span><br><span class="line">    n_H = int(<span class="number">1</span> + (n_H_prev - f) / stride)</span><br><span class="line">    n_W = int(<span class="number">1</span> + (n_W_prev - f) / stride)</span><br><span class="line">    n_C = n_C_prev</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize output matrix A</span></span><br><span class="line">    A = np.zeros((m, n_H, n_W, n_C))              </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                         <span class="comment"># loop over the training examples</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                     <span class="comment"># loop on the vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):                 <span class="comment"># loop on the horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range (n_C):            <span class="comment"># loop over the channels of the output volume</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)</span></span><br><span class="line">                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.</span></span><br><span class="line">                    <span class="keyword">if</span> mode == <span class="string">"max"</span>:</span><br><span class="line">                        A[i, h, w, c] = np.max(a_prev_slice)</span><br><span class="line">                    <span class="keyword">elif</span> mode == <span class="string">"average"</span>:</span><br><span class="line">                        A[i, h, w, c] = np.mean(a_prev_slice)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Store the input and hparameters in "cache" for pool_backward()</span></span><br><span class="line">    cache = (A_prev, hparameters)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(A.shape == (m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A, cache</span><br></pre></td></tr></table></figure><h3 id="多层卷积神经网络">多层卷积神经网络</h3><p>一个卷积层、一个激活层加上一个池化层算一层，通常还会在卷积神经网络后面加上一个全连接层，多层卷积神经网络的模型结构如下图所示：</p><p><img src="/2018/12/03/convolutional-neural-networks/model.png"></p><p>上图为两个（x2）卷积层和一个全连接层的神经网络，假设输入为 <span class="math inline">\(32\times 32\times 3\)</span> 的图像，参数如下所示：</p><ul><li>CONV1：8 个大小为 5 的滤波器，步长为 1；</li><li>POOL1：滤波器大小为 2，步长为 2；</li><li>CONV2：16 个大小为 5 的滤波器，步长为 1；</li><li>POOL2：滤波器大小为 2，步长为 2；</li><li>FC：128 个神经元节点；</li><li>SOFTMAX：10 个神经元节点（用于手写数字分类）。</li></ul><p>网络各层的参数个数如下表所示：</p><table><thead><tr class="header"><th></th><th>Activation Shape</th><th>Activation Size</th><th># parameters</th></tr></thead><tbody><tr class="odd"><td>Input</td><td>(32, 32, 3)</td><td>3,072</td><td>0</td></tr><tr class="even"><td>CONV1(f=5, s=1)</td><td>(28, 28, 8)</td><td>6,272</td><td><span class="math inline">\(208=8\times (25+1)\)</span></td></tr><tr class="odd"><td>POOL1(f=2, s=2)</td><td>(14, 14, 8)</td><td>1,568</td><td>0</td></tr><tr class="even"><td>CONV2(f=5, s=1)</td><td>(10, 10, 16)</td><td>1,600</td><td><span class="math inline">\(416=16\times (25+1)\)</span></td></tr><tr class="odd"><td>POOL2(f=2, s=2)</td><td>(5, 5, 16)</td><td>400</td><td>0</td></tr><tr class="even"><td>FC</td><td>(128, 1)</td><td>128</td><td><span class="math inline">\(51,201=400\times 128+1\)</span></td></tr><tr class="odd"><td>SOFTMAX</td><td>(10, 1)</td><td>10</td><td><span class="math inline">\(1281=128\times 10+1\)</span></td></tr></tbody></table><h2 id="反向传播">反向传播</h2><p>相比较于循环神经网络，卷积神经网络的反向传播就比较简单，因为卷积操作的过程就是加权求和（线性滤波）。卷积神经网络的反向传播分为两部分：卷积层和池化层。</p><h3 id="卷积层">卷积层</h3><p>类似是普通的深度神经网络，卷积层的反向传播主要计算 <span class="math inline">\(dA\)</span>、<span class="math inline">\(dW_c\)</span> 和 <span class="math inline">\(db\)</span>。</p><h4 id="计算-da">计算 dA</h4><p>给定一个滤波器 <span class="math inline">\(W_c\)</span>，卷积层关于代价函数的梯度为： <span class="math display">\[dA+=\sum_{h=0}^{n_H}\sum_{w=0}^{n_W}W_c\times dZ_{hw}\]</span> 其中 <span class="math inline">\(dZ_{hw}\)</span> 为卷积层 <span class="math inline">\(Z\)</span> 的第 <span class="math inline">\(h\)</span> 行的第 <span class="math inline">\(w\)</span> 列关于代价函数的梯度。因为在前向卷积的时候，不同的 <code>a_slice</code> 与同一个滤波器进行运算，因此在反向传播的时候也是用同一个 <span class="math inline">\(W_c\)</span>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]</span><br></pre></td></tr></table></figure><h4 id="计算-dw">计算 dW</h4><p><span class="math inline">\(dW_{c}\)</span> 是损失函数关于一个滤波器的导数，定义为： <span class="math display">\[dW_c+=\sum_{h=0}^{n_H}\sum_{w=0}^{n_W} a_{slice} \times dZ_{hw}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dW[:,:,:,c] += a_slice * dZ[i, h, w, c]</span><br></pre></td></tr></table></figure><h4 id="计算-db">计算 db</h4><p><span class="math inline">\(db\)</span> 为滤波器中偏置关于损失函数的导数，定义为： <span class="math display">\[db=\sum_h\sum_w dZ_{hw}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db[:,:,:,c] += dZ[i, h, w, c]</span><br></pre></td></tr></table></figure><p>卷积层全部反向传播的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_backward</span><span class="params">(dZ, cache)</span>:</span>    </span><br><span class="line">    <span class="comment"># Retrieve information from "cache"</span></span><br><span class="line">    (A_prev, W, b, hparameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape</span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from W's shape</span></span><br><span class="line">    (f, f, n_C_prev, n_C) = W.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve information from "hparameters"</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    pad = hparameters[<span class="string">'pad'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from dZ's shape</span></span><br><span class="line">    (m, n_H, n_W, n_C) = dZ.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize dA_prev, dW, db with the correct shapes</span></span><br><span class="line">    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           </span><br><span class="line">    dW = np.zeros((f, f, n_C_prev, n_C))</span><br><span class="line">    db = np.zeros((<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, n_C))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pad A_prev and dA_prev</span></span><br><span class="line">    A_prev_pad = zero_pad(A_prev, pad)</span><br><span class="line">    dA_prev_pad = zero_pad(dA_prev, pad)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                       <span class="comment"># loop over the training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># select ith training example from A_prev_pad and dA_prev_pad</span></span><br><span class="line">        a_prev_pad = A_prev_pad[i,:,:,:]</span><br><span class="line">        da_prev_pad = dA_prev_pad[i,:,:,:]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                   <span class="comment"># loop over vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):               <span class="comment"># loop over horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):           <span class="comment"># loop over the channels of the output volume</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice"</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Use the corners to define the slice from a_prev_pad</span></span><br><span class="line">                    a_slice = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Update gradients for the window and the filter's parameters using the code formulas given above</span></span><br><span class="line">                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] +=  W[:,:,:,c] * dZ[i,h,w,c]</span><br><span class="line">                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]</span><br><span class="line">                    db[:,:,:,c] += dZ[i, h, w, c]</span><br><span class="line">                    </span><br><span class="line">        <span class="comment"># Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])</span></span><br><span class="line">        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad,pad:-pad,:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure><h3 id="池化层-1">池化层</h3><p>好在池化层中只有超参数，因此不需要学习。但是为了让梯度反向传播，还是需要计算 <span class="math inline">\(dZ\)</span>。由于池化层是非线性操作，因此最大池化需要计算一个 mask 矩阵用来记录最大元素的位置。例如滤波器大小为 2 的最大池化中的 mask 矩阵 <span class="math inline">\(M\)</span> 为： <span class="math display">\[X = \begin{bmatrix}1 &amp;&amp; 3 \\\4 &amp;&amp; 2\end{bmatrix} \quad \rightarrow  \quad M =\begin{bmatrix}0 &amp;&amp; 0 \\\1 &amp;&amp; 0\end{bmatrix}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_mask_from_window</span><span class="params">(x)</span>:</span></span><br><span class="line">    mask = (x==np.max(x))  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure><p>最大池化的反向传播只需要让梯度乘上 mask 矩阵即可。而滤波器大小为 2 的平均池化的 mask 矩阵如下所示： <span class="math display">\[dZ = 1 \quad \rightarrow  \quad dZ =\begin{bmatrix}1/4 &amp;&amp; 1/4 \\\1/4 &amp;&amp; 1/4\end{bmatrix}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute_value</span><span class="params">(dz, shape)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from shape (≈1 line)</span></span><br><span class="line">    (n_H, n_W) = shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the value to distribute on the matrix (≈1 line)</span></span><br><span class="line">    average = np.float(dz) / np.float(n_H * n_W)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a matrix where every entry is the "average" value (≈1 line)</span></span><br><span class="line">    a = np.ones((n_H, n_W)) * average</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><p>池化层全部反向传播的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_backward</span><span class="params">(dA, cache, mode = <span class="string">"max"</span>)</span>:</span>    </span><br><span class="line">    <span class="comment"># Retrieve information from cache (≈1 line)</span></span><br><span class="line">    (A_prev, hparameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve hyperparameters from "hparameters" (≈2 lines)</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    f = hparameters[<span class="string">'f'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)</span></span><br><span class="line">    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape</span><br><span class="line">    m, n_H, n_W, n_C = dA.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize dA_prev with zeros (≈1 line)</span></span><br><span class="line">    dA_prev = np.zeros((m,n_H_prev,n_W_prev,n_C_prev))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                       <span class="comment"># loop over the training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># select training example from A_prev (≈1 line)</span></span><br><span class="line">        a_prev = A_prev[i,:,:,:]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                   <span class="comment"># loop on the vertical axis</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):               <span class="comment"># loop on the horizontal axis</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):           <span class="comment"># loop over the channels (depth)</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Compute the backward propagation in both modes.</span></span><br><span class="line">                    <span class="keyword">if</span> mode == <span class="string">"max"</span>:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Use the corners and "c" to define the current slice from a_prev (≈1 line)</span></span><br><span class="line">                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]</span><br><span class="line">                        <span class="comment"># Create the mask from a_prev_slice (≈1 line)</span></span><br><span class="line">                        mask = create_mask_from_window(a_prev_slice)</span><br><span class="line">                        <span class="comment"># Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)</span></span><br><span class="line">                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask,dA[i, h, w, c])</span><br><span class="line">                        </span><br><span class="line">                    <span class="keyword">elif</span> mode == <span class="string">"average"</span>:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Get the value a from dA (≈1 line)</span></span><br><span class="line">                        da = dA[i, h, w, c]</span><br><span class="line">                        <span class="comment"># Define the shape of the filter as fxf (≈1 line)</span></span><br><span class="line">                        shape = (f, f)</span><br><span class="line">                        <span class="comment"># Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)</span></span><br><span class="line">                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)</span><br><span class="line">                            </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(dA_prev.shape == A_prev.shape)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev</span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>卷积神经网络听起来很难，但是理解后比循环神经网络简单多了。说到底就是卷积这个概念听起来难，其实也就是那么回事。之前一直不太理解池化层的操作，前几篇博客总结了滤波器后反而有意外的收获，池化也就是非线性空间滤波，只不过通常步长会大点，让输出的图像小点，从而加速计算；重叠池化也是在计算速度和过拟合之间的一个 trade-off。最后还有收获比较大的一点就是池化层中并没有参数需要学习，也就是不需要计算参数的梯度，同时最大池化需要记录最大值的位置用于计算上一层的梯度。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;“如果我们要建成一个更好的世界，我们必须有从头做起的勇气”，我差的很远，最近没什么效率，总是不想改开题报告和论文，只能看看书和学学深度学习。读研以前对未来的那种憧憬也没了，我现在的想法就是赶紧毕业，找一个工程师的岗位，在实践中成长吧！学术搞不来！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>集束搜索和 BLEU</title>
    <link href="https://pengzhendong.cn/2018/11/26/beam-search-and-bleu/"/>
    <id>https://pengzhendong.cn/2018/11/26/beam-search-and-bleu/</id>
    <published>2018-11-26T02:43:02.000Z</published>
    <updated>2018-11-26T06:43:53.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>花了几天时间总结了一下滤波器，发现滤波器还分时域和频域，涨知识了。突然想起来课程中还有集束搜索和 BLEU 这部分内容，并没有出现在序列学习的实验中，所以还是先把这部分内容再学习学习。</p><a id="more"></a><h2 id="集束搜索">集束搜索</h2><p>Beam Search（集束搜索）是计算机科学中最重要的 32 个算法之一，它是一种启发式的图搜索算法，通常用在图的解空间较大的情况下，减少搜索所占用的时间和空间。</p><p>集束搜索使用广度优先策略建立搜索树，在树的每一层按照启发代价对节点进行排序，然后仅留下 B（集束宽度）个节点，仅这些节点在下一层次继续扩展。集束宽度越小，搜索速度越快，但是最终输出的序列质量越有可能不是最优的，因此集束搜索算法是不完全的。</p><ul><li><span class="math inline">\(B=1\)</span>，每次只挑出最可能的那一个词，相当于<strong>贪婪算法</strong></li><li><span class="math inline">\(B=\infty\)</span>，每次都保留所有可能的词，相当于<strong>宽度优先搜索</strong></li></ul><p>假设有一个法语句子：“Jane visite l'Afrique en Septembre.”，我们希望翻译成英语：“Jane is visiting Africa in September.”。不考虑大小写，假设词汇表有 10000 个单词，集束宽度为 3，第一步是给定输入法语序列 <span class="math inline">\(x\)</span>，评估第一个单词为词汇表中每个单词的概率 <span class="math inline">\(P(y^{\langle 1 \rangle}|x)\)</span> 是多少。贪婪算法只挑出概率最大的单词，然后继续评估下一个单词的概率，而集束搜索则会考虑多个选择，因为概率最大的也不一定是最好的，我们需要找的是让整个句子的概率最大的单词。例如第一个单词最可能的三个选项为：<strong>in</strong>、<strong>jane</strong> 和 <strong>september</strong>。</p><p>即： <span class="math display">\[P(y^{\langle 1 \rangle}=“\text{in}”|x)&gt;P(y^{\langle 1 \rangle}=“\text{jane}”|x)&gt;P(y^{\langle 1 \rangle}=“\text{september}”|x)&gt;...\]</span> 第二步我们想让前第一个和第二个单词同时出现的概率最大，则在第一个词为<strong>in</strong>、<strong>jane</strong> 和 <strong>september</strong> 的时候，分别计算前两个词的概率，即第一个时间步的输出作为第二个时间步的输入：</p><p><img src="/2018/11/26/beam-search-and-bleu/a.png"> <span class="math display">\[P(y^{\langle 1 \rangle},y^{\langle 2 \rangle}|x)=P(y^{\langle 1 \rangle}|x)\times P(y^{\langle 2 \rangle}|x,y^{\langle 1 \rangle})\]</span> 因此一共会有 30000 个选择，我们还是选择 3 个概率最大的选项，例如可能是：<strong>in September</strong>、<strong>jane is</strong> 和 <strong>jane visits</strong>，即： <span class="math display">\[P(“\text{in September}”|x)&gt;P(“\text{jane is}”|x)&gt;P(“\text{jane visits}”|x)&gt;...\]</span></p><p>这个时候第一个单词为 <strong>september</strong> 的选项已经不存在了，然后继续以上步骤直到输出终结符 <strong>&lt;EOS&gt;</strong>。</p><h3 id="改进集束搜索">改进集束搜索</h3><p>机器翻译就是给定输入，找到一个最后可能的输出，即最大化概率 <span class="math inline">\(P(y^{\langle 1 \rangle},...,y^{\langle T_y \rangle}|x)\)</span>。而集束搜索就是找到最大化这个概率（目标函数）的参数的一种非完全方法，该概率表示成： <span class="math display">\[P(y^{\langle 1 \rangle}|x)P(y^{\langle 2 \rangle}|x,y^{\langle 1 \rangle})...P(y^{&lt;T_y&gt;}|x,y^{\langle 1 \rangle},...,y^{\langle T_y-1 \rangle})\]</span> 由于这些概率值通常远小于 1。连乘会造成数值下溢，即电脑的浮点表示不能精确地储存，因此我们通常对其取对数，即最大化： <span class="math display">\[\sum_{t=1}^{T_y}logP(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},...,y^{\langle t-1 \rangle})\]</span> 集束搜索还存在一个问题就是，对于一个很长的句子，那么这个概率的可能就会很小。也就是说这个目标函数比较倾向于简短的翻译结果，我们可以通过归一化，即除以翻译结果的单词数量（实践中是单词数量的 <span class="math inline">\(\alpha\)</span> 次方，这是一个超参数），来减少对输出长的结果的惩罚，这个也叫归一化的对数似然目标函数。 <span class="math display">\[\frac{\sum_{t=1}^{T_y}logP(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},...,y^{\langle t-1 \rangle})}{T_y^\alpha}\]</span></p><h3 id="误差分析">误差分析</h3><p>因为集束搜索是一种启发式（近似）搜索算法，不总能输出可能性最大的句子，那么如何才能知道束宽的设置是否合适呢？如果 Seq2Seq 模型解码结果不好，那么造成这个不好结果是 RNN 还是集束搜索算法的参数呢？</p><p>假设模型的输出 <span class="math inline">\(\hat y\)</span> 为 <strong>Jane visited Africa last September.</strong>，人工翻译 <span class="math inline">\(y^*\)</span> 为 <strong>Jane visits Africa in September.</strong>。很明显模型的翻译结果不对，我们可以计算 <span class="math inline">\(P(\hat y|x)\)</span> 和 <span class="math inline">\(P(y^*|x)\)</span>：</p><ul><li><span class="math inline">\(P(\hat y|x) &lt; P(y^*|x)\)</span>，表示存在更好的翻译结果 <span class="math inline">\(y^*\)</span>，而模型没搜索到，即集束搜索出问题了；</li><li><span class="math inline">\(P(\hat y|x) \geq P(y^*|x)\)</span>，表示更好的翻译结果 <span class="math inline">\(y^*\)</span> 在模型中的概率反而更小，即 RNN 编码解码出问题了。</li></ul><p>因此可以通过遍历开发集中的所有数据，分析更有可能是集束搜索有问题还是 RNN 有问题。</p><h2 id="bleu">BLEU</h2><p>机器翻译的一大难题是一个法语句子可以有多种英文翻译而且都同样好，所以当有多个同样好的答案时，怎样评估一个机器翻译系统呢？假如一个法语句子：<strong>Le chat est sur le tapis</strong>，人工翻译的参考译文为：</p><ul><li><strong>The cat is on the mat.</strong></li><li><strong>There is a cat on the mat.</strong></li></ul><p>这两个英语句子都准确地翻译了这个法语句子。BLEU (Bilingual Evaluation Understudy) 可以评价机器译文与参考译文的相似度，它能够自动地计算一个分数来衡量机器翻译的好坏。首先来看一种比较简单的方法： <span class="math display">\[P=\frac{m}{\omega_t}\]</span> 其中 <span class="math inline">\(m\)</span> 表示在参考译文中出现的机器译文中的单词数，<span class="math inline">\(\omega_t\)</span> 表示机器译文词的总数，例如机器译文：<strong>the the the the the the the.</strong>，相似度 <span class="math inline">\(P=\frac{7}{7}=1\)</span>。但是这个翻译并不好，因为参考译文中的 <strong>the</strong> 没那么多，所以改良一下，给它加个上限： <span class="math display">\[Count_{clip}(word)=min\lbrace Count(word), MaxRefCount(word)\rbrace\]</span> 其中 <span class="math inline">\(Count(word)\)</span> 表示单词在机器译文中出现的次数，<span class="math inline">\(MaxRefCount(word)\)</span> 表示该单词在参考译文中出现的最大次数。<strong>the</strong> 在机器译文中出现了 7 次所以 <span class="math inline">\(Count(word)=7\)</span>；<strong>the</strong> 在第一个参考译文中出现了两次，在第二个参考译文中出现了 1 次，所以 <span class="math inline">\(MaxRefCount(word)=2\)</span>，进而： <span class="math display">\[P=\frac{Count_{clip}(word)}{\omega_t}=\frac{2}{7}\]</span> 根据定义，<span class="math inline">\(\omega_t\)</span> 的计算公式如下所示： <span class="math display">\[\omega_t=\sum_{word \in \hat y}Count(word)\]</span> 现实情况中，使用单个词衡量相似度效果往往不好，对 n-gram 求平均能够有效改善上述问题。因此，对于整个测试语料，n-gram 相似度的计算公式如下： <span class="math display">\[P_n=\frac{\sum_{n-gram\in \hat y}Count_{clip}(n-gram)}{\sum_{n-gram\in \hat y}Count(n-gram)}\]</span> 所以 BLEU 的计算公式如下： <span class="math display">\[BLEU=BP\bullet exp(\frac{1}{N}\sum_{n=1}^{N}p_n)\]</span> 其中 <span class="math inline">\(BP\)</span> 为简短惩罚，当机器译文的长度大于参考译文时，惩罚因子为 1，否则如下： <span class="math display">\[BP=exp\Big(1-\frac{\text{机器译文长度}}{\text{参考译文长度}}\Big)\]</span></p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Papineni, K., et al. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;花了几天时间总结了一下滤波器，发现滤波器还分时域和频域，涨知识了。突然想起来课程中还有集束搜索和 BLEU 这部分内容，并没有出现在序列学习的实验中，所以还是先把这部分内容再学习学习。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>卷积与滤波器</title>
    <link href="https://pengzhendong.cn/2018/11/20/convolution-and-filters/"/>
    <id>https://pengzhendong.cn/2018/11/20/convolution-and-filters/</id>
    <published>2018-11-20T08:16:03.000Z</published>
    <updated>2018-11-20T12:34:36.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>开完题了，论文的审稿意见也下来了。不出意料，有两个评委给了 No，一个给了 Yes。值得开心的是他们都说这是一个新颖的想法，不足还是自己的写作方面，没有把模型说清楚，而且实验做的也不够充分，接下来可能就是要慢慢改了。循环神经网络部分的实验内容也总结完了，虽然还是模模糊糊，但是这些东西大体上在我看来也没那么高深莫测，倒是一些细节方面确实挺难的。</p><a id="more"></a><h2 id="卷积运算">卷积运算</h2><p>在学习卷积神经网络之前需要再好好巩固一下什么是卷积运算，然后顺便把大四学习的滤波器的内容总结一下。知乎上有不少通俗易懂的解释可以参考<a href="https://www.zhihu.com/question/22298352" target="_blank" rel="noopener">通俗易懂地理解卷积</a>，其实卷积是之前在<a href="/2018/06/06/Optimization-algorithms">优化算法</a>中提到的移动平均的推广。</p><h3 id="定义">定义</h3><p><span class="math inline">\(f\)</span> 和 <span class="math inline">\(g\)</span> 的卷积写为 <span class="math inline">\((f*g)(n)\)</span>，其离散的定义为： <span class="math display">\[(f*g)[n]=\sum_{\tau=-\infty}^\infty f[\tau]g[n-\tau]\]</span> 连续的定义为：</p><p><span class="math display">\[(f*g)(n)=\int_{-\infty}^\infty f(\tau)g(n-\tau)d\tau\]</span> 其中 <span class="math inline">\(n=\tau+(n-\tau)\)</span>，借鉴一下马同学在知乎中的<a href="如何通俗易懂地解释卷积？%20-%20马同学的回答%20-%20知乎%20https://www.zhihu.com/question/22298352/answer/228543288">例子</a>，离散卷积的应用场景：两个普通骰子点数加起来等于四的概率。 <span class="math display">\[f[1]g[3]+f[2]g[2]+f[3]g[1]\]</span> 符合卷积的定义，写成标准形式就是： <span class="math display">\[(f*g)[4]=\sum_{m=1}^3f[4-m]g[m]\]</span> 连续卷积的应用场景：追踪飞船的位置 <span class="math inline">\(f(t)\)</span>，由于噪声的影响，我们需要对得到的结果进行加权平均，时间上越近的测量结果越相关，相关函数为 <span class="math inline">\(g(t)\)</span>，所以对飞船的位置的估计为： <span class="math display">\[\int_0^T f(t)g(T-t)dt\]</span> 这就是连续的卷积，也就是将信号 <span class="math inline">\(f(t)\)</span> 和翻转平移后的信号 <span class="math inline">\(g(t)\)</span> 进行积分。在卷积神经网络中，卷积的第一个参数 <span class="math inline">\(f\)</span> 通常叫做输入，第二个参数 <span class="math inline">\(g\)</span> 通常叫做核函数，输出有时候叫特征映射。</p><h3 id="计算离散卷积">计算离散卷积</h3><p>计算离散卷积 <span class="math inline">\(f[n]*g[n]\)</span> 一般有三种方法：</p><ol type="1"><li>直接计算</li><li>快速傅里叶变换</li><li>分段卷积</li></ol><p>第一种方法就是直接根据定义来计算，第二种和第三种方法则都用到了快速傅里叶变换的知识，第三种方法是先将信号分成一小段一小段再以第二种方法来计算，时间复杂度会小一点，这里就只介绍第二种方法。三种方法的时间复杂度可以参考<a href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF" target="_blank" rel="noopener">维基百科</a>。</p><h4 id="快速傅里叶变换">快速傅里叶变换</h4><blockquote><p>两个离散信号在时域(time domain)做卷积相当于这两个信号在频域(frequence domain)相乘。</p></blockquote><p><span class="math display">\[y[t]=f[t]*g[t]\leftrightarrow Y[f]=F[f]G[f]\]</span></p><p>根据定义不难证明以上公式，由于乘法比较简单，因此在计算卷积的时候先将信号从时域转成频域，然后计算 <span class="math inline">\(Y[f]\)</span> ，在将计算结果用傅里叶变换的逆变换转回时域。</p><h2 id="滤波器">滤波器</h2><p>卷积运算通常用于图像处理领域中的滤波操作，首先先来看看数字图像处理领域的女神 Lena。由于这张图包含了各种细节、平滑区域、阴影和纹理，因此广泛用于图像处理。</p><p>这是一张 400*400 三通道的图片，为了更方便演示算法，我们通常在灰度图上进行操作（Matlab 中可以使用 <code>rgb2gray()</code> 函数获取图像的灰度值）。那么如何把灰度图和波联系起来呢？我们取灰度图的<strong>第一行</strong>像素，然后根据灰度值画出曲线就能得到波：</p><p><img src="/2018/11/20/convolution-and-filters/lena.png"></p><blockquote><p>图像的频率反映了图像的像素灰度在空间中变化的情况，是灰度在平面空间上的梯度。</p></blockquote><p>图中曲线波动较大代表灰度图明暗差距大的地方，即高频成分较强，低频成分较弱；而波动较小代表灰度图明暗差距较小的地方，即低频成分较强，高频成分较弱。</p><p>这段话虽然能理解，但是学了傅里叶变换之后感觉懵懵的，总是觉得这一整个波不就是由同样的正弦波组成的吗？后来才醒悟过来，所谓的高频低频是相对的。先举个例子两张图片，一面墙壁的图像和国际象棋棋盘，前者灰度值分布平坦，其低频成分就较强，而高频成分较弱；而后者具有快速空间变化的图像来说，其高频成分会相对较强，低频则较弱。那么在一张图片中怎么理解呢？那就是将需要比较的两个地方分别截取出来，然后进行周期性延拓，因此波动较大的地方截取出来周期性延拓，进行傅里叶变换后，得到一系列正弦波，高频的正弦波就比较强（相比较于时域比较平坦的区域）。</p><p>滤波器根据滤波的目的可以分为两种，通过低频的滤波器称为低通滤波器，通过高频的滤波器称为高通滤波器。实现滤波的方式也分为两种，空间滤波和频域滤波。</p><h3 id="空间滤波器">空间滤波器</h3><p>空间滤波器指对图像一个邻域内的像素执行<strong>预定义的操作</strong>，滤波产生一个新像素，它的坐标等于邻域中心的坐标，滤波器的中心访问图像的每一个像素后就生成了滤波后的图像。通常会将滤波的结果存在新的图像中，避免改变图像内容的同时进行滤波操作。通常使用奇数尺寸 <span class="math inline">\(3\times 3\)</span> 的滤波器，对一张 <span class="math inline">\(4\times 4\)</span>的图像进行滤波，第一行第一个像素和第三行第二个像素的滤波过程如下图所示：</p><p><img src="/2018/11/20/convolution-and-filters/a.png"></p><p>图像边界的像素点没有那么多邻域，通常需要零填充（如下图所示）或者其他操作，然后对中间的像素进行滤波操作。</p><p><img src="/2018/11/20/convolution-and-filters/b.png"></p><p>根据上面提到的预定义的操作，空间滤波分为线性空间滤波和非线性空间滤波。非线性空间滤波例如统计排序滤波器（中值、最大值和最小值）和自适应滤波器等等。举个例子，最大值滤波器就是输出邻域内的像素的灰度值的最大值，如下图所示：</p><p><img src="/2018/11/20/convolution-and-filters/c.png"></p><p><span class="math inline">\(7=max(4, 7, 7, 2, 2, 5, 2, 4, 3)\)</span>，就是说新的图像的灰度值为原图像邻域内像素的灰度值的最大值。线性空间滤波器有一个和邻域对应的滤波器系数矩阵 <span class="math inline">\(\omega\)</span>，在滤波过程中，每个邻域内的像素的灰度值分别与对应位置的系数相乘，最后再相加，如下图所示：</p><p><img src="/2018/11/20/convolution-and-filters/d.png"></p><p>对于图像 <span class="math inline">\(f\)</span> 中任意一点 <span class="math inline">\((x, y)\)</span>，滤波器的响应 <span class="math inline">\(g(x, y)\)</span> 是滤波器系数与该滤波器所包围的像素的灰度值的乘积之和： <span class="math display">\[g(x, y)=\omega(-1, -1)f(x-1, y-1)+\omega(-1, 0)f(x-1, y)...\omega(1, 1)f(x+1, y+1)\]</span> 对于奇数尺寸 <span class="math inline">\((2a+1)\times (2b+1)\)</span> 的滤波器，有： <span class="math display">\[g(x, y)=\sum_{s=-a}^a\sum_{t=-b}^b\omega(s, t)f(x+s, y+t)\]</span> 这个操作叫做<strong>相关</strong>，有点类似于二维卷积操作，不过卷积需要滤波器翻转： <span class="math display">\[\omega(x, y)*f(x, y)=\sum_{s=-a}^a\sum_{t=-b}^b\omega(s, t)f(x-s, y-t)\]</span> 所以如果滤波器是对称的，那么相关和卷积将得到相同的结果，我们将翻转后的滤波器系数和图像进行卷积即可实现线性空间滤波操作。</p><h4 id="边缘提取">边缘提取</h4><p>大四选修数字图像处理的实验三就要求实现四种（Sobel 算子、Prewitt 算子、Roberts 算子和 Marr 算子）边缘提取函数（空间高通滤波），代码也都托管在 <a href="https://github.com/pengzhendong/MatlabDIP/tree/master/lab2" target="_blank" rel="noopener">Github</a>。不同的边缘提取函数的区别就是算子的不同，即滤波器系数矩阵不同，这里只详细介绍一下 Sobel 算子：</p><p><img src="/2018/11/20/convolution-and-filters/sobel.png"></p><p>用这两个算子与原图像做卷积运算可以分别得到纵向和横向灰度值的梯度（即变化率），像素两边的灰度值差距越大，卷积的结果的绝对值也就越大，因此可以得到图像的边缘：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[img, map] = imread(<span class="string">'Lena.jpg'</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">131</span>), imshow(img);</span><br><span class="line"></span><br><span class="line">hx = [<span class="number">-1</span> <span class="number">-2</span> <span class="number">-1</span>; <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>; <span class="number">1</span> <span class="number">2</span> <span class="number">1</span>];</span><br><span class="line">hy = hx';</span><br><span class="line">Gx = conv2(im2double(img), hx);</span><br><span class="line">Gy = conv2(im2double(img), hy);</span><br><span class="line">sobel = <span class="built_in">abs</span>(Gx) + <span class="built_in">abs</span>(Gy);</span><br><span class="line">subplot(<span class="number">132</span>), imshow(sobel);</span><br><span class="line"></span><br><span class="line">threshold = <span class="built_in">max</span>(<span class="built_in">max</span>(sobel)) * <span class="number">0.18</span>;</span><br><span class="line">sobel(sobel &gt;= threshold) = <span class="number">1</span>;</span><br><span class="line">sobel(sobel &lt; threshold) = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">133</span>), imshow(sobel);</span><br></pre></td></tr></table></figure><p>得到横向和纵向的梯度后，使用以下公式计算灰度的大小（注意是矩阵元素的平方 <code>sqrt(Gx.^2+Gy.^2)</code>）： <span class="math display">\[G=\sqrt{G_x^2+G_y^2}\]</span> 但是为了提高运算效率，通常使用不开方的近似值，即使会损失一定的精度： <span class="math display">\[|G|=|G_x|+|G_y|\]</span> 最后可以进行阈值处理，将灰度图变成二值图像，让检测的边缘更加明显。其他的算子如下所示：</p><ul><li>Roberts 算子：<code>hx = [-1 -1 -1; 0 0 0; 1 1 1]; hy = hx';</code></li><li>Prewitt 算子：<code>hx = [-1 0; 0 1]; hy = [0 -1; 1 0];</code></li><li>...</li></ul><h3 id="频域滤波器">频域滤波器</h3><p>实验二要求实现三种（理想、布特沃斯和高斯滤波）低通滤波器和高通滤波器，由于时域上的卷积操作等于频域上的乘积操作，因此线性空间滤波和频域滤波一一对应，但是频域滤波不能进行非线性滤波。</p><h4 id="频谱图">频谱图</h4><p>傅里叶变换可以将信号从时域变换成频域，在数字图行处理中时域体现为空间上的分布，因此傅里叶变换可以将图像的灰度分布函数变成图像的频率分布函数。在做傅里叶变换的时候相当于是先将图片做周期性延拓，然后再进行傅里叶变换，通常我们只取一个周期分析，越亮表示该频率的幅值越大。</p><p>由于图像是一个<strong>实数</strong>信号，可以在数学上严格证明，它的傅里叶变换后的频域信号关于 0 频轴对称。所以频谱图中四个角为低频，中间为高频，而且低频幅值较大。为了便于频域的滤波和频谱的分析，常常在变换之前进行频谱的中心化。离中心越近，频率越低，离中心越远，频率越高，类似于二维的坐标轴。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[img, map] = imread(<span class="string">'Lena.jpg'</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line">subplot(<span class="number">131</span>), imshow(img);</span><br><span class="line">subplot(<span class="number">132</span>), f = fft2(img), imshow(<span class="built_in">log</span>(<span class="number">1</span>+<span class="built_in">abs</span>(f)), []);</span><br><span class="line">subplot(<span class="number">133</span>), f = fftshift(f), imshow(<span class="built_in">log</span>(<span class="number">1</span>+<span class="built_in">abs</span>(f)), []);</span><br></pre></td></tr></table></figure><p>由于幅度值范围很大，所以在显示频谱图之前要取对数处理；<code>imshow(I,[])</code>对取对数后的值进行归一化，自动拉伸动态范围，增大对比度； <code>fftshift()</code> 将低频调整到中间，高频在外围。</p><h4 id="理想低通滤波器">理想低通滤波器</h4><p>这里就只在详细介绍理想低通滤波器，它由下面的函数确定： <span class="math display">\[\begin{align*}H(u, v)=\begin{cases}1 &amp; D(u, v) \leq D_0 \\\0 &amp; D(u, v) &gt; D_0\end{cases}\end{align*}\]</span> 其中 <span class="math inline">\(D_0\)</span> 是正常数，<span class="math inline">\(D(u, v)\)</span> 是频域中的点 <span class="math inline">\((u, v)\)</span> 和中心的距离，即 <span class="math display">\[D(u, v)=\sqrt{(u-P/2)^2+(v-Q/2)^2}\]</span> <span class="math inline">\(P, Q\)</span> 是频域图的尺寸。“理想”的意思是在以 0 频率为中心，半径为 <span class="math inline">\(D_0\)</span> 的圆内，所有频率无衰减地通过，圆外地所有频率则被完全过滤。滤波代码和效果如下所示：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[img, map] = imread(<span class="string">'Lena.jpg'</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line">D0 = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">221</span>), imshow(img);</span><br><span class="line">subplot(<span class="number">222</span>), f = fftshift(fft2(img)), imshow(<span class="number">1</span>+<span class="built_in">log</span>(<span class="built_in">abs</span>(f)), []);</span><br><span class="line"></span><br><span class="line">[P, Q] = <span class="built_in">size</span>(f);</span><br><span class="line">H = <span class="built_in">zeros</span>(P, Q);</span><br><span class="line"><span class="keyword">for</span> u = <span class="number">1</span>:P</span><br><span class="line">    <span class="keyword">for</span> v = <span class="number">1</span>:Q</span><br><span class="line">        D = <span class="built_in">sqrt</span>((u - <span class="built_in">round</span>(P/<span class="number">2</span>))^<span class="number">2</span> + (v - <span class="built_in">round</span>(Q/<span class="number">2</span>))^<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span> D &lt;= D0</span><br><span class="line">            H(u, v) = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            H(u, v) = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">end</span>;</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line">f = f .* H;</span><br><span class="line"></span><br><span class="line">img = uint8(<span class="built_in">real</span>(ifft2(ifftshift(f))));</span><br><span class="line">subplot(<span class="number">223</span>), imshow(img);</span><br><span class="line">subplot(<span class="number">224</span>), f = fftshift(fft2(img)), imshow(<span class="built_in">log</span>(<span class="built_in">abs</span>(f)), []);</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>, surf(<span class="number">1</span>:P, <span class="number">1</span>:Q, H);</span><br><span class="line">axis([<span class="number">1</span> m <span class="number">1</span> n <span class="number">0</span> <span class="number">1</span>]);</span><br></pre></td></tr></table></figure><p>对于一幅图像来说，低频就是边缘以内的内容，也就是图像的大部分信息，即图像的大致概貌和轮廓，是图像的近似信息。高频指图像边缘的灰度值变化快，图像的细节处也是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。另外噪点也是因为像素点灰度值明显不一样了，即高频部分，因此噪声在高频。因此低通滤波器可以去噪，高通滤波器可以去模糊，各种滤波器对应的公式如下所示，n 阶布特沃斯滤波器的阶数趋于正无穷时，就是理想滤波器，对频率的截止也就会更加尖锐。</p><table><colgroup><col style="width: 26%"><col style="width: 73%"></colgroup><thead><tr class="header"><th>滤波器</th><th>函数</th></tr></thead><tbody><tr class="odd"><td>理想低通滤波器</td><td><span class="math inline">\(\begin{equation}H(u, v)=\begin{cases}1 &amp; D(u, v) \leq D_0 \\\ 0 &amp; D(u, v) &gt; D_0\end{cases}\end{equation}\)</span></td></tr><tr class="even"><td>n 阶布特沃斯低通滤波器</td><td><span class="math inline">\(H(u,v)=\frac{1}{1+\Big[D(u, v)/D_0\Big]^{2n}}\)</span></td></tr><tr class="odd"><td>高斯低通滤波器</td><td><span class="math inline">\(H(u, v)=e^{-D^2(u, v)/2D_0^2}\)</span></td></tr><tr class="even"><td>理想高通滤波器</td><td><span class="math inline">\(\begin{equation}H(u, v)=\begin{cases}0 &amp; D(u, v) \leq D_0 \\\ 1 &amp; D(u, v) &gt; D_0\end{cases}\end{equation}\)</span></td></tr><tr class="odd"><td>n 阶布特沃斯高通滤波器</td><td><span class="math inline">\(H(u,v)=\frac{1}{1+\Big[D_0/D(u, v)\Big]^{2n}}\)</span></td></tr><tr class="even"><td>高斯高通滤波器</td><td><span class="math inline">\(H(u, v)=1-e^{-D^2(u, v)/2D_0^2}\)</span></td></tr></tbody></table><h2 id="参考文献">参考文献</h2><ol type="1"><li>ViatorSun. 图像傅里叶变换的频谱图. https://blog.csdn.net/ViatorSun/article/details/82387854</li><li>冈萨雷斯. 数字图像处理</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;开完题了，论文的审稿意见也下来了。不出意料，有两个评委给了 No，一个给了 Yes。值得开心的是他们都说这是一个新颖的想法，不足还是自己的写作方面，没有把模型说清楚，而且实验做的也不够充分，接下来可能就是要慢慢改了。循环神经网络部分的实验内容也总结完了，虽然还是模模糊糊，但是这些东西大体上在我看来也没那么高深莫测，倒是一些细节方面确实挺难的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>触发词检测</title>
    <link href="https://pengzhendong.cn/2018/11/15/trigger-word-detection/"/>
    <id>https://pengzhendong.cn/2018/11/15/trigger-word-detection/</id>
    <published>2018-11-15T12:16:00.000Z</published>
    <updated>2018-11-15T13:22:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>花了一些时间填补了 WAV 文件的基础知识和快速傅里叶变换算法的内容。终于可以继续学习深度学习啦！前段时间买了个小米的小爱同学，用来睡前关灯还是挺方便的，这次的实验就是研究小爱同学究竟是如何被唤醒的。</p><a id="more"></a><h2 id="触发词检测">触发词检测</h2><p>这次的任务是收集语音数据集并且实现触发词（也称关键字或者唤醒字）检测。举个例子：小米的小爱同学，在检测到触发词“小爱同学”后，就会被唤醒。这里的触发词是 “activate”。</p><h3 id="数据合成创建语音数据集">数据合成：创建语音数据集</h3><p>在真实场景中，还会有其他声音，例如负面词（一些其他的词）和环境背景噪声（会和触发词混合在一起出现）。很难收集大量的音频，通常都是单独下载背景噪声然后将触发词、负面词与背景噪声混合。</p><ul><li>正面词</li></ul><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/activate.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></center><ul><li>负面词</li></ul><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/negative.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></center><ul><li>背景噪声</li></ul><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/background.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></center><h4 id="波形图">波形图</h4><p>声音是弹性介质中压力变化形式的机械能，这些压力变化来自振动源的波传播。声音在介质中传播时，会造成介质的压缩和稀疏，从而引起原有环境压强的变化。压缩是比环境压力更高的时段，稀疏是压力低于环境压力的时段。</p><p><img src="/2018/11/15/trigger-word-detection/voice.png"></p><p>波形图 (Waveform) 如上所示，总压强等于环境静态压强（即标准大气压 <span class="math inline">\(P\)</span>: <span class="math inline">\(10^5\)</span> Pa）加上声音扰动带来的动态压强（即声压 <span class="math inline">\(P_A\)</span>）。① 时段声压为 0 即为无声阶段；② 时段有声音扰动；③ 为大气压；④ 为瞬时声压。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fs = <span class="number">44100</span></span><br><span class="line">rate, data = wavfile.read(<span class="string">'audio_examples/example_train.wav'</span>)</span><br><span class="line">time = np.linspace(<span class="number">0</span>, len(data)/fs, num=len(data))</span><br><span class="line">plt.xlabel(<span class="string">'time/s'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'$P_A$'</span>)</span><br><span class="line">plt.plot(time, data) </span><br><span class="line"> </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/11/15/trigger-word-detection/wav.png"></p><p>这里的 WAV 文件使用的是 16 位量化数字，因此声压的取值范围是 (-32768, 32767)，音频时长为 10 秒。波形图看不出声音的特征，因此需要对其使用傅里叶变换，得到频谱图再分析声音的特征。</p><h2 id="波形图-1">波形图</h2><p>通过傅立叶变换可以得到信号的频谱，傅立叶变换有一个假设就是信号是平稳的，即信号的统计特性不随时间变化。声音信号就不是平稳信号，在很长的一段时间内，有很多信号会出现，然后立即消失。如果将这信号全部进行傅立叶变换，就不能反映声音随时间的变化。</p><h3 id="短时傅里叶变换">短时傅里叶变换</h3><p>声音信号虽然不是平稳信号，但在较短的一段时间内可以看作是平稳的，所以解决方案是取一小段进行傅立叶变换，即短时傅立叶变换（Short-time Fourier transform）。</p><h4 id="窗函数">窗函数</h4><p>从一段长的信号截取一段信号（通常在0.02~0.05s，称为一帧），相当于将原始信号乘以一个方窗，而方窗的傅里叶变换并不是理想的冲击函数，所以用 <code>sinc</code> 函数，<code>sinc</code> 较高的副瓣意味着在真实频点以外，副瓣的位置上的频谱也会不为零。如果在副瓣的位置上恰好有一个幅度很小的信号，就会被完全淹没。解决方案是使用窗函数，代替简单地截取一段信号，在窗的边缘，信号会乘上一个很小的数。这又会导致边缘数据并没有充分被利用，两个相邻窗之间的信号没有完全反映到频谱当中。因此解决办法是两个相邻的窗有一定的重叠，同时如果需要恢复成为时间序列，也能弥补窗函数带来的影响。总之一句话就是取一小段信号进行短时傅里叶变换会导致数据丢失，因此两个相邻的窗口之间需要有一定的重叠，重叠取加可以选择为窗长度的 50% 或者 25%。</p><h4 id="声谱图">声谱图</h4><p>语音的时域分析和频域分析是两种语音分析方法，但是这两种分析方法都有局限性。时域分析对语音信号的频率没有直观的了解，而频域分析出的特征中又没有语音信号随时间变化的关系。<strong>声谱图</strong>（语谱图）是一种三位频谱，表示语音频谱随着时间变化的图形。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">rate, data = wavfile.read(<span class="string">'audio_examples/example_train.wav'</span>)</span><br><span class="line">nfft = <span class="number">200</span>     <span class="comment"># 截取的信号长度，即窗长</span></span><br><span class="line">fs = <span class="number">44100</span>     <span class="comment"># 采样频率</span></span><br><span class="line">noverlap = <span class="number">120</span> <span class="comment"># 重叠长度</span></span><br><span class="line">pxx, freqs, bins, im = plt.specgram(data[:,<span class="number">0</span>], nfft, fs, noverlap = noverlap)</span><br></pre></td></tr></table></figure><p><img src="/2018/11/15/trigger-word-detection/spectrogram.png"></p><p>横坐标为时间，纵坐标为频率。任意给定频率成分，在给定时刻的强弱用相应点的色调的浓淡来表示，颜色越深表示语音能量越强（声音更加响亮）。10 秒音频输出 <code>pxx</code> 的时间步长度为：<span class="math inline">\(5511=\frac{10\times fs-nfft}{nfft-overlap}+1\)</span>，在原始音频中一共有 441000 个时间步，而在声谱图中一共有 5511 个时间步，因此前者每个时间步代表 0.000023 秒，后者代表 0.0018 秒。也就是说 10 秒的时间可以被离散成不同的数值，例如 GRU 的输出离散成 1375 个时间步，也就是每个时间步 0.0072 秒，模型的输出就表示这个 0.0072 秒内是否有人说过触发词。</p><h2 id="生成训练示例">生成训练示例</h2><p>为了合成一个训练样本，需要：</p><ul><li>随机选择一个 10 秒的背景音频剪辑</li><li>随机将 0-4 个正面音频片段插入此 10 秒剪辑中</li><li>随机将 0-2 个反面音频片段插入此 10 秒剪辑中</li></ul><p>通常使用 <code>pydub</code> 来处理音频。 Pydub 将原始音频文件转换为 Pydub 数据结构列表，使用 1ms 作为离散化间隔，因此 10 秒剪辑一共有 10,000 个时间步。我们希望在背景噪声中插入多个触发词和负面，同时不希望这些词重叠（声音合成而不是声音拼接，最终输出音频还是 10 秒）。</p><p>首先初始化背景噪声的标签，因为里面还没有触发词，所以对于所有的 <span class="math inline">\(t\)</span>，有 <span class="math inline">\(y^{\langle t \rangle}=0\)</span>。在插入触发词的时候，还需要更新标签 <span class="math inline">\(y^{\langle t \rangle}\)</span>。假设在第 5 秒的时候插入了触发词（即输出的第 <span class="math inline">\(687=int(1375\times\frac{5}{10})\)</span> 个时间步），那么我们希望模型在接下来一小段时间内能检测到就行，我们选择 50 个时间步，也就是 <span class="math inline">\(y^{\langle 688 \rangle} = y^{\langle 689 \rangle} = \cdots = y^{\langle 737 \rangle} = 1\)</span>。如下图所示，每个触发词后 50 个时间步的标签都是 1：</p><p><img src="/2018/11/15/trigger-word-detection/label_diagram.png"></p><p>合成训练数据还有一个好处就是容易生成标签，如果在录制声音的时候手动标记是非常耗时的。</p><h3 id="辅助函数">辅助函数</h3><p>为了实现训练集的合成，还需要以下辅助函数，这些函数都使用 1 毫秒离散化间隔，即 10 秒的音频总是被离散化成 10,000 步。</p><ol type="1"><li><p><code>get_random_time_segment(segment_ms)</code> 从背景音频中选择指定长度的随机时间片段；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_random_time_segment</span><span class="params">(segment_ms)</span>:</span></span><br><span class="line">    segment_start = np.random.randint(low=<span class="number">0</span>, high=<span class="number">10000</span>-segment_ms) <span class="comment"># 防止超出 10s</span></span><br><span class="line">    segment_end = segment_start + segment_ms - <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (segment_start, segment_end)</span><br></pre></td></tr></table></figure></li><li><p><code>is_overlapping(segment_time, existing_segments)</code> 判断时间片是否与先前的时间片重叠；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_overlapping</span><span class="params">(segment_time, previous_segments)</span>:</span></span><br><span class="line">    segment_start, segment_end = segment_time</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Initialize overlap as a "False" flag.</span></span><br><span class="line">    overlap = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: loop over the previous_segments start and end times.</span></span><br><span class="line">    <span class="comment"># Compare start/end times and set the flag to True if there is an overlap.</span></span><br><span class="line">    <span class="keyword">for</span> previous_start, previous_end <span class="keyword">in</span> previous_segments:</span><br><span class="line">        <span class="keyword">if</span> segment_start &lt;= previous_end <span class="keyword">and</span> segment_end &gt;= previous_start:</span><br><span class="line">            overlap = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> overlap</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">overlap1 = is_overlapping((<span class="number">950</span>, <span class="number">1430</span>), [(<span class="number">2000</span>, <span class="number">2550</span>), (<span class="number">260</span>, <span class="number">949</span>)])</span><br><span class="line">overlap2 = is_overlapping((<span class="number">2305</span>, <span class="number">2950</span>), [(<span class="number">824</span>, <span class="number">1532</span>), (<span class="number">1900</span>, <span class="number">2305</span>), (<span class="number">3424</span>, <span class="number">3656</span>)])</span><br><span class="line">assertFalse(overlap1)</span><br><span class="line">assertTrue(overlap2)</span><br></pre></td></tr></table></figure></li><li><p><code>insert_audio_clip(background, audio_clip, existing_times)</code> 使用上述两个辅助函数在背景音频的随机时间处插入一个音频时间片，需要完成 4 步：</p><ol type="1"><li>以毫秒为单位随机选择时间片；</li><li>确保时间片与先前的时间片都不重叠，否则返回上一个步骤重新选择时间片；</li><li>将新时间片添加到现有时间片列表中，以跟踪插入的所有时间片；</li><li>使用 pydub 将音频重叠在背景噪声中（使用 overlay 函数）。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_audio_clip</span><span class="params">(background, audio_clip, previous_segments)</span>:</span></span><br><span class="line">    <span class="comment"># Get the duration of the audio clip in ms</span></span><br><span class="line">    segment_ms = len(audio_clip)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Use one of the helper functions to pick a random time segment onto which to insert </span></span><br><span class="line">    <span class="comment"># the new audio clip. (≈ 1 line)</span></span><br><span class="line">    segment_time = get_random_time_segment(segment_ms)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Check if the new segment_time overlaps with one of the previous_segments. If so, keep </span></span><br><span class="line">    <span class="comment"># picking new segment_time at random until it doesn't overlap. (≈ 2 lines)</span></span><br><span class="line">    <span class="keyword">while</span> is_overlapping(segment_time, previous_segments):</span><br><span class="line">        segment_time = get_random_time_segment(segment_ms)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Add the new segment_time to the list of previous_segments (≈ 1 line)</span></span><br><span class="line">    previous_segments.append(segment_time)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 4: Superpose audio segment and background</span></span><br><span class="line">    new_background = background.overlay(audio_clip, position = segment_time[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> new_background, segment_time</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">5</span>)</span><br><span class="line">audio_clip, segment_time = insert_audio_clip(backgrounds[<span class="number">0</span>], activates[<span class="number">0</span>], [(<span class="number">3790</span>, <span class="number">4400</span>)])</span><br><span class="line">audio_clip.export(<span class="string">"insert_test.wav"</span>, format=<span class="string">"wav"</span>)</span><br><span class="line">print(<span class="string">"Segment Time: "</span>, segment_time)</span><br><span class="line">IPython.display.Audio(<span class="string">"insert_test.wav"</span>)</span><br></pre></td></tr></table></figure></li></ol><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/insert_test.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></center><ol start="4" type="1"><li><p><code>insert_ones(y, segment_end_ms)</code> 在 ”activate” 之后插入 1 到标签向量 <span class="math inline">\(y\)</span> 中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_ones</span><span class="params">(y, segment_end_ms)</span>:</span></span><br><span class="line">    <span class="comment"># duration of the background (in terms of spectrogram time-steps)</span></span><br><span class="line">    segment_end_y = int(segment_end_ms * Ty / <span class="number">10000.0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Add 1 to the correct index in the background label (y)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(segment_end_y + <span class="number">1</span>, segment_end_y + <span class="number">51</span>):</span><br><span class="line">        <span class="keyword">if</span> i &lt; Ty:</span><br><span class="line">            y[<span class="number">0</span>, i] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><p>注意标签一共有 1375 个时间步，因此不能越界。测试一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr1 = insert_ones(np.zeros((<span class="number">1</span>, Ty)), <span class="number">9700</span>)</span><br><span class="line">plt.plot(insert_ones(arr1, <span class="number">4251</span>)[<span class="number">0</span>,:])</span><br><span class="line">print(<span class="string">"sanity checks:"</span>, arr1[<span class="number">0</span>][<span class="number">1333</span>], arr1[<span class="number">0</span>][<span class="number">634</span>], arr1[<span class="number">0</span>][<span class="number">635</span>])</span><br></pre></td></tr></table></figure><p>sanity checks: 0.0 1.0 0.0</p><p><img src="/2018/11/15/trigger-word-detection/output1.png"></p></li></ol><h3 id="生成训练样本">生成训练样本</h3><p>实现 <code>create_training_example()</code> 来生成所有训练样本：</p><ol type="1"><li>将标签向量 <span class="math inline">\(y\)</span> 初始化为零值的 <span class="math inline">\((1，T_y)\)</span> numpy 数组；</li><li>将已存在时间片集合初始化为空列表；</li><li>随机选择 0 至 4 个 “activate” 音频剪辑，并将其插入 10 秒剪辑，记着将标签插入标签向量 <span class="math inline">\(y\)</span> 中的正确位置；</li><li>随机选择 0 到 2 个负面音频片段，并将它们插入 10 秒片段。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_training_example</span><span class="params">(background, activates, negatives)</span>:</span></span><br><span class="line">    <span class="comment"># Set the random seed</span></span><br><span class="line">    np.random.seed(<span class="number">18</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Make background quieter</span></span><br><span class="line">    background = background - <span class="number">20</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Initialize y (label vector) of zeros (≈ 1 line)</span></span><br><span class="line">    y = np.zeros((<span class="number">1</span>, Ty))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Initialize segment times as empty list (≈ 1 line)</span></span><br><span class="line">    previous_segments = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Select 0-4 random "activate" audio clips from the entire list of "activates" recordings</span></span><br><span class="line">    number_of_activates = np.random.randint(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">    random_indices = np.random.randint(len(activates), size=number_of_activates)</span><br><span class="line">    random_activates = [activates[i] <span class="keyword">for</span> i <span class="keyword">in</span> random_indices]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Loop over randomly selected "activate" clips and insert in background</span></span><br><span class="line">    <span class="keyword">for</span> random_activate <span class="keyword">in</span> random_activates:</span><br><span class="line">        <span class="comment"># Insert the audio clip on the background</span></span><br><span class="line">        background, segment_time = insert_audio_clip(background, random_activate, previous_segments)</span><br><span class="line">        <span class="comment"># Retrieve segment_start and segment_end from segment_time</span></span><br><span class="line">        segment_start, segment_end = segment_time</span><br><span class="line">        <span class="comment"># Insert labels in "y"</span></span><br><span class="line">        y = insert_ones(y, segment_end_ms=segment_end)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select 0-2 random negatives audio recordings from the entire list of "negatives" recordings</span></span><br><span class="line">    number_of_negatives = np.random.randint(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">    random_indices = np.random.randint(len(negatives), size=number_of_negatives)</span><br><span class="line">    random_negatives = [negatives[i] <span class="keyword">for</span> i <span class="keyword">in</span> random_indices]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 4: Loop over randomly selected negative clips and insert in background</span></span><br><span class="line">    <span class="keyword">for</span> random_negative <span class="keyword">in</span> random_negatives:</span><br><span class="line">        <span class="comment"># Insert the audio clip on the background </span></span><br><span class="line">        background, _ = insert_audio_clip(background, random_negative, previous_segments)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Standardize the volume of the audio clip </span></span><br><span class="line">    background = match_target_amplitude(background, <span class="number">-20.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Export new training example </span></span><br><span class="line">    file_handle = background.export(<span class="string">"train"</span> + <span class="string">".wav"</span>, format=<span class="string">"wav"</span>)</span><br><span class="line">    print(<span class="string">"File (train.wav) was saved in your directory."</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><h2 id="开发测试集">开发测试集</h2><p>为了测试模型，实验记录了 25 个样本的开发集。虽然训练数据是合成的，但是开发集应该与实际输入具有相同的分布，因此实验手工标记了 25 个 10 秒钟的音频剪辑。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load preprocessed training examples</span></span><br><span class="line">X = np.load(<span class="string">"./XY_train/X.npy"</span>)</span><br><span class="line">Y = np.load(<span class="string">"./XY_train/Y.npy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load preprocessed dev set examples</span></span><br><span class="line">X_dev = np.load(<span class="string">"./XY_dev/X_dev.npy"</span>)</span><br><span class="line">Y_dev = np.load(<span class="string">"./XY_dev/Y_dev.npy"</span>)</span><br></pre></td></tr></table></figure><h2 id="模型">模型</h2><p>实验模型使用一维的卷积层、GRU 层和全连接层，首先载入相关的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model, Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> GRU, Bidirectional, BatchNormalization, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br></pre></td></tr></table></figure><h3 id="构建模型">构建模型</h3><p>模型结构如下图所示：</p><p><img src="/2018/11/15/trigger-word-detection/model.png"></p><p>该模型的一个关键步骤是一维卷积步骤，它的输入是 5511 个时间步的频谱，然后输出一个 1375 个时间步的输出。从计算的角度而言，卷积层有助于加速模型，经过卷积层后 GRU 仅处理 1375 个时间步而不是 5511 个时间步。两层 GRU 从左往右读入绪论，然后使用全连接神经网络加 Sigmoid 层对 <span class="math inline">\(y^{\langle t \rangle}\)</span> 进行预测，判断用户是否刚刚说过 “activate”。</p><p>注意：这里使用的是单向 RNN，因为如果想要使用双向 RNN，那么就必须等待整个 10 秒的音频被记录下来后从能确定音频片段是都具有 “activate”。</p><p>可以通过以下 4 个步骤来实现模型：</p><ol type="1"><li><p>使用 <code>Conv1D()</code> 来实现卷积层，有 196 个卷积核，每个卷积核的大小为 15(<code>kernel_size=15</code>)，并且步长为 4；</p></li><li><p>用 <code>X = GRU(units = 128, return_sequences = True)(X)</code> 实现 GRU 层，设置 <code>return_sequences=True</code> 确保所有时间步的隐藏状态都会喂给下一层，同时记得添加 Dropout 和 BatchNorm 层；</p></li><li><p>第二个 GRU 层，和上一个步骤类似，只不过多了一个 Dropout 层；</p></li><li><p>创建全连接层：</p><p><code>X = TimeDistributed(Dense(1, activation = "sigmoid"))(X)</code></p><p>这样全连接层后面就会跟一个 Sigmoid 层，TimeDistributed 可以让每个时间步的全连接层的参数一样。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">    X_input = Input(shape = input_shape)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: CONV layer</span></span><br><span class="line">    X = Conv1D(<span class="number">196</span>, <span class="number">15</span>, strides=<span class="number">4</span>)(X_input)             <span class="comment"># CONV1D</span></span><br><span class="line">    X = BatchNormalization()(X)                         <span class="comment"># Batch normalization</span></span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)                           <span class="comment"># ReLu activation</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: First GRU Laye</span></span><br><span class="line">    X = GRU(units = <span class="number">128</span>, return_sequences=<span class="literal">True</span>)(X)      <span class="comment"># GRU (use 128 units and return the sequences)</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line">    X = BatchNormalization()(X)                         <span class="comment"># Batch normalization</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Second GRU Layer</span></span><br><span class="line">    X = GRU(units = <span class="number">128</span>, return_sequences=<span class="literal">True</span>)(X)      <span class="comment"># GRU (use 128 units and return the sequences)</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line">    X = BatchNormalization()(X)                         <span class="comment"># Batch normalization</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 4: Time-distributed dense layer</span></span><br><span class="line">    X = TimeDistributed(Dense(<span class="number">1</span>, activation = <span class="string">"sigmoid"</span>))(X) <span class="comment"># time distributed  (sigmoid)</span></span><br><span class="line"></span><br><span class="line">    model = Model(inputs = X_input, outputs = X)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = model(input_shape = (Tx, n_freq))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><h3 id="拟合测试模型">拟合&amp;测试模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.0001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=opt, metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line">model.fit(X, Y, batch_size = <span class="number">5</span>, epochs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">loss, acc = model.evaluate(X_dev, Y_dev)</span><br><span class="line">print(<span class="string">"Dev set accuracy = "</span>, acc)</span><br></pre></td></tr></table></figure><p>这个问题的样本不太均衡，因为神经网络很有可能就将所有的数据判断为 0，即不是触发词。因此需要定义更多有用的指标，例如 F1 分数或者 Precision/Recall。</p><h3 id="预测">预测</h3><p>模型训练完成后就可以用来对真实音频进行预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect_triggerword</span><span class="params">(filename)</span>:</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x = graph_spectrogram(filename)</span><br><span class="line">    <span class="comment"># the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model</span></span><br><span class="line">    x  = x.swapaxes(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">    predictions = model.predict(x)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(predictions[<span class="number">0</span>,:,<span class="number">0</span>])</span><br><span class="line">    plt.ylabel(<span class="string">'probability'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure><p>计算出在每个输出步骤检测到 “activate” 这个词的概率，当概率超过某个阈值时，就可以触发鸣响。此外，在检测到触发词后，对于后面连续的许多值，标签可能都接近于 1，但是我们只想响一次，因此可以设置每 75 个输出时间步最多响一次，类似于计算机视觉的非最大抑制作用。</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">chime_file = <span class="string">"audio_examples/chime.wav"</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chime_on_activate</span><span class="params">(filename, predictions, threshold)</span>:</span></span><br><span class="line">    audio_clip = AudioSegment.from_wav(filename)</span><br><span class="line">    chime = AudioSegment.from_wav(chime_file)</span><br><span class="line">    Ty = predictions.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># Step 1: Initialize the number of consecutive output steps to 0</span></span><br><span class="line">    consecutive_timesteps = <span class="number">0</span></span><br><span class="line">    <span class="comment"># Step 2: Loop over the output steps in the y</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Ty):</span><br><span class="line">        <span class="comment"># Step 3: Increment consecutive output steps</span></span><br><span class="line">        consecutive_timesteps += <span class="number">1</span></span><br><span class="line">        <span class="comment"># Step 4: If prediction is higher than the threshold and more than 75 consecutive output steps have passed</span></span><br><span class="line">        <span class="keyword">if</span> predictions[<span class="number">0</span>,i,<span class="number">0</span>] &gt; threshold <span class="keyword">and</span> consecutive_timesteps &gt; <span class="number">75</span>:</span><br><span class="line">            <span class="comment"># Step 5: Superpose audio and background using pydub</span></span><br><span class="line">            audio_clip = audio_clip.overlay(chime, position = ((i / Ty) * audio_clip.duration_seconds)*<span class="number">1000</span>)</span><br><span class="line">            <span class="comment"># Step 6: Reset consecutive output steps to 0</span></span><br><span class="line">            consecutive_timesteps = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    audio_clip.export(<span class="string">"chime_output.wav"</span>, format=<span class="string">'wav'</span>)</span><br></pre></td></tr></table></figure></p><h4 id="测试例子">测试例子</h4><p>原音频：</p><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/my_audio.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></center><p>接下来对该音频进行预测，如果检测到 “activate”，就发出鸣响：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">filename  = <span class="string">"audio_examples/my_audio.wav"</span><span class="string">"</span></span><br><span class="line"><span class="string">prediction = detect_triggerword(filename)</span></span><br><span class="line"><span class="string">chime_on_activate(filename, prediction, 0.5)</span></span><br><span class="line"><span class="string">IPython.display.Audio("</span>./chime_output.wav<span class="string">")</span></span><br></pre></td></tr></table></figure><p><img src="/2018/11/15/trigger-word-detection/output2.png"></p><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/chime_output.wav" type="audio/mpeg">Your browser does not support the audio element.</audio></center><p>Sigmoid 的输出大于 0.5，表示检测到了触发词，因此添加了鸣响。</p><h2 id="总结">总结</h2><p>终于完成了 Sequence 系列的实验，对触发词检测的流程有了个大致的了解，但是还是感觉神经网络就像炼丹，知道模型的结构这么设置有什么好处，但是还是不知道为什么要这么设置，都是靠直觉？</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>meelo. 短时傅里叶变换解析. https://www.cnblogs.com/meelo/p/5640009.html</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;花了一些时间填补了 WAV 文件的基础知识和快速傅里叶变换算法的内容。终于可以继续学习深度学习啦！前段时间买了个小米的小爱同学，用来睡前关灯还是挺方便的，这次的实验就是研究小爱同学究竟是如何被唤醒的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>快速傅里叶变换</title>
    <link href="https://pengzhendong.cn/2018/10/29/fast-fourier-transform/"/>
    <id>https://pengzhendong.cn/2018/10/29/fast-fourier-transform/</id>
    <published>2018-10-29T07:04:34.000Z</published>
    <updated>2018-10-29T11:34:59.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>终于下定决心要啃掉这块骨头。大四选修数字图像处理的时候，第一次接触傅里叶变换，然后实现了时间度复杂度为 <span class="math inline">\(O(n^2)\)</span> 的算法，后来才知道还有快速傅里叶变换，时间复杂度是 <span class="math inline">\(O(nlogn)\)</span>。</p><a id="more"></a><p>拉格朗日等数学家发现某些周期函数可以由三角函数的和表示，而傅里叶则猜测任意周期函数都可以写成三角函数的和，也就是高等数学中的<strong>傅里叶级数</strong>。大家当然都不相信啦，但又不能给出有力的论据。直到20年后（1829年）狄利克雷才给出了让人满意的答案：只有满足一定条件时，周期函数才能展开成傅里叶级数。这个条件被称为<strong>狄利克雷条件</strong>。傅里叶级数用吴文俊先生的话说就是：</p><blockquote><p>把质的困难转化成量的复杂</p></blockquote><p>而最早具有这种想法的人是泰勒，他在 1715 年研究出泰勒公式。泰勒级数把函数表达式转化为多项式函数来近似，是求导函数组成的特征函数和，反应变化剧烈程度。傅里叶级数是频谱叠加的三角函数和，反应变化频率本质属性。</p><blockquote><p>实函数的傅立叶级数和泰勒级数不过是观察复幂级数的两种不同方式</p></blockquote><h2 id="傅里叶级数">傅里叶级数</h2><p>傅里叶级数具体构造过程可以参考<a href="https://www.matongxue.com/madocs/619.html" target="_blank" rel="noopener">马同学高等数学</a>的文章。假设 <span class="math inline">\(f(x)\)</span> 的周期为 <span class="math inline">\(T\)</span>，并且满足狄利克雷条件，则构造结果如下所示： <span class="math display">\[f(x)=\frac{a_0}{2}+\sum_{n=1}^{\infty}\Big(a_ncos(\frac{2\pi nx}{T})+b_nsin(\frac{2\pi nx}{T})\Big),a_0\in\mathbb{R}\]</span> 这就是傅里叶级数，其中 <span class="math inline">\(a_n, b_n\)</span> 为傅里叶系数。利用三角函数的正交性等性质（详细推导过程可参考高数课本），可以推导出： <span class="math display">\[\begin{cases}a_n=\frac{2}{T}\int_{x_0}^{x_0+T}f(x)cos(\frac{2\pi nx}{T})dx \\\b_n=\frac{2}{T}\int_{x_0}^{x_0+T}f(x)sin(\frac{2\pi nx}{T})dx\end{cases}\]</span> 举个简单的例子，有以周期为 <span class="math inline">\(2\pi\)</span> 的三角波函数，在一个周期内的表达式为： <span class="math display">\[f(x)=\begin{cases}1+\frac{x}{\pi}, &amp; -\pi\leq x&lt;0 \\\1-\frac{x}{\pi}, &amp; 0\leq x&lt;\pi\end{cases}\]</span> 即 <span class="math inline">\(f(x)=1-2\times |nint(\frac{x}{2\pi})-\frac{x}{2\pi}|\)</span>，其中 <code>nint()</code> 为向下取整函数，在 Python 中相当于 <code>round()</code> 函数。由于 <span class="math inline">\(f(x)\)</span> 为偶函数，所以正弦分量的幅值 <span class="math inline">\(b_n=0\)</span>。解得:</p><p><span class="math display">\[f(x)=\frac{1}{2}+\frac{4}{\pi^2}\Big(cos(x)+\frac{cos(3x)}{3^2}+\frac{cos(5x)}{5^2}+...\Big)\]</span> 傅里叶级数实际上相当于是把 <span class="math inline">\(f(x)\)</span> 当做了基的向量。当 <span class="math inline">\(n\)</span> 取 5 时该函数的基为： <span class="math display">\[\lbrace 1, cos(x), cos(2x), cos(3x), cos(5x)\rbrace\]</span> 该函数相当于向量： <span class="math display">\[(1, \frac{4}{\pi^2}, 0, \frac{4}{3^2\pi^2}, 0, \frac{4}{5^2\pi^2})\]</span></p><p>根据这个向量就能得到函数的幅值频谱图，其中纵坐标为幅值，也就是上面的向量。横坐标为角频率（角速度的标量），也就是对应的基中的 <span class="math inline">\(\omega_n=\frac{2\pi n}{T}\)</span>，单位为 <span class="math inline">\(Hz\)</span>。</p><p><img src="/2018/10/29/fast-fourier-transform/5XSSNh.png"></p><p>非奇非偶函数既有正弦分量也有余弦分量，所以就需要有两个频域图。当 <span class="math inline">\(n\)</span> 取值越大，则越能逼近原函数。</p><h3 id="复数形式">复数形式</h3><p>傅里叶级数具有两个频域图，而另一种角度，即复数形式的傅里叶级数就可以结合正弦和余弦分量，详情可见<a href="https://www.matongxue.com/madocs/619.html" target="_blank" rel="noopener">马同学高等数学</a>。复数形式的傅里叶级数如下所示： <span class="math display">\[f(x)=\sum_{n=-\infty}^{\infty}c_ne^{i\frac{2\pi nx}{T}}\]</span> 其中 <span class="math display">\[c_n=\frac{1}{T}\int_{x_0}^{x_0+T}f(x)e^{-i\frac{2\pi nx}{T}}dx\]</span> 由于 <span class="math inline">\(c_n\)</span> 是复数，周期函数的频域图还是不好画，那复数形式有啥用？欸，先来看看非周期函数和傅里叶变换。</p><h2 id="傅里叶变换">傅里叶变换</h2><p>傅里叶级数只能用于周期函数，后来的数学家将其扩展到非周期函数上，其思想就是让周期 <span class="math inline">\(T\)</span> 趋于无穷。由傅里叶级数公式可知，两个相邻频域直接的差越小，即频率越密集，详情可见<a href="https://www.matongxue.com/madocs/712.html" target="_blank" rel="noopener">马同学高等数学</a>。因此时域上周期的函数其频域是离散的，在时域上非周期的函数其频域是连续的。对于非周期函数，周期趋于无穷，令 <span class="math inline">\(F(\omega_n)=T\times c_n\)</span>，有： <span class="math display">\[\begin{align*} f(x)&amp;=\lim_{T\rightarrow \infty}\sum_{n=-\infty}^{\infty}\frac{1}{T}F(\omega_n)e^{i\frac{2\pi nx}{T}} \\\&amp;=\lim_{T\rightarrow \infty}\frac{1}{2\pi}\sum_{n=-\infty}^{\infty}F(\omega_n)e^{i\omega_nx}(\omega_n-\omega_{n-1}) \\\&amp;=\frac{1}{2\pi}\int_{-\infty}^{\infty}F(\omega)e^{i\omega x}d\omega \\\\end{align*}\]</span> 其中 <span class="math display">\[F(\omega)=\int_{-\infty}^{\infty}f(x)e^{-i\omega x}dx\]</span> ### 总结</p><p><span class="math inline">\(F(\omega)\)</span> 就是傅里叶变换，得到的就是频域曲线，即各频率分量的幅值。<span class="math inline">\(f(x)\)</span> 是傅里叶变换的逆变换，所以时域和频域就是看待同一个数学对象的两种角度，可以来回切换。</p><h2 id="离散时间傅里叶变换">离散时间傅里叶变换</h2><p>上面提及的傅里叶变换 <span class="math inline">\(F(\omega)\)</span> 是连续时间傅里叶变换，即信号在时域上是连续的。但是计算机存储的信号都是采样得到的离散的、有限长的信号。在数学上可以用原信号与脉冲函数（具有筛选性）的乘积表示采样，假设采样周期为 <span class="math inline">\(T\)</span>，即每隔时间 <span class="math inline">\(T\)</span> 进行一次采样，则 <span class="math inline">\(f[nT]\)</span> 相当于 <span class="math inline">\(f(x)\)</span> 在时间点 <span class="math inline">\(nT\)</span> 上的采样，即： <span class="math display">\[\begin{align*}f_{discrete}(x)&amp;=f(x)\sum_{n=-\infty}^{\infty}\delta(x-nT) \\\&amp;=\sum_{n=-\infty}^{\infty}f[nT]\delta(x-nT) \\\\end{align*}\]</span> 所以 <span class="math display">\[F(e^{i\omega})=\sum_{n=-\infty}^{\infty}f[nT]e^{-i\omega nT}\]</span> 这就是离散时间傅里叶变换（DTFT），由于离散时间傅里叶变换可以被看作 <a href="https://zh.wikipedia.org/wiki/%E7%A6%BB%E6%95%A3%E6%97%B6%E9%97%B4%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2#DTFT%E4%B8%8EZ%E5%8F%98%E6%8D%A2" target="_blank" rel="noopener">Z 变换</a>的特例，因此通常用 <span class="math inline">\(F(e^{i\omega})\)</span> 表示离散时间傅里叶变换，其逆变换为： <span class="math display">\[f[nT]=\frac{1}{2\pi}\int_{-\infty}^{\infty}F(e^{i\omega})e^{i\omega nT}d\omega\]</span> 由于 <span class="math inline">\(e^{i\theta}\)</span> 的周期是 <span class="math inline">\(2\pi\)</span>，因此对于离散时间傅里叶变换，<span class="math inline">\(n\)</span> 为整数，只要采样周期 <span class="math inline">\(T\)</span> 设置为整数，就有： <span class="math display">\[\begin{align*}F(e^{i\omega})&amp;=\sum_{n=-\infty}^{\infty}f[nT]e^{-i\omega nT} \\\&amp;=\sum_{n=-\infty}^{\infty}f[nT]e^{-i(\omega nT+2\pi MnT)} \\\&amp;=\sum_{n=-\infty}^{\infty}f[nT]e^{-i(\omega+2\pi M)nT} \\\&amp;=F(e^{i(\omega+2\pi M)}) \\\\end{align*}\]</span> 其中 <span class="math inline">\(M\)</span> 为整数，所以离散时间傅里叶变换是频率 <span class="math inline">\(\omega\)</span> 的周期函数，周期为 <span class="math inline">\(2\pi\)</span>。而对于连续时间傅里叶变换，时间是连续的时间 <span class="math inline">\(x\)</span>，则： <span class="math display">\[\int_{-\infty}^{\infty}f(x)e^{-i\omega x}dx\neq\int_{-\infty}^{\infty}f(x)e^{-i(\omega +2\pi M)x}dx\]</span> ### 总结</p><p>时域和频域具有以下关系：</p><table><thead><tr class="header"><th>时域</th><th>频域</th></tr></thead><tbody><tr class="odd"><td>周期</td><td>离散</td></tr><tr class="even"><td>非周期</td><td>连续</td></tr><tr class="odd"><td>连续</td><td>非周期</td></tr><tr class="even"><td>离散</td><td>周期</td></tr></tbody></table><p>即大部分的信号为：连续时间周期信号、连续时间非周期信号、离散时间非周期信号和离散时间周期信号。而计算机存储的信号为时域上采样得到的信号，因此在计算机中我们用不到连续时域信号，以下内容均默认为时域离散，即频域是周期的。</p><h2 id="离散傅里叶变换">离散傅里叶变换</h2><p>由于计算机只能处理有限长的信号，对于时域周期的信号，则可以对其一个周期内的信号进行傅里叶变换，然后扩展到整个时域上。对于无限长非周期信号就需要对信号进行截断，然后再当成是周期信号的一个周期来处理</p><p>例如在 <span class="math inline">\([0, L]\)</span> 对离散时域的信号进行<strong>截断</strong>，设采样周期为 <span class="math inline">\(T\)</span>，则时域的采样点数为 <span class="math inline">\(N=\frac{L}{T}\)</span>，有： <span class="math display">\[f_{discrete}(x)=\sum_{n=0}^{N-1}f[nT]\delta(x-nT)\]</span> 截断后的离散时间傅里叶变换为： <span class="math display">\[F(e^{i\omega})=\sum_{n=0}^{N-1}f[nT]e^{-i\omega nT}\]</span> 由于非周期信号的频域是连续的，也无法表示，所以也要在频域上采样，就是相当于以截断的这一段信号当成是周期信号的一个周期，对周期信号的一个周期进行傅里叶变换。根据<a href="https://zh.wikipedia.org/wiki/%E9%87%87%E6%A0%B7%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">采样定理</a>，频域的采样间隔应为 <span class="math inline">\(\frac{1}{L}\)</span>，频域采样点数为： <span class="math display">\[\frac{1/T}{1/L}=N\]</span> 即频域采样的点数和时域采样同为 <span class="math inline">\(N\)</span>，频域的采样点为 <span class="math inline">\(\lbrace\omega_n=2\pi k/NT\rbrace_{0\leq k&lt;N}\)</span>。这就是离散傅里叶变换（DFT），令 <span class="math inline">\(T=1\)</span> 并且将其归一化，得： <span class="math display">\[F[k]=\sum_{n=0}^{N-1}f[n]e^{-i\frac{2\pi}{N}nk}, k=0, 1, ..., N-1\]</span> 逆变换为： <span class="math display">\[f[n]=\frac{1}{N}\sum_{k=0}^{N-1}F[k]e^{i\frac{2\pi}{N}nk}, n=0, 1, ..., N-1\]</span></p><h3 id="总结">总结</h3><p>综上所述，计算机对现实中的信号的时域采样（离散化）得到了离散时间傅里叶变换（DTFT），这个过程中频域会被周期化；然后对信号进行截断，即只收集一段时间的信号；继而对频域进行采样（离散化）得到离散周期傅里叶级数（DFS），这个过程中时域会被周期化。最后只取一个周期进行分析，即只取一个周期内的 <span class="math inline">\(N\)</span> 个采样点。</p><h2 id="快速傅里叶变换">快速傅里叶变换</h2><p>1965年，Cooley 和 Tukey 提出了计算离散傅里叶变换（DFT）的快速算法，将 DFT 的运算量减少了几个数量级。快速傅里叶变换（FFT）中的”快速”等价于快速排序中的“快速”。也就是说，我们需要在计算机上实现排序，有各种各样的排序算法，快速排序这个算法比较好用。快速傅里叶变换也一样，利用了<strong>分治</strong>策略，减小了算法的时间复杂度。对于 <span class="math inline">\(N\)</span> 点信号进行离散傅里叶变换，令 <span class="math inline">\(W_N=e^{-i\frac{2\pi}{N}}\)</span>，有： <span class="math display">\[F[k]=\sum_{n=0}^{N-1}f[n]W_N^{nk}, k=0, 1, ..., N-1\]</span> 直接计算的话，算法的时间复杂度为 <span class="math inline">\(N^2\)</span>。快速傅里叶变换算法就能像快速排序算法一样，将时间复杂度从 <span class="math inline">\(N^2\)</span> 降到 <span class="math inline">\(Nlog_2N\)</span>。快速傅里叶变换是根据离散傅里叶变换的奇、偶、虚、实等特性，对离散傅立叶变换的算法进行改进获得的，它对傅里叶变换的理论并没有新的发现，但是对于在计算机中应用离散傅立叶变换，可以说是进了一大步。</p><p>大部分快速傅里叶变换是基于 2 的，即信号的长度为 2 的整数幂（不足则补 0）。快速傅里叶算法每次将长度为 <span class="math inline">\(N\)</span> 的信号分解为两个长度为 <span class="math inline">\(\frac{N}{2}\)</span> 的信号进行处理（按奇数和偶数），即： <span class="math display">\[\begin{align*}F[k]&amp;=\sum_{n=0}^{N-1}f[n]W_N^{nk} \\\&amp;=\sum_{n=0}^{\frac{N}{2}-1}f[2n]W_N^{(2n)k}+\sum_{n=0}^{\frac{N}{2}-1}f[2n+1]W_N^{(2n+1)k} \\\\end{align*}\]</span> 因为 <span class="math display">\[W_N^{(2n)k}=e^{-i\frac{2\pi}{N}(2n)k}=e^{-i\frac{2\pi}{\frac{N}{2}}nk}=W_{\frac{N}{2}}^{nk}\]</span></p><p>所以 <span class="math display">\[F[k]=E[k]+W_N^kO[k], 0\leq k\leq N-1\]</span> 其中，偶数样本点信号的离散傅里叶变换为： <span class="math display">\[E[k]=\sum_{n=0}^{\frac{N}{2}-1}f[2n]W_{\frac{N}{2}}^{nk}\]</span> 奇数样本点信号的离散傅里叶变换为： <span class="math display">\[O[k]=\sum_{n=0}^{\frac{N}{2}-1}f[2n+1]W_{\frac{N}{2}}^{nk}\]</span> 由于 <span class="math inline">\(W_N^{nk}\)</span> 对 <span class="math inline">\(n\)</span> 和 <span class="math inline">\(k\)</span> 都具有周期性，即 <span class="math display">\[W_N^{nk}=W_N^{(n+N)k}=W_N^{n(k+N)}\]</span> 所以 <span class="math display">\[\begin{cases}E[k]=E[k+\frac{N}{2}] \\\O[k]=O[k+\frac{N}{2}]\end{cases}\]</span></p><h3 id="蝶形图">蝶形图</h3><p>以 <span class="math inline">\(N=8\)</span> 为例，通过蝶形图可视化快速傅里叶具体计算过程，有：</p><p><span class="math display">\[\begin{cases}F[0]=E[0]+W_8^0O[0] \\\... \\\F[4]=E[4]+W_8^4O[4]=E[4-\frac{8}{2}]+W_8^4O[4-\frac{8}{2}]=E[0]+W_8^4O[0] \\\...\end{cases}\]</span> 同理，可以继续分解直到最后，一共有 24 次加法操作。由于 <span class="math inline">\(W^0=1\)</span>，所以乘法操作的次数小于加法操作的次数。因此快速傅里叶变换的时间复杂度为 <span class="math inline">\(O(Nlog_2N)\)</span>。</p><h3 id="测试">测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFT</span><span class="params">(x)</span>:</span></span><br><span class="line">    x = np.asarray(x, dtype=float)</span><br><span class="line">    N = x.shape[<span class="number">0</span>]</span><br><span class="line">    n = np.arange(N)</span><br><span class="line">    k = n.reshape((N, <span class="number">1</span>))</span><br><span class="line">    M = np.exp(<span class="number">-2j</span> * np.pi * k * n / N)</span><br><span class="line">    <span class="keyword">return</span> np.dot(M, x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    x = np.random.random(<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    dft = DFT(x)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(end - start)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    fft = np.fft.fft(x)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(end - start)</span><br><span class="line"></span><br><span class="line">    ret = np.allclose(dft, fft)</span><br><span class="line">    print(ret)</span><br></pre></td></tr></table></figure><p>对于一个长度为 1024 的序列，手动实现的离散傅里叶变换算法需要的时间为 0.2748403549194336 秒，而<code>numpy</code> 的快速傅里叶变换算法只需要 0.0009996891021728516 秒，最终计算结果一致。</p><h2 id="总结-1">总结</h2><p>花了整整一周的时间终于总结完了快速傅里叶变换相关的内容，虽然复数部分不是很深入，但是目前至少能比较熟练得使用这个 20 世纪最伟大的算法了。以上内容之所以花了这么多时间，还是因为概念不清晰，了解傅里叶变换、离散时间傅里叶变换、离散傅里叶变换和快速傅里叶变换就花了不少时间，如果这次没有记录下来，我相信下次看到还是不会！</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>马同学高等数学. 如何理解傅立叶级数公式？. https://www.matongxue.com/madocs/619.html.</li><li>马同学高等数学. 从傅立叶级数到傅立叶变换. https://www.matongxue.com/madocs/712.html.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;终于下定决心要啃掉这块骨头。大四选修数字图像处理的时候，第一次接触傅里叶变换，然后实现了时间度复杂度为 &lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt; 的算法，后来才知道还有快速傅里叶变换，时间复杂度是 &lt;span class=&quot;math inline&quot;&gt;\(O(nlogn)\)&lt;/span&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>WAV 文件</title>
    <link href="https://pengzhendong.cn/2018/10/22/wav-file/"/>
    <id>https://pengzhendong.cn/2018/10/22/wav-file/</id>
    <published>2018-10-22T01:16:00.000Z</published>
    <updated>2018-10-22T03:22:47.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>距离上一篇博客已经过去了一个半月，这段时间看了几篇关于 Learning to Rank 的文章，老肖就很固执地想让我用到代码错误检测中去，我还是想再慢慢学一下推荐算法，看能不能做点小工作。同时这段时间想搭一个 BBS，于是升级重构了一下 phphub，算是捡起 Laravel 再学习了一下吧！深度学习也不能落下，继续搞起来。</p><a id="more"></a><h2 id="wav-文件">WAV 文件</h2><p>在触发词检测实验之前，先来学习一下 WAV 文件。根据百度百科的解释：</p><blockquote><p>WAV 为微软公司开发的一种声音文件格式，它符合RIFF (Resource Interchange File Format) 文件规范，用于保存 Windows 平台的音频信息资源，被 Windows 平台及其应用程序所广泛支持，该格式也支持 MSADPCM，CCITT A LAW 等多种压缩运算法，支持多种音频数字，取样频率和声道，标准格式化的 WAV 文件和 CD 格式一样，也是 44.1K 的取样频率，16 位量化数字，因此在声音文件质量和 CD 相差无几！</p></blockquote><p>表示 WAV 文件使用的是 44.1K 的采样频率，16位量化数字（即采样位数为 16）。音频文件记录的是空气压力随时间的变化，表示麦克风检测到的微小气压变化。在 DeepLearning 触发词检测实验提供的数据中，我们查看 <code>example_train.wav</code> 文件的属性可知：</p><ul><li>文件大小：1764044 字节</li><li>时长：00:00:10</li><li>比特率：1411 kbps</li></ul><p>这些值是怎么计算出来的呢？首先需要了解一下 WAV 格式文件的几个参数：</p><h3 id="采样频率">采样频率</h3><blockquote><p>指每秒钟取得声音样本的次数。采样的过程就是抽取某点的频率值，在一秒中内抽取的点越多，获取得频率信息更丰富，采样频率越高，声音的还原也就越真实越自然，但同时它占的资源比较多。</p></blockquote><p>现实的时间是连续的，而电脑却做不到在每个时刻都能记录声音，所以只能通过采样。由于人耳的分辨率很有限，太高的频率并不能分辨出来。22050 赫兹的采样频率是常用的，44100 赫兹已是 CD 音质，超过 48000 赫兹或 96000 赫兹的采样对人耳已经没有意义。实验数据的采样频率为 44100 赫兹，即每秒获取声音样本 44100 次。</p><h3 id="通道数">通道数</h3><blockquote><p>声音的通道的数目。常见的单声道和立体声（双声道），现在发展到了四声环绕（四声道）和5.1声道。</p></blockquote><p>实验数据为双声道音频，所以采样就是双份的，即一次采样包含两帧。</p><h3 id="采样位数">采样位数</h3><blockquote><p>声卡处理声音的解析度。这个数值越大，解析度就越高，录制和回放的声音就越真实。 采样位数也叫采样大小或量化位数。它是用来衡量声音波动变化的一个参数，也就是声卡的分辨率。它的数值越大，分辨率也就越高，录制和回放的声音就越真实。</p></blockquote><p>类似于图像的位数，位数越大，色彩越鲜艳，表达能力越强。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line">rate, data = wavfile.read(<span class="string">'example_train.wav'</span>)</span><br></pre></td></tr></table></figure><p>使用 <code>wavfile.read()</code> 获取 WAV 文件的采样频率和数据，<code>data.shape</code> 为：<code>(441000, 2)</code>。表示 10 秒音频一共获取声音样本 44100 × 10 次，每次采样包含两个声道（这里两个声道的声音一样）。<code>data</code> 的取值范围为 <code>(-32768, 32767)</code>，即 <span class="math inline">\(2^{16}\)</span>，表示每次的采样位数为 16。</p><h3 id="比特率">比特率</h3><blockquote><p>每秒平均传输的<strong>千比特</strong>数</p></blockquote><p><span class="math display">\[比特率 = 采样频率 × 通道数 × 采样位数 / 1000\]</span></p><p>根据以上公式可以计算出比特率为 1411.2 kbps，与文件属性一致。</p><h3 id="波形数据传输速率">波形数据传输速率</h3><blockquote><p>每秒平均传输的<strong>字节</strong>数</p></blockquote><p><span class="math display">\[波形传输速率 = 采样频率 × 通道数 × 采样位数 / 8\]</span></p><p>根据以上公式可以算出波形传输速率为 176400 字节每秒。</p><h3 id="文件大小">文件大小</h3><p><span class="math display">\[文件大小 = 波形数据传输速率 × 音频文件时长\]</span></p><p>根据以上公式可以算出文件大小为 176400,000 字节，即约为 1.68 MB，与文件属性一致。</p><h3 id="音频文件时长">音频文件时长</h3><p>也可以根据文件大小和波形数据传输速率计算出音频文件的时长： <span class="math display">\[音频文件时长 = 文件大小 / 波形数据传输速率\]</span> 同样可以验证音频文件的时长为 10 秒，在 Windows 操作系统中按整数显示音频文件的时长。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;距离上一篇博客已经过去了一个半月，这段时间看了几篇关于 Learning to Rank 的文章，老肖就很固执地想让我用到代码错误检测中去，我还是想再慢慢学一下推荐算法，看能不能做点小工作。同时这段时间想搭一个 BBS，于是升级重构了一下 phphub，算是捡起 Laravel 再学习了一下吧！深度学习也不能落下，继续搞起来。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WAV" scheme="https://pengzhendong.cn/tags/WAV/"/>
    
  </entry>
  
  <entry>
    <title>自然机器翻译</title>
    <link href="https://pengzhendong.cn/2018/09/10/neural-machine-translation/"/>
    <id>https://pengzhendong.cn/2018/09/10/neural-machine-translation/</id>
    <published>2018-09-10T05:47:00.000Z</published>
    <updated>2018-09-10T07:27:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>将人类可读的日期格式翻译成机器可读的日期格式，这个想法真的很有意思。这篇博客记录了如何使用 attention 机制来进行机器翻译。</p><a id="more"></a><h2 id="数据集">数据集</h2><p>首先来看一下数据集，即人类和机器可读的日期格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = <span class="number">10000</span></span><br><span class="line">dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)</span><br><span class="line">dataset[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[(&apos;9 may 1998&apos;, &apos;1998-05-09&apos;),</span><br><span class="line"> (&apos;10.09.70&apos;, &apos;1970-09-10&apos;),</span><br><span class="line"> (&apos;4/28/90&apos;, &apos;1990-04-28&apos;),</span><br><span class="line"> (&apos;thursday january 26 1995&apos;, &apos;1995-01-26&apos;),</span><br><span class="line"> (&apos;monday march 7 1983&apos;, &apos;1983-03-07&apos;),</span><br><span class="line"> (&apos;sunday may 22 1988&apos;, &apos;1988-05-22&apos;),</span><br><span class="line"> (&apos;tuesday july 8 2008&apos;, &apos;2008-07-08&apos;),</span><br><span class="line"> (&apos;08 sep 1999&apos;, &apos;1999-09-08&apos;),</span><br><span class="line"> (&apos;1 jan 1981&apos;, &apos;1981-01-01&apos;),</span><br><span class="line"> (&apos;monday may 22 1995&apos;, &apos;1995-05-22&apos;)]</span><br></pre></td></tr></table></figure><p>二元组的第一个元素是人类可读的日期格式，第二个是对应的机器可读的日期格式。假设人可读日期格式的最大长度为 30，机器的为 10，数据处理如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tx = <span class="number">30</span></span><br><span class="line">Ty = <span class="number">10</span></span><br><span class="line">X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)</span><br></pre></td></tr></table></figure><ul><li>X.shape: (10000, 30)</li><li>Y.shape: (10000, 10)</li><li>Xoh.shape: (10000, 30, 37)</li><li>Yoh.shape: (10000, 10, 11)</li></ul><p>一共有 10000 个样本，将样本以字符级别变成独热向量。人类可读的日期格式包含 26 个字母、10 个数字和 1 个分隔符；机器可读的日期格式包含 10 个数字和 1 个分割符。</p><h2 id="attention-机制">Attention 机制</h2><p>Attention 机制如下图左图所示；右图为一个 attention 步，计算的 attention 变量 <span class="math inline">\(\alpha^{\langle t, t&#39; \rangle}\)</span> 将被用来计算每个时间步 <span class="math inline">\(t\)</span> 的上下文变量 <span class="math inline">\(context^{\langle t \rangle}\)</span>。</p><table><thead><tr class="header"><th style="text-align: center;">Attention 机制</th><th style="text-align: center;">Attention step</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><img src="/2018/09/10/neural-machine-translation/attn_model.png"></td><td style="text-align: center;"><img src="/2018/09/10/neural-machine-translation/attn_mechanism.png"></td></tr></tbody></table><p>值得注意的是左图中有两个 LSTM 网络，下面在 attention 机制之前的是一个双向的 LSTM 网络，被称为 pre-attention Bi-LSTM；上面在 attention 机制之后的是一个单向的 LSTM 网络，被称为 post-attention LSTM。pre-attention Bi-LSTM 一共有 <span class="math inline">\(T_x\)</span> 个时间步，post-attention LSTM 一共有 <span class="math inline">\(T_y\)</span> 个时间步。</p><p>Post-attention LSTM 会将隐藏状态 <span class="math inline">\(s^{\langle t \rangle}\)</span> (与生成型模型不同，前一个字符和下一个字符之间没有很强的依赖，因此不是输出而是隐藏状态)和细胞的状态 <span class="math inline">\(c^{\langle t \rangle}\)</span> 传输给下一个时间步。模型的实现如下所示：</p><ol type="1"><li><p><strong><code>one_step_attention()</code></strong>：在时间步 <span class="math inline">\(t\)</span>，给定 pre-attention Bi-LSTM 的隐藏状态 <span class="math inline">\([a^{\langle 1 \rangle},a^{\langle 2 \rangle}, ..., a^{\langle T_x \rangle}]\)</span> 和 post-attention LSTM 上一个时间步的隐藏状态 <span class="math inline">\(s^{\langle t-1 \rangle}\)</span>。<code>one_step_attention()</code> 计算将会计算 attention 的权值和上下文变量： <span class="math display">\[context^{\langle t \rangle} = \sum_{t&#39; = 0}^{T_x} \alpha^{\langle t,t&#39;\rangle}a^{\langle t&#39;\rangle}\]</span> Keras 实现 <strong><code>one_step_attention()</code></strong> 代码如下所示： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">repeator = RepeatVector(Tx)</span><br><span class="line">concatenator = Concatenate(axis=<span class="number">-1</span>)</span><br><span class="line">densor1 = Dense(<span class="number">10</span>, activation = <span class="string">"tanh"</span>)</span><br><span class="line">densor2 = Dense(<span class="number">1</span>, activation = <span class="string">"relu"</span>)</span><br><span class="line">activator = Activation(softmax, name=<span class="string">'attention_weights'</span>) <span class="comment"># We are using a custom softmax(axis = 1) loaded in this notebook</span></span><br><span class="line">dotor = Dot(axes = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_step_attention</span><span class="params">(a, s_prev)</span>:</span></span><br><span class="line">    <span class="comment"># Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states "a" (≈ 1 line)</span></span><br><span class="line">    s_prev = repeator(s_prev)</span><br><span class="line">    <span class="comment"># Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)</span></span><br><span class="line">    concat = concatenator([a, s_prev])</span><br><span class="line">    <span class="comment"># Use densor1 to propagate concat through a small fully-connected neural network to compute the "intermediate energies" variable e. (≈1 lines)</span></span><br><span class="line">    e = densor1(concat)</span><br><span class="line">    <span class="comment"># Use densor2 to propagate e through a small fully-connected neural network to compute the "energies" variable energies. (≈1 lines)</span></span><br><span class="line">    energies = densor2(e)</span><br><span class="line">    <span class="comment"># Use "activator" on "energies" to compute the attention weights "alphas" (≈ 1 line)</span></span><br><span class="line">    alphas = activator(energies)</span><br><span class="line">    <span class="comment"># Use dotor together with "alphas" and "a" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)</span></span><br><span class="line">    context = dotor([alphas, a])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure></p></li><li><p><strong><code>model()</code></strong>：实现整个模型。首先运行 Bi-LSTM 获取 <span class="math inline">\([a^{\langle 1 \rangle},a^{\langle 2 \rangle}, ..., a^{\langle T_x \rangle}]\)</span>。然后运行 <code>one_step_attention()</code> <span class="math inline">\(T_y\)</span> 个时间步（每个时间步共享权值参数），对于每一个时间步，首先计算上下文变量，然后运行 post-attention LSTM，其输出经过带有 softmax 激活函数的全连接层网络后生成预测 <span class="math inline">\(\hat{y}^{\langle t \rangle}\)</span>。 Keras 实现 <strong><code>model()</code></strong> 代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">n_a = <span class="number">32</span></span><br><span class="line">n_s = <span class="number">64</span></span><br><span class="line">post_activation_LSTM_cell = LSTM(n_s, return_state = <span class="literal">True</span>)</span><br><span class="line">output_layer = Dense(len(machine_vocab), activation=softmax)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size)</span>:</span></span><br><span class="line">    <span class="comment"># Define the inputs of your model with a shape (Tx,)</span></span><br><span class="line">    <span class="comment"># Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)</span></span><br><span class="line">    X = Input(shape=(Tx, human_vocab_size))</span><br><span class="line">    s0 = Input(shape=(n_s,), name=<span class="string">'s0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_s,), name=<span class="string">'c0'</span>)</span><br><span class="line">    s = s0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize empty list of outputs</span></span><br><span class="line">    outputs = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)</span></span><br><span class="line">    a = Bidirectional(LSTM(n_a, return_sequences=<span class="literal">True</span>), input_shape=(m, Tx, n_a * <span class="number">2</span>))(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Iterate for Ty steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Ty):</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)</span></span><br><span class="line">        context = one_step_attention(a, s)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.B: Apply the post-attention LSTM cell to the "context" vector.</span></span><br><span class="line">        <span class="comment"># Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)</span></span><br><span class="line">        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)</span></span><br><span class="line">        out = output_layer(s)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.D: Append "out" to the "outputs" list (≈ 1 line)</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)</span></span><br><span class="line">    model = Model(inputs=[X, s0, c0], outputs=outputs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></li></ol><p>然后可以使用 <span class="math inline">\(summary()\)</span> 查看模型概况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><h2 id="优化">优化</h2><p>创建完模型后则需要需要定义损失函数、优化器和度量标准：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.005</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=opt, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><p>最后定义拟合模型的输入和输出，拟合模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s0 = np.zeros((m, n_s))</span><br><span class="line">c0 = np.zeros((m, n_s))</span><br><span class="line">outputs = list(Yoh.swapaxes(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">model.fit([Xoh, s0, c0], outputs, epochs=<span class="number">1</span>, batch_size=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h2 id="可视化-attention">可视化 Attention</h2><p>可以通过输出 attention 层的输出 <span class="math inline">\(\alpha^{\langle t, t&#39; \rangle}\)</span> 来可视化 Attention (实现细节可看 <code>mnt_utils.py</code>)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, <span class="string">"Tuesday 09 Oct 1993"</span>, num = <span class="number">7</span>, n_s = <span class="number">64</span>)</span><br></pre></td></tr></table></figure><p><img src="/2018/09/10/neural-machine-translation/output.png"></p><p>可以看到输出忽略了 "Tuesday"，在输出日期的时候，注意力明显也是放在输入的日期上，虽然图中月份部分翻译的注意力不是很明显。</p><h2 id="总结">总结</h2><p>机器翻译模型可以将输入的序列匹配成别的序列，注意力机制则可以允许网络在输出时聚焦于与输入相关的部分。总之，这个实验更加强化了 Encoder-Decoder 模型，首先将序列编码成一个定长表示，然后再解码成其他序列。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;将人类可读的日期格式翻译成机器可读的日期格式，这个想法真的很有意思。这篇博客记录了如何使用 attention 机制来进行机器翻译。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>词向量表示</title>
    <link href="https://pengzhendong.cn/2018/08/31/word-vector-representation/"/>
    <id>https://pengzhendong.cn/2018/08/31/word-vector-representation/</id>
    <published>2018-08-31T08:35:00.000Z</published>
    <updated>2018-08-31T12:18:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>实验和上一篇博客都使用了 Embedding，这篇博客正好可以加深对词向量和嵌入矩阵的理解。发现吴恩达课程里面很多内容他说在实验里有，但是我却没找到，例如本节中的负采样，难道他也喜欢挖坑不喜欢填？</p><a id="more"></a><h2 id="词汇表征">词汇表征</h2><p>在自然语言处理领域一个很重要的概念就是词嵌入 (Word Embeddings)，这是语言表示的一种方式，可以让算法理解一些<strong>类似</strong>的词。在使用词嵌入以前，通常用的都是词汇表，也就是将一个个单词变成独热向量，但是这样的表示没有办法让模型理解相似的词，引用夏树涛老师的一句话就是：独热向量的欧氏距离是没有意义的！</p><p>因此很有必要使用特征化的表示来表示每个词，也就是学习给每个词进行分类，例如词汇量为 5 的词汇表对应的嵌入矩阵如下所示：</p><table><thead><tr class="header"><th></th><th>Man</th><th>Woman</th><th>King</th><th>Queen</th><th>Apple</th><th>Orange</th></tr></thead><tbody><tr class="odd"><td>Gender</td><td>-1</td><td>1</td><td>-0.95</td><td>0.97</td><td>0.00</td><td>0.01</td></tr><tr class="even"><td>Royal</td><td>0.01</td><td>0.02</td><td>0.93</td><td>0.95</td><td>-0.01</td><td>0.00</td></tr><tr class="odd"><td>Age</td><td>0.03</td><td>0.02</td><td>0.7</td><td>0.69</td><td>0.03</td><td>-0.02</td></tr><tr class="even"><td>Food</td><td>0.09</td><td>0.01</td><td>0.02</td><td>0.01</td><td>0.95</td><td>0.97</td></tr></tbody></table><p>对于词汇表中任意单词的独热向量 <span class="math inline">\(O_i\)</span>，它的大小是 <span class="math inline">\(5\times 1\)</span> ，嵌入矩阵 <span class="math inline">\(E\)</span> 大小为 <span class="math inline">\(4\times 5\)</span> ， 那么 <span class="math inline">\(EO_i\)</span> 就可以得到词汇表中单词 <span class="math inline">\(i\)</span> 的嵌入向量。 模型在遇到 Apple 和 Orange 的时候就可以计算两个向量的余弦相似度，从而知道它们都是食物。在实践中可以使用 t-SNE 算法可视化高维特征向量，这个算法会将高维向量映射到一个二维空间中。</p><h3 id="余弦相似度">余弦相似度</h3><p>为了衡量两个单词的相似性，我们需要一种衡量两个单词的嵌入向量的方法。给定两个向量 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span>，其余弦相似度定义为： <span class="math display">\[\text{CosineSimilarity(u, v)} = \frac {u . v} {||u||_2 ||v||_2} = cos(\theta)\]</span> 其中分子是两个向量的点乘，分母是两个向量的二范数的乘积，<span class="math inline">\(\theta\)</span> 是两个向量形成的角度。两个向量越相似，余弦相似度就越接近于 1，不相似则取值会很小。图像如下图所示：</p><p><img src="/2018/08/31/word-vector-representation/cosine_sim.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosine_similarity</span><span class="params">(u, v)</span>:</span></span><br><span class="line">    distance = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the dot product between u and v (≈1 line)</span></span><br><span class="line">    dot = np.dot(u, v)</span><br><span class="line">    <span class="comment"># Compute the L2 norm of u (≈1 line)</span></span><br><span class="line">    norm_u = np.sqrt(np.sum(np.power(u,<span class="number">2</span>)))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the L2 norm of v (≈1 line)</span></span><br><span class="line">    norm_v = np.sqrt(np.sum(np.power(v,<span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># Compute the cosine similarity defined by formula (1) (≈1 line)</span></span><br><span class="line">    cosine_similarity = np.divide(dot, norm_u * norm_v)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cosine_similarity</span><br></pre></td></tr></table></figure><h3 id="学习词嵌入">学习词嵌入</h3><p>通常在使用词嵌入的时候，可以针对自己的数据集训练（也就是学习上面表格中的嵌入矩阵 <span class="math inline">\(E\)</span>），如果数据集不是很充分也可以从网上下载训练好的词嵌入模型。在实践中通常是建立一个语言模型进行学习词嵌入（也就是说不是单独地去训练词嵌入），例如使用神经网络预测序列的下一个单词，I want a glass of orange __。 在实践中通常的做法是使用一个固定的历史窗口，例如超参数窗口大小为 4，那么就只用前面 4 个单词来预测下一个单词。嵌入矩阵也是一个参数，可以在训练过程中学习出来。如果训练集中的句子比较复杂还可以考虑上下文，即用前面四个词和后面四个词来预测中间的词。所以如果使用预训练的嵌入矩阵，那么在这个步骤就可以再训练一下，或者不训练（把它当成超参数）直接使用。</p><h4 id="word2vec">Word2Vec</h4><p>Word2Vec 算法有两种模型 Skip-grams 和 CBOW，视频中只介绍了 Skip-grams，因为它在大型语料库中表现更好。这个模型的做法是随机选择一个单词 <span class="math inline">\(O_c\)</span> 作为上下文，然后在一定的词距内随机选另一个词 <span class="math inline">\(O_t\)</span> 作为待预测的词，即目标词，然后进行监督学习。虽然不太容易预测，但是这个模型可以很好地学习出嵌入矩阵，其中 <span class="math inline">\(e_c=EO_c\)</span>，对于 10,000 个单词的词汇表，softmax 预测目标词 <span class="math inline">\(O_t\)</span> 的概率为： <span class="math display">\[P(O_t|O_c) = \frac{e^{\theta_{t}^{T}e_{c}}}{\sum_{i=1}^{10,000}e^{\theta_{i}^{T}e_{c}}}\]</span> 其中 <span class="math inline">\(\theta_t\)</span> 是判断输出为 <span class="math inline">\(O_t\)</span> 这个类别的参数。损失函数为： <span class="math display">\[L(\hat y,y)=-\sum_{i=1}^{10,000}{y_{i}\log\hat y_{i}}\]</span> 损失函数中的 <span class="math inline">\(\hat y\)</span> 和 <span class="math inline">\(y\)</span> 都是独热向量。在计算概率的时候，分母要累加所有词汇在给定词汇情况下的概率，所以词汇量比较大的时候计算量比较大，因此可以采用分级 softmax 分类器或者<strong>负采样</strong>。分级 softmax 分类器的思想是使用霍夫曼树，先判断词属于前 5000 个还是后 5000 个，然后继续分析，最后时间复杂度就从 N 变成 logN。 不过需要注意的是，在实践中使用的不是完全平衡的分类树，而且通常常用词会放在树根。详细的内容可以参考原文献[2]。</p><h4 id="负采样">负采样</h4><p>Skim-grams 其实就是学习从 <span class="math inline">\(x\)</span> 映射到 <span class="math inline">\(y\)</span> 的监督模型，只不过时间复杂度有点大。而负采样需要构造一个新的监督学习问题，即给定一对单词，例如 orange 和 juice，预测它们是否属于一对上下文-目标词。例如有一个句子：I want a glass of orange juice to go along with my cereal.</p><p>首先从句子中采样得到一个上下文词 orange 和一个目标词 juice，然后标记为 1；然后去字典中随机选 k （这里 k=4）个单词，标记为 0（即使 of 也出现在句子中）：</p><table><thead><tr class="header"><th>Context</th><th>Word</th><th>Target?</th></tr></thead><tbody><tr class="odd"><td>orange</td><td>juice</td><td>1</td></tr><tr class="even"><td>orange</td><td>king</td><td>0</td></tr><tr class="odd"><td>orange</td><td>book</td><td>0</td></tr><tr class="even"><td>orange</td><td>the</td><td>0</td></tr><tr class="odd"><td>orange</td><td>of</td><td>0</td></tr></tbody></table><p>给定输入的上下文词 <span class="math inline">\(O_c\)</span> 和可能的目标词 <span class="math inline">\(O_t\)</span> ，定义一个逻辑回归模型，判断输出： <span class="math display">\[P(y=1|c,t)=\sigma(\theta_t^Te_c)\]</span> 即每个正样本都有 K 个对应的负样本来训练一个逻辑回归模型，相对而言每次迭代的成本更低，详细内容可以参考原文献[3]。在负采样的时候如果均匀采样，则学不到单词的分布，如果根据单词的频率采样又可能导致一些介词的频率很高，因此通常介于这两者之间： <span class="math display">\[P(\omega_i)=\frac{f(\omega_i)^{\frac{3}{4}}}{\sum_{j=1}^{10,000}f(\omega_i)^{\frac{3}{4}}}\]</span> 其中 <span class="math inline">\(f(\omega_i)\)</span> 是语料库中某个单词的词频。</p><h4 id="glove-词向量">GloVe 词向量</h4><p>GloVe 表示<strong>用于词表示的全局变量</strong>（Global vectors for word representation），假设 <span class="math inline">\(X_{ij}\)</span> 为单词 <span class="math inline">\(i\)</span> 在上下文词 <span class="math inline">\(j\)</span> 中出现的次数（即两个词出现在同一个窗口中的次数）。如果上下文词和目标词的范围定义为左右各 10 各词的话，根据定义有 <span class="math inline">\(X_{ij}=X_{ji}\)</span>，矩阵 <span class="math inline">\(X\)</span> 也叫做语料库的共现矩阵。GloVe 就是要最小化： <span class="math display">\[\text{minimize}\sum_{i=1}^{10,000}\sum_{j=1}^{10,000}f(X_{ij})(\theta_i^Te_j+b_i+\tilde{b_j}-logX_{ij})^2\]</span> 其中 <span class="math inline">\(b_i\)</span> 和 <span class="math inline">\(\tilde{b_j}\)</span> 是两个词向量的偏置项， 权重函数 <span class="math inline">\(f(X_{ij})\)</span> 是一个截断函数： <span class="math display">\[f(x) =\begin{cases}(x/x_{max})^\alpha &amp; \text{if $x&lt;x_{max}$ } \\\1 &amp; \text{otherwise}\end{cases}\]</span> 原文献中 <span class="math inline">\(\alpha\)</span> 的取值都是 0.75，而 <span class="math inline">\(x_{max}\)</span> 取值都是 100，损失函数的详细推导过程可以参考原文献[4]。</p><h2 id="单词类比任务">单词类比任务</h2><p><strong>man is to woman as king is to queen</strong>，即给定单词 a(man)、b(woman) 和 c(king)，需要找到一个单词 d 满足 <span class="math inline">\(e_b - e_a \approx e_d - e_c\)</span>。这里衡量 <span class="math inline">\(e_b - e_a\)</span> 就用余弦相似度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">complete_analogy</span><span class="params">(word_a, word_b, word_c, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="comment"># convert words to lower case</span></span><br><span class="line">    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the word embeddings v_a, v_b and v_c (≈1-3 lines)</span></span><br><span class="line">    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]</span><br><span class="line">    </span><br><span class="line">    words = word_to_vec_map.keys()</span><br><span class="line">    max_cosine_sim = <span class="number">-100</span>              <span class="comment"># Initialize max_cosine_sim to a large negative number</span></span><br><span class="line">    best_word = <span class="literal">None</span>                   <span class="comment"># Initialize best_word with None, it will help keep track of the word to output</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># loop over the whole word vector set</span></span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> words:        </span><br><span class="line">        <span class="comment"># to avoid best_word being one of the input words, pass on them.</span></span><br><span class="line">        <span class="keyword">if</span> w <span class="keyword">in</span> [word_a, word_b, word_c] :</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)  (≈1 line)</span></span><br><span class="line">        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># If the cosine_sim is more than the max_cosine_sim seen so far,</span></span><br><span class="line">            <span class="comment"># then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word (≈3 lines)</span></span><br><span class="line">        <span class="keyword">if</span> cosine_sim &gt; max_cosine_sim:</span><br><span class="line">            max_cosine_sim = cosine_sim</span><br><span class="line">            best_word = w</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> best_word</span><br></pre></td></tr></table></figure><h2 id="去偏词向量">去偏词向量</h2><p>首先计算一个向量 <span class="math inline">\(g = e_{woman}-e_{man}\)</span>，这个向量可以粗略地看成是性别 <strong>g</strong>ender。或者可以同时计算:</p><ul><li><p><span class="math inline">\(g_1 = e_{mother}-e_{father}\)</span></p></li><li><p><span class="math inline">\(g_2 = e_{girl}-e_{boy}\)</span></p></li></ul><p>最后取这三个向量的均值作为性别则会更加精确。可以通过以下代码验证我们的想法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">name_list = [<span class="string">'john'</span>, <span class="string">'marie'</span>, <span class="string">'sophie'</span>, <span class="string">'ronaldo'</span>, <span class="string">'priya'</span>, <span class="string">'rahul'</span>, <span class="string">'danielle'</span>, <span class="string">'reza'</span>, <span class="string">'katy'</span>, <span class="string">'yasmin'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> name_list:</span><br><span class="line">    <span class="keyword">print</span> (w, cosine_similarity(word_to_vec_map[w], g))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">List of names and their similarities with constructed vector:</span><br><span class="line">john [-0.23163356]</span><br><span class="line">marie [0.31559794]</span><br><span class="line">sophie [0.3186879]</span><br><span class="line">ronaldo [-0.31244797]</span><br><span class="line">priya [0.17632042]</span><br><span class="line">rahul [-0.16915471]</span><br><span class="line">danielle [0.24393299]</span><br><span class="line">reza [-0.0793043]</span><br><span class="line">katy [0.28310687]</span><br><span class="line">yasmin [0.23313858]</span><br></pre></td></tr></table></figure><p>可以看出，一些比较女性化的名字和 <span class="math inline">\(g\)</span> 的相似性大于0，比较男性化的名字和 <span class="math inline">\(g\)</span> 的相似性则小于 0。</p><h3 id="中和无性别单词的偏差">中和无性别单词的偏差</h3><p>下面是一些词和性别的相似性，虽然大部分的工程师是男性，但是这有点性别歧视了，而且这些词本身是不应该有性别之分的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">receptionist [0.33077942]</span><br><span class="line">technology [-0.13193732]</span><br><span class="line">teacher [0.17920923]</span><br><span class="line">engineer [-0.0803928]</span><br></pre></td></tr></table></figure><p>假如词嵌入是 50 维，则可以分为两部分：偏置方向 <span class="math inline">\(g\)</span> 和其余的 49 维 <span class="math inline">\(g_{\perp}\)</span>。其余的 49 维与性别无关，所以是正交的。下面的任务就是把向量 <span class="math inline">\(e_{receptionist}\)</span> 的 <span class="math inline">\(g\)</span> 方向置 0，得到 <span class="math inline">\(e_{receptionist}^{debiased}\)</span>。如下图所示：</p><p><img src="/2018/08/31/word-vector-representation/neutral.png"> <span class="math display">\[e^{bias\\_component} = \frac{e \cdot g}{||g||_2^2} * g\]</span></p><p><span class="math display">\[e^{debiased} = e - e^{bias\\_component}\]</span></p><p><span class="math inline">\(e^{bias\\_component}\)</span> 也就是 <span class="math inline">\(e\)</span> 在方向 <span class="math inline">\(g\)</span> 上的投影。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neutralize</span><span class="params">(word, g, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="comment"># Select word vector representation of "word". Use word_to_vec_map. (≈ 1 line)</span></span><br><span class="line">    e = word_to_vec_map[word]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute e_biascomponent using the formula give above. (≈ 1 line)</span></span><br><span class="line">    e_biascomponent = np.divide(np.dot(e, g), np.linalg.norm(g)**<span class="number">2</span>) * g</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Neutralize e by substracting e_biascomponent from it </span></span><br><span class="line">    <span class="comment"># e_debiased should be equal to its orthogonal projection. (≈ 1 line)</span></span><br><span class="line">    e_debiased = e - e_biascomponent</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> e_debiased</span><br></pre></td></tr></table></figure><h3 id="性别专用词均衡算法">性别专用词均衡算法</h3><p>均衡算法可以应用于两个只有性别之分的词。例如男演员 (actor) 和女演员 (actress)，可能女演员更接近保姆 (babysit)，通过对 babysit 的中和可以减少保姆和性别的关联性，但是还是不能保证这两种演员和其他词的关联性是否相同。均衡算法就可以处理这个问题，均衡算法的原理如下图所示：</p><p><img src="/2018/08/31/word-vector-representation/equalize.png"></p><p>原理就是保证这两个词到 49 维的 <span class="math inline">\(g_\perp\)</span> 的距离相等，公式参考 Bolukbasi et al., 2016： <span class="math display">\[\mu = \frac{e_{w1} + e_{w2}}{2}\]</span></p><p><span class="math display">\[\mu_{B} = \frac {\mu \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}\]</span></p><p><span class="math display">\[\mu_{\perp} = \mu - \mu_{B}\]</span></p><p><span class="math display">\[e_{w1B} = \frac {e_{w1} \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}\]</span></p><p><span class="math display">\[e_{w2B} = \frac {e_{w2} \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}\]</span></p><p><span class="math display">\[e_{w1B}^{corrected} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{e_{\text{w1B}} - \mu_B} {|(e_{w1} - \mu_{\perp}) - \mu_B)|}\]</span></p><p><span class="math display">\[e_{w2B}^{corrected} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{e_{\text{w2B}} - \mu_B} {|(e_{w2} - \mu_{\perp}) - \mu_B)|}\]</span></p><p><span class="math display">\[e_1 = e_{w1B}^{corrected} + \mu_{\perp}\]</span></p><p><span class="math display">\[e_2 = e_{w2B}^{corrected} + \mu_{\perp}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">equalize</span><span class="params">(pair, bias_axis, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Select word vector representation of "word". Use word_to_vec_map. (≈ 2 lines)</span></span><br><span class="line">    w1, w2 = pair</span><br><span class="line">    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Compute the mean of e_w1 and e_w2 (≈ 1 line)</span></span><br><span class="line">    mu = (e_w1 + e_w2) / <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Compute the projections of mu over the bias axis and the orthogonal axis (≈ 2 lines)</span></span><br><span class="line">    mu_B = np.divide(np.dot(mu, bias_axis), np.linalg.norm(bias_axis)**<span class="number">2</span>) * bias_axis</span><br><span class="line">    mu_orth = mu - mu_B</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 4: Use equations (7) and (8) to compute e_w1B and e_w2B (≈2 lines)</span></span><br><span class="line">    e_w1B = np.divide(np.dot(e_w1, bias_axis), np.linalg.norm(bias_axis)**<span class="number">2</span>) * bias_axis</span><br><span class="line">    e_w2B = np.divide(np.dot(e_w2, bias_axis), np.linalg.norm(bias_axis)**<span class="number">2</span>) * bias_axis</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Step 5: Adjust the Bias part of e_w1B and e_w2B using the formulas (9) and (10) given above (≈2 lines)</span></span><br><span class="line">    corrected_e_w1B = np.sqrt(np.abs(<span class="number">1</span> - np.sum(mu_orth**<span class="number">2</span>))) * np.divide(e_w1B - mu_B, np.abs(e_w1 - mu_orth - mu_B))</span><br><span class="line">    corrected_e_w2B = np.sqrt(np.abs(<span class="number">1</span> - np.sum(mu_orth**<span class="number">2</span>))) * np.divide(e_w2B - mu_B, np.abs(e_w2 - mu_orth - mu_B))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 6: Debias by equalizing e1 and e2 to the sum of their corrected projections (≈2 lines)</span></span><br><span class="line">    e1 = corrected_e_w1B + mu_orth</span><br><span class="line">    e2 = corrected_e_w2B + mu_orth</span><br><span class="line">                                                                </span><br><span class="line">    <span class="keyword">return</span> e1, e2</span><br></pre></td></tr></table></figure><p>通过均衡算法，两个只有性别之分的词和性别的相似度应该大致成相反数的关系。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Mikolov T, Chen K, Corrado G, et al. Efficient Estimation of Word Representations in Vector Space[J]. Computer Science, 2013.</li><li>Mikolov T, Sutskever I, Chen K, et al. Distributed Representations of Words and Phrases and their Compositionality[J]. 2013, 26:3111-3119.</li><li>Pennington J, Socher R, Manning C. Glove: Global Vectors for Word Representation[C]// Conference on Empirical Methods in Natural Language Processing. 2014:1532-1543.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;实验和上一篇博客都使用了 Embedding，这篇博客正好可以加深对词向量和嵌入矩阵的理解。发现吴恩达课程里面很多内容他说在实验里有，但是我却没找到，例如本节中的负采样，难道他也喜欢挖坑不喜欢填？&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Emojify 文本情感分析</title>
    <link href="https://pengzhendong.cn/2018/08/31/emojify/"/>
    <id>https://pengzhendong.cn/2018/08/31/emojify/</id>
    <published>2018-08-31T02:18:33.000Z</published>
    <updated>2018-08-31T04:18:57.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>写论文做实验的时候曾经想过用文本分类的模型，无奈样本太不均衡，所以最后用了自编码器提取特征。在 Coursera 的作业中，该实验分为两个小实验，一个是普通的文本分类，一个是使用 LSTM RNN 进行文本分类。</p><a id="more"></a><h2 id="baseline-模型-emojifier-v1">Baseline 模型: Emojifier-V1</h2><p>训练集 X 中包含 127 个句子，其标签为 0 到 4 分别对应一个 emoji 表情，如下图所示：</p><p><img src="/2018/08/31/emojify/data_set.png"></p><p>现在载入数据集，并且测试一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_train, Y_train = read_csv(<span class="string">'data/train_emoji.csv'</span>)</span><br><span class="line">X_test, Y_test = read_csv(<span class="string">'data/tesss.csv'</span>)</span><br><span class="line">maxLen = len(max(X_train, key=len).split())</span><br><span class="line"></span><br><span class="line">index = <span class="number">1</span></span><br><span class="line">print(X_train[index], label_to_emoji(Y_train[index]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I am proud of your achievements 😄</span><br></pre></td></tr></table></figure><h3 id="emojifier-v1-概况">Emojifier-V1 概况</h3><p>Emojifier-V1 的概况如下图所示：</p><p><img src="/2018/08/31/emojify/emo_model.png"></p><p>该模型比较简单，首先去训练好的 Embedding 中找到每个单词的嵌入，然后对句子中所有单词的嵌入求平均，将其作为输入，输入到一个多分类的全连接网络中，最后预测句子的情感。</p><h3 id="实现-emojifier-v1">实现 Emojifier-V1</h3><p>此处不再细述多分类的过程，模型的主要内容如下所示： <span class="math display">\[z^{(i)} = W \times avg^{(i)} + b\]</span></p><p><span class="math display">\[a^{(i)} = softmax(z^{(i)})\]</span></p><p><span class="math display">\[\mathcal{L}^{(i)} = - \sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)\]</span></p><p>其中 <span class="math inline">\(Yoh\)</span> (Y one hot) 是输出的独热编码。最后模型在训练集和测试集上的准确率能够达到 97% 和 86% ，同时对于一些在训练集中没有出现过的单词 (例如: adore) 也能得到不错的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_my_sentences = np.array([<span class="string">"i adore you"</span>, <span class="string">"i love you"</span>, <span class="string">"funny lol"</span>, <span class="string">"lets play with a ball"</span>, <span class="string">"food is ready"</span>, <span class="string">"you are not happy"</span>])</span><br><span class="line">Y_my_labels = np.array([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">2</span>], [<span class="number">1</span>], [<span class="number">4</span>],[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)</span><br><span class="line">print_predictions(X_my_sentences, pred)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 0.8333333333333334</span><br><span class="line"></span><br><span class="line">i adore you ❤️</span><br><span class="line">i love you ❤️</span><br><span class="line">funny lol 😄</span><br><span class="line">lets play with a ball ⚾</span><br><span class="line">food is ready 🍴</span><br><span class="line">you are not happy ❤️</span><br></pre></td></tr></table></figure><p>但是该模型并不能分析 not happy 是表示不开心，而只是简单地学习了 happy 这个单词。输出模型的混淆矩阵看一下模型的表现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(Y_test.shape)</span><br><span class="line">print(<span class="string">'           '</span>+ label_to_emoji(<span class="number">0</span>)+ <span class="string">'    '</span> + label_to_emoji(<span class="number">1</span>) + <span class="string">'    '</span> +  label_to_emoji(<span class="number">2</span>)+ <span class="string">'    '</span> + label_to_emoji(<span class="number">3</span>)+<span class="string">'   '</span> + label_to_emoji(<span class="number">4</span>))</span><br><span class="line">print(pd.crosstab(Y_test, pred_test.reshape(<span class="number">56</span>,), rownames=[<span class="string">'Actual'</span>], colnames=[<span class="string">'Predicted'</span>], margins=<span class="literal">True</span>))</span><br><span class="line">plot_confusion_matrix(Y_test, pred_test)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(56,)</span><br><span class="line">           ❤️   ⚾   😄   😞  🍴</span><br><span class="line">Predicted  0.0  1.0  2.0  3.0  4.0  All</span><br><span class="line">Actual                                 </span><br><span class="line">0            6    0    0    1    0    7</span><br><span class="line">1            0    8    0    0    0    8</span><br><span class="line">2            2    0   16    0    0   18</span><br><span class="line">3            1    1    2   12    0   16</span><br><span class="line">4            0    0    1    0    6    7</span><br><span class="line">All          9    9   19   13    6   56</span><br></pre></td></tr></table></figure><p><img src="/2018/08/31/emojify/output.png"></p><p>矩阵对角线上的颜色比较深，表示模型的表现还不错。但是模型却无法分析 not xxx 这类的短语，因为嵌入矩阵中没有对应的表示，而且单纯地对所有单词的嵌入求平均会丢失输入的单词的顺序，因此需要更好的算法。</p><h2 id="emojifier-v2-在-keras-中使用-lstms">Emojifier-V2: 在 Keras 中使用 LSTMs</h2><p>Emojifier-V2 的概况如下图所示：</p><p><img src="/2018/08/31/emojify/emojifier-v2.png"></p><p>这是一个两层的 LSTM 序列分类器。这次实验使用 mini-batches 来训练 Keras，因此一个 batch 中的序列的长度应该相同，因此需要补 0。例如一个 batch 中的序列的最大长度为 5，那么 "I love you" 这个句子的表示为 <span class="math inline">\((e_{i}, e_{love}, e_{you}, \vec{0}, \vec{0})\)</span>。</p><h3 id="embedding-层">Embedding 层</h3><p>在 Keras 中，嵌入矩阵被表示成一个层，然后将词的索引匹配成嵌入向量。嵌入矩阵可以被训练出来，也可以用一个训练好的矩阵来初始化它。<code>Embedding()</code> 层输出是一个 (batch size, max input length, dimension of word vectors) 的矩阵。word_to_index 的实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentences_to_indices</span><span class="params">(X, word_to_index, max_len)</span>:</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]                                   <span class="comment"># number of training examples</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize X_indices as a numpy matrix of zeros and the correct shape</span></span><br><span class="line">    X_indices = np.zeros((m, max_len))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                               <span class="comment"># loop over training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Convert the ith training sentence in lower case and split is into words. You should get a list of words.</span></span><br><span class="line">        sentence_words = X[i].lower().split()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initialize j to 0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Loop over the words of sentence_words</span></span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> sentence_words:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Set the (i,j)th entry of X_indices to the index of the correct word.</span></span><br><span class="line">            X_indices[i, j] = word_to_index[w]</span><br><span class="line">            <span class="comment"># Increment j to j + 1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> X_indices</span><br></pre></td></tr></table></figure><p>接下来需要实现预训练的 Embedding 层，将训练好的嵌入矩阵设置到 <code>Embedding()</code> 层的权值中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretrained_embedding_layer</span><span class="params">(word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    vocab_len = len(word_to_index) + <span class="number">1</span>                  <span class="comment"># adding 1 to fit Keras embedding (requirement)</span></span><br><span class="line">    emb_dim = word_to_vec_map[<span class="string">"cucumber"</span>].shape[<span class="number">0</span>]      <span class="comment"># define dimensionality of your GloVe word vectors (= 50)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)</span></span><br><span class="line">    emb_matrix = np.zeros((vocab_len, emb_dim))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set each row "index" of the embedding matrix to be the word vector representation of the "index"th word of the vocabulary</span></span><br><span class="line">    <span class="keyword">for</span> word, index <span class="keyword">in</span> word_to_index.items():</span><br><span class="line">        emb_matrix[index, :] = word_to_vec_map[word]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Keras embedding layer with the correct output/input sizes, make it trainable.</span></span><br><span class="line">    <span class="comment"># Use Embedding(...). Make sure to set trainable=False.</span></span><br><span class="line">    embedding_layer = Embedding(vocab_len, emb_dim, trainable = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the "None".</span></span><br><span class="line">    embedding_layer.build((<span class="literal">None</span>,))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.</span></span><br><span class="line">    embedding_layer.set_weights([emb_matrix])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> embedding_layer</span><br></pre></td></tr></table></figure><h3 id="构建模型">构建模型</h3><p>接下来需要构建模型，模型分为：</p><ul><li>输入层: <code>Input((max_len, m), dtype='int32')</code></li><li>LSTM 层: <code>LSTM(hidden_units, return_sequence)(embeddings)</code></li><li>Dropout 层: <code>Dropout(keep_prob)(X)</code></li><li>全连接层: <code>Dense(output_dimension)(X)</code></li><li>激活层: <code>Activation(activation_func)(X)</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Emojify_V2</span><span class="params">(input_shape, word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    <span class="comment"># Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).</span></span><br><span class="line">    sentence_indices = Input(input_shape, dtype=<span class="string">'int32'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the embedding layer pretrained with GloVe Vectors (≈1 line)</span></span><br><span class="line">    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Propagate sentence_indices through your embedding layer, you get back the embeddings</span></span><br><span class="line">    embeddings = embedding_layer(sentence_indices)   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Propagate the embeddings through an LSTM layer with 128-dimensional hidden state</span></span><br><span class="line">    <span class="comment"># Be careful, the returned output should be a batch of sequences.</span></span><br><span class="line">    X = LSTM(<span class="number">128</span>, return_sequences=<span class="literal">True</span>)(embeddings)</span><br><span class="line">    <span class="comment"># Add dropout with a probability of 0.5</span></span><br><span class="line">    X = Dropout(<span class="number">0.5</span>)(X)</span><br><span class="line">    <span class="comment"># Propagate X trough another LSTM layer with 128-dimensional hidden state</span></span><br><span class="line">    <span class="comment"># Be careful, the returned output should be a single hidden state, not a batch of sequences.</span></span><br><span class="line">    X = LSTM(<span class="number">128</span>, return_sequences=<span class="literal">False</span>)(X)</span><br><span class="line">    <span class="comment"># Add dropout with a probability of 0.5</span></span><br><span class="line">    X = Dropout(<span class="number">0.5</span>)(X)</span><br><span class="line">    <span class="comment"># Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.</span></span><br><span class="line">    X = Dense(<span class="number">5</span>)(X)</span><br><span class="line">    <span class="comment"># Add a softmax activation</span></span><br><span class="line">    X = Activation(<span class="string">'softmax'</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Model instance which converts sentence_indices into X.</span></span><br><span class="line">    model = Model(inputs=sentence_indices, outputs=X)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>构建好模型后可以通过模型的 <code>summary()</code> 方法来检查模型的概要 (max_len = 10)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_1 (InputLayer)         (None, 10)                0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">embedding_2 (Embedding)      (None, 10, 50)            20000050  </span><br><span class="line">_________________________________________________________________</span><br><span class="line">lstm_1 (LSTM)                (None, 10, 128)           91648     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout)          (None, 10, 128)           0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">lstm_2 (LSTM)                (None, 128)               131584    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_2 (Dropout)          (None, 128)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 5)                 645       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">activation_1 (Activation)    (None, 5)                 0         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 20,223,927</span><br><span class="line">Trainable params: 223,877</span><br><span class="line">Non-trainable params: 20,000,050</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure><p>由于嵌入矩阵是训练好的 <code>trainable = False</code>，因此有 400,001 * 50 = 20,000,050 个参数是 Non-trainable 参数。接下来需要编译模型，定义损失函数、优化器和评估指标，最后拟合模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)</span><br><span class="line">Y_train_oh = convert_to_one_hot(Y_train, C = <span class="number">5</span>)</span><br><span class="line">model.fit(X_train_indices, Y_train_oh, epochs = <span class="number">50</span>, batch_size = <span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>训练集和测试集上的准确率能接近 100% 和 91%。对于 not happy 也能准确预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_test = np.array([<span class="string">'you are not happy'</span>])</span><br><span class="line">X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)</span><br><span class="line">print(x_test[<span class="number">0</span>] +<span class="string">' '</span>+  label_to_emoji(np.argmax(model.predict(X_test_indices))))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">you are not happy 😞</span><br></pre></td></tr></table></figure><p>因为 LSTM 网络具有长短期记忆，所以能够很好地预测某些单词的组合。</p><h2 id="总结">总结</h2><p>在 NLP 任务中，如果训练集比较小，比较适合直接用训练好的嵌入矩阵而不是自己训练一个。在 RNN 中，如果想用 mini-batches 提高效率(矩阵的运算比循环快)，那么就需要对样本进行补 0。<code>LSTM()</code> 的 <code>return_sequence</code> 参数决定返回所有的隐藏状态还是只返回最后一个时间步的隐藏状态。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;写论文做实验的时候曾经想过用文本分类的模型，无奈样本太不均衡，所以最后用了自编码器提取特征。在 Coursera 的作业中，该实验分为两个小实验，一个是普通的文本分类，一个是使用 LSTM RNN 进行文本分类。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>用 LSTM 网络创作爵士独奏</title>
    <link href="https://pengzhendong.cn/2018/08/28/jazz-with-an-lstm-network/"/>
    <id>https://pengzhendong.cn/2018/08/28/jazz-with-an-lstm-network/</id>
    <published>2018-08-28T03:16:15.000Z</published>
    <updated>2018-08-28T06:22:43.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>终于把论文投出去了，虽然中的概率很渺茫，但是我肖的态度确实好了不少。终于又可以闲下来好好学学深度学习了，论文的实验过程中用了 LSTM Autoencoder，正好趁着这个机会再强化一下。在上篇学习笔记中，由于恐龙名字不会很长，所以在生成恐龙名字的作业中使用 RNN 已经可以满足任务要求。本次作业是创作爵士独奏，普通 RNN 无法解决长期依赖问题，所以使用了 LSTM。</p><a id="more"></a><h2 id="数据集">数据集</h2><p>数据集是一首长达约8分钟的爵士音乐，下面是其中的一个小片段：</p><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/30s_seq.mp3" type="audio/mpeg">Your browser does not support the audio element.</audio></center><p>在这次实验中不用考虑和弦，只需要在数据集上训练出一个 RNN 模型，然后用来生成新的序列。首先加载数据 <code>data/original_metheny.mid</code>，然后将它处理成以下形状，每三十个值作为一个序列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, Y, n_values, indices_values = load_music_utils()</span><br></pre></td></tr></table></figure><ul><li><p>训练样本的个数 <span class="math inline">\(m\)</span>: 60</p></li><li><p>序列的长度 <span class="math inline">\(T_x\)</span>: 30</p></li><li><p>不同的值的总数(独热向量的维度): 78</p></li><li><p>X 的形状: <span class="math inline">\((m, T_x, 78)\)</span></p></li><li><p>Y 的形状: <span class="math inline">\((T_x, m, 78)\)</span></p></li></ul><p>Y 实质上和 X 相同，只不过是偏移了一步。在训练过程中，给定序列 <span class="math inline">\(x^{\langle 1\rangle}, \ldots, x^{\langle t \rangle}\)</span>，模型则预测 <span class="math inline">\(y^{\langle t \rangle}\)</span>。在 RNN 中，数据的形状分为两种：time major <code>[max_time, batch_size, depth]</code> 和 batch major <code>[batch_size, max_time, depth]</code>。使用 <code>time_major=True</code> 效率更高，能够避免一些转置的操作，因此 Y 的形状是 time major。</p><h2 id="模型">模型</h2><p>模型的结构如下图所示：</p><p><img src="/2018/08/28/jazz-with-an-lstm-network/model.png"></p><p>每次从 <code>original_metheny.mid</code> 中随机选取 30 个值训练模型。与生成恐龙名字的模型类似，<span class="math inline">\(x^{\langle 1 \rangle} = \vec{0}\)</span> 作为输入的开始。</p><h3 id="构建模型">构建模型</h3><p>本次实验使用隐藏状态是 64 维的 LSTM，对于序列生成模型，在实验之前输入序列未知，每个时间步的输出生成下一个时间步的输入 <span class="math inline">\(x^{\langle t \rangle}=y^{\langle t-1 \rangle}\)</span>，因此需要使用 for 循环调用 LSTM 层 <span class="math inline">\(T_x\)</span> 次，且 LSTM 细胞共享参数。</p><ul><li>定义层对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reshapor = Reshape((<span class="number">1</span>, <span class="number">78</span>))</span><br><span class="line">LSTM_cell = LSTM(n_a, return_state = <span class="literal">True</span>)</span><br><span class="line">densor = Dense(n_values, activation=<span class="string">'softmax'</span>)</span><br></pre></td></tr></table></figure><ul><li>实现 <code>djmodel()</code><ol type="1"><li>创建空列表用于存储每个时间步的输出</li><li>循环 <span class="math inline">\(T_x\)</span> 个时间步<ol type="1"><li>使用 Keras的 Lambda 层：<code>x = Lambda(lambda x: X[:,t,:])(X)</code></li><li>Reshape x 的形状成 <span class="math inline">\((1, 78)\)</span></li><li>将 x 输入到一个 LSTM_cell 中：<code>a, _, c = LSTM_cell(input_x, initial_state=[previous hidden state, previous cell state])</code></li><li>输出经过激活函数和全连接层后，保存到输出列表中</li></ol></li></ol></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">djmodel</span><span class="params">(Tx, n_a, n_values)</span>:</span></span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    X = Input(shape=(Tx, n_values))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Create empty list to append the outputs while you iterate (≈1 line)</span></span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="comment"># Step 2: Loop</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Tx):</span><br><span class="line">        <span class="comment"># Step 2.A: select the "t"th time step vector from X. </span></span><br><span class="line">        x =  Lambda(<span class="keyword">lambda</span> x: X[:, t, :])(X)</span><br><span class="line">        <span class="comment"># Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)</span></span><br><span class="line">        x = reshapor(x)</span><br><span class="line">        <span class="comment"># Step 2.C: Perform one step of the LSTM_cell</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c])</span><br><span class="line">        <span class="comment"># Step 2.D: Apply densor to the hidden state output of LSTM_Cell</span></span><br><span class="line">        out = densor(a)</span><br><span class="line">        <span class="comment"># Step 2.E: add the output to "outputs"</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">    <span class="comment"># Step 3: Create model instance</span></span><br><span class="line">    model = Model(inputs=[X, a0, c0], outputs=outputs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>接下来使用 Adam 优化和一个分类的交叉熵损失训练模型 100 个 epochs：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = djmodel(Tx = <span class="number">30</span> , n_a = <span class="number">64</span>, n_values = <span class="number">78</span>)</span><br><span class="line">opt = Adam(lr=<span class="number">0.01</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.compile(optimizer=opt, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">m = <span class="number">60</span></span><br><span class="line">a0 = np.zeros((m, n_a))</span><br><span class="line">c0 = np.zeros((m, n_a))</span><br><span class="line">model.fit([X, a0, c0], list(Y), epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h3 id="生成">生成</h3><p><img src="/2018/08/28/jazz-with-an-lstm-network/music_generation.png"></p><p>在采样的每个时间步中，输出被用于生成音乐和作为下一个时间步的输入。实验步骤如下：</p><ol type="1"><li>使用 LSTM_Cell，输入时上一个时间步的输出 <code>y</code> 和隐藏状态 <code>a</code></li><li>对当前时间步的隐藏状态 <code>a</code> 使用 <code>softmax</code> 函数，将输入加入输出列表中</li><li>对输出使用 <code>x = Lambda(one_hot)(out)</code> 转化成独热向量，输入下一个时间步</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">music_inference_model</span><span class="params">(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    x0 = Input(shape=(<span class="number">1</span>, n_values))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    x = x0</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Create an empty list of "outputs" to later store your predicted values (≈1 line)</span></span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="comment"># Step 2: Loop over Ty and generate a value at every time step</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Ty):</span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of LSTM_cell (≈1 line)</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c])</span><br><span class="line">        <span class="comment"># Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)</span></span><br><span class="line">        out = densor(a)</span><br><span class="line">        <span class="comment"># Step 2.C: Append the prediction "out" to "outputs". out.shape = (None, 78) (≈1 line)</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">        <span class="comment"># Step 2.D: Select the next value according to "out", and set "x" to be the one-hot representation of the</span></span><br><span class="line">        <span class="comment">#           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided </span></span><br><span class="line">        <span class="comment">#           the line of code you need to do this. </span></span><br><span class="line">        x = Lambda(one_hot)(out)</span><br><span class="line">    <span class="comment"># Step 3: Create model instance with the correct "inputs" and "outputs" (≈1 line)</span></span><br><span class="line">    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inference_model</span><br></pre></td></tr></table></figure><p>定义推断模型和初始化参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inference_model = music_inference_model(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">50</span>)</span><br><span class="line">x_initializer = np.zeros((<span class="number">1</span>, <span class="number">1</span>, <span class="number">78</span>))</span><br><span class="line">a_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br><span class="line">c_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br></pre></td></tr></table></figure><p>预测输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_and_sample</span><span class="params">(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, c_initializer = c_initializer)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.</span></span><br><span class="line">    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])</span><br><span class="line">    <span class="comment"># Step 2: Convert "pred" into an np.array() of indices with the maximum probabilities</span></span><br><span class="line">    indices = np.argmax(pred, axis = <span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )</span></span><br><span class="line">    results = to_categorical(indices, num_classes=<span class="number">78</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> results, indices</span><br><span class="line"></span><br><span class="line">results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)</span><br></pre></td></tr></table></figure><p>生成音乐：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_stream = generate_music(inference_model)</span><br></pre></td></tr></table></figure><center><audio controls controlslist="nodownload"><source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/30s_trained_model.mp3" type="audio/mpeg">Your browser does not support the audio element.</audio></center><h2 id="总结">总结</h2><p>这篇博客写的有点简单，因为 Coursera 的资料也比较全面了，而且和恐龙名字生成模型也很类似。如果我再去仔细分析它各个工具的实现感觉进度有点慢，所以只是简单地实现了作业内容，再加上自己对整个作业的理解。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;终于把论文投出去了，虽然中的概率很渺茫，但是我肖的态度确实好了不少。终于又可以闲下来好好学学深度学习了，论文的实验过程中用了 LSTM Autoencoder，正好趁着这个机会再强化一下。在上篇学习笔记中，由于恐龙名字不会很长，所以在生成恐龙名字的作业中使用 RNN 已经可以满足任务要求。本次作业是创作爵士独奏，普通 RNN 无法解决长期依赖问题，所以使用了 LSTM。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>字符级别的语言模型</title>
    <link href="https://pengzhendong.cn/2018/06/27/character-level-language-model/"/>
    <id>https://pengzhendong.cn/2018/06/27/character-level-language-model/</id>
    <published>2018-06-27T01:10:57.000Z</published>
    <updated>2018-06-27T03:32:46.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在介绍 RNN 的文章中，重点是学习 RNN 的结构，前向传播和反向传播的大致流程，所以在实现代码中并不是很全面，甚至没有关于损失函数的定义，这个作业基于字符级别，实现了一个语言模型。</p><a id="more"></a><p>作业背景：根据已有的<a href="https://nbviewer.jupyter.org/github/pengzhendong/DeepLearning/blob/master/5.%20Sequence%20Models/Week%201/Dinosaurus%20Island%20-%20Character%20level%20language%20model/dinos.txt" target="_blank" rel="noopener">恐龙的名字</a>，生成一些相似风格的恐龙名字。</p><h2 id="数据处理">数据处理</h2><p>首先需要读取所有名字，然后保存所有名字中出现过的不同字符：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = open(<span class="string">'dinos.txt'</span>, <span class="string">'r'</span>).read()</span><br><span class="line">data= data.lower()</span><br><span class="line">chars = list(set(data))</span><br><span class="line">data_size, vocab_size = len(data), len(chars)</span><br><span class="line">print(<span class="string">'There are %d total characters and %d unique characters in your data.'</span> % (data_size, vocab_size))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">There are 19909 total characters and 27 unique characters in your data.</span><br></pre></td></tr></table></figure><p>字符有 a-z 和 ""，换行符的作用类似 <code>&lt;EOS&gt;</code> (End Of Sentence)，在这里是恐龙名字的结束符。然后需要创建字典来保存这些字符，在 Softmax 输出的概率分布中，就能知道哪个索引对应哪个字符，也能将名字中的每个字符转化成向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">char_to_ix = &#123; ch:i <span class="keyword">for</span> i,ch <span class="keyword">in</span> enumerate(sorted(chars)) &#125;</span><br><span class="line">ix_to_char = &#123; i:ch <span class="keyword">for</span> i,ch <span class="keyword">in</span> enumerate(sorted(chars)) &#125;</span><br><span class="line">print(ix_to_char)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;0: &apos;\n&apos;, 1: &apos;a&apos;, 2: &apos;b&apos;, 3: &apos;c&apos;, 4: &apos;d&apos;, 5: &apos;e&apos;, 6: &apos;f&apos;, 7: &apos;g&apos;, 8: &apos;h&apos;, 9: &apos;i&apos;, 10: &apos;j&apos;, 11: &apos;k&apos;, 12: &apos;l&apos;, 13: &apos;m&apos;, 14: &apos;n&apos;, 15: &apos;o&apos;, 16: &apos;p&apos;, 17: &apos;q&apos;, 18: &apos;r&apos;, 19: &apos;s&apos;, 20: &apos;t&apos;, 21: &apos;u&apos;, 22: &apos;v&apos;, 23: &apos;w&apos;, 24: &apos;x&apos;, 25: &apos;y&apos;, 26: &apos;z&apos;&#125;</span><br></pre></td></tr></table></figure><h2 id="模型">模型</h2><p>模型的结构如下所示：</p><ul><li>初始化参数</li><li>运行优化循环<ul><li>前向传播计算损失函数</li><li>反向传播计算关于损失函数的梯度</li><li>梯度裁剪避免梯度爆炸</li><li>使用梯度下降更新规则更新参数</li></ul></li><li>返回学习好的参数</li></ul><p><img src="/2018/06/27/character-level-language-model/rnn.png"></p><p>在每一个时间步给定前一个字符，RNN 就会预测出下一个字符，所以对于每一个时间步有 <span class="math inline">\(y^{\langle t \rangle} = x^{\langle t+1 \rangle}\)</span>。</p><h3 id="初始化参数">初始化参数</h3><p>初始化三个权值参数 <span class="math inline">\(W_{ax}, W_{aa}, W_{ya}\)</span> 和两个偏置参数 <span class="math inline">\(b_a, b_y\)</span>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_a, n_x, n_y)</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    Wax = np.random.randn(n_a, n_x)*<span class="number">0.01</span> <span class="comment"># input to hidden</span></span><br><span class="line">    Waa = np.random.randn(n_a, n_a)*<span class="number">0.01</span> <span class="comment"># hidden to hidden</span></span><br><span class="line">    Wya = np.random.randn(n_y, n_a)*<span class="number">0.01</span> <span class="comment"># hidden to output</span></span><br><span class="line">    ba = np.zeros((n_a, <span class="number">1</span>)) <span class="comment"># hidden bias</span></span><br><span class="line">    by = np.zeros((n_y, <span class="number">1</span>)) <span class="comment"># output bias</span></span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">"Wax"</span>: Wax, <span class="string">"Waa"</span>: Waa, <span class="string">"Wya"</span>: Wya, <span class="string">"ba"</span>: ba,<span class="string">"by"</span>: by&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="前向传播">前向传播</h3><p><span class="math display">\[a^{\langle t\rangle}=tanh(W_{ax}x^{\langle t\rangle}+W_{aa}^{\langle t-1\rangle}+b_a)\]</span></p><p><span class="math display">\[\hat y^{\langle t\rangle}=softmax(W_{ya}a^{\langle t\rangle}+b_y)\]</span></p><p>前向传播的代码和<a href="2018/06/20/Recurrent-neural-network">循环神经网络</a>稍有区别，输入 <code>rnn_step_foward</code> 中的参数不需要缓存返回。输入一个字符，通过 RNN 细胞得到下一个字符的概率分布，RNN 细胞的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span><span class="params">(parameters, a_prev, x)</span>:</span></span><br><span class="line">    Waa, Wax, Wya, by, ba = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'ba'</span>]</span><br><span class="line">    a_next = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + ba) <span class="comment"># hidden state</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wya, a_next) + by) <span class="comment"># unnormalized log probabilities for next chars # probabilities for next chars </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a_next, yt_pred</span><br></pre></td></tr></table></figure><p>在完整的 RNN 前向传播中，需要定义一个字典 <code>a</code> 来存储每个时间步 <span class="math inline">\(\langle t\rangle\)</span> 与其对应的隐藏状态 <span class="math inline">\(a^{\langle t\rangle}\)</span>；输入一个序列：0 + <code>X</code> (一个恐龙的名字)，然后遍历序列的每个字符 <code>X[t]</code>，将其转化成一个 27 维的 ont-hot 向量 <code>x[t]</code>；计算每个时间步的损失函数 <span class="math inline">\(loss=-log\hat y^{\langle t\rangle}_{y^{\langle t\rangle}}\)</span> (<span class="math inline">\(\hat y^{\langle t\rangle}\)</span> 为 Softmax 函数输出的概率分布，<span class="math inline">\(y^{\langle t\rangle}\)</span> 为真实的下一个字符，即 <span class="math inline">\(x^{\langle t+1\rangle}\)</span>，损失函数可参考 Softmax 回归的损失函数)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(X, Y, a0, parameters, vocab_size = <span class="number">27</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize x, a and y_hat as empty dictionaries</span></span><br><span class="line">    x, a, y_hat = &#123;&#125;, &#123;&#125;, &#123;&#125;</span><br><span class="line">    a[<span class="number">-1</span>] = np.copy(a0)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize your loss to 0</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(len(X)):</span><br><span class="line">        <span class="comment"># Set x[t] to be the one-hot vector representation of the t'th character in X.</span></span><br><span class="line">        <span class="comment"># if X[t] == None, we just have x[t]=0. This is used to set the input for the first timestep to the zero vector. </span></span><br><span class="line">        x[t] = np.zeros((vocab_size,<span class="number">1</span>)) </span><br><span class="line">        <span class="keyword">if</span> (X[t] != <span class="literal">None</span>):</span><br><span class="line">            x[t][X[t]] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run one step forward of the RNN</span></span><br><span class="line">        a[t], y_hat[t] = rnn_step_forward(parameters, a[t<span class="number">-1</span>], x[t])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update the loss by substracting the cross-entropy term of this time-step from it.</span></span><br><span class="line">        loss -= np.log(y_hat[t][Y[t],<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">    cache = (y_hat, a, x)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> loss, cache</span><br></pre></td></tr></table></figure><h3 id="反向传播">反向传播</h3><p><span class="math display">\[dW_{ya}=\sum_{t=1}^{T_x}dy^{\langle t\rangle}*a^T\]</span></p><p><span class="math display">\[db_y=\sum_{t=1}^{T_x}dy^{\langle t\rangle}\]</span></p><p><span class="math display">\[da=W_{ya}^Tdy+W_{aa}^Tda^{\langle t+1\rangle}diag(1-a^{\langle t+1\rangle2})\]</span></p><p><span class="math display">\[db_a=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})a^{\langle t\rangle}\]</span></p><p><span class="math display">\[dW_{ax}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})a^{\langle t\rangle}x^{\langle t\rangle T}\]</span></p><p>在反向传播中需要实现以上公式，在反向传播中需要注意代码的顺序，代码实现如下所示： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span><span class="params">(dy, gradients, parameters, x, a, a_prev)</span>:</span></span><br><span class="line">    gradients[<span class="string">'dWya'</span>] += np.dot(dy, a.T)</span><br><span class="line">    gradients[<span class="string">'dby'</span>] += dy</span><br><span class="line">    da = np.dot(parameters[<span class="string">'Wya'</span>].T, dy) + gradients[<span class="string">'da_next'</span>] <span class="comment"># backprop into h</span></span><br><span class="line">    daraw = (<span class="number">1</span> - a * a) * da <span class="comment"># backprop through tanh nonlinearity</span></span><br><span class="line">    gradients[<span class="string">'dba'</span>] += daraw</span><br><span class="line">    gradients[<span class="string">'dWax'</span>] += np.dot(daraw, x.T)</span><br><span class="line">    gradients[<span class="string">'dWaa'</span>] += np.dot(daraw, a_prev.T)</span><br><span class="line">    gradients[<span class="string">'da_next'</span>] = np.dot(parameters[<span class="string">'Waa'</span>].T, daraw)</span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure></p><p>在完整的 RNN 反向传播中，需要定义参数的梯度且形状应该和该参数一样，例如 <code>gradients['dWax'] = np.zeros_like(Wax)</code>；遍历所有时间步，计算当前时间步的损失函数对输出的梯度 <span class="math inline">\(dy^{\langle t\rangle}[\hat y^{\langle t\rangle }]-=1\)</span> (可参考 Softmax 回归损失函数关于输出的梯度)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(X, Y, parameters, cache)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize gradients as an empty dictionary</span></span><br><span class="line">    gradients = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve from cache and parameters</span></span><br><span class="line">    (y_hat, a, x) = cache</span><br><span class="line">    Waa, Wax, Wya, by, ba = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'ba'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># each one should be initialized to zeros of the same dimension as its corresponding parameter</span></span><br><span class="line">    gradients[<span class="string">'dWax'</span>], gradients[<span class="string">'dWaa'</span>], gradients[<span class="string">'dWya'</span>] = np.zeros_like(Wax), np.zeros_like(Waa), np.zeros_like(Wya)</span><br><span class="line">    gradients[<span class="string">'dba'</span>], gradients[<span class="string">'dby'</span>] = np.zeros_like(ba), np.zeros_like(by)</span><br><span class="line">    gradients[<span class="string">'da_next'</span>] = np.zeros_like(a[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagate through time</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(len(X))):</span><br><span class="line">        dy = np.copy(y_hat[t])</span><br><span class="line">        dy[Y[t]] -= <span class="number">1</span></span><br><span class="line">        gradients = rnn_step_backward(dy, gradients, parameters, x[t], a[t], a[t<span class="number">-1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients, a</span><br></pre></td></tr></table></figure><h3 id="梯度裁剪">梯度裁剪</h3><p>在反向传播中，我们需要对参数求梯度，然后根据参数梯度更新参数。在更新参数之前，需要对参数梯度进行裁剪，保证梯度不会爆炸，即梯度的取值不会太大。</p><p><img src="/2018/06/27/character-level-language-model/clip.png"></p><p>梯度裁剪的实现有许多不同方法，例如对梯度的 L2 范数进行裁剪和对梯度值进行裁剪，这里实现的是对梯度值进行裁剪，确保梯度在 <span class="math inline">\([-maxValue, maxValue]\)</span> 中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip</span><span class="params">(gradients, maxValue)</span>:</span></span><br><span class="line">    dWaa, dWax, dWya, dba, dby = gradients[<span class="string">'dWaa'</span>], gradients[<span class="string">'dWax'</span>], gradients[<span class="string">'dWya'</span>], gradients[<span class="string">'dba'</span>], gradients[<span class="string">'dby'</span>]</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># clip to mitigate exploding gradients, loop over [dWax, dWaa, dWya, dba, dby].</span></span><br><span class="line">    <span class="keyword">for</span> gradient <span class="keyword">in</span> [dWax, dWaa, dWya, dba, dby]:</span><br><span class="line">        np.clip(gradient, a_min=-maxValue, a_max=maxValue, out=gradient)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dWaa"</span>: dWaa, <span class="string">"dWax"</span>: dWax, <span class="string">"dWya"</span>: dWya, <span class="string">"dba"</span>: dba, <span class="string">"dby"</span>: dby&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h3 id="更新参数">更新参数</h3><p>更新参数部分的代码比较简单，就是减去学习率 (<strong>l</strong>earning <strong>r</strong>ate) 乘以梯度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, gradients, lr)</span>:</span></span><br><span class="line">    parameters[<span class="string">'Wax'</span>] += -lr * gradients[<span class="string">'dWax'</span>]</span><br><span class="line">    parameters[<span class="string">'Waa'</span>] += -lr * gradients[<span class="string">'dWaa'</span>]</span><br><span class="line">    parameters[<span class="string">'Wya'</span>] += -lr * gradients[<span class="string">'dWya'</span>]</span><br><span class="line">    parameters[<span class="string">'ba'</span>]  += -lr * gradients[<span class="string">'dba'</span>]</span><br><span class="line">    parameters[<span class="string">'by'</span>]  += -lr * gradients[<span class="string">'dby'</span>]</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="构建语言模型">构建语言模型</h3><p>将上面步骤结合在一起，实现模型，最后需要返回最后一个时间步的隐藏状态，用做<strong>下一个序列</strong>的第 0 个时间步的隐藏状态：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(X, Y, a_prev, parameters, learning_rate = <span class="number">0.01</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Forward propagate through time</span></span><br><span class="line">    loss, cache = rnn_forward(X, Y, a_prev, parameters)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backpropagate through time (≈1 line)</span></span><br><span class="line">    gradients, a = rnn_backward(X, Y, parameters, cache)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Clip your gradients between -5 (min) and 5 (max)</span></span><br><span class="line">    gradients = clip(gradients, maxValue = <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update parameters</span></span><br><span class="line">    parameters = update_parameters(parameters, gradients, learning_rate)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss, gradients, a[len(X)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><h2 id="采样">采样</h2><p>训练出参数后，我们可能想让模型生成一些恐龙的名字，看看效果怎么样，生成流程如下图所示：</p><p><img src="/2018/06/27/character-level-language-model/dinos3.png"></p><ol type="1"><li><p><span class="math inline">\(a^{\langle 0\rangle}\)</span> 和 <span class="math inline">\(x^{\langle 1\rangle}\)</span> 为 0 向量</p></li><li><p>向前传播一个时间步得到隐藏状态 <span class="math inline">\(a^{\langle 1\rangle}\)</span> 输出 <span class="math inline">\(\hat y^{\langle 1\rangle}\)</span> (即各个字符的概率分布)： <span class="math display">\[a^{\langle t+1 \rangle} = \tanh(W_{ax}  x^{\langle t \rangle } + W_{aa} a^{\langle t \rangle } + ba)\]</span></p><p><span class="math display">\[\hat y^{\langle t + 1 \rangle } = softmax(W_{ya}  a^{\langle t + 1 \rangle } + b_y)\]</span></p></li><li><p>进行采样：假设 <span class="math inline">\(\hat{y}^{\langle t+1 \rangle }_i = 0.16\)</span>，则以 16% 的概率选取索引 i 所对应的字符，可以使用 <code>np.random.choice</code> 实现。这也正是 <code>softmax</code> 名字的由来，没有强硬地输出一个最大值，而是输出每个值为最大的概率，虽然大部分情况下用的就是概率最大的那个，但是采样的时候就可以按概率分布随机采样。</p></li><li><p>用上一个时间步的输出作为输入，重复采样，直到遇到结束符(或者名字长度为 50 个字符，避免停不下来)。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(parameters, char_to_ix, seed)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve parameters and relevant shapes from "parameters" dictionary</span></span><br><span class="line">    Waa, Wax, Wya, by, ba = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'ba'</span>]</span><br><span class="line">    vocab_size = by.shape[<span class="number">0</span>]</span><br><span class="line">    n_a = Waa.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Create the one-hot vector x for the first character (initializing the sequence generation).</span></span><br><span class="line">    x = np.zeros((vocab_size, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># Step 1': Initialize a_prev as zeros</span></span><br><span class="line">    a_prev = np.zeros((n_a, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate</span></span><br><span class="line">    indices = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Idx is a flag to detect a newline character, we initialize it to -1</span></span><br><span class="line">    idx = <span class="number">-1</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop over time-steps t. At each time-step, sample a character from a probability distribution and append </span></span><br><span class="line">    <span class="comment"># its index to "indices". We'll stop if we reach 50 characters (which should be very unlikely with a well </span></span><br><span class="line">    <span class="comment"># trained model), which helps debugging and prevents entering an infinite loop. </span></span><br><span class="line">    counter = <span class="number">0</span></span><br><span class="line">    newline_character = char_to_ix[<span class="string">'\n'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (idx != newline_character <span class="keyword">and</span> counter != <span class="number">50</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2: Forward propagate x using the equations (1), (2) and (3)</span></span><br><span class="line">        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + ba)</span><br><span class="line">        z = np.dot(Wya, a) + by</span><br><span class="line">        y = softmax(z)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for grading purposes</span></span><br><span class="line">        np.random.seed(counter+seed)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Sample the index of a character within the vocabulary from the probability distribution y</span></span><br><span class="line">        idx = np.random.choice(list(range(vocab_size)), p = y[:,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Append the index to "indices"</span></span><br><span class="line">        indices.append(idx)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 4: Overwrite the input character as the one corresponding to the sampled index.</span></span><br><span class="line">        x = np.zeros((vocab_size,<span class="number">1</span>))</span><br><span class="line">        x[idx] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update "a_prev" to be "a"</span></span><br><span class="line">        a_prev = a</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for grading purposes</span></span><br><span class="line">        seed += <span class="number">1</span></span><br><span class="line">        counter +=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> (counter == <span class="number">50</span>):</span><br><span class="line">        indices.append(char_to_ix[<span class="string">'\n'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> indices</span><br></pre></td></tr></table></figure></p></li></ol><h2 id="训练模型">训练模型</h2><p>对于数据集中的每一行数据(随机打乱)，随机梯度下降 100 次后则随机采样生成 10 个名字。首先需要生成数据的标签，即每个字符对于的标签是它的下一个字符：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index = j % len(examples)</span><br><span class="line">X = [<span class="literal">None</span>] + [char_to_ix[ch] <span class="keyword">for</span> ch <span class="keyword">in</span> examples[index]] </span><br><span class="line">Y = X[<span class="number">1</span>:] + [char_to_ix[<span class="string">"\n"</span>]]</span><br></pre></td></tr></table></figure><p>由于使用的梯度下降法是随机梯度下降，会存在振荡现象，需要用带修正的指数加权平均的方法来减小噪声：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_initial_loss</span><span class="params">(vocab_size, seq_length)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> -np.log(<span class="number">1.0</span>/vocab_size)*seq_length</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth</span><span class="params">(loss, cur_loss)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> loss * <span class="number">0.999</span> + cur_loss * <span class="number">0.001</span></span><br></pre></td></tr></table></figure><p>模型的完整代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(data, ix_to_char, char_to_ix, num_iterations = <span class="number">35000</span>, n_a = <span class="number">50</span>, dino_names = <span class="number">7</span>, vocab_size = <span class="number">27</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve n_x and n_y from vocab_size</span></span><br><span class="line">    n_x, n_y = vocab_size, vocab_size</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters(n_a, n_x, n_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize loss (this is required because we want to smooth our loss, don't worry about it)</span></span><br><span class="line">    loss = get_initial_loss(vocab_size, dino_names)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Build list of all dinosaur names (training examples).</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"dinos.txt"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        examples = f.readlines()</span><br><span class="line">    examples = [x.lower().strip() <span class="keyword">for</span> x <span class="keyword">in</span> examples]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Shuffle list of all dinosaur names</span></span><br><span class="line">    shuffle(examples)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the hidden state of your LSTM</span></span><br><span class="line">    a_prev = np.zeros((n_a, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Optimization loop</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Use the hint above to define one training example (X,Y) (≈ 2 lines)</span></span><br><span class="line">        index = j % len(examples)</span><br><span class="line">        X = [<span class="literal">None</span>] + [char_to_ix[ch] <span class="keyword">for</span> ch <span class="keyword">in</span> examples[index]] </span><br><span class="line">        Y = X[<span class="number">1</span>:] + [char_to_ix[<span class="string">"\n"</span>]]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Perform one optimization step: Forward-prop -&gt; Backward-prop -&gt; Clip -&gt; Update parameters</span></span><br><span class="line">        <span class="comment"># Choose a learning rate of 0.01</span></span><br><span class="line">        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = <span class="number">0.01</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Use a latency trick to keep the loss smooth. It happens here to accelerate the training.</span></span><br><span class="line">        loss = smooth(loss, curr_loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Every 2000 Iteration, generate "n" characters thanks to sample() to check if the model is learning properly</span></span><br><span class="line">        <span class="keyword">if</span> j % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Iteration: %d, Loss: %f'</span> % (j, loss) + <span class="string">'\n'</span>)</span><br><span class="line">            <span class="comment"># The number of dinosaur names to print</span></span><br><span class="line">            seed = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> range(dino_names):</span><br><span class="line">                <span class="comment"># Sample indices and print them</span></span><br><span class="line">                sampled_indices = sample(parameters, char_to_ix, seed)</span><br><span class="line">                print_sample(sampled_indices, ix_to_char)</span><br><span class="line">                seed += <span class="number">1</span>  <span class="comment"># To get the same result for grading purposed, increment the seed by one. </span></span><br><span class="line">            print(<span class="string">'\n'</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h2 id="莎士比亚风格">* 莎士比亚风格</h2><p>作业最后还展示了如何使用 LSTM 生成莎士比亚风格的诗词，由于恐龙的名字很短，所以长期依赖问题不明显。生成莎士比亚风格诗词的时候就很明显，所以需要使用 LSTM 来解决长期以来问题。</p><p>基于字符的语言模型有优点也有缺点，优点是不必担心出现未知的标识，例如 <code>Mau</code> 这样的序列。而基于词汇的语言模型，如果 <code>Mau</code> 不在字典中就只能把它当成 UNK。缺点是序列太长，即时间步太多，很难捕捉长期依赖关系，计算成本高。除非需要处理大量未知文本和未知词汇的应用，大多数都是使用基于词汇的语言模型。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;在介绍 RNN 的文章中，重点是学习 RNN 的结构，前向传播和反向传播的大致流程，所以在实现代码中并不是很全面，甚至没有关于损失函数的定义，这个作业基于字符级别，实现了一个语言模型。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>循环神经网络</title>
    <link href="https://pengzhendong.cn/2018/06/20/recurrent-neural-network/"/>
    <id>https://pengzhendong.cn/2018/06/20/recurrent-neural-network/</id>
    <published>2018-06-20T02:29:57.000Z</published>
    <updated>2018-06-20T06:33:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>按照吴恩达 Deeplearning 系列课程，应该是先学卷积神经网络，但是自己的实验中要用到递归神经网络，感觉不能再拖了，就先学习一下序列模型这一章节。在普通的神经网络中，一般都是输入一个向量，然后输出一个向量或者通过 Sigmoid 函数后输出一个值。</p><a id="more"></a><h2 id="循环神经网络">循环神经网络</h2><p>循环神经网络 (Recurrent neural network) 是一类用于处理<strong>序列数据</strong>的神经网络。在普通的神经网络中，前一个输入和后一个输入没有关系；而在有时候需要网络在处理当前输入的时候，记住之前的输入的相关信息。如果将整个序列当成一个整体输入普通神经网络的话，则会遇到输入的长度不同(可通过填充解决)和参数量大的问题。</p><p>根据处理的问题，网络按结构可以分为以下几种：</p><ul><li>一对一：非 RNN 结构，例如图片分类</li><li>一对多：序列输出，例如生成图片的描述</li><li>多对一：序列输入，例如评论的情感分类</li><li>多对多：<ul><li>序列输入和序列输出，例如机器翻译</li><li>同步序列输入和输出，例如视频的帧分类</li></ul></li><li>递归神经网络 (Recursive nerual network) 是空间上的展开，处理的是树状结构信息(例如语法树)；循环神经网络是时间上的展开(也叫时间递归神经网络)，处理的是序列结构信息； RNN 一般指循环神经网络。</li></ul><h2 id="前向传播">前向传播</h2><p>在同步序列输入和输出结构中，有 <span class="math inline">\(T_x=T_y\)</span> ，其结构如下图所示：</p><p><img src="/2018/06/20/recurrent-neural-network/rnn.png"></p><p>一共有 <span class="math inline">\(T_x\)</span> 个时间步，所以只需要实现一个时间步，然后循环 <span class="math inline">\(T_x\)</span> 次则可以实现 RNN 的前向传播。</p><h3 id="rnn-细胞">RNN 细胞</h3><p>一个循环神经网络可以看成是单个细胞(即时间步)的循环，所有细胞共享参数。细胞内部结构如下图所示：</p><p><img src="/2018/06/20/recurrent-neural-network/rnn_step_forward.png"></p><p>细胞的输入有当前(第 <span class="math inline">\(t\)</span> 个时间步)的输入 <span class="math inline">\(x^{\langle t\rangle}\)</span> 和之前的隐藏状态 <span class="math inline">\(a^{\langle t-1\rangle}\)</span> (包含了以前的信息)，输出有 <span class="math inline">\(a^{\langle t\rangle}\)</span> 和 <span class="math inline">\(\hat y^{\langle t\rangle}\)</span> 。在前向传播过程中，需要缓存各种值用于反向传播计算参数梯度，实现 RNN 细胞代码主要分为以下几个步骤：</p><ol type="1"><li>用 <span class="math inline">\(tanh\)</span> 激活函数计算隐藏状态：<span class="math inline">\(a^{\langle t\rangle}=tanh(W_{aa}a^{\langle t-1\rangle}+W_{ax}x^{\langle t\rangle}+b_a)\)</span></li><li>用新的隐藏状态 <span class="math inline">\(a^{\langle t \rangle}\)</span> 计算预测值 <span class="math inline">\(\hat y^{\langle t\rangle}=softmax(W_{ya}a^{\langle t\rangle}+b_y)\)</span></li><li>缓存 <span class="math inline">\(a^{\langle t\rangle}, a^{\langle t-1\rangle}, x^{\langle t\rangle}\)</span></li><li>返回 <span class="math inline">\(a^{\langle t\rangle}, \hat y^{\langle t\rangle}\)</span> 和缓存</li></ol><p>一共有 <span class="math inline">\(m\)</span> 个样本数据，其中 <span class="math inline">\(x^{\langle t\rangle}\)</span> 的维度为 <span class="math inline">\((n_x, m)\)</span>，<span class="math inline">\(a^{\langle t\rangle}\)</span> 的维度为 <span class="math inline">\((n_a, m)\)</span>。代码中使用 <code>_prev</code> 表示上一个时间步 <span class="math inline">\(\langle t-1\rangle\)</span> ，<code>_next</code> 和 <code>t</code> 表示当前时间步 <span class="math inline">\(\langle t\rangle\)</span>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell_forward</span><span class="params">(xt, a_prev, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve parameters from "parameters"</span></span><br><span class="line">    Wax = parameters[<span class="string">"Wax"</span>]</span><br><span class="line">    Waa = parameters[<span class="string">"Waa"</span>]</span><br><span class="line">    Wya = parameters[<span class="string">"Wya"</span>]</span><br><span class="line">    ba = parameters[<span class="string">"ba"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute next activation state using the formula given above</span></span><br><span class="line">    a_next = np.tanh(np.dot(Wax, xt) + np.dot(Waa, a_prev) + ba)</span><br><span class="line">    <span class="comment"># compute output of the current cell using the formula given above</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wya, a_next) + by)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store values you need for backward propagation in cache</span></span><br><span class="line">    cache = (a_next, a_prev, xt, parameters)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a_next, yt_pred, cache</span><br></pre></td></tr></table></figure><h3 id="rnn-前向传播">RNN 前向传播</h3><p><img src="/2018/06/20/recurrent-neural-network/cell_rnn.png"></p><p>RNN 的前向传播主要分为以下几个步骤：</p><ol type="1"><li>创建零向量 <span class="math inline">\(\boldsymbol{a}\)</span> 用于存储<strong>所有</strong>隐藏状态</li><li>初始化隐藏状态 <span class="math inline">\(a_0\)</span></li><li>循环所有时间步，当前时间步为 <span class="math inline">\(t\)</span><ul><li>使用 <code>run_cell_forward</code> 函数更新隐藏状态 <span class="math inline">\(a^{\langle t\rangle}\)</span> 和缓存</li><li>存储 <span class="math inline">\(a^{\langle t\rangle}\)</span> 到 <span class="math inline">\(\boldsymbol{a}\)</span> 中的第 <span class="math inline">\(t\)</span> 个位置</li><li>存储预测值 <span class="math inline">\(\hat y^{\langle t\rangle}\)</span> 到 <span class="math inline">\(\boldsymbol{\hat y}\)</span> 中</li><li>添加缓存到缓存列表中</li></ul></li><li>返回 <span class="math inline">\(\boldsymbol{a}, \boldsymbol{\hat y}\)</span> 和缓存列表</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(x, a0, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize "caches" which will contain the list of all caches</span></span><br><span class="line">    caches = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of x and Wy</span></span><br><span class="line">    n_x, m, T_x = x.shape</span><br><span class="line">    n_y, n_a = parameters[<span class="string">"Wya"</span>].shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize "a" and "y" with zeros</span></span><br><span class="line">    a = np.zeros((n_a, m, T_x))</span><br><span class="line">    y_pred = np.zeros((n_y, m, T_x))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize a_next</span></span><br><span class="line">    a_next = a0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop over all time-steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T_x):</span><br><span class="line">        <span class="comment"># Update next hidden state, compute the prediction, get the cache</span></span><br><span class="line">        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t], a_next, parameters)</span><br><span class="line">        <span class="comment"># Save the value of the new "next" hidden state in a</span></span><br><span class="line">        a[:,:,t] = a_next</span><br><span class="line">        <span class="comment"># Save the value of the prediction in y</span></span><br><span class="line">        y_pred[:,:,t] = yt_pred</span><br><span class="line">        <span class="comment"># Append "cache" to "caches"</span></span><br><span class="line">        caches.append(cache)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    caches = (caches, x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a, y_pred, caches</span><br></pre></td></tr></table></figure><h3 id="长期依赖">长期依赖</h3><p>循环神经网络具有长期依赖的问题，在经过许多阶段传播后的梯度倾向于消失(大部分情况)或爆炸(很少而且容易发现，但对优化过程影响很大，可以使用梯度截断的方法解决)，因此只能学习到短期的依赖关系。以一个简单的、缺少非线性激活函数和输入 <span class="math inline">\(x\)</span> 的循环神经网络为例： <span class="math display">\[a^{\langle t\rangle}=W_{aa}a^{\langle t-1\rangle}\]</span></p><p><span class="math display">\[a^{\langle t\rangle}=W_{aa}^ta^{\langle 0\rangle}\]</span> 类似于深度神经网络，当 <span class="math inline">\(W_{aa}\)</span> 的特征值小于 1 时就会导致隐藏状态约等于 0。即 RNN 会忘了很久以前的信息，如果不需要用很久以前的信息(有意义的信息都在前<strong>几个</strong>时间步)就能估计输出 <span class="math inline">\(\hat y^{\langle t\rangle}\)</span> ，那么 RNN 效果也不错。而 LSTM 则可以很好得解决这个问题，可以记住更多时间步以前的信息。目前实际应用中最有效的序列模型称为门控 RNN (gated RNN)。包括基于长短期记忆 (Long Short-Term Memory, LSTM) 和基于门控循环单元 (gated recurrent unit, GRU) 网络。</p><h3 id="lstm-细胞">LSTM 细胞</h3><p>基于长短期记忆 (LSTM) 的网络的细胞结构如下图所示：</p><p><img src="/2018/06/20/recurrent-neural-network/LSTM.png"></p><p><strong>LSTM 最关键的地方就在于细胞的状态 <span class="math inline">\(c^{\langle t\rangle}\)</span>，即上图中上面横穿的水平线，这种结构能够很轻松地实现信息从整个细胞中穿过而不做改变(没有经过 <span class="math inline">\(tanh\)</span> 激活函数)，从而实现了长时期的记忆保留</strong>。可以参考反向传播时的分析，LSTM 通过门 (gates) 的结构来实现给细胞的状态添加或者删除信息。</p><h4 id="遗忘门">遗忘门</h4><p>假如我们希望用 LSTM 来跟踪主语是单数还是复数，如果主语从单数变成复数，我们需要忘记之前存储的状态。在 LSTM 中使用遗忘门 (<strong>F</strong>orget gate) 实现这一点： <span class="math display">\[\Gamma_f^{\langle t\rangle}=\sigma(W_f[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_f)\tag{1}\]</span> 其中 <span class="math inline">\(W_f\)</span> 是控制遗忘门行为的权重，遗忘门的输出 <span class="math inline">\(\Gamma_f^{\langle t \rangle}\)</span> 最后要作用于细胞的状态 (<span class="math inline">\(\Gamma_f^{\langle t\rangle}*c^{\langle t-1\rangle}\)</span>)，因此使用 <span class="math inline">\(sigmoid\)</span> 激活函数保证输出是一个 0，1 之间的向量，表示让 <span class="math inline">\(c^{\langle t-1\rangle}\)</span> 各部分信息通过的比例，0 表示不让任何信息通过，1 表示让所有信息通过。</p><h4 id="更新门">更新门</h4><p>类似于遗忘门，更新门 (<strong>U</strong>pdate gate) 也可以叫输入门 (<strong>I</strong>nput gate)，决定让多少新的信息加入到细胞状态中： <span class="math display">\[\Gamma_u^{\langle t\rangle}=\sigma(W_u[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_u)\tag{2}\]</span> 更新门的输出 <span class="math inline">\(\Gamma_u^{\langle t\rangle}\)</span> 要作用于新的信息 <span class="math inline">\(\tilde{c}^{\langle t\rangle}\)</span>，生成更新内容 <span class="math inline">\(\Gamma_u^{\langle t\rangle}*\tilde{c}^{\langle t\rangle}\)</span>，然后再添加到细胞的状态上： <span class="math display">\[\tilde{c}^{\langle t\rangle}=\tanh(W_c[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_c)\tag{3}\]</span></p><p><span class="math display">\[c^{\langle t\rangle}=\Gamma_f^{\langle t\rangle}*c^{\langle t-1\rangle}+\Gamma_u^{\langle t\rangle}*\tilde{c}^{\langle t\rangle}\tag{4}\]</span></p><h4 id="输出门">输出门</h4><p>输出门 (<strong>O</strong>utput gate) 的输出如下所示： <span class="math display">\[\Gamma_o^{\langle t\rangle}=\sigma(W_o[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_o)\tag{5}\]</span> 最后细胞的隐藏状态为： <span class="math display">\[a^{\langle t \rangle}=\Gamma_o^{\langle t\rangle}*\tanh(c^{\langle t\rangle})\tag{6}\]</span> 遗忘门、更新门和输出门的输入只取决于 <span class="math inline">\(a^{\langle t-1\rangle}\)</span> 和 <span class="math inline">\(x^{\langle t\rangle}\)</span>，如果还取决与上一个细胞的状态 <span class="math inline">\(c^{\langle t-1\rangle}\)</span> 则称为<strong>窥孔连接</strong>。类似于 RNN 细胞需要缓存各种值用于反向传播计算参数梯度，实现 LSTM 细胞代码主要分为以下几个步骤：</p><ol type="1"><li>连接 <span class="math inline">\(a^{\langle t-1\rangle}\)</span> 和 <span class="math inline">\(x^{\langle t \rangle}\)</span> 到一个矩阵中：<span class="math inline">\(concat = \begin{bmatrix} a^{\langle t-1 \rangle} \\\ x^{\langle t \rangle} \end{bmatrix}\)</span></li><li>实现公式 <span class="math inline">\((1)-(6)\)</span></li><li>计算预测值 <span class="math inline">\(y^{\langle t \rangle}\)</span></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell_forward</span><span class="params">(xt, a_prev, c_prev, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve parameters from "parameters"</span></span><br><span class="line">    Wf = parameters[<span class="string">"Wf"</span>]</span><br><span class="line">    bf = parameters[<span class="string">"bf"</span>]</span><br><span class="line">    Wu = parameters[<span class="string">"Wu"</span>]</span><br><span class="line">    bu = parameters[<span class="string">"bu"</span>]</span><br><span class="line">    Wc = parameters[<span class="string">"Wc"</span>]</span><br><span class="line">    bc = parameters[<span class="string">"bc"</span>]</span><br><span class="line">    Wo = parameters[<span class="string">"Wo"</span>]</span><br><span class="line">    bo = parameters[<span class="string">"bo"</span>]</span><br><span class="line">    Wy = parameters[<span class="string">"Wy"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of xt and Wy</span></span><br><span class="line">    n_x, m = xt.shape</span><br><span class="line">    n_y, n_a = Wy.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Concatenate a_prev and xt</span></span><br><span class="line">    concat = np.zeros([n_a + n_x, m])</span><br><span class="line">    concat[:n_a,:] = a_prev</span><br><span class="line">    concat[n_a:,:] = xt</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute values for ft, ut, cct, c_next, ot, a_next using the formulas</span></span><br><span class="line">    ft = sigmoid(np.dot(Wf, concat) + bf)</span><br><span class="line">    ut = sigmoid(np.dot(Wu, concat) + bu)</span><br><span class="line">    cct = np.tanh(np.dot(Wc, concat) + bc)</span><br><span class="line">    c_next = ft * c_prev + ut * cct</span><br><span class="line">    ot = sigmoid(np.dot(Wo, concat) + bo)</span><br><span class="line">    a_next = ot * np.tanh(c_next)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute prediction of the LSTM cell</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wy, a_next) + by)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    cache = (a_next, c_next, a_prev, c_prev, ft, ut, cct, ot, xt, parameters)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a_next, c_next, yt_pred, cache</span><br></pre></td></tr></table></figure><h3 id="lstm-前向传播">LSTM 前向传播</h3><p><img src="/2018/06/20/recurrent-neural-network/LSTM_rnn.png"></p><p>类似于 RNN 前向传播，只不过多了一个细胞的状态，所以需要初始化为 0 向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span><span class="params">(x, a0, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize "caches", which will track the list of all the caches</span></span><br><span class="line">    caches = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of xt and Wy</span></span><br><span class="line">    n_x, m, T_x = x.shape</span><br><span class="line">    n_y, n_a = parameters[<span class="string">'Wy'</span>].shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize "a", "c" and "y" with zeros</span></span><br><span class="line">    a = np.zeros([n_a, m, T_x])</span><br><span class="line">    c = np.zeros([n_a, m, T_x])</span><br><span class="line">    y = np.zeros([n_y, m, T_x])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize a_next and c_next</span></span><br><span class="line">    a_next = a0</span><br><span class="line">    c_next = np.zeros([n_a, m])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop over all time-steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T_x):</span><br><span class="line">        <span class="comment"># Update next hidden state, next memory state, compute the prediction, get the cache</span></span><br><span class="line">        a_next, c_next, yt, cache = lstm_cell_forward(x[:,:,t], a_next, c_next, parameters)</span><br><span class="line">        <span class="comment"># Save the value of the new "next" hidden state in a</span></span><br><span class="line">        a[:,:,t] = a_next</span><br><span class="line">        <span class="comment"># Save the value of the prediction in y</span></span><br><span class="line">        y[:,:,t] = yt</span><br><span class="line">        <span class="comment"># Save the value of the next cell state</span></span><br><span class="line">        c[:,:,t]  = c_next</span><br><span class="line">        <span class="comment"># Append the cache into caches</span></span><br><span class="line">        caches.append(cache)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    caches = (caches, x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a, y, c, caches</span><br></pre></td></tr></table></figure><h2 id="反向传播">反向传播</h2><p>在 DeepLearning 课程作业中，RNN 反向传播直接忽略了细胞的输出，没有考虑细胞的输出的误差对参数的梯度，降低了作业的难度，在 LSTM 反向传播中考虑了细胞的输出的误差对参数的梯度。</p><p>在预测输出的时候，RNN 使用了 Softmax 函数，关于 Softmax 函数的求导过程可以参考 <a href="/2018/04/26/Logistic-regression">Logistic 回归和 Softmax 回归</a>。RNN 在时间步上反向传播，因此也叫做 BackPropagation Through Time(BPTT) 算法。</p><h3 id="简单版-rnn-细胞">简单版 RNN 细胞</h3><p>没有输出只有隐藏状态的 RNN 细胞的反向传播过程如下图所示：</p><p><img src="/2018/06/20/recurrent-neural-network/rnn_cell_backprop.png"></p><p>由链式求导公式、复合求导公式和矩阵的求导公式或者参考<a href="/2018/05/19/Neuron-network">单隐层神经网络</a>可以推导出右边的表达式，其代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell_backward</span><span class="params">(da_next, cache)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve values from cache</span></span><br><span class="line">    (a_next, a_prev, xt, parameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve values from parameters</span></span><br><span class="line">    Wax = parameters[<span class="string">"Wax"</span>]</span><br><span class="line">    Waa = parameters[<span class="string">"Waa"</span>]</span><br><span class="line">    ba = parameters[<span class="string">"ba"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient of tanh with respect to a_next</span></span><br><span class="line">    dtanh = (<span class="number">1</span>-a_next * a_next) * da_next  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient of the loss with respect to Wax</span></span><br><span class="line">    dxt = np.dot(Wax.T,dtanh)</span><br><span class="line">    dWax = np.dot(dtanh, xt.T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient with respect to Waa</span></span><br><span class="line">    da_prev = np.dot(Waa.T,dtanh)</span><br><span class="line">    dWaa = np.dot(dtanh, a_prev.T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient with respect to b</span></span><br><span class="line">    dba = np.sum(dtanh, keepdims=<span class="literal">True</span>, axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dxt"</span>: dxt, <span class="string">"da_prev"</span>: da_prev, <span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa, <span class="string">"dba"</span>: dba&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h3 id="rnn-反向传播">RNN 反向传播</h3><p>在 RNN 反向传播中不但要计算参数的梯度，也要计算 <span class="math inline">\(a^{\langle t\rangle}\)</span> 的梯度，这样才能将梯度反向传播到前一个 RNN 细胞，代码中还保存了输入的梯度到 <span class="math inline">\(dx\)</span> 中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(da, caches)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve values from the first cache (t=1) of caches</span></span><br><span class="line">    (caches, x) = caches</span><br><span class="line">    (a1, a0, x1, parameters) = caches[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from da's and x1's shapes</span></span><br><span class="line">    n_a, m, T_x = da.shape</span><br><span class="line">    n_x, m = x1.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the gradients with the right sizes</span></span><br><span class="line">    dx = np.zeros([n_x, m, T_x])</span><br><span class="line">    dWax = np.zeros([n_a, n_x])</span><br><span class="line">    dWaa = np.zeros([n_a, n_a])</span><br><span class="line">    dba = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    da0 = np.zeros([n_a, m])</span><br><span class="line">    da_prevt = np.zeros([n_a, m])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop through all the time steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T_x)):</span><br><span class="line">        <span class="comment"># Compute gradients at time step t. Choose wisely the "da_next" and the "cache" to use in the backward propagation step.</span></span><br><span class="line">        gradients = rnn_cell_backward(da[:,:,t] + da_prevt, caches[t])</span><br><span class="line">        <span class="comment"># Retrieve derivatives from gradients</span></span><br><span class="line">        dxt, da_prevt, dWaxt, dWaat, dbat = gradients[<span class="string">"dxt"</span>], gradients[<span class="string">"da_prev"</span>], gradients[<span class="string">"dWax"</span>], gradients[<span class="string">"dWaa"</span>], gradients[<span class="string">"dba"</span>]</span><br><span class="line">        <span class="comment"># Increment global derivatives w.r.t parameters by adding their derivative at time-step t</span></span><br><span class="line">        dx[:,:,t] = dxt</span><br><span class="line">        dWax += dWaxt</span><br><span class="line">        dWaa += dWaat</span><br><span class="line">        dba += dbat</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Set da0 to the gradient of a which has been backpropagated through all time-steps</span></span><br><span class="line">    da0 = da_prevt</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dx"</span>: dx, <span class="string">"da0"</span>: da0, <span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa,<span class="string">"dba"</span>: dba&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h3 id="完整版-rnn-细胞">完整版 RNN 细胞</h3><p>完整的 RNN 细胞有输出，代价函数是所有时间步的输出的损失函数的和，对参数 <span class="math inline">\(W_{ya}\)</span> 和 <span class="math inline">\(b_y\)</span> 的求导比较简单，因为它们当前梯度只和当前时间步的损失函数相关： <span class="math display">\[J=\sum_{t=1}^{T_x}J^{\langle t\rangle}\]</span></p><p><span class="math display">\[\frac{\partial J}{\partial W_{ya}}=\sum_{t=1}^{T_x}(\hat y^{\langle t\rangle}-y^{\langle t\rangle})a^{\langle t\rangle T}\]</span></p><p><span class="math display">\[\frac{\partial J}{\partial b_y}=\sum_{t=1}^{T_x}\hat y^{\langle t\rangle}-y^{\langle t\rangle}\]</span></p><p>参数 <span class="math inline">\(W_{aa}, b_a\)</span> 和 <span class="math inline">\(W_{ax}\)</span> 的梯度就比较复杂，因为它们的当前梯度不仅和当前时间步的损失函数相关，还和后面的时间步的损失函数相关。首先定义当前时间步的隐藏状态的梯度 <span class="math inline">\(\delta^{\langle t\rangle}\)</span>，其递推公式如下所示： <span class="math display">\[\begin{align}\delta^{\langle t\rangle}&amp;=\frac{\partial J}{\partial a^{\langle t\rangle}}=\frac{\sum_{i=t}^{T_x}\partial J^{\langle i\rangle}}{\partial a^{\langle t\rangle}} \\\&amp;=\frac{\partial J^{\langle t\rangle}}{\partial a^{\langle t\rangle}}+\frac{\sum_{i=t+1}^{T_x}\partial J^{\langle i\rangle}}{\partial a^{\langle t+1\rangle}}\frac{\partial a^{\langle t+1\rangle}}{\partial a^{\langle t\rangle}} \\\&amp;=W_{ya}^T(\hat y^{\langle t\rangle}-y^{\langle t\rangle})+W_{aa}^T\delta^{\langle t+1\rangle}diag(1-a^{\langle t+1\rangle2})\tag{1}\end{align}\]</span> 隐藏状态在时间步方向上的代价函数的梯度(即不考虑当前时间步的输出) 为 <span class="math inline">\(\delta^{\langle T_x\rangle}\prod_{i=t+1}^{T_x}W_{aa}^Tdiag(1-a^{\langle i\rangle2})\)</span>，当参数 <span class="math inline">\(W_{aa}^T\)</span> 小于 1 时就产生了梯度消失，即使使用 <span class="math inline">\(ReLU\)</span> 函数作为激活函数，梯度为 <span class="math inline">\(\delta^{\langle T_x\rangle}\prod_{i=t+1}^{T_x}W_{aa}^T\)</span>，也不能解决长期依赖问题。隐藏状态在最后一个时间步 <span class="math inline">\(\langle T_{x}\rangle\)</span> 梯度只由该时间步的损失函数相关，因为后面不再有损失函数，所以有： <span class="math display">\[\delta^{\langle T_x\rangle}=\frac{\partial J}{\partial a^{\langle T_x\rangle}}=\frac{\partial J^{\langle T_x\rangle}}{\partial a^{\langle T_x\rangle}}=W_{ya}^T(\hat y^{\langle t\rangle}-y^{\langle t\rangle})\tag{2}\]</span> 根据 <span class="math inline">\((1)\)</span> 和 <span class="math inline">\((2)\)</span> 递推公式可以求得 <span class="math inline">\(\delta^{\langle t\rangle}\)</span>，有了 <span class="math inline">\(\delta^{\langle t\rangle}\)</span> 就可以很轻松地求解参数 <span class="math inline">\(W_{aa}, b_a\)</span> 和 <span class="math inline">\(W_{ax}\)</span> 的梯度： <span class="math display">\[\frac{\partial J}{\partial W_{aa}}=\sum_{t=1}^{T_x}\frac{\partial J}{\partial a^{\langle t\rangle}}\frac{\partial a^{\langle t\rangle}}{\partial W_{aa}}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})\delta^{\langle t\rangle}a^{\langle t-1\rangle T}\]</span></p><p><span class="math display">\[\frac{\partial J}{\partial b_a}=\sum_{t=1}^{T_x}\frac{\partial J}{\partial a^{\langle t\rangle}}\frac{\partial a^{\langle t\rangle}}{\partial b_a}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})\delta^{\langle t\rangle}\]</span></p><p><span class="math display">\[\frac{\partial J}{\partial W_{ax}}=\sum_{t=1}^{T_x}\frac{\partial J}{\partial a^{\langle t\rangle}}\frac{\partial a^{\langle t\rangle}}{\partial W_{ax}}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})\delta^{\langle t\rangle}x^{\langle t\rangle T}\]</span></p><h3 id="lstm-细胞-1">LSTM 细胞</h3><p>LSTM 的细胞结构比较复杂，反向传播的公式也比较难，关于隐藏状态的梯度公式和普通 RNN 类似。参数的梯度不仅和当前时间步的损失函数相关(通过隐藏状态 <span class="math inline">\(a^{\langle t\rangle}\)</span>)，还和后面的时间步的损失函数相关(通过细胞的状态 <span class="math inline">\(c^{\langle t\rangle}\)</span>)。定义当前时间步的细胞状态的梯度 <span class="math inline">\(\delta^{\langle t\rangle}\)</span>，其递推公式如下所示： <span class="math display">\[\begin{align}\delta^{\langle t\rangle}&amp;=\frac{\partial J}{\partial c^{\langle t\rangle}}=\frac{\sum_{i=t}^{T_x}\partial J^{\langle i\rangle}}{\partial c^{\langle t\rangle}} \\\&amp;=\frac{\partial J^{\langle t\rangle}}{\partial c^{\langle t\rangle}}+\frac{\sum_{i=t+1}^{T_x}\partial J^{\langle i\rangle}}{\partial c^{\langle t+1\rangle}}\frac{\partial c^{\langle t+1\rangle}}{\partial c^{\langle t\rangle}} \\\&amp;=\frac{\partial J^{\langle t\rangle}}{\partial c^{\langle t\rangle}}+\delta^{\langle t+1\rangle}\Gamma_f^{\langle t\rangle}\end{align}\]</span> 细胞状态在时间步方向上的代价函数的梯度为 <span class="math inline">\(\delta^{\langle T_x\rangle}\prod_{i=t+1}^k\Gamma_f^{\langle i\rangle}\)</span>，因为最原始的 LSTM 没有遗忘门，即 <span class="math inline">\(\Gamma_f^{\langle t\rangle}=1\)</span>，所以不存在梯度消失问题。目前流行的深度学习框架中 <span class="math inline">\(b_f\)</span> 一般会设置的大一些，这样遗忘门的输出 <span class="math inline">\(\Gamma_f^{\langle t\rangle}=\sigma(W_f[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_f)\)</span> 就会约等于 1，可以减缓梯度消失，所以即使遗忘门的输出很小，那也是当前时间步的输入导致的模型的选择，不是多层嵌套导致的梯度消失。</p><p>LSTM 细胞的梯度主要分为两部分：门的梯度和参数的梯度，参数的梯度公式如下：</p><ul><li><p>门的梯度 <span class="math display">\[d\Gamma_o^{\langle t \rangle}=da^{\langle t\rangle}*\tanh(c^{\langle t\rangle})\]</span></p><p><span class="math display">\[d\tilde c^{\langle t\rangle}=dc^{\langle t\rangle}*\Gamma_u^{\langle t \rangle}+\Gamma_o^{\langle t\rangle}\big(1-\tanh(c^{\langle t\rangle})^2\big)*\Gamma_u^{\langle t \rangle}*da^{\langle t\rangle}\]</span></p><p><span class="math display">\[d\Gamma_u^{\langle t \rangle}=dc^{\langle t\rangle}*\tilde c^{\langle t\rangle}+\Gamma_o^{\langle t\rangle}\big(1-\tanh(c^{\langle t\rangle})^2\big)*\tilde c^{\langle t\rangle}*da^{\langle t\rangle}\]</span></p><p><span class="math display">\[d\Gamma_f^{\langle t\rangle}=dc^{\langle t\rangle}*c^{\langle t-1\rangle}+\Gamma_o^{\langle t\rangle}\big(1-\tanh(c^{\langle t\rangle})^2\big)*c^{\langle t-1\rangle}*da^{\langle t\rangle}\]</span></p></li><li><p>参数的梯度 <span class="math display">\[dW_f = d\Gamma_f^{\langle t\rangle}*\Gamma_f^{\langle t\rangle}*(1-\Gamma_f^{\langle t\rangle})\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T\]</span></p><p><span class="math display">\[dW_u=d\Gamma_u^{\langle t \rangle}*\Gamma_u^{\langle t\rangle}*(1-\Gamma_u^{\langle t\rangle})*\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T\]</span></p><p><span class="math display">\[dW_c=d\tilde c^{\langle t \rangle}*(1-\tilde c^{\langle t\rangle 2})*\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T\]</span></p><p><span class="math display">\[dW_o=d\Gamma_o^{\langle t\rangle}*\Gamma_o^{\langle t\rangle}*(1-\Gamma_o^{\langle t\rangle})*\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T\]</span></p></li></ul><p><span class="math inline">\(b_f, b_u, b_c, b_o\)</span> 的梯度只需要将 <span class="math inline">\(\Gamma_f^{\langle t\rangle}, \Gamma_u^{\langle t\rangle}, \tilde c^{\langle t\rangle}, \Gamma_o^{\langle t\rangle}\)</span> 的梯度沿水平方向 (axis=1) 累加即可，当前时间步的输入、上一个时间步的细胞状态和隐藏状态的梯度如下所示： <span class="math display">\[\begin{align}da^{\langle t-1\rangle} &amp;= W_f^T*d\Gamma_f^{\langle t\rangle}*\Gamma_f^{\langle t\rangle}*(1-\Gamma_f^{\langle t\rangle})  \\\&amp;+ W_u^T * d\Gamma_u^{\langle t \rangle}*\Gamma_u^{\langle t\rangle}*(1-\Gamma_u^{\langle t\rangle}) \\\&amp;+ W_c^T * d\tilde c^{\langle t \rangle}*(1-\tilde c^{\langle t\rangle 2})  \\\&amp;+ W_o^T * d\Gamma_o^{\langle t\rangle}*\Gamma_o^{\langle t\rangle}*(1-\Gamma_o^{\langle t\rangle})\end{align}\]</span></p><p><span class="math display">\[dc^{\langle t-1\rangle} = dc^{\langle t\rangle}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} * (1- \tanh(c^{\langle t-1\rangle})^2)*\Gamma_f^{\langle t \rangle}*da^{\langle t\rangle}\]</span></p><p><span class="math display">\[\begin{align}dx^{\langle t \rangle} &amp;= W_f^T*d\Gamma_f^{\langle t\rangle}*\Gamma_f^{\langle t\rangle}*(1-\Gamma_f^{\langle t\rangle}) \\\&amp;+ W_u^T * d\Gamma_u^{\langle t \rangle}*\Gamma_u^{\langle t\rangle}*(1-\Gamma_u^{\langle t\rangle}) \\\&amp;+ W_c^T * d\tilde c^{\langle t \rangle}*(1-\tilde c^{\langle t\rangle 2}) \\\&amp;+ W_o^T * d\Gamma_o^{\langle t\rangle}*\Gamma_o^{\langle t\rangle}*(1-\Gamma_o^{\langle t\rangle})\end{align}\]</span></p><p>DeepLearning 的目前最新版本作业中的公式和代码的表示有些小问题，这里已经修正。其代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell_backward</span><span class="params">(da_next, dc_next, cache)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve information from "cache"</span></span><br><span class="line">    (a_next, c_next, a_prev, c_prev, ft, ut, cct, ot, xt, parameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from xt's and a_next's shape</span></span><br><span class="line">    n_x, m = xt.shape</span><br><span class="line">    n_a, m = a_next.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute gates related derivatives, you can find their values can be found by looking carefully at equations (7) to (10)</span></span><br><span class="line">    dot = da_next * np.tanh(c_next)</span><br><span class="line">    dcct = (dc_next * ut + ot * (<span class="number">1</span> - np.square(np.tanh(c_next))) * ut * da_next)</span><br><span class="line">    dut = (dc_next * cct + ot * (<span class="number">1</span> - np.square(np.tanh(c_next))) * cct * da_next)</span><br><span class="line">    dft = (dc_next * c_prev + ot * (<span class="number">1</span> - np.square(np.tanh(c_next))) * c_prev * da_next)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute parameters related derivatives. Use equations (11)-(14)</span></span><br><span class="line">    concat = np.concatenate((a_prev, xt), axis=<span class="number">0</span>).T</span><br><span class="line">    dWf = np.dot(dft * ft * (<span class="number">1</span> - ft), concat)</span><br><span class="line">    dWu = np.dot(dut * ut * (<span class="number">1</span> - ut), concat)</span><br><span class="line">    dWc = np.dot(dcct * (<span class="number">1</span> - np.square(cct)), concat)</span><br><span class="line">    dWo = np.dot(dot * ot * (<span class="number">1</span> - ot), concat)</span><br><span class="line">    dbf = np.sum(dft * ft * (<span class="number">1</span> - ft), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  </span><br><span class="line">    dbu = np.sum(dut * ut * (<span class="number">1</span> - ut), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  </span><br><span class="line">    dbc = np.sum(dcct * (<span class="number">1</span> - np.square(cct)), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  </span><br><span class="line">    dbo = np.sum(dot * ot * (<span class="number">1</span> - ot),axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (15)-(17).</span></span><br><span class="line">    da_prev = np.dot(parameters[<span class="string">"Wf"</span>][:, :n_a].T, dft * ft * (<span class="number">1</span> - ft)) + np.dot(parameters[<span class="string">"Wc"</span>][:, :n_a].T, dcct * (<span class="number">1</span> - np.square(cct))) + np.dot(parameters[<span class="string">"Wu"</span>][:, :n_a].T, dut * ut * (<span class="number">1</span> - ut)) + np.dot(parameters[<span class="string">"Wo"</span>][:, :n_a].T, dot * ot * (<span class="number">1</span> - ot))</span><br><span class="line">    dc_prev = dc_next*ft+ot*(<span class="number">1</span>-np.square(np.tanh(c_next)))*ft*da_next</span><br><span class="line">    dxt = np.dot(parameters[<span class="string">"Wf"</span>][:, n_a:].T, dft * ft * (<span class="number">1</span> - ft)) + np.dot(parameters[<span class="string">"Wc"</span>][:, n_a:].T, dcct * (<span class="number">1</span> - np.square(cct))) + np.dot(parameters[<span class="string">"Wu"</span>][:, n_a:].T, dut * ut * (<span class="number">1</span> - ut)) + np.dot(parameters[<span class="string">"Wo"</span>][:, n_a:].T, dot * ot * (<span class="number">1</span> - ot))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save gradients in dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dxt"</span>: dxt, <span class="string">"da_prev"</span>: da_prev, <span class="string">"dc_prev"</span>: dc_prev, <span class="string">"dWf"</span>: dWf,<span class="string">"dbf"</span>: dbf, <span class="string">"dWu"</span>: dWu,<span class="string">"dbu"</span>: dbu,</span><br><span class="line">                <span class="string">"dWc"</span>: dWc,<span class="string">"dbc"</span>: dbc, <span class="string">"dWo"</span>: dWo,<span class="string">"dbo"</span>: dbo&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h3 id="lstm-反向传播">LSTM 反向传播</h3><p>类似于 RNN 的反向传播，最后一个时间步的细胞状态和隐藏状态的梯度为 0，其代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span><span class="params">(da, caches)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve values from the first cache (t=1) of caches.</span></span><br><span class="line">    (caches, x) = caches</span><br><span class="line">    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from da's and x1's shapes (≈2 lines)</span></span><br><span class="line">    n_a, m, T_x = da.shape</span><br><span class="line">    n_x, m = x1.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the gradients with the right sizes (≈12 lines)</span></span><br><span class="line">    dx = np.zeros([n_x, m, T_x])</span><br><span class="line">    da0 = np.zeros([n_a, m])</span><br><span class="line">    da_prevt = np.zeros([n_a, m])</span><br><span class="line">    dc_prevt = np.zeros([n_a, m])</span><br><span class="line">    dWf = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWu = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWc = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWo = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dbf = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbu = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbc = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbo = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop back over the whole sequence</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T_x)):</span><br><span class="line">        <span class="comment"># Compute all gradients using lstm_cell_backward</span></span><br><span class="line">        gradients = lstm_cell_backward(da[:,:,t],dc_prevt,caches[t])</span><br><span class="line">        <span class="comment"># Store or add the gradient to the parameters' previous step's gradient</span></span><br><span class="line">        dx[:,:,t] = gradients[<span class="string">'dxt'</span>]</span><br><span class="line">        dWf = dWf+gradients[<span class="string">'dWf'</span>]</span><br><span class="line">        dWu = dWu+gradients[<span class="string">'dWu'</span>]</span><br><span class="line">        dWc = dWc+gradients[<span class="string">'dWc'</span>]</span><br><span class="line">        dWo = dWo+gradients[<span class="string">'dWo'</span>]</span><br><span class="line">        dbf = dbf+gradients[<span class="string">'dbf'</span>]</span><br><span class="line">        dbu = dbu+gradients[<span class="string">'dbu'</span>]</span><br><span class="line">        dbc = dbc+gradients[<span class="string">'dbc'</span>]</span><br><span class="line">        dbo = dbo+gradients[<span class="string">'dbo'</span>]</span><br><span class="line">    <span class="comment"># Set the first activation's gradient to the backpropagated gradient da_prev.</span></span><br><span class="line">    da0 = gradients[<span class="string">'da_prev'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dx"</span>: dx, <span class="string">"da0"</span>: da0, <span class="string">"dWf"</span>: dWf,<span class="string">"dbf"</span>: dbf, <span class="string">"dWu"</span>: dWu,<span class="string">"dbu"</span>: dbu,</span><br><span class="line">                <span class="string">"dWc"</span>: dWc,<span class="string">"dbc"</span>: dbc, <span class="string">"dWo"</span>: dWo,<span class="string">"dbo"</span>: dbo&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h2 id="激活函数选择">激活函数选择</h2><ul><li>在 RNN 中，使用 <span class="math inline">\(tanh\)</span> 函数作为激活函数是因为 RNN 主要存在梯度消失问题。相比于 <span class="math inline">\(sigmoid\)</span> 激活函数，<span class="math inline">\(tanh\)</span> 函数的二阶导数在 0 之前持续很长的范围，更加有利于保持梯度在激活函数的线性区域。</li><li>在 RNN 中，参数 <span class="math inline">\(W_{ax}\)</span> 和 <span class="math inline">\(W_{aa}\)</span> 参与了每个时间步的运算，即使使用 <span class="math inline">\(ReLU\)</span> 函数作为激活函数，当参数 <span class="math inline">\(W\)</span> 小于 1 时也会产生梯度消失问题，而且 <span class="math inline">\(ReLU\)</span> 函数还会导致模型的输出过大，<span class="math inline">\(tanh\)</span> 函数则可以控制输出范围在 <span class="math inline">\((-1, 1)\)</span>。</li><li>在 LSTM 的门单元中，使用 <span class="math inline">\(sigmoid\)</span> 函数作为激活函数是因为要保证门的输出是一个 0，1 之间的向量，例如遗忘门 的输出表示让 <span class="math inline">\(c^{\langle t-1\rangle}\)</span> 各部分信息通过的比例，0 表示不让任何信息通过，1 表示让所有信息通过。</li></ul><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li><li>Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" target="_blank" rel="noopener">Understanding LSTM Networks</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;按照吴恩达 Deeplearning 系列课程，应该是先学卷积神经网络，但是自己的实验中要用到递归神经网络，感觉不能再拖了，就先学习一下序列模型这一章节。在普通的神经网络中，一般都是输入一个向量，然后输出一个向量或者通过 Sigmoid 函数后输出一个值。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://pengzhendong.cn/tags/Deep-Learning/"/>
    
  </entry>
  
</feed>
