<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>自动驾驶</title>
    <url>/2019/01/08/autonomous-driving/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>最近在看《梁实秋读书与做人》，开始感受到了时间的宝贵，究竟如何才能掌握尚未逝去的时光呢？同时也尝试了刷一刷 LeetCode，毕竟这是每一个计算机从业者的基本功，不能再浑浑噩噩了。论文还是没有结果，在一个博士的指导下投了 B 刊，也是不能松懈，继续折腾吧！正好自己又有了一点小想法，可是为什么我的想法总是这么难实现呢？每一篇博客的前言都是被用来吐槽的，吐槽最近的生活与科研。空闲之余继续学习深度学习，这一节的内容是使用 YOLO 算法实现“自动驾驶”，其实是对摄像头拍摄的视频中的每一帧进行目标检测。</p>
<a id="more"></a>
<h2 id="目标检测">目标检测</h2>
<p>这部分内容属于自动驾驶的一个模块，即车辆检测。通常自动驾驶需要给汽车安装一个摄像头，对前方路况进行拍摄，我们需要检测前方有无车辆以及车辆的位置信息，以供其它模块避开车辆。</p>
<p><img src="/2019/01/08/autonomous-driving/box_label.png"></p>
<p>这里使用 YOLO 算法进行目标检测，一共有 80 个类别，即 <span class="math inline">\(c\)</span> 的取值为 <span class="math inline">\([1, 80]\)</span> 或者是一个 80 维的独热向量，这两种表示在实验中都会使用，哪个方便用哪个。由于 YOLO 训练比较耗时，因此主要是了解 YOLO 算法的原理，最后实验会提供预训练好的模型。</p>
<h2 id="yolo">YOLO</h2>
<p>YOLO (You Only Look Once) 算法在目标检测领域比较受欢迎，因为它的准确率比较高而且可以做到实时检测。这个算法只需要前向传播一次即可做出预测，在非极大值抑制后即可输出识别的目标和其位置信息。而前面介绍的 RCNN 系列算法则是需要先提取图像的感兴趣区域，再对这些区域进行分析，即需要“看”两次。</p>
<h3 id="模型">模型</h3>
<ul>
<li>输入：一个批次的三通道图像，其 shape 为 <span class="math inline">\((m, 608, 608, 3)\)</span></li>
<li>输出：一个列表，列表中每个元素为一个 6 维向量 <span class="math inline">\((p_c, b_x, b_y, b_h, b_w, c)\)</span>；如果使用独热向量则是 85 维向量。</li>
</ul>
<p>实验使用 5 个锚框，因此 YOLO 的结构为：IMAGE (m, 608, 608, 3) -&gt; DEEP CNN -&gt; ENCODING (m, 19, 19, 5, 85)，如下图所示：</p>
<p><img src="/2019/01/08/autonomous-driving/architecture.png"></p>
<p>如果目标的中心在网格中，该网格就需要检测到该目标。由于使用了 5 个锚框，所以输出的 <span class="math inline">\(19\times 19\)</span> 网格中的每一个网格对应 5 个边界框，即输出的维度为 <span class="math inline">\((19, 19, 5, 85)\)</span>。将最后两个维度拉平得 <span class="math inline">\((19, 19, 425)\)</span>，如下图所示：</p>
<p><img src="/2019/01/08/autonomous-driving/flatten.png"></p>
<p>对于网格中的每一个锚框，我们需要计算其中分类为每一个类别的概率，如下图所示：</p>
<p><img src="/2019/01/08/autonomous-driving/probability_extraction.png"></p>
<p>图中 <span class="math inline">\(p_c\)</span> 为包含待检测目标的概率，<span class="math inline">\(c_n\)</span> 为属于第 <span class="math inline">\(n\)</span> 个类别的概率。因此 <span class="math inline">\(p_cc_n\)</span> 为锚框中包含第 <span class="math inline">\(n\)</span> 类目标的概率，最后取概率最大的一类作为该锚框的预测结果。由于一个网格对应 5 个锚框，最后再对这 5 个锚框的输出取最大值作为该网格的预测结果，即一个网格只保留一个锚框，该锚框对应一个类别的物体。有两种方法可以对算法进行可视化：对网格上色和绘制出每个网格对应的边界框。两种方式如下图所示：</p>
<p><img src="/2019/01/08/autonomous-driving/proba_anchor.png"></p>
<p>即使取了最大值，但是输出的边界框还是很多。因此还可以对其进行过滤：</p>
<ul>
<li>去除得分比较低的边界框（阈值过滤），得分低表示边界框不敢肯定其中检测到的目标</li>
<li>对于重叠内容比较多的边界框，只保留其中一个（非极大值抑制）</li>
</ul>
<h3 id="阈值过滤">阈值过滤</h3>
<p>设定阈值，过滤掉得分低于阈值的边界框。模型输出的维度为 <span class="math inline">\(19\times 19\times 5\times 85\)</span>，每个 85 维的向量对应一个边界框，因此可以将模型的输出分为以下三部分：</p>
<ul>
<li><code>box_confidence</code>: 维度为 <span class="math inline">\((19 \times 19, 5, 1)\)</span> 的张量，对应所有边界框的 <span class="math inline">\(p_c\)</span></li>
<li><code>boxes</code>: 维度为 <span class="math inline">\((19 \times 19, 5, 4)\)</span> 的张量，对应所有边界框的位置信息 <span class="math inline">\((b_x, b_y, b_h, b_w)\)</span></li>
<li><code>box_class_probs</code>: 维度为 <span class="math inline">\((19 \times 19, 5, 80)\)</span> 的张量，对应检测到的目标的类别的概率 <span class="math inline">\((c_1, c_2, ... c_{80})\)</span></li>
</ul>
<p>实现阈值过滤包含以下四个步骤：</p>
<ol type="1">
<li><p>计算每个边界框包含的具体类别目标的概率 <span class="math inline">\(p_cc_n\)</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.random.randn(<span class="number">19</span>*<span class="number">19</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">b = np.random.randn(<span class="number">19</span>*<span class="number">19</span>, <span class="number">5</span>, <span class="number">80</span>)</span><br><span class="line">c = a * b <span class="comment"># shape of c will be (19*19, 5, 80)</span></span><br></pre></td></tr></table></figure></li>
<li><p>对于每一个边界框，找到最大的得分 <code>box_class_scores</code> 与其对应类别的索引 <code>box_classes</code></p></li>
<li><p>根据阈值创建 mask 矩阵。如 <code>([0.9, 0.3, 0.4, 0.5, 0.1] &lt; 0.4</code> 返回 <code>[False, True, False, False, True]</code></p></li>
<li><p>将 mask 矩阵应用到 <code>box_class_scores</code> 和 <code>box_classes</code> 中即可过滤出超过阈值的边界框</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_filter_boxes</span><span class="params">(box_confidence, boxes, box_class_probs, threshold = <span class="number">.6</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Compute box scores</span></span><br><span class="line">    box_scores = np.multiply(box_confidence, box_class_probs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score</span></span><br><span class="line">    box_classes = K.argmax(box_scores, axis=<span class="number">-1</span>)</span><br><span class="line">    box_class_scores = K.max(box_scores, axis=<span class="number">-1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Create a filtering mask based on "box_class_scores" by using "threshold". The mask should have the</span></span><br><span class="line">    <span class="comment"># same dimension as box_class_scores, and be True for the boxes you want to keep (with probability &gt;= threshold)</span></span><br><span class="line">    filtering_mask = K.greater_equal(box_class_scores, threshold)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 4: Apply the mask to scores, boxes and classes</span></span><br><span class="line">    scores = tf.boolean_mask(box_class_scores, filtering_mask)</span><br><span class="line">    boxes = tf.boolean_mask(boxes, filtering_mask)</span><br><span class="line">    classes = tf.boolean_mask(box_classes, filtering_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores, boxes, classes</span><br></pre></td></tr></table></figure>
<h3 id="非极大值抑制">非极大值抑制</h3>
<p>阈值过滤后，还是会有很多边界框。它们框住同一个目标，因此 <span class="math inline">\(p_cc_n\)</span> 都会大于阈值，我们可以使用非极大值抑制来保留一个边界框，如下图所示：</p>
<p><img src="/2019/01/08/autonomous-driving/non-max-suppression.png"></p>
<p>上图中模型预测出三个车，但是属于同一辆车，非极大值抑制可以保留最准确的一个边界框，即概率最大的一个。非极大值抑制中有一个很重要的概念叫<strong>交并比 IoU</strong>(Intersection over Union)，其原理如下图所示：</p>
<p><img src="/2019/01/08/autonomous-driving/iou.png"></p>
<p>实验给定的边界框位置信息为左上角和右下角：(x1, y1, x2, y2)。即边界框的高为 (y2 - y1)，宽为 (x2 - x1)；图像的左上角为 (0, 0)，右上角为 (1, 0)，右下角为 (1, 1)。给定两个边界框，还需要找到交并后的坐标：</p>
<ul>
<li><code>xi1</code>: 两个边界框 x1 的最大值</li>
<li><code>yi1</code>: 两个边界框 y1 的最大值</li>
<li><code>xi2</code>: 两个边界框 x2 的最小值</li>
<li><code>yi2</code>: 两个边界框 y2 的最小值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iou</span><span class="params">(box1, box2)</span>:</span></span><br><span class="line">    <span class="comment"># Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1 and box2. Calculate its Area.</span></span><br><span class="line">    xi1 = max(box1[<span class="number">0</span>], box2[<span class="number">0</span>])</span><br><span class="line">    yi1 = max(box1[<span class="number">1</span>], box2[<span class="number">1</span>])</span><br><span class="line">    xi2 = min(box1[<span class="number">2</span>], box2[<span class="number">2</span>])</span><br><span class="line">    yi2 = min(box1[<span class="number">3</span>], box2[<span class="number">3</span>])</span><br><span class="line">    inter_area = (xi2 - xi1)*(yi2 - yi1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)</span></span><br><span class="line">    box1_area = (box1[<span class="number">3</span>] - box1[<span class="number">1</span>])*(box1[<span class="number">2</span>]- box1[<span class="number">0</span>])</span><br><span class="line">    box2_area = (box2[<span class="number">3</span>] - box2[<span class="number">1</span>])*(box2[<span class="number">2</span>]- box2[<span class="number">0</span>])</span><br><span class="line">    union_area = (box1_area + box2_area) - inter_area</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute the IoU</span></span><br><span class="line">    iou = inter_area / union_area</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>
<p>实现非极大值抑制分为三个步骤：</p>
<ol type="1">
<li><p>将所有边界框按照得分排序，选择最高分的边界框</p></li>
<li><p>遍历其余的边界框，计算得分最高的边界框与这些边界框的交并比。如果交并比大于阈值 <code>iou_threshold</code>，则删除这些边界框</p></li>
<li><p>迭代以上过程，直到处理完毕所有的边界框</p></li>
</ol>
<p>Tensorflow 内置函数实现了非极大值抑制，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_non_max_suppression</span><span class="params">(scores, boxes, classes, max_boxes = <span class="number">10</span>, iou_threshold = <span class="number">0.5</span>)</span>:</span></span><br><span class="line">    max_boxes_tensor = K.variable(max_boxes, dtype=<span class="string">'int32'</span>)     <span class="comment"># tensor to be used in tf.image.non_max_suppression()</span></span><br><span class="line">    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) <span class="comment"># initialize variable max_boxes_tensor</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep</span></span><br><span class="line">    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use K.gather() to select only nms_indices from scores, boxes and classes</span></span><br><span class="line">    scores = K.gather(scores, nms_indices)</span><br><span class="line">    boxes = K.gather(boxes, nms_indices)</span><br><span class="line">    classes = K.gather(classes, nms_indices)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores, boxes, classes</span><br></pre></td></tr></table></figure>
<h3 id="合并过滤器">合并过滤器</h3>
<p>将以上两种过滤器合并为 <code>yolo_filter_boxes</code>；深度 CNN 输出的 <span class="math inline">\(19\times 19\times 5\times 85\)</span> 维向量，即 YOLO 的编码 <code>yolo_outputs</code>。由于过滤器需要的位置信息不同，需要将 (x, y, w, h) 转化为 (x1, y1, x2, y2)。如果测试集的图像尺寸与训练集不一致，例需要将其扩展到图像大小的测试集上，例如图像大小为 (720, 1280) 。实验提供这些功能的接口，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_eval</span><span class="params">(yolo_outputs, image_shape = <span class="params">(<span class="number">720.</span>, <span class="number">1280.</span>)</span>, max_boxes=<span class="number">10</span>, score_threshold=<span class="number">.6</span>, iou_threshold=<span class="number">.5</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve outputs of the YOLO model (≈1 line)</span></span><br><span class="line">    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert boxes to be ready for filtering functions </span></span><br><span class="line">    boxes = yolo_boxes_to_corners(box_xy, box_wh)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line)</span></span><br><span class="line">    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Scale boxes back to original image shape.</span></span><br><span class="line">    boxes = scale_boxes(boxes, image_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use one of the functions you've implemented to perform Non-max suppression with a threshold of iou_threshold (≈1 line)</span></span><br><span class="line">    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes = max_boxes, iou_threshold = iou_threshold)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores, boxes, classes</span><br></pre></td></tr></table></figure>
<h2 id="测试">测试</h2>
<p>在图像大小为 (720, 1280) 的测试集上测试预训练的模型，由于需要检测 80 种类别并且使用 5 个锚框，因此需要先载入这些信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line">class_names = read_classes(<span class="string">"model_data/coco_classes.txt"</span>)</span><br><span class="line">anchors = read_anchors(<span class="string">"model_data/yolo_anchors.txt"</span>)</span><br><span class="line">image_shape = (<span class="number">720.</span>, <span class="number">1280.</span>)</span><br><span class="line"></span><br><span class="line">yolo_model = load_model(<span class="string">"model_data/yolo.h5"</span>)</span><br></pre></td></tr></table></figure>
<p>该模型的输出维度为 (m, 608, 608, 3))，输出维度为 (m, 19, 19, 5, 85)。将输出转化为过滤器的输入所需的维度，继而对边界框进行过滤：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))</span><br><span class="line">scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)</span><br></pre></td></tr></table></figure>
<h3 id="运行图">运行图</h3>
<p>目前为止，我们已经创建了一个 (sess) 图，主要包含以下三部分内容：</p>
<ol type="1">
<li><code>yolo_model</code>: 输入为 yolo_model.input，输出为 yolo_model.output</li>
<li><code>yolo_head</code>: 输入为 yolo_model.output，输出为 yolo_outputs</li>
<li><code>yolo_eval</code>: 过滤函数，输入为 yolo_outputs，输出为预测结果 scores, boxes 和 classes</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(sess, image_file)</span>:</span></span><br><span class="line">    <span class="comment"># Preprocess your image</span></span><br><span class="line">    image, image_data = preprocess_image(<span class="string">"images/"</span> + image_file, model_image_size = (<span class="number">608</span>, <span class="number">608</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run the session with the correct tensors and choose the correct placeholders in the feed_dict.</span></span><br><span class="line">    <span class="comment"># You'll need to use feed_dict=&#123;yolo_model.input: ... , K.learning_phase(): 0&#125;)</span></span><br><span class="line">    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict=&#123;yolo_model.input: image_data, K.learning_phase(): <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print predictions info</span></span><br><span class="line">    print(<span class="string">'Found &#123;&#125; boxes for &#123;&#125;'</span>.format(len(out_boxes), image_file))</span><br><span class="line">    <span class="comment"># Generate colors for drawing bounding boxes.</span></span><br><span class="line">    colors = generate_colors(class_names)</span><br><span class="line">    <span class="comment"># Draw bounding boxes on the image file</span></span><br><span class="line">    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)</span><br><span class="line">    <span class="comment"># Save the predicted bounding box on the image</span></span><br><span class="line">    image.save(os.path.join(<span class="string">"out"</span>, image_file), quality=<span class="number">90</span>)</span><br><span class="line">    <span class="comment"># Display the results in the notebook</span></span><br><span class="line">    output_image = scipy.misc.imread(os.path.join(<span class="string">"out"</span>, image_file))</span><br><span class="line">    imshow(output_image)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out_scores, out_boxes, out_classes</span><br></pre></td></tr></table></figure>
<p><code>preprocess_image</code> 函数返回的 image 用于绘制边界框。在测试图像种运行结果如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out_scores, out_boxes, out_classes = predict(sess, <span class="string">"test.jpg"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Found 7 boxes <span class="keyword">for</span> test.jpg</span><br><span class="line">car 0.60 (925, 285) (1045, 374)</span><br><span class="line">car 0.66 (706, 279) (786, 350)</span><br><span class="line">bus 0.67 (5, 266) (220, 407)</span><br><span class="line">car 0.70 (947, 324) (1280, 705)</span><br><span class="line">car 0.74 (159, 303) (346, 440)</span><br><span class="line">car 0.80 (761, 282) (942, 412)</span><br><span class="line">car 0.89 (367, 300) (745, 648)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/08/autonomous-driving/output.png"></p>
<h2 id="总结">总结</h2>
<p>YOLO 是目前目标检测领域最快最准确的算法，其直接在整张图像上运行 CNN 网络，输出 <span class="math inline">\(19\times 19\times 5\times 85\)</span> 的向量。这个输出的编码可以看成是一个 <span class="math inline">\(19\times 19\)</span> 的网格，每个网格对应 5 个边界框。然后使用非极大值抑制对边界框进行过滤，得到最后的结果。这种直接对图像运行 CNN 得到输出的形式，只需要一趟即可得到结果，不像 RCNN 需要先提取感兴趣的区域。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - <a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">You Only Look Once: Unified, Real-Time Object Detection</a> (2015)</li>
<li>Joseph Redmon, Ali Farhadi - <a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">YOLO9000: Better, Faster, Stronger</a> (2016)</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础</title>
    <url>/2018/05/28/basic-concepts-in-machine-learning/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>DeepLearning.ai 第二部分内容是改善深层神经网络，主要包括超参数的调试、正则化以及优化。这些内容大部分都是机器学习的基础，深度学习是机器学习的一个特定分支，要想充分理解深度学习就必须对机器学习的基本原理有深刻的理解。</p>
<a id="more"></a>
<h2 id="训练验证测试集">训练/验证/测试集</h2>
<p>当训练神经网络的时候，我们需要做出很多决策，例如神经网络要分多少层、隐藏层有多少个神经元、学习率是多少、每一层用什么激活函数等等。当创建一个新的应用的时候，我们不可能一开始就准确地预测出这些信息和其他超参数。所以应用型机器学习是一个高度迭代地过程：有个想法，然后写代码实现，分析实验结果，再改进自己的想法，然后写代码实现...创建高质量的训练集(Train set)、验证集(Development set)和测试集(Test set)有助于提高迭代效率。</p>
<p>在小数据量时代，常见的作法是将数据三七分(70% 训练集，30% “测试”集)或者 60%/20%/20% 划分训练集、验证集和测试集。在大数据时代，训练集的比重可能会更大，例如有一百万条数据，验证集和测试集可能只需要一万条数据，即 98%/1%/1% 。值得注意的是，验证集和测试集应该是同分布的，在测试集上评估的是验证集选出的模型；但是为了获取更大规模的训练集，训练集的分布可以和验证集/测试集不同分布。</p>
<h2 id="超参数">超参数</h2>
<p>大多机器学习算法都有超参数(例如上面需要做的决策)来控制算法行为，不同的超参数表示不同的模型。超参数的值<strong>不是</strong>通过算法本身学习出来(即使可以设计一个嵌套的学习过程学出最优超参数)。有时一个选项被设为超参数是因为它太难优化了，例如代价函数并不能给出<strong>学习率</strong>的更新方向，很难优化学习率；更多的情况是该选项必须是超参数，因为它不适合在训练集上学习，例如在<strong>训练集</strong>上学习控制模型容量的超参数，这些超参数总是趋向于最大可能的模型容量，导致过拟合。例如 M 次多项式拟合中，更倾向于在训练集上学出次数最高的模型，虽然训练误差小，但是拟合了噪声会导致过拟合，在遇到新数据的时候泛化误差就会很大。</p>
<p>超参数优化或模型选择是为了优化算法在<strong>独立数据集</strong>上的性能的度量 ，通常使用<strong>验证集</strong>进行交叉验证来<strong>估计这种泛化性能</strong>，指导超参数的调节。和训练数据相同分布的样本组成的测试集用来估计学习器的泛化误差，其重点在于测试样本不能以任何形式参与到模型的选择中 (包括设定超参数)。基于这个原因，测试集中的样本不能用于验证集，因此总是从训练数据中构建验证集。</p>
<p>深度学习中的超参数根据其重要性排序，大概有以下几个：</p>
<ul>
<li><font color="red">学习率 <span class="math inline">\(\alpha\)</span> </font></li>
<li><font color="orange">Momentum 参数 </font></li>
<li><font color="orange">隐藏神经元数 #hidden units</font></li>
<li><font color="orange">小批量的大小 mini-batch size</font></li>
<li><font color="purple">神经网络层数 #layers</font></li>
<li><font color="purple">学习率衰减</font></li>
<li><font color="blue">Adam 算法参数</font></li>
</ul>
<h3 id="超参数的调节">超参数的调节</h3>
<p>调节参数一般选择网格搜索的方法，但是推荐在网格中随机选择点，因为可能某个参数的某些取值不重要；另一个惯例是采用由粗糙到精细的策略，因为某个点效果好的话，也许这个点周围的其他一些点效果也很好。其次要为超参数选择合适的范围，而且对于某些超参数，不应该在取值范围内随机均匀取值，例如学习率 <span class="math inline">\(\alpha\)</span> 用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取 <span class="math inline">\(0.0001, 0.001, 0.01, 0.1, 1\)</span>。</p>
<p>超参数的调节主要有两种方法：</p>
<ol type="1">
<li>一次试验一个模型，将超参数随机初始化，然后观察模型的学习曲线(例如代价函数曲线)，根据学习曲线慢慢调节超参数</li>
<li>同时试验多种模型，最后快速选择工作效果最好的那个</li>
</ol>
<p>在机器学习中，如果只有一个训练集和一个验证集，验证集则被人们称为“测试”集，不过人们只是把测试集当成简单交叉验证集使用，即评估模型的泛化能力，然后调节模型的超参数，所以“训练验证集“在专业用词上更准确。</p>
<p>因此，训练集用来训练模型，调节参数；验证集用来调节超参数，选择模型；尽管验证集的误差通常比训练集误差小，但是验证集会低估泛化误差，完成超参数优化后，还需要测试集来估计泛化误差。如果验证集具有足够泛化性，那么就不需要测试集来给出泛化误差的无偏估计。</p>
<h2 id="偏差方差">偏差/方差</h2>
<p>假设有数据集 <span class="math inline">\(x=\{x_1, x_2, …, x_n\}\)</span>，并且真实标签 <span class="math inline">\(y_i\)</span> 对应数据点 <span class="math inline">\(x_i\)</span>。假设函数 <span class="math inline">\(y=f(x)+\epsilon\)</span> ，其中噪声 <span class="math inline">\(\epsilon\)</span> 为 0 均值的高斯分布，方差为 <span class="math inline">\(\sigma^2\)</span>，表示数据集与标签并不是完全符合函数 <span class="math inline">\(y\)</span>。我们希望通过机器学习找到 <span class="math inline">\(\hat f(x)\)</span>，通过最小化均方误差 <span class="math inline">\((y-\hat f(x))^2\)</span>，尽可能地逼近 <span class="math inline">\(f(x)\)</span>。由于样本数据具有噪声，所以 <span class="math inline">\(\hat f(x)\)</span> 不会完全拟合 <span class="math inline">\(y\)</span>。<font color="red">误差</font>定义为： <span class="math display">\[
\begin{align}
Err(x)&amp;=E\left[(y-\hat f(x))\right]^2 \\\
&amp;= \left(E[\hat f(x)]-f(x)\right)^2+E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]+\sigma^2 \\\
&amp;= \text{Bias}^2+\text{Variance}+\text{Irreducible Error}
\end{align}
\]</span> 对于训练误差，由于训练数据已知，即输入输出不是变量，常量的期望等于它本身，所以偏差 <span class="math inline">\(\text{Bias}=\hat f(x)-f(x)\)</span>，度量着偏离真实函数或参数的误差；方差 <span class="math inline">\(\text{Variance}=\Big(\hat f(x)-\hat f(x)\Big)^2=0\)</span>。表示训练误差由偏差和随机误差构成。</p>
<p>对于泛化误差，偏差 <span class="math inline">\(\text{Bias}=E[\hat f(x)]-f(x)\)</span> 度量着偏离真实函数或参数的误差期望；方差 <span class="math inline">\(\text{Variance}=E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]\)</span> 度量着数据上任意特定采样可能导致的估计期望的偏差(方差大，则对于不同采样，估计期望不一样)；噪声的方差为随机误差。一般说偏差、方差都是针对泛化来说的，因为验证集和训练集是同分布随机采样，所以 <span class="math inline">\(E[\hat f(x)]=\hat f(x)\)</span>，即泛化误差的偏差的平方等于训练误差(泛化误差=训练误差+方差)。在机器学习中，我们不仅希望降低训练误差(避免欠拟合)，也希望缩小训练误差和泛化误差的差距(避免过拟合)，这样就能缩小泛化误差。</p>
<h3 id="欠拟合过拟合">欠拟合/过拟合</h3>
<p>假设 <span class="math inline">\(y=f(x)+\epsilon=sin(2\pi x)+\epsilon, x \in [0, 1]\)</span>，根据已有数据，我们只能猜测它是一个 M 多项式。</p>
<p><img src="/2018/05/28/basic-concepts-in-machine-learning/polynomials.jpg"></p>
<p>M = 0, 1 则欠拟合，因为模型不能在训练集上获得足够低的误差，所以偏差比较大。对于 M = 0，<span class="math inline">\(\hat f(x)=c\)</span> <strong>泛化误差</strong>为： <span class="math display">\[
\begin{align}
Err(x)&amp;=E\left[(y-\hat f(x))\right]^2 \\\
&amp;= \left(E[\hat f(x)]-f(x)\right)^2+E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]+\sigma^2 \\\
&amp;= \Big(c-f(x)\Big)^2+E\Big[\Big(c-E[c]\Big)^2\Big]+\sigma^2 \\\
&amp;= \Big(c-f(x)\Big)^2+0+\sigma^2
\end{align}
\]</span> 所以欠拟合会导致偏差大；而 M = 9 则过拟合，因为它同时拟合了噪声，所以对于 <span class="math inline">\([0, 1]\)</span> 中未知的数据，训练误差和泛化误差之间的差距很大，方差比较大。对于 M = 9 预测模型输出的期望为样本的期望，即： <span class="math display">\[
E[\hat f(x)]=E[y(x)]=E[f(x)+\epsilon]=f(x)=E[y]
\]</span> <strong>泛化误差</strong>为： <span class="math display">\[
\begin{align}
Err(x)&amp;=E\left[(y-\hat f(x))\right]^2 \\\
&amp;= \left(E[\hat f(x)]-f(x)\right)^2+E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]+\sigma^2 \\\
&amp;= \Big(E[y]-E[y]\Big)^2+E\left[\Big(\hat f(x)-E[y]\Big)^2\right]+\sigma^2 \\\
&amp;= 0+E\Big[\Big(E[y]+\epsilon-E[y]\Big)^2\Big]+\sigma^2 \\\
&amp;= 0+E[\epsilon^2]+\sigma^2
\end{align}
\]</span> 所以过拟合会导致方差大；M = 3 就是一个比较合适的模型，偏差和方差权衡得比较好。模型泛化误差、偏差、方差和模型的复杂度的关系，模型越复杂越能拟合训练数据，所以偏差越小，但是由于拟合了噪声越多，所以遇到新数据时，泛化能力越弱，方差越大。</p>
<p>对于偏差和方差的分析要基于最优误差(贝叶斯误差)，即对于一个问题，如果机器学习算法的偏差为 10%，而人类分析的误差为 15%，那么就不能说该算法的偏差高。假设人类错误率为 0%，且训练误差和验证误差如下表所示，则有：</p>
<table>
<tbody>
<tr class="odd">
<td>Train set error</td>
<td>1%</td>
<td>15%</td>
<td>15%</td>
<td>0.5%</td>
</tr>
<tr class="even">
<td>Dev set error</td>
<td>11%</td>
<td>16%</td>
<td>30%</td>
<td>1%</td>
</tr>
<tr class="odd">
<td></td>
<td>高方差(低偏差)</td>
<td>高偏差(低方差)</td>
<td>高偏差，高方差</td>
<td>低偏差，低方差</td>
</tr>
<tr class="even">
<td></td>
<td>过拟合</td>
<td>欠拟合</td>
<td>欠拟合</td>
<td>Good</td>
</tr>
</tbody>
</table>
<p>遇到高偏差，可以考虑添加多一些数据特征、使用复杂一点的模型或者调低正则项的惩罚因数；遇到高方差，可以考虑使用更多的训练数据、更少的数据特征或者调高正则项的惩罚因数。总之就是不断调整模型，不断尝试，直到找到一个比较合适的模型，能够较好地均衡偏差和方差。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] 吴恩达. DeepLearning.</p>
<p>[2] Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</p>
<p>[3] 机器学习笔记. https://feisky.xyz/machine-learning</p>
<p>[4] Christopher M.Bishop. Pattern Recognition and Machine Learning. 2006.</p>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>批归一化</title>
    <url>/2018/06/07/batch-normalization/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在深度神经网络中，有效的参数初始化和输入特征归一化等方法能够很大程度上避免梯度消失，加速网络的训练过程。但是深度神经网络由很多层网络叠加，而每一层网络的参数更新会导致下一层网络的输入数据的分布发生变化，通过层层叠加，输入的分布变化会非常剧烈，这就使得网络需要不断重新适应不同分布的输入，而批归一化能够很出色地解决隐藏层间输入分布改变问题。</p>
<a id="more"></a>
<h2 id="批归一化">批归一化</h2>
<p>批归一化 (Batch normalization) 简称 BN，Google 2015 年提出。批归一化通过对<strong>每一层</strong>的输入进行归一化，将数据预处理的方法引入到每一个隐藏层，保持深度网络各层的输入分布不变。</p>
<p>在传统机器学习通常有个假设：“源空间 (source domain) 和目标空间 (target domain) 的数据分布 (distribution) 是一致的”，即训练集和测试集满足独立同分布。目的是希望训练集训练的模型可以<strong>合理</strong>用在测试集上，如果不太关心泛化性 (如在线学习算法) 就不需要这个假设。</p>
<p>迁移学习可以将训练好的模型参数迁移到新的模来帮助模型训练，虽然大部分数据存在相关性，但是它们不是独立同分布的。</p>
<h3 id="internal-covariate-shift">Internal Covariate Shift</h3>
<p>Covariate shift 指源空间和目标空间的条件概率一致，对边缘概率不同：</p>
<blockquote>
<p><span class="math inline">\(\forall x \in \mathcal{X}, P_s(Y|X=x)=P_t(Y|X=x), P_s(X) \neq P_t(X)\)</span></p>
</blockquote>
<p>神经网络的输入经过了一层网络后分布会发生改变，而且差异会随着网络深度增大而增大，但是训练集的真实标签不变，符合 Covariate Shift 的定义，Internal 表示神经网络内部。隐藏层需要重新适应新的分布的输入，因此会降低收敛速度，批归一化通过对每一层网络的输入进行缩放，保证了输入分布的统一。</p>
<h3 id="前向传播">前向传播</h3>
<p>在深度学习文献中有一些争论关于应该批归一化 <span class="math inline">\(Z\)</span> 还是 <span class="math inline">\(A\)</span>，吴恩达表示在实践中通常批归一化的是 <span class="math inline">\(Z\)</span>。给定第 <span class="math inline">\(l\)</span> 层隐藏单元的值 <span class="math inline">\(\mathcal{Z}=\lbrace z^{(1)}, z^{(2)}, …, z^{(m)}\rbrace\)</span> (为了方便表示，省略其层数的上标 <span class="math inline">\([l]\)</span>)，对其进行归一化，有： <span class="math display">\[
\mu_\mathcal{Z}=\frac{1}{m}\sum_{i=1}^{m}z^{(i)}
\]</span></p>
<p><span class="math display">\[
\sigma_\mathcal{Z}^2=\frac{1}{m}\sum_{i=1}^{m}(z^{(i)}-\mu_\mathcal{Z})^2
\]</span></p>
<p><span class="math display">\[
z_{norm}^{(i)}=\frac{z^{(i)}-\mu_\mathcal{Z}}{\sqrt{\sigma_\mathcal{Z}^2+\varepsilon}}
\]</span></p>
<p>归一化后的 <span class="math inline">\(z_{norm}^{(i)}\)</span> 具有 0 均值和标准方差，但是这样会降低模型的灵活度，导致新的分丧失从前层传递过来的特征与知识，对于 Sigmoid 激活函数也无法有效利用其非线性功能，所以需要再次对其进行缩放和平移： <span class="math display">\[
\hat z^{(i)}=\gamma z_{norm}^{(i)}+\beta
\]</span> 其中 <span class="math inline">\(\gamma\)</span> 和 <span class="math inline">\(\beta\)</span> 是需要学习的参数，在每个隐藏层中通过 <span class="math inline">\(\gamma\)</span> 和 <span class="math inline">\(\beta\)</span> 可以随意设置 <span class="math inline">\(\hat z^{(i)}\)</span> 的均值和方差。当 <span class="math inline">\(\gamma=\sqrt{\sigma_\mathcal{Z}^2+\varepsilon}\)</span> 和 <span class="math inline">\(\beta=\mu_\mathcal{Z}\)</span> 时，有 <span class="math inline">\(\hat z^{(i)}=z^{(i)}\)</span>。因此在梯度下降算法中，第 <span class="math inline">\(l\)</span> 层神经网络需要更新的参数不止有 <span class="math inline">\(W^{[l]}\)</span> 和 <span class="math inline">\(b^{[l]}\)</span>，还有 <span class="math inline">\(\gamma^{[l]}\)</span> 和 <span class="math inline">\(\beta^{[l]}\)</span>。批归一化有轻微的正则化效果 (类似于 Dropout)，因为使用小批量训练数据给隐藏单元添加了噪声，使得后部的神经元不过分依赖任何一个隐层单元。</p>
<h3 id="反向传播">反向传播</h3>
<p>在反向传播计算 <span class="math inline">\(\gamma\)</span> 和 <span class="math inline">\(\beta\)</span> 的梯度的时候，同样使用链式法则求导，对于最后一层神经网络，有： <span class="math display">\[
d\gamma=\frac{\partial{\mathscr{l}}}{\partial{\gamma}}=\frac{\partial{\mathscr{l}}}{\partial{\hat z^{(i)}}}\cdot z_{norm}^{(i)}
\]</span></p>
<p><span class="math display">\[
d\beta=\frac{\partial{\mathscr{l}}}{\partial{\beta}}=\frac{\partial{\mathscr{l}}}{\partial{\hat z^{(i)}}}
\]</span></p>
<p><span class="math display">\[
dz_{norm}^{(i)}=\frac{\partial{\mathscr{l}}}{\partial{z_{norm}^{(i)}}}=\frac{\partial{\mathscr{l}}}{\partial{\hat z^{(i)}}}\cdot \gamma
\]</span></p>
<p><span class="math display">\[
d\sigma_\mathcal{Z}^2=\frac{\partial{\mathscr{l}}}{\partial{\sigma_\mathcal{Z}^2}}=\sum_{i=1}^{m}dz_{norm}^{(i)}\cdot (z^{(i)}-\mu_\mathcal{Z})\cdot \frac{-1}{2}(\sigma_\mathcal{Z}^2+\varepsilon)^{\frac{-3}{2}}
\]</span></p>
<p><span class="math display">\[
d\mu_\mathcal{Z}=\frac{\partial{\mathscr{l}}}{\partial{\mu_\mathcal{Z}}}=\sum_{i=1}^{m}dz_{norm}^{(i)}\cdot \frac{-1}{\sqrt{\sigma_\mathcal{Z}^2+\varepsilon}}
\]</span></p>
<h3 id="测试">测试</h3>
<p>在训练过程中，使用批归一化将数据以小批量的形式逐一处理，但是在测试的时候，每次测试只有一个数据，计算一个数据的 <span class="math inline">\(\mu_\mathcal{Z}\)</span> 和 <span class="math inline">\(\sigma_\mathcal{Z}^2\)</span> 没有意义，所以需要重新估计 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\sigma^2\)</span>。理论上可以对整个训练集求 <span class="math inline">\(\mu_\mathcal{D}\)</span> 和 <span class="math inline">\(\sigma_\mathcal{D}^2\)</span>，但在实际操作中通常使用指数加权平均来追踪训练过程中看到的所有 <span class="math inline">\(\mu_\mathcal{Z}\)</span> 和 <span class="math inline">\(\sigma_\mathcal{Z}^2\)</span>，在第 <span class="math inline">\(l\)</span> 层隐藏层第 <span class="math inline">\(t\)</span> 个小批量处，有： <span class="math display">\[
\mu_t=\beta_1\mu_{t-1}+(1-\beta_1)\mu^{\lbrace t\rbrace[l]}
\]</span></p>
<p><span class="math display">\[
\sigma_t^2=\beta_2 \sigma_{t-1}^2+(1-\beta_2)\sigma^{2\lbrace t\rbrace[l]}
\]</span></p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>lan Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</li>
<li><a href="https://zhuanlan.zhihu.com/p/33173246" target="_blank" rel="noopener">详解深度学习中的 Normalization，不只是 BN</a></li>
<li><a href="https://www.quora.com/Why-does-batch-normalization-help" target="_blank" rel="noopener">Why does batch normalization help?</a></li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>集束搜索和 BLEU</title>
    <url>/2018/11/26/beam-search-and-bleu/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>花了几天时间总结了一下滤波器，发现滤波器还分时域和频域，涨知识了。突然想起来课程中还有集束搜索和 BLEU 这部分内容，并没有出现在序列学习的实验中，所以还是先把这部分内容再学习学习。</p>
<a id="more"></a>
<h2 id="集束搜索">集束搜索</h2>
<p>Beam Search（集束搜索）是计算机科学中最重要的 32 个算法之一，它是一种启发式的图搜索算法，通常用在图的解空间较大的情况下，减少搜索所占用的时间和空间。</p>
<p>集束搜索使用广度优先策略建立搜索树，在树的每一层按照启发代价对节点进行排序，然后仅留下 B（集束宽度）个节点，仅这些节点在下一层次继续扩展。集束宽度越小，搜索速度越快，但是最终输出的序列质量越有可能不是最优的，因此集束搜索算法是不完全的。</p>
<ul>
<li><span class="math inline">\(B=1\)</span>，每次只挑出最可能的那一个词，相当于<strong>贪婪算法</strong></li>
<li><span class="math inline">\(B=\infty\)</span>，每次都保留所有可能的词，相当于<strong>宽度优先搜索</strong></li>
</ul>
<p>假设有一个法语句子：“Jane visite l'Afrique en Septembre.”，我们希望翻译成英语：“Jane is visiting Africa in September.”。不考虑大小写，假设词汇表有 10000 个单词，集束宽度为 3，第一步是给定输入法语序列 <span class="math inline">\(x\)</span>，评估第一个单词为词汇表中每个单词的概率 <span class="math inline">\(P(y^{\langle 1 \rangle}|x)\)</span> 是多少。贪婪算法只挑出概率最大的单词，然后继续评估下一个单词的概率，而集束搜索则会考虑多个选择，因为概率最大的也不一定是最好的，我们需要找的是让整个句子的概率最大的单词。例如第一个单词最可能的三个选项为：<strong>in</strong>、<strong>jane</strong> 和 <strong>september</strong>。</p>
<p>即： <span class="math display">\[
P(y^{\langle 1 \rangle}=“\text{in}”|x)&gt;P(y^{\langle 1 \rangle}=“\text{jane}”|x)&gt;P(y^{\langle 1 \rangle}=“\text{september}”|x)&gt;...
\]</span> 第二步我们想让前第一个和第二个单词同时出现的概率最大，则在第一个词为<strong>in</strong>、<strong>jane</strong> 和 <strong>september</strong> 的时候，分别计算前两个词的概率，即第一个时间步的输出作为第二个时间步的输入：</p>
<p><img src="/2018/11/26/beam-search-and-bleu/a.png"> <span class="math display">\[
P(y^{\langle 1 \rangle},y^{\langle 2 \rangle}|x)=P(y^{\langle 1 \rangle}|x)\times P(y^{\langle 2 \rangle}|x,y^{\langle 1 \rangle})
\]</span> 因此一共会有 30000 个选择，我们还是选择 3 个概率最大的选项，例如可能是：<strong>in September</strong>、<strong>jane is</strong> 和 <strong>jane visits</strong>，即： <span class="math display">\[
P(“\text{in September}”|x)&gt;P(“\text{jane is}”|x)&gt;P(“\text{jane visits}”|x)&gt;...
\]</span></p>
<p>这个时候第一个单词为 <strong>september</strong> 的选项已经不存在了，然后继续以上步骤直到输出终结符 <strong>&lt;EOS&gt;</strong>。</p>
<h3 id="改进集束搜索">改进集束搜索</h3>
<p>机器翻译就是给定输入，找到一个最后可能的输出，即最大化概率 <span class="math inline">\(P(y^{\langle 1 \rangle},...,y^{\langle T_y \rangle}|x)\)</span>。而集束搜索就是找到最大化这个概率（目标函数）的参数的一种非完全方法，该概率表示成： <span class="math display">\[
P(y^{\langle 1 \rangle}|x)P(y^{\langle 2 \rangle}|x,y^{\langle 1 \rangle})...P(y^{&lt;T_y&gt;}|x,y^{\langle 1 \rangle},...,y^{\langle T_y-1 \rangle})
\]</span> 由于这些概率值通常远小于 1。连乘会造成数值下溢，即电脑的浮点表示不能精确地储存，因此我们通常对其取对数，即最大化： <span class="math display">\[
\sum_{t=1}^{T_y}logP(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},...,y^{\langle t-1 \rangle})
\]</span> 集束搜索还存在一个问题就是，对于一个很长的句子，那么这个概率的可能就会很小。也就是说这个目标函数比较倾向于简短的翻译结果，我们可以通过归一化，即除以翻译结果的单词数量（实践中是单词数量的 <span class="math inline">\(\alpha\)</span> 次方，这是一个超参数），来减少对输出长的结果的惩罚，这个也叫归一化的对数似然目标函数。 <span class="math display">\[
\frac{\sum_{t=1}^{T_y}logP(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},...,y^{\langle t-1 \rangle})}{T_y^\alpha}
\]</span></p>
<h3 id="误差分析">误差分析</h3>
<p>因为集束搜索是一种启发式（近似）搜索算法，不总能输出可能性最大的句子，那么如何才能知道束宽的设置是否合适呢？如果 Seq2Seq 模型解码结果不好，那么造成这个不好结果是 RNN 还是集束搜索算法的参数呢？</p>
<p>假设模型的输出 <span class="math inline">\(\hat y\)</span> 为 <strong>Jane visited Africa last September.</strong>，人工翻译 <span class="math inline">\(y^*\)</span> 为 <strong>Jane visits Africa in September.</strong>。很明显模型的翻译结果不对，我们可以计算 <span class="math inline">\(P(\hat y|x)\)</span> 和 <span class="math inline">\(P(y^*|x)\)</span>：</p>
<ul>
<li><span class="math inline">\(P(\hat y|x) &lt; P(y^*|x)\)</span>，表示存在更好的翻译结果 <span class="math inline">\(y^*\)</span>，而模型没搜索到，即集束搜索出问题了；</li>
<li><span class="math inline">\(P(\hat y|x) \geq P(y^*|x)\)</span>，表示更好的翻译结果 <span class="math inline">\(y^*\)</span> 在模型中的概率反而更小，即 RNN 编码解码出问题了。</li>
</ul>
<p>因此可以通过遍历开发集中的所有数据，分析更有可能是集束搜索有问题还是 RNN 有问题。</p>
<h2 id="bleu">BLEU</h2>
<p>机器翻译的一大难题是一个法语句子可以有多种英文翻译而且都同样好，所以当有多个同样好的答案时，怎样评估一个机器翻译系统呢？假如一个法语句子：<strong>Le chat est sur le tapis</strong>，人工翻译的参考译文为：</p>
<ul>
<li><strong>The cat is on the mat.</strong></li>
<li><strong>There is a cat on the mat.</strong></li>
</ul>
<p>这两个英语句子都准确地翻译了这个法语句子。BLEU (Bilingual Evaluation Understudy) 可以评价机器译文与参考译文的相似度，它能够自动地计算一个分数来衡量机器翻译的好坏。首先来看一种比较简单的方法： <span class="math display">\[
P=\frac{m}{\omega_t}
\]</span> 其中 <span class="math inline">\(m\)</span> 表示在参考译文中出现的机器译文中的单词数，<span class="math inline">\(\omega_t\)</span> 表示机器译文词的总数，例如机器译文：<strong>the the the the the the the.</strong>，相似度 <span class="math inline">\(P=\frac{7}{7}=1\)</span>。但是这个翻译并不好，因为参考译文中的 <strong>the</strong> 没那么多，所以改良一下，给它加个上限： <span class="math display">\[
Count_{clip}(word)=min\lbrace Count(word), MaxRefCount(word)\rbrace
\]</span> 其中 <span class="math inline">\(Count(word)\)</span> 表示单词在机器译文中出现的次数，<span class="math inline">\(MaxRefCount(word)\)</span> 表示该单词在参考译文中出现的最大次数。<strong>the</strong> 在机器译文中出现了 7 次所以 <span class="math inline">\(Count(word)=7\)</span>；<strong>the</strong> 在第一个参考译文中出现了两次，在第二个参考译文中出现了 1 次，所以 <span class="math inline">\(MaxRefCount(word)=2\)</span>，进而： <span class="math display">\[
P=\frac{Count_{clip}(word)}{\omega_t}=\frac{2}{7}
\]</span> 根据定义，<span class="math inline">\(\omega_t\)</span> 的计算公式如下所示： <span class="math display">\[
\omega_t=\sum_{word \in \hat y}Count(word)
\]</span> 现实情况中，使用单个词衡量相似度效果往往不好，对 n-gram 求平均能够有效改善上述问题。因此，对于整个测试语料，n-gram 相似度的计算公式如下： <span class="math display">\[
P_n=\frac{\sum_{n-gram\in \hat y}Count_{clip}(n-gram)}{\sum_{n-gram\in \hat y}Count(n-gram)}
\]</span> 所以 BLEU 的计算公式如下： <span class="math display">\[
BLEU=BP\bullet exp(\frac{1}{N}\sum_{n=1}^{N}p_n)
\]</span> 其中 <span class="math inline">\(BP\)</span> 为简短惩罚，当机器译文的长度大于参考译文时，惩罚因子为 1，否则如下： <span class="math display">\[
BP=exp\Big(1-\frac{\text{机器译文长度}}{\text{参考译文长度}}\Big)
\]</span></p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Papineni, K., et al. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>字符级别的语言模型</title>
    <url>/2018/06/27/character-level-language-model/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在介绍 RNN 的文章中，重点是学习 RNN 的结构，前向传播和反向传播的大致流程，所以在实现代码中并不是很全面，甚至没有关于损失函数的定义，这个作业基于字符级别，实现了一个语言模型。</p>
<a id="more"></a>
<p>作业背景：根据已有的<a href="https://nbviewer.jupyter.org/github/pengzhendong/DeepLearning/blob/master/5.%20Sequence%20Models/Week%201/Dinosaurus%20Island%20-%20Character%20level%20language%20model/dinos.txt" target="_blank" rel="noopener">恐龙的名字</a>，生成一些相似风格的恐龙名字。</p>
<h2 id="数据处理">数据处理</h2>
<p>首先需要读取所有名字，然后保存所有名字中出现过的不同字符：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = open(<span class="string">'dinos.txt'</span>, <span class="string">'r'</span>).read()</span><br><span class="line">data= data.lower()</span><br><span class="line">chars = list(set(data))</span><br><span class="line">data_size, vocab_size = len(data), len(chars)</span><br><span class="line">print(<span class="string">'There are %d total characters and %d unique characters in your data.'</span> % (data_size, vocab_size))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">There are 19909 total characters and 27 unique characters in your data.</span><br></pre></td></tr></table></figure>
<p>字符有 a-z 和 ""，换行符的作用类似 <code>&lt;EOS&gt;</code> (End Of Sentence)，在这里是恐龙名字的结束符。然后需要创建字典来保存这些字符，在 Softmax 输出的概率分布中，就能知道哪个索引对应哪个字符，也能将名字中的每个字符转化成向量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">char_to_ix = &#123; ch:i <span class="keyword">for</span> i,ch <span class="keyword">in</span> enumerate(sorted(chars)) &#125;</span><br><span class="line">ix_to_char = &#123; i:ch <span class="keyword">for</span> i,ch <span class="keyword">in</span> enumerate(sorted(chars)) &#125;</span><br><span class="line">print(ix_to_char)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;0: &apos;\n&apos;, 1: &apos;a&apos;, 2: &apos;b&apos;, 3: &apos;c&apos;, 4: &apos;d&apos;, 5: &apos;e&apos;, 6: &apos;f&apos;, 7: &apos;g&apos;, 8: &apos;h&apos;, 9: &apos;i&apos;, 10: &apos;j&apos;, 11: &apos;k&apos;, 12: &apos;l&apos;, 13: &apos;m&apos;, 14: &apos;n&apos;, 15: &apos;o&apos;, 16: &apos;p&apos;, 17: &apos;q&apos;, 18: &apos;r&apos;, 19: &apos;s&apos;, 20: &apos;t&apos;, 21: &apos;u&apos;, 22: &apos;v&apos;, 23: &apos;w&apos;, 24: &apos;x&apos;, 25: &apos;y&apos;, 26: &apos;z&apos;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="模型">模型</h2>
<p>模型的结构如下所示：</p>
<ul>
<li>初始化参数</li>
<li>运行优化循环
<ul>
<li>前向传播计算损失函数</li>
<li>反向传播计算关于损失函数的梯度</li>
<li>梯度裁剪避免梯度爆炸</li>
<li>使用梯度下降更新规则更新参数</li>
</ul></li>
<li>返回学习好的参数</li>
</ul>
<p><img src="/2018/06/27/character-level-language-model/rnn.png"></p>
<p>在每一个时间步给定前一个字符，RNN 就会预测出下一个字符，所以对于每一个时间步有 <span class="math inline">\(y^{\langle t \rangle} = x^{\langle t+1 \rangle}\)</span>。</p>
<h3 id="初始化参数">初始化参数</h3>
<p>初始化三个权值参数 <span class="math inline">\(W_{ax}, W_{aa}, W_{ya}\)</span> 和两个偏置参数 <span class="math inline">\(b_a, b_y\)</span>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_a, n_x, n_y)</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    Wax = np.random.randn(n_a, n_x)*<span class="number">0.01</span> <span class="comment"># input to hidden</span></span><br><span class="line">    Waa = np.random.randn(n_a, n_a)*<span class="number">0.01</span> <span class="comment"># hidden to hidden</span></span><br><span class="line">    Wya = np.random.randn(n_y, n_a)*<span class="number">0.01</span> <span class="comment"># hidden to output</span></span><br><span class="line">    ba = np.zeros((n_a, <span class="number">1</span>)) <span class="comment"># hidden bias</span></span><br><span class="line">    by = np.zeros((n_y, <span class="number">1</span>)) <span class="comment"># output bias</span></span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">"Wax"</span>: Wax, <span class="string">"Waa"</span>: Waa, <span class="string">"Wya"</span>: Wya, <span class="string">"ba"</span>: ba,<span class="string">"by"</span>: by&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h3 id="前向传播">前向传播</h3>
<p><span class="math display">\[
a^{\langle t\rangle}=tanh(W_{ax}x^{\langle t\rangle}+W_{aa}^{\langle t-1\rangle}+b_a)
\]</span></p>
<p><span class="math display">\[
\hat y^{\langle t\rangle}=softmax(W_{ya}a^{\langle t\rangle}+b_y)
\]</span></p>
<p>前向传播的代码和<a href="2018/06/20/Recurrent-neural-network">循环神经网络</a>稍有区别，输入 <code>rnn_step_foward</code> 中的参数不需要缓存返回。输入一个字符，通过 RNN 细胞得到下一个字符的概率分布，RNN 细胞的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span><span class="params">(parameters, a_prev, x)</span>:</span></span><br><span class="line">    Waa, Wax, Wya, by, ba = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'ba'</span>]</span><br><span class="line">    a_next = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + ba) <span class="comment"># hidden state</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wya, a_next) + by) <span class="comment"># unnormalized log probabilities for next chars # probabilities for next chars </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a_next, yt_pred</span><br></pre></td></tr></table></figure>
<p>在完整的 RNN 前向传播中，需要定义一个字典 <code>a</code> 来存储每个时间步 <span class="math inline">\(\langle t\rangle\)</span> 与其对应的隐藏状态 <span class="math inline">\(a^{\langle t\rangle}\)</span>；输入一个序列：0 + <code>X</code> (一个恐龙的名字)，然后遍历序列的每个字符 <code>X[t]</code>，将其转化成一个 27 维的 ont-hot 向量 <code>x[t]</code>；计算每个时间步的损失函数 <span class="math inline">\(loss=-log\hat y^{\langle t\rangle}_{y^{\langle t\rangle}}\)</span> (<span class="math inline">\(\hat y^{\langle t\rangle}\)</span> 为 Softmax 函数输出的概率分布，<span class="math inline">\(y^{\langle t\rangle}\)</span> 为真实的下一个字符，即 <span class="math inline">\(x^{\langle t+1\rangle}\)</span>，损失函数可参考 Softmax 回归的损失函数)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(X, Y, a0, parameters, vocab_size = <span class="number">27</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize x, a and y_hat as empty dictionaries</span></span><br><span class="line">    x, a, y_hat = &#123;&#125;, &#123;&#125;, &#123;&#125;</span><br><span class="line">    a[<span class="number">-1</span>] = np.copy(a0)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize your loss to 0</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(len(X)):</span><br><span class="line">        <span class="comment"># Set x[t] to be the one-hot vector representation of the t'th character in X.</span></span><br><span class="line">        <span class="comment"># if X[t] == None, we just have x[t]=0. This is used to set the input for the first timestep to the zero vector. </span></span><br><span class="line">        x[t] = np.zeros((vocab_size,<span class="number">1</span>)) </span><br><span class="line">        <span class="keyword">if</span> (X[t] != <span class="literal">None</span>):</span><br><span class="line">            x[t][X[t]] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run one step forward of the RNN</span></span><br><span class="line">        a[t], y_hat[t] = rnn_step_forward(parameters, a[t<span class="number">-1</span>], x[t])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update the loss by substracting the cross-entropy term of this time-step from it.</span></span><br><span class="line">        loss -= np.log(y_hat[t][Y[t],<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">    cache = (y_hat, a, x)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> loss, cache</span><br></pre></td></tr></table></figure>
<h3 id="反向传播">反向传播</h3>
<p><span class="math display">\[
dW_{ya}=\sum_{t=1}^{T_x}dy^{\langle t\rangle}*a^T
\]</span></p>
<p><span class="math display">\[
db_y=\sum_{t=1}^{T_x}dy^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
da=W_{ya}^Tdy+W_{aa}^Tda^{\langle t+1\rangle}diag(1-a^{\langle t+1\rangle2})
\]</span></p>
<p><span class="math display">\[
db_a=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})a^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
dW_{ax}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})a^{\langle t\rangle}x^{\langle t\rangle T}
\]</span></p>
<p>在反向传播中需要实现以上公式，在反向传播中需要注意代码的顺序，代码实现如下所示： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span><span class="params">(dy, gradients, parameters, x, a, a_prev)</span>:</span></span><br><span class="line">    gradients[<span class="string">'dWya'</span>] += np.dot(dy, a.T)</span><br><span class="line">    gradients[<span class="string">'dby'</span>] += dy</span><br><span class="line">    da = np.dot(parameters[<span class="string">'Wya'</span>].T, dy) + gradients[<span class="string">'da_next'</span>] <span class="comment"># backprop into h</span></span><br><span class="line">    daraw = (<span class="number">1</span> - a * a) * da <span class="comment"># backprop through tanh nonlinearity</span></span><br><span class="line">    gradients[<span class="string">'dba'</span>] += daraw</span><br><span class="line">    gradients[<span class="string">'dWax'</span>] += np.dot(daraw, x.T)</span><br><span class="line">    gradients[<span class="string">'dWaa'</span>] += np.dot(daraw, a_prev.T)</span><br><span class="line">    gradients[<span class="string">'da_next'</span>] = np.dot(parameters[<span class="string">'Waa'</span>].T, daraw)</span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure></p>
<p>在完整的 RNN 反向传播中，需要定义参数的梯度且形状应该和该参数一样，例如 <code>gradients['dWax'] = np.zeros_like(Wax)</code>；遍历所有时间步，计算当前时间步的损失函数对输出的梯度 <span class="math inline">\(dy^{\langle t\rangle}[\hat y^{\langle t\rangle }]-=1\)</span> (可参考 Softmax 回归损失函数关于输出的梯度)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(X, Y, parameters, cache)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize gradients as an empty dictionary</span></span><br><span class="line">    gradients = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve from cache and parameters</span></span><br><span class="line">    (y_hat, a, x) = cache</span><br><span class="line">    Waa, Wax, Wya, by, ba = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'ba'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># each one should be initialized to zeros of the same dimension as its corresponding parameter</span></span><br><span class="line">    gradients[<span class="string">'dWax'</span>], gradients[<span class="string">'dWaa'</span>], gradients[<span class="string">'dWya'</span>] = np.zeros_like(Wax), np.zeros_like(Waa), np.zeros_like(Wya)</span><br><span class="line">    gradients[<span class="string">'dba'</span>], gradients[<span class="string">'dby'</span>] = np.zeros_like(ba), np.zeros_like(by)</span><br><span class="line">    gradients[<span class="string">'da_next'</span>] = np.zeros_like(a[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagate through time</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(len(X))):</span><br><span class="line">        dy = np.copy(y_hat[t])</span><br><span class="line">        dy[Y[t]] -= <span class="number">1</span></span><br><span class="line">        gradients = rnn_step_backward(dy, gradients, parameters, x[t], a[t], a[t<span class="number">-1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients, a</span><br></pre></td></tr></table></figure>
<h3 id="梯度裁剪">梯度裁剪</h3>
<p>在反向传播中，我们需要对参数求梯度，然后根据参数梯度更新参数。在更新参数之前，需要对参数梯度进行裁剪，保证梯度不会爆炸，即梯度的取值不会太大。</p>
<p><img src="/2018/06/27/character-level-language-model/clip.png"></p>
<p>梯度裁剪的实现有许多不同方法，例如对梯度的 L2 范数进行裁剪和对梯度值进行裁剪，这里实现的是对梯度值进行裁剪，确保梯度在 <span class="math inline">\([-maxValue, maxValue]\)</span> 中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip</span><span class="params">(gradients, maxValue)</span>:</span></span><br><span class="line">    dWaa, dWax, dWya, dba, dby = gradients[<span class="string">'dWaa'</span>], gradients[<span class="string">'dWax'</span>], gradients[<span class="string">'dWya'</span>], gradients[<span class="string">'dba'</span>], gradients[<span class="string">'dby'</span>]</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># clip to mitigate exploding gradients, loop over [dWax, dWaa, dWya, dba, dby].</span></span><br><span class="line">    <span class="keyword">for</span> gradient <span class="keyword">in</span> [dWax, dWaa, dWya, dba, dby]:</span><br><span class="line">        np.clip(gradient, a_min=-maxValue, a_max=maxValue, out=gradient)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dWaa"</span>: dWaa, <span class="string">"dWax"</span>: dWax, <span class="string">"dWya"</span>: dWya, <span class="string">"dba"</span>: dba, <span class="string">"dby"</span>: dby&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h3 id="更新参数">更新参数</h3>
<p>更新参数部分的代码比较简单，就是减去学习率 (<strong>l</strong>earning <strong>r</strong>ate) 乘以梯度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, gradients, lr)</span>:</span></span><br><span class="line">    parameters[<span class="string">'Wax'</span>] += -lr * gradients[<span class="string">'dWax'</span>]</span><br><span class="line">    parameters[<span class="string">'Waa'</span>] += -lr * gradients[<span class="string">'dWaa'</span>]</span><br><span class="line">    parameters[<span class="string">'Wya'</span>] += -lr * gradients[<span class="string">'dWya'</span>]</span><br><span class="line">    parameters[<span class="string">'ba'</span>]  += -lr * gradients[<span class="string">'dba'</span>]</span><br><span class="line">    parameters[<span class="string">'by'</span>]  += -lr * gradients[<span class="string">'dby'</span>]</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h3 id="构建语言模型">构建语言模型</h3>
<p>将上面步骤结合在一起，实现模型，最后需要返回最后一个时间步的隐藏状态，用做<strong>下一个序列</strong>的第 0 个时间步的隐藏状态：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(X, Y, a_prev, parameters, learning_rate = <span class="number">0.01</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Forward propagate through time</span></span><br><span class="line">    loss, cache = rnn_forward(X, Y, a_prev, parameters)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backpropagate through time (≈1 line)</span></span><br><span class="line">    gradients, a = rnn_backward(X, Y, parameters, cache)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Clip your gradients between -5 (min) and 5 (max)</span></span><br><span class="line">    gradients = clip(gradients, maxValue = <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update parameters</span></span><br><span class="line">    parameters = update_parameters(parameters, gradients, learning_rate)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss, gradients, a[len(X)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="采样">采样</h2>
<p>训练出参数后，我们可能想让模型生成一些恐龙的名字，看看效果怎么样，生成流程如下图所示：</p>
<p><img src="/2018/06/27/character-level-language-model/dinos3.png"></p>
<ol type="1">
<li><p><span class="math inline">\(a^{\langle 0\rangle}\)</span> 和 <span class="math inline">\(x^{\langle 1\rangle}\)</span> 为 0 向量</p></li>
<li><p>向前传播一个时间步得到隐藏状态 <span class="math inline">\(a^{\langle 1\rangle}\)</span> 输出 <span class="math inline">\(\hat y^{\langle 1\rangle}\)</span> (即各个字符的概率分布)： <span class="math display">\[
a^{\langle t+1 \rangle} = \tanh(W_{ax}  x^{\langle t \rangle } + W_{aa} a^{\langle t \rangle } + ba)
\]</span></p>
<p><span class="math display">\[
\hat y^{\langle t + 1 \rangle } = softmax(W_{ya}  a^{\langle t + 1 \rangle } + b_y)
\]</span></p></li>
<li><p>进行采样：假设 <span class="math inline">\(\hat{y}^{\langle t+1 \rangle }_i = 0.16\)</span>，则以 16% 的概率选取索引 i 所对应的字符，可以使用 <code>np.random.choice</code> 实现。这也正是 <code>softmax</code> 名字的由来，没有强硬地输出一个最大值，而是输出每个值为最大的概率，虽然大部分情况下用的就是概率最大的那个，但是采样的时候就可以按概率分布随机采样。</p></li>
<li><p>用上一个时间步的输出作为输入，重复采样，直到遇到结束符(或者名字长度为 50 个字符，避免停不下来)。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(parameters, char_to_ix, seed)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve parameters and relevant shapes from "parameters" dictionary</span></span><br><span class="line">    Waa, Wax, Wya, by, ba = parameters[<span class="string">'Waa'</span>], parameters[<span class="string">'Wax'</span>], parameters[<span class="string">'Wya'</span>], parameters[<span class="string">'by'</span>], parameters[<span class="string">'ba'</span>]</span><br><span class="line">    vocab_size = by.shape[<span class="number">0</span>]</span><br><span class="line">    n_a = Waa.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Create the one-hot vector x for the first character (initializing the sequence generation).</span></span><br><span class="line">    x = np.zeros((vocab_size, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># Step 1': Initialize a_prev as zeros</span></span><br><span class="line">    a_prev = np.zeros((n_a, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate</span></span><br><span class="line">    indices = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Idx is a flag to detect a newline character, we initialize it to -1</span></span><br><span class="line">    idx = <span class="number">-1</span> </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop over time-steps t. At each time-step, sample a character from a probability distribution and append </span></span><br><span class="line">    <span class="comment"># its index to "indices". We'll stop if we reach 50 characters (which should be very unlikely with a well </span></span><br><span class="line">    <span class="comment"># trained model), which helps debugging and prevents entering an infinite loop. </span></span><br><span class="line">    counter = <span class="number">0</span></span><br><span class="line">    newline_character = char_to_ix[<span class="string">'\n'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (idx != newline_character <span class="keyword">and</span> counter != <span class="number">50</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2: Forward propagate x using the equations (1), (2) and (3)</span></span><br><span class="line">        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + ba)</span><br><span class="line">        z = np.dot(Wya, a) + by</span><br><span class="line">        y = softmax(z)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for grading purposes</span></span><br><span class="line">        np.random.seed(counter+seed)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Sample the index of a character within the vocabulary from the probability distribution y</span></span><br><span class="line">        idx = np.random.choice(list(range(vocab_size)), p = y[:,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Append the index to "indices"</span></span><br><span class="line">        indices.append(idx)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 4: Overwrite the input character as the one corresponding to the sampled index.</span></span><br><span class="line">        x = np.zeros((vocab_size,<span class="number">1</span>))</span><br><span class="line">        x[idx] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update "a_prev" to be "a"</span></span><br><span class="line">        a_prev = a</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for grading purposes</span></span><br><span class="line">        seed += <span class="number">1</span></span><br><span class="line">        counter +=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> (counter == <span class="number">50</span>):</span><br><span class="line">        indices.append(char_to_ix[<span class="string">'\n'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> indices</span><br></pre></td></tr></table></figure></p></li>
</ol>
<h2 id="训练模型">训练模型</h2>
<p>对于数据集中的每一行数据(随机打乱)，随机梯度下降 100 次后则随机采样生成 10 个名字。首先需要生成数据的标签，即每个字符对于的标签是它的下一个字符：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">index = j % len(examples)</span><br><span class="line">X = [<span class="literal">None</span>] + [char_to_ix[ch] <span class="keyword">for</span> ch <span class="keyword">in</span> examples[index]] </span><br><span class="line">Y = X[<span class="number">1</span>:] + [char_to_ix[<span class="string">"\n"</span>]]</span><br></pre></td></tr></table></figure>
<p>由于使用的梯度下降法是随机梯度下降，会存在振荡现象，需要用带修正的指数加权平均的方法来减小噪声：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_initial_loss</span><span class="params">(vocab_size, seq_length)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> -np.log(<span class="number">1.0</span>/vocab_size)*seq_length</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth</span><span class="params">(loss, cur_loss)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> loss * <span class="number">0.999</span> + cur_loss * <span class="number">0.001</span></span><br></pre></td></tr></table></figure>
<p>模型的完整代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(data, ix_to_char, char_to_ix, num_iterations = <span class="number">35000</span>, n_a = <span class="number">50</span>, dino_names = <span class="number">7</span>, vocab_size = <span class="number">27</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve n_x and n_y from vocab_size</span></span><br><span class="line">    n_x, n_y = vocab_size, vocab_size</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters(n_a, n_x, n_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize loss (this is required because we want to smooth our loss, don't worry about it)</span></span><br><span class="line">    loss = get_initial_loss(vocab_size, dino_names)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Build list of all dinosaur names (training examples).</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"dinos.txt"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        examples = f.readlines()</span><br><span class="line">    examples = [x.lower().strip() <span class="keyword">for</span> x <span class="keyword">in</span> examples]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Shuffle list of all dinosaur names</span></span><br><span class="line">    shuffle(examples)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the hidden state of your LSTM</span></span><br><span class="line">    a_prev = np.zeros((n_a, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Optimization loop</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Use the hint above to define one training example (X,Y) (≈ 2 lines)</span></span><br><span class="line">        index = j % len(examples)</span><br><span class="line">        X = [<span class="literal">None</span>] + [char_to_ix[ch] <span class="keyword">for</span> ch <span class="keyword">in</span> examples[index]] </span><br><span class="line">        Y = X[<span class="number">1</span>:] + [char_to_ix[<span class="string">"\n"</span>]]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Perform one optimization step: Forward-prop -&gt; Backward-prop -&gt; Clip -&gt; Update parameters</span></span><br><span class="line">        <span class="comment"># Choose a learning rate of 0.01</span></span><br><span class="line">        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = <span class="number">0.01</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Use a latency trick to keep the loss smooth. It happens here to accelerate the training.</span></span><br><span class="line">        loss = smooth(loss, curr_loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Every 2000 Iteration, generate "n" characters thanks to sample() to check if the model is learning properly</span></span><br><span class="line">        <span class="keyword">if</span> j % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Iteration: %d, Loss: %f'</span> % (j, loss) + <span class="string">'\n'</span>)</span><br><span class="line">            <span class="comment"># The number of dinosaur names to print</span></span><br><span class="line">            seed = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> range(dino_names):</span><br><span class="line">                <span class="comment"># Sample indices and print them</span></span><br><span class="line">                sampled_indices = sample(parameters, char_to_ix, seed)</span><br><span class="line">                print_sample(sampled_indices, ix_to_char)</span><br><span class="line">                seed += <span class="number">1</span>  <span class="comment"># To get the same result for grading purposed, increment the seed by one. </span></span><br><span class="line">            print(<span class="string">'\n'</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h2 id="莎士比亚风格">* 莎士比亚风格</h2>
<p>作业最后还展示了如何使用 LSTM 生成莎士比亚风格的诗词，由于恐龙的名字很短，所以长期依赖问题不明显。生成莎士比亚风格诗词的时候就很明显，所以需要使用 LSTM 来解决长期以来问题。</p>
<p>基于字符的语言模型有优点也有缺点，优点是不必担心出现未知的标识，例如 <code>Mau</code> 这样的序列。而基于词汇的语言模型，如果 <code>Mau</code> 不在字典中就只能把它当成 UNK。缺点是序列太长，即时间步太多，很难捕捉长期依赖关系，计算成本高。除非需要处理大量未知文本和未知词汇的应用，大多数都是使用基于词汇的语言模型。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络应用</title>
    <url>/2018/12/05/convnet-application/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>写了两周基金申请报告也是醉了，说什么基金申请下来后我们出国交流就不用钱啦！多么拙劣的谎言，我只想中一篇论文达到毕业要求，然后去实习就行。今天又吐槽我说我晚上出勤不够，您真不愧是大学城最努力的老师。这都还没毕业，实验室的同学们都已经过上了公务员那种朝九晚五的生活。继续学习卷积神经网络，看看怎么用 Tensorflow 实现多分类问题。</p>
<a id="more"></a>
<h2 id="tensorflow-模型">Tensorflow 模型</h2>
<p>这个实验的要求是对手势进行识别，分析图片中的手势表示的是哪个数字（0~6）。手势图像如下所示：</p>
<p><img src="/2018/12/05/convnet-application/SIGNS.png"></p>
<p>首先载入需要用到的包和数据集，对数据进行简单的预处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line"><span class="keyword">from</span> cnn_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line">conv_layers = &#123;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="创建-placeholders">创建 placeholders</h3>
<p>需要给数据创建 placeholders，在运行 session 的时候就可以喂入数据。使用 <code>None</code> 作为 batch size，这样就可以在后面的时候比较灵活地设置小批量的大小：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span><span class="params">(n_H0, n_W0, n_C0, n_y)</span>:</span></span><br><span class="line">    X = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_H0, n_W0, n_C0])</span><br><span class="line">    Y = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_y])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure>
<h3 id="初始化参数">初始化参数</h3>
<p>网络为两层卷积神经网络，分别初始化每一层的权值 <span class="math inline">\(W1\)</span> 和 <span class="math inline">\(W2\)</span>，也就是滤波器 。其中 <span class="math inline">\(W1\)</span> 包含 8 个大小为 4 的 3 通道滤波器，<span class="math inline">\(W2\)</span> 包含 16 个大小为 2 的 8 通道滤波器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">()</span>:</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    W1 = tf.get_variable(<span class="string">"W1"</span>, [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    W2 = tf.get_variable(<span class="string">"W2"</span>, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">16</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">"W1"</span>: W1, <span class="string">"W2"</span>: W2&#125;</span><br></pre></td></tr></table></figure>
<h3 id="前向传播">前向传播</h3>
<p>在 Tensorflow 中，提供了以下函数可以用来快速构建卷积神经网络：</p>
<ul>
<li><code>tf.nn.conv2d(X, W1, strides=[1,s,s,1], padding='SAME')</code>：给定输入 <span class="math inline">\(X\)</span> 和一组滤波器 <span class="math inline">\(W1\)</span>，该函数回使用 <span class="math inline">\(W1\)</span> 中的滤波器和 <span class="math inline">\(X\)</span> 进行卷积运算，第三个参数指定了 <span class="math inline">\(X\)</span> 每个维度的卷积步长。</li>
<li><code>tf.nn.max_pool(A, ksize=[1,f,f,1], strides=[1,s,s,1], padding='SAME')</code>：给定输入 A，滤波器大小为 f，使用最大池化进行运算。</li>
<li><code>tf.nn.relu(Z1)</code>：对 Z1 中的每个元素进行 ReLU 运算。</li>
<li><code>tf.contrib.layers.flatten(P)</code>：给定输入 P，将其变平（flatten）成一维向量。如果 P 中包含 batch-size 则变成形状为 [batch_size, k] 的张量。</li>
<li><code>tf.contrib.layers.fully_connected(F, num_outputs)</code>：给定变平的输入，返回全连接神经网络层计算的输出，该层自动初始化权值。</li>
</ul>
<p>卷积神经网络的前向传播主要流程为：<code>CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</code>，每一层的参数配置如下所示：</p>
<ol type="1">
<li>Conv2D：步长为 1，零填充为 SAME 卷积；</li>
<li>ReLU；</li>
<li>Max pool：滤波器大小为 8，步长为 8；</li>
<li>Conv2D：卷积步长为 1，零填充为 SAME 卷积；</li>
<li>ReLU；</li>
<li>Max pool：滤波器尺大小为 4，步长为 4</li>
<li>将前面的输出变平（flatten）；</li>
<li>FULLYCONNECTED (全连接) 层：此处不需要使用 softmax 函数，在 Tensorflow 中，softmax 和代价函数被写成了一个单独的函数，所以可以直接在全连接层的输出上计算代价。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary "parameters" </span></span><br><span class="line">    W1 = parameters[<span class="string">'W1'</span>]</span><br><span class="line">    W2 = parameters[<span class="string">'W2'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># CONV2D: stride of 1, padding 'SAME'</span></span><br><span class="line">    Z1 = tf.nn.conv2d(X, W1, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A1 = tf.nn.relu(Z1)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 8x8, stride 8, padding 'SAME'</span></span><br><span class="line">    P1 = tf.nn.max_pool(A1, ksize = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># CONV2D: filters W2, stride 1, padding 'SAME'</span></span><br><span class="line">    Z2 = tf.nn.conv2d(P1, W2, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A2 = tf.nn.relu(Z2)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 4x4, stride 4, padding 'SAME'</span></span><br><span class="line">    P2 = tf.nn.max_pool(A2, ksize = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># FLATTEN</span></span><br><span class="line">    P = tf.contrib.layers.flatten(P2)</span><br><span class="line">    <span class="comment"># FULLY-CONNECTED without non-linear activation function (not not call softmax).</span></span><br><span class="line">    <span class="comment"># 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" </span></span><br><span class="line">    Z3 = tf.contrib.layers.fully_connected(P, <span class="number">6</span>, activation_fn=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure>
<h3 id="计算代价">计算代价</h3>
<ul>
<li><code>tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y)</code>：计算 softmax 交叉损失，该函数包含了 softmax 函数。</li>
<li><code>tf.reduce_mean</code>：计算张量每个维度的均值，用来计算整体的代价。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(Z3, Y)</span>:</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h3 id="模型">模型</h3>
<p>整体的模型包含以上几个步骤，最后需要创建优化器，然后运行 session 迭代数据集 num_epochs 次，在每个最小批量上运行优化器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X_train, Y_train, X_test, Y_test, learning_rate=<span class="number">0.009</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          num_epochs=<span class="number">100</span>, minibatch_size=<span class="number">64</span>, print_cost=True)</span>:</span></span><br><span class="line">    ops.reset_default_graph()                         <span class="comment"># to be able to rerun the model without overwriting tf variables</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             <span class="comment"># to keep results consistent (tensorflow seed)</span></span><br><span class="line">    seed = <span class="number">3</span>                                          <span class="comment"># to keep results consistent (numpy seed)</span></span><br><span class="line">    (m, n_H0, n_W0, n_C0) = X_train.shape             </span><br><span class="line">    n_y = Y_train.shape[<span class="number">1</span>]                            </span><br><span class="line">    costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Placeholders of the correct shape</span></span><br><span class="line">    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagation: Build the forward propagation in the tensorflow graph</span></span><br><span class="line">    Z3 = forward_propagation(X, parameters)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Cost function: Add cost function to tensorflow graph</span></span><br><span class="line">    cost = compute_cost(Z3, Y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize all the variables globally</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># Start the session to compute the tensorflow graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run the initialization</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Do the training loop</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line"></span><br><span class="line">            minibatch_cost = <span class="number">0.</span></span><br><span class="line">            num_minibatches = int(m / minibatch_size) <span class="comment"># number of minibatches of size minibatch_size in the train set</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Select a minibatch</span></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                <span class="comment"># IMPORTANT: The line that runs the graph on a minibatch.</span></span><br><span class="line">                <span class="comment"># Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).</span></span><br><span class="line">                _ , temp_cost = sess.run([optimizer, cost], feed_dict=&#123;X:minibatch_X, Y:minibatch_Y&#125;)</span><br><span class="line">                </span><br><span class="line">                minibatch_cost += temp_cost / num_minibatches</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Print the cost every epoch</span></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after epoch %i: %f"</span> % (epoch, minibatch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(minibatch_cost)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        predict_op = tf.argmax(Z3, <span class="number">1</span>)</span><br><span class="line">        correct_prediction = tf.equal(predict_op, tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">        print(accuracy)</span><br><span class="line">        train_accuracy = accuracy.eval(&#123;X: X_train, Y: Y_train&#125;)</span><br><span class="line">        test_accuracy = accuracy.eval(&#123;X: X_test, Y: Y_test&#125;)</span><br><span class="line">        print(<span class="string">"Train Accuracy:"</span>, train_accuracy)</span><br><span class="line">        print(<span class="string">"Test Accuracy:"</span>, test_accuracy)</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> train_accuracy, test_accuracy, parameters</span><br></pre></td></tr></table></figure>
<p>运行以下代码，将模型训练 100 个 epoch，同时每 5 个 epoch 输出模型的代价：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_, _, parameters = model(X_train, Y_train, X_test, Y_test)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/12/05/convnet-application/output.png"></p>
<p>最后模型在训练集上的准确度能达到 94%，在测试集上能达到 78%。模型的方差比较高，还可以继续调节超参数和使用正则项提高模型的性能。</p>
<h2 id="总结">总结</h2>
<p>投出去的论文的实验也是用 Tensorflow 实现的，Tensorflow 确实强大，但是如果不是很熟悉就想用还是有点难，当时遇到一些小问题都得花半天时间解决，看来还需要多学习一下，多看看文档。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积与滤波器</title>
    <url>/2018/11/20/convolution-and-filters/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>开完题了，论文的审稿意见也下来了。不出意料，有两个评委给了 No，一个给了 Yes。值得开心的是他们都说这是一个新颖的想法，不足还是自己的写作方面，没有把模型说清楚，而且实验做的也不够充分，接下来可能就是要慢慢改了。循环神经网络部分的实验内容也总结完了，虽然还是模模糊糊，但是这些东西大体上在我看来也没那么高深莫测，倒是一些细节方面确实挺难的。</p>
<a id="more"></a>
<h2 id="卷积运算">卷积运算</h2>
<p>在学习卷积神经网络之前需要再好好巩固一下什么是卷积运算，然后顺便把大四学习的滤波器的内容总结一下。知乎上有不少通俗易懂的解释可以参考<a href="https://www.zhihu.com/question/22298352" target="_blank" rel="noopener">通俗易懂地理解卷积</a>，其实卷积是之前在<a href="/2018/06/06/Optimization-algorithms">优化算法</a>中提到的移动平均的推广。</p>
<h3 id="定义">定义</h3>
<p><span class="math inline">\(f\)</span> 和 <span class="math inline">\(g\)</span> 的卷积写为 <span class="math inline">\((f*g)(n)\)</span>，其离散的定义为： <span class="math display">\[
(f*g)[n]=\sum_{\tau=-\infty}^\infty f[\tau]g[n-\tau]
\]</span> 连续的定义为：</p>
<p><span class="math display">\[
(f*g)(n)=\int_{-\infty}^\infty f(\tau)g(n-\tau)d\tau
\]</span> 其中 <span class="math inline">\(n=\tau+(n-\tau)\)</span>，借鉴一下马同学在知乎中的<a href="如何通俗易懂地解释卷积？%20-%20马同学的回答%20-%20知乎%20https://www.zhihu.com/question/22298352/answer/228543288">例子</a>，离散卷积的应用场景：两个普通骰子点数加起来等于四的概率。 <span class="math display">\[
f[1]g[3]+f[2]g[2]+f[3]g[1]
\]</span> 符合卷积的定义，写成标准形式就是： <span class="math display">\[
(f*g)[4]=\sum_{m=1}^3f[4-m]g[m]
\]</span> 连续卷积的应用场景：追踪飞船的位置 <span class="math inline">\(f(t)\)</span>，由于噪声的影响，我们需要对得到的结果进行加权平均，时间上越近的测量结果越相关，相关函数为 <span class="math inline">\(g(t)\)</span>，所以对飞船的位置的估计为： <span class="math display">\[
\int_0^T f(t)g(T-t)dt
\]</span> 这就是连续的卷积，也就是将信号 <span class="math inline">\(f(t)\)</span> 和翻转平移后的信号 <span class="math inline">\(g(t)\)</span> 进行积分。在卷积神经网络中，卷积的第一个参数 <span class="math inline">\(f\)</span> 通常叫做输入，第二个参数 <span class="math inline">\(g\)</span> 通常叫做核函数，输出有时候叫特征映射。</p>
<h3 id="计算离散卷积">计算离散卷积</h3>
<p>计算离散卷积 <span class="math inline">\(f[n]*g[n]\)</span> 一般有三种方法：</p>
<ol type="1">
<li>直接计算</li>
<li>快速傅里叶变换</li>
<li>分段卷积</li>
</ol>
<p>第一种方法就是直接根据定义来计算，第二种和第三种方法则都用到了快速傅里叶变换的知识，第三种方法是先将信号分成一小段一小段再以第二种方法来计算，时间复杂度会小一点，这里就只介绍第二种方法。三种方法的时间复杂度可以参考<a href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF" target="_blank" rel="noopener">维基百科</a>。</p>
<h4 id="快速傅里叶变换">快速傅里叶变换</h4>
<blockquote>
<p>两个离散信号在时域(time domain)做卷积相当于这两个信号在频域(frequence domain)相乘。</p>
</blockquote>
<p><span class="math display">\[
y[t]=f[t]*g[t]\leftrightarrow Y[f]=F[f]G[f]
\]</span></p>
<p>根据定义不难证明以上公式，由于乘法比较简单，因此在计算卷积的时候先将信号从时域转成频域，然后计算 <span class="math inline">\(Y[f]\)</span> ，在将计算结果用傅里叶变换的逆变换转回时域。</p>
<h2 id="滤波器">滤波器</h2>
<p>卷积运算通常用于图像处理领域中的滤波操作，首先先来看看数字图像处理领域的女神 Lena。由于这张图包含了各种细节、平滑区域、阴影和纹理，因此广泛用于图像处理。</p>
<p>这是一张 400*400 三通道的图片，为了更方便演示算法，我们通常在灰度图上进行操作（Matlab 中可以使用 <code>rgb2gray()</code> 函数获取图像的灰度值）。那么如何把灰度图和波联系起来呢？我们取灰度图的<strong>第一行</strong>像素，然后根据灰度值画出曲线就能得到波：</p>
<p><img src="/2018/11/20/convolution-and-filters/lena.png"></p>
<blockquote>
<p>图像的频率反映了图像的像素灰度在空间中变化的情况，是灰度在平面空间上的梯度。</p>
</blockquote>
<p>图中曲线波动较大代表灰度图明暗差距大的地方，即高频成分较强，低频成分较弱；而波动较小代表灰度图明暗差距较小的地方，即低频成分较强，高频成分较弱。</p>
<p>这段话虽然能理解，但是学了傅里叶变换之后感觉懵懵的，总是觉得这一整个波不就是由同样的正弦波组成的吗？后来才醒悟过来，所谓的高频低频是相对的。先举个例子两张图片，一面墙壁的图像和国际象棋棋盘，前者灰度值分布平坦，其低频成分就较强，而高频成分较弱；而后者具有快速空间变化的图像来说，其高频成分会相对较强，低频则较弱。那么在一张图片中怎么理解呢？那就是将需要比较的两个地方分别截取出来，然后进行周期性延拓，因此波动较大的地方截取出来周期性延拓，进行傅里叶变换后，得到一系列正弦波，高频的正弦波就比较强（相比较于时域比较平坦的区域）。</p>
<p>滤波器根据滤波的目的可以分为两种，通过低频的滤波器称为低通滤波器，通过高频的滤波器称为高通滤波器。实现滤波的方式也分为两种，空间滤波和频域滤波。</p>
<h3 id="空间滤波器">空间滤波器</h3>
<p>空间滤波器指对图像一个邻域内的像素执行<strong>预定义的操作</strong>，滤波产生一个新像素，它的坐标等于邻域中心的坐标，滤波器的中心访问图像的每一个像素后就生成了滤波后的图像。通常会将滤波的结果存在新的图像中，避免改变图像内容的同时进行滤波操作。通常使用奇数尺寸 <span class="math inline">\(3\times 3\)</span> 的滤波器，对一张 <span class="math inline">\(4\times 4\)</span>的图像进行滤波，第一行第一个像素和第三行第二个像素的滤波过程如下图所示：</p>
<p><img src="/2018/11/20/convolution-and-filters/a.png"></p>
<p>图像边界的像素点没有那么多邻域，通常需要零填充（如下图所示）或者其他操作，然后对中间的像素进行滤波操作。</p>
<p><img src="/2018/11/20/convolution-and-filters/b.png"></p>
<p>根据上面提到的预定义的操作，空间滤波分为线性空间滤波和非线性空间滤波。非线性空间滤波例如统计排序滤波器（中值、最大值和最小值）和自适应滤波器等等。举个例子，最大值滤波器就是输出邻域内的像素的灰度值的最大值，如下图所示：</p>
<p><img src="/2018/11/20/convolution-and-filters/c.png"></p>
<p><span class="math inline">\(7=max(4, 7, 7, 2, 2, 5, 2, 4, 3)\)</span>，就是说新的图像的灰度值为原图像邻域内像素的灰度值的最大值。线性空间滤波器有一个和邻域对应的滤波器系数矩阵 <span class="math inline">\(\omega\)</span>，在滤波过程中，每个邻域内的像素的灰度值分别与对应位置的系数相乘，最后再相加，如下图所示：</p>
<p><img src="/2018/11/20/convolution-and-filters/d.png"></p>
<p>对于图像 <span class="math inline">\(f\)</span> 中任意一点 <span class="math inline">\((x, y)\)</span>，滤波器的响应 <span class="math inline">\(g(x, y)\)</span> 是滤波器系数与该滤波器所包围的像素的灰度值的乘积之和： <span class="math display">\[
g(x, y)=\omega(-1, -1)f(x-1, y-1)+\omega(-1, 0)f(x-1, y)...\omega(1, 1)f(x+1, y+1)
\]</span> 对于奇数尺寸 <span class="math inline">\((2a+1)\times (2b+1)\)</span> 的滤波器，有： <span class="math display">\[
g(x, y)=\sum_{s=-a}^a\sum_{t=-b}^b\omega(s, t)f(x+s, y+t)
\]</span> 这个操作叫做<strong>相关</strong>，有点类似于二维卷积操作，不过卷积需要滤波器翻转： <span class="math display">\[
\omega(x, y)*f(x, y)=\sum_{s=-a}^a\sum_{t=-b}^b\omega(s, t)f(x-s, y-t)
\]</span> 所以如果滤波器是对称的，那么相关和卷积将得到相同的结果，我们将翻转后的滤波器系数和图像进行卷积即可实现线性空间滤波操作。</p>
<h4 id="边缘提取">边缘提取</h4>
<p>大四选修数字图像处理的实验三就要求实现四种（Sobel 算子、Prewitt 算子、Roberts 算子和 Marr 算子）边缘提取函数（空间高通滤波），代码也都托管在 <a href="https://github.com/pengzhendong/MatlabDIP/tree/master/lab2" target="_blank" rel="noopener">Github</a>。不同的边缘提取函数的区别就是算子的不同，即滤波器系数矩阵不同，这里只详细介绍一下 Sobel 算子：</p>
<p><img src="/2018/11/20/convolution-and-filters/sobel.png"></p>
<p>用这两个算子与原图像做卷积运算可以分别得到纵向和横向灰度值的梯度（即变化率），像素两边的灰度值差距越大，卷积的结果的绝对值也就越大，因此可以得到图像的边缘：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[img, map] = imread(<span class="string">'Lena.jpg'</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">131</span>), imshow(img);</span><br><span class="line"></span><br><span class="line">hx = [<span class="number">-1</span> <span class="number">-2</span> <span class="number">-1</span>; <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>; <span class="number">1</span> <span class="number">2</span> <span class="number">1</span>];</span><br><span class="line">hy = hx';</span><br><span class="line">Gx = conv2(im2double(img), hx);</span><br><span class="line">Gy = conv2(im2double(img), hy);</span><br><span class="line">sobel = <span class="built_in">abs</span>(Gx) + <span class="built_in">abs</span>(Gy);</span><br><span class="line">subplot(<span class="number">132</span>), imshow(sobel);</span><br><span class="line"></span><br><span class="line">threshold = <span class="built_in">max</span>(<span class="built_in">max</span>(sobel)) * <span class="number">0.18</span>;</span><br><span class="line">sobel(sobel &gt;= threshold) = <span class="number">1</span>;</span><br><span class="line">sobel(sobel &lt; threshold) = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">133</span>), imshow(sobel);</span><br></pre></td></tr></table></figure>
<p>得到横向和纵向的梯度后，使用以下公式计算灰度的大小（注意是矩阵元素的平方 <code>sqrt(Gx.^2+Gy.^2)</code>）： <span class="math display">\[
G=\sqrt{G_x^2+G_y^2}
\]</span> 但是为了提高运算效率，通常使用不开方的近似值，即使会损失一定的精度： <span class="math display">\[
|G|=|G_x|+|G_y|
\]</span> 最后可以进行阈值处理，将灰度图变成二值图像，让检测的边缘更加明显。其他的算子如下所示：</p>
<ul>
<li>Roberts 算子：<code>hx = [-1 -1 -1; 0 0 0; 1 1 1]; hy = hx';</code></li>
<li>Prewitt 算子：<code>hx = [-1 0; 0 1]; hy = [0 -1; 1 0];</code></li>
<li>...</li>
</ul>
<h3 id="频域滤波器">频域滤波器</h3>
<p>实验二要求实现三种（理想、布特沃斯和高斯滤波）低通滤波器和高通滤波器，由于时域上的卷积操作等于频域上的乘积操作，因此线性空间滤波和频域滤波一一对应，但是频域滤波不能进行非线性滤波。</p>
<h4 id="频谱图">频谱图</h4>
<p>傅里叶变换可以将信号从时域变换成频域，在数字图行处理中时域体现为空间上的分布，因此傅里叶变换可以将图像的灰度分布函数变成图像的频率分布函数。在做傅里叶变换的时候相当于是先将图片做周期性延拓，然后再进行傅里叶变换，通常我们只取一个周期分析，越亮表示该频率的幅值越大。</p>
<p>由于图像是一个<strong>实数</strong>信号，可以在数学上严格证明，它的傅里叶变换后的频域信号关于 0 频轴对称。所以频谱图中四个角为低频，中间为高频，而且低频幅值较大。为了便于频域的滤波和频谱的分析，常常在变换之前进行频谱的中心化。离中心越近，频率越低，离中心越远，频率越高，类似于二维的坐标轴。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[img, map] = imread(<span class="string">'Lena.jpg'</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line">subplot(<span class="number">131</span>), imshow(img);</span><br><span class="line">subplot(<span class="number">132</span>), f = fft2(img), imshow(<span class="built_in">log</span>(<span class="number">1</span>+<span class="built_in">abs</span>(f)), []);</span><br><span class="line">subplot(<span class="number">133</span>), f = fftshift(f), imshow(<span class="built_in">log</span>(<span class="number">1</span>+<span class="built_in">abs</span>(f)), []);</span><br></pre></td></tr></table></figure>
<p>由于幅度值范围很大，所以在显示频谱图之前要取对数处理；<code>imshow(I,[])</code>对取对数后的值进行归一化，自动拉伸动态范围，增大对比度； <code>fftshift()</code> 将低频调整到中间，高频在外围。</p>
<h4 id="理想低通滤波器">理想低通滤波器</h4>
<p>这里就只在详细介绍理想低通滤波器，它由下面的函数确定： <span class="math display">\[
\begin{align*}
H(u, v)=\begin{cases}
1 &amp; D(u, v) \leq D_0 \\\
0 &amp; D(u, v) &gt; D_0
\end{cases}
\end{align*}
\]</span> 其中 <span class="math inline">\(D_0\)</span> 是正常数，<span class="math inline">\(D(u, v)\)</span> 是频域中的点 <span class="math inline">\((u, v)\)</span> 和中心的距离，即 <span class="math display">\[
D(u, v)=\sqrt{(u-P/2)^2+(v-Q/2)^2}
\]</span> <span class="math inline">\(P, Q\)</span> 是频域图的尺寸。“理想”的意思是在以 0 频率为中心，半径为 <span class="math inline">\(D_0\)</span> 的圆内，所有频率无衰减地通过，圆外地所有频率则被完全过滤。滤波代码和效果如下所示：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[img, map] = imread(<span class="string">'Lena.jpg'</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line">D0 = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">221</span>), imshow(img);</span><br><span class="line">subplot(<span class="number">222</span>), f = fftshift(fft2(img)), imshow(<span class="number">1</span>+<span class="built_in">log</span>(<span class="built_in">abs</span>(f)), []);</span><br><span class="line"></span><br><span class="line">[P, Q] = <span class="built_in">size</span>(f);</span><br><span class="line">H = <span class="built_in">zeros</span>(P, Q);</span><br><span class="line"><span class="keyword">for</span> u = <span class="number">1</span>:P</span><br><span class="line">    <span class="keyword">for</span> v = <span class="number">1</span>:Q</span><br><span class="line">        D = <span class="built_in">sqrt</span>((u - <span class="built_in">round</span>(P/<span class="number">2</span>))^<span class="number">2</span> + (v - <span class="built_in">round</span>(Q/<span class="number">2</span>))^<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span> D &lt;= D0</span><br><span class="line">            H(u, v) = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            H(u, v) = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">end</span>;</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line">f = f .* H;</span><br><span class="line"></span><br><span class="line">img = uint8(<span class="built_in">real</span>(ifft2(ifftshift(f))));</span><br><span class="line">subplot(<span class="number">223</span>), imshow(img);</span><br><span class="line">subplot(<span class="number">224</span>), f = fftshift(fft2(img)), imshow(<span class="built_in">log</span>(<span class="built_in">abs</span>(f)), []);</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>, surf(<span class="number">1</span>:P, <span class="number">1</span>:Q, H);</span><br><span class="line">axis([<span class="number">1</span> m <span class="number">1</span> n <span class="number">0</span> <span class="number">1</span>]);</span><br></pre></td></tr></table></figure>
<p>对于一幅图像来说，低频就是边缘以内的内容，也就是图像的大部分信息，即图像的大致概貌和轮廓，是图像的近似信息。高频指图像边缘的灰度值变化快，图像的细节处也是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。另外噪点也是因为像素点灰度值明显不一样了，即高频部分，因此噪声在高频。因此低通滤波器可以去噪，高通滤波器可以去模糊，各种滤波器对应的公式如下所示，n 阶布特沃斯滤波器的阶数趋于正无穷时，就是理想滤波器，对频率的截止也就会更加尖锐。</p>
<table>
<colgroup>
<col style="width: 26%">
<col style="width: 73%">
</colgroup>
<thead>
<tr class="header">
<th>滤波器</th>
<th>函数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>理想低通滤波器</td>
<td><span class="math inline">\(\begin{equation}H(u, v)=\begin{cases}1 &amp; D(u, v) \leq D_0 \\\ 0 &amp; D(u, v) &gt; D_0\end{cases}\end{equation}\)</span></td>
</tr>
<tr class="even">
<td>n 阶布特沃斯低通滤波器</td>
<td><span class="math inline">\(H(u,v)=\frac{1}{1+\Big[D(u, v)/D_0\Big]^{2n}}\)</span></td>
</tr>
<tr class="odd">
<td>高斯低通滤波器</td>
<td><span class="math inline">\(H(u, v)=e^{-D^2(u, v)/2D_0^2}\)</span></td>
</tr>
<tr class="even">
<td>理想高通滤波器</td>
<td><span class="math inline">\(\begin{equation}H(u, v)=\begin{cases}0 &amp; D(u, v) \leq D_0 \\\ 1 &amp; D(u, v) &gt; D_0\end{cases}\end{equation}\)</span></td>
</tr>
<tr class="odd">
<td>n 阶布特沃斯高通滤波器</td>
<td><span class="math inline">\(H(u,v)=\frac{1}{1+\Big[D_0/D(u, v)\Big]^{2n}}\)</span></td>
</tr>
<tr class="even">
<td>高斯高通滤波器</td>
<td><span class="math inline">\(H(u, v)=1-e^{-D^2(u, v)/2D_0^2}\)</span></td>
</tr>
</tbody>
</table>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>ViatorSun. 图像傅里叶变换的频谱图. https://blog.csdn.net/ViatorSun/article/details/82387854</li>
<li>冈萨雷斯. 数字图像处理</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络</title>
    <url>/2018/12/03/convolutional-neural-networks/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>“如果我们要建成一个更好的世界，我们必须有从头做起的勇气”，我差的很远，最近没什么效率，总是不想改开题报告和论文，只能看看书和学学深度学习。读研以前对未来的那种憧憬也没了，我现在的想法就是赶紧毕业，找一个工程师的岗位，在实践中成长吧！学术搞不来！</p>
<a id="more"></a>
<h2 id="卷积神经网络">卷积神经网络</h2>
<p>平常我们使用神经网络的时候，输入的特征的维度一般不会很大，但是如果需要处理图片，例如一张 <span class="math inline">\(1000\times 1000\)</span> 像素的三通道图，那么就会有三百万个输入。如果下一层神经元的节点数为 1000，那么就需要三十亿个参数！很难处理这么多的参数，而且也很难有足够多的数据来保证模型不会过拟合，因此就需要卷积运算。</p>
<p>卷积神经网络的思想就是检测图像左上角的特征检测器也适用于图像的右下角，图像的分布通常差不多，参数通过移动卷积核达到共享的效果。卷积神经网络的原理就是把卷积的滤波器（算子）当成参数来学习，而不是用固定的 Sobel 算子或者其他人工定义的算子。需要注意的是，在深度学习领域，卷积神经网络中实际的操作是相关操作，即省略了滤波器翻转的过程，不过这影响并不大，因此人们还是把它叫做卷积神经网络。</p>
<p><strong>符号定义：</strong></p>
<ul>
<li><span class="math inline">\([l]\)</span> 表示第 <span class="math inline">\(l\)</span> 层，例如 <span class="math inline">\(W^{[5]}\)</span> 是第五层的参数</li>
<li><span class="math inline">\((i)\)</span> 表示第 <span class="math inline">\(i\)</span> 个样本，例如 <span class="math inline">\(x^{(i)}\)</span> 是第 <span class="math inline">\(i\)</span> 个训练样本</li>
<li><span class="math inline">\(i\)</span> 表示向量的第 <span class="math inline">\(i\)</span> 维，例如 <span class="math inline">\(a^{[l]}_i\)</span> 是第 <span class="math inline">\(l\)</span> 层的激活向量得第 <span class="math inline">\(i\)</span> 维</li>
<li><span class="math inline">\(n^{[l]}_H, n^{[l]}_W\)</span> 和 <span class="math inline">\(n^{[l]}_C\)</span> 分别表示第 <span class="math inline">\(l\)</span> 层的高、宽和通道数</li>
<li><span class="math inline">\(n^{[l]}_{H_{prev}}, n^{[l]}_{W_{prev}}\)</span> 和 <span class="math inline">\(n^{[l]}_{C_{prev}}\)</span> 分别表示第 <span class="math inline">\(l\)</span> 层的的上一层高、宽和通道数，即 <span class="math inline">\(n^{[l-1]}_H, n^{[l-1]}_W\)</span> 和 <span class="math inline">\(n^{[l-1]}_C\)</span></li>
</ul>
<h3 id="卷积">卷积</h3>
<p>对于一张 <span class="math inline">\(n\times n\)</span> 的图片和尺寸为 <span class="math inline">\(f\times f\)</span> 的滤波器，对于步长为 1 的卷积神经网络，卷积后的图片大小是： <span class="math display">\[
n\times n * f\times f \rightarrow (n-f+1)\times (n-f+1)
\]</span> 多通道图像的滤波器的通道数要和图像的一致，通道数为 <span class="math inline">\(n_C\)</span> 的立体卷积输出的图像大小为： <span class="math display">\[
n\times n\times n_C * f\times f\times n_C \rightarrow (n-f+1)\times (n-f+1)
\]</span></p>
<h4 id="零填充">零填充</h4>
<p>没有零填充的叫 <strong>Valid 卷积</strong>，由于网络的层数可能会比较多，经过卷积之后的图片就会越来越小，所以需要对图片的进行零填充。</p>
<p><img src="/2018/12/03/convolutional-neural-networks/PAD.png"></p>
<p>如果填充使得输出和原图一样大，就叫 <strong>Same 卷积</strong>，假设进行了 <span class="math inline">\(p\)</span> 次零填充，有： <span class="math display">\[
n+2p-f+1=n
\]</span> 解得 <span class="math inline">\(p=\frac{f-1}{2}\)</span>。对数据集中的图像进行零填充的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_pad</span><span class="params">(X, pad)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    X -- (m, n_H, n_W, n_C) representing a batch of m images</span></span><br><span class="line"><span class="string">    pad -- integer</span></span><br><span class="line"><span class="string">    X_pad -- (m, n_H + 2*pad, n_W + 2*pad, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    X_pad = np.pad(X, ((<span class="number">0</span>,<span class="number">0</span>), (pad,pad), (pad,pad), (<span class="number">0</span>,<span class="number">0</span>)), <span class="string">'constant'</span>, constant_values = (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X_pad</span><br></pre></td></tr></table></figure>
<h4 id="步长">步长</h4>
<p>卷积神经网络中还有一个参数叫做步长（stride），也就是滤波器移动的步长 <span class="math inline">\(s\)</span>，卷积后的图片大小是： <span class="math display">\[
n\times n * f\times f \rightarrow (\lfloor\frac{n+2p-f}{s}+1\rfloor)\times (\lfloor\frac{n+2p-f}{s}+1\rfloor)
\]</span></p>
<p>对于后面所有内容，如果两个维度上的数值相等，则只记一个维度。例如 <span class="math inline">\(f\times f\)</span> 的滤波器，则说是大小为 <span class="math inline">\(f\)</span> 的滤波器；两个维度上的步长为 <span class="math inline">\(1\times 1\)</span>，则说是步长为 1。</p>
<h3 id="单层卷积神经网络">单层卷积神经网络</h3>
<p>步长为 1 的立体 valid 卷积输出的图像是单通道图像，代表图像的某一种特征，可以使用多个提取图像多种特征。在卷积神经网络中，得到输出后通常还需要进行激活函数操作，即加上偏置后经过 ReLU 函数，最后才叠在一起 。假设原图像为 <span class="math inline">\(I\)</span>，对于第 <span class="math inline">\(i\)</span> 个滤波器 <span class="math inline">\(f_i\)</span>， 输出图像的第 <span class="math inline">\(i\)</span> 个通道 <span class="math inline">\(O_i\)</span> 为：</p>
<p><span class="math display">\[
O_i=ReLU(I* f_i+b_i)
\]</span> 卷积神经网络的动态视频如下所示：</p>
<center>
<video width="620" height="440" controls>
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/conv_kiank.mp4" type="video/mp4">
Your browser does not support the video tag. </video>
</center>
<h4 id="代码">代码</h4>
<p>在计算卷积的过程中，每次从图像中选出一部分与滤波器进行加权求和，然后加上偏置。代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_single_step</span><span class="params">(a_slice_prev, W, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    a_slice_prev -- (f, f, n_C_prev) slice of input data</span></span><br><span class="line"><span class="string">    W -- (f, f, n_C_prev) Weight parameters contained in a window</span></span><br><span class="line"><span class="string">    b -- (1, 1, 1) Bias parameters contained in a window</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Element-wise product between a_slice and W. Do not add the bias yet.</span></span><br><span class="line">    s = np.multiply(a_slice_prev, W)</span><br><span class="line">    <span class="comment"># Sum over all entries of the volume s.</span></span><br><span class="line">    Z = np.sum(s)</span><br><span class="line">    <span class="comment"># Add bias b to Z. Cast b to a float() so that Z results in a scalar value.</span></span><br><span class="line">    Z = Z + b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z</span><br></pre></td></tr></table></figure>
<p>那么如何从图像中选出一部分呢？需要对选出的部分图像进行定义，定义其水平和竖直的起点和终点。如下图所示：</p>
<p><img src="/2018/12/03/convolutional-neural-networks/vert_horiz_kiank.png"></p>
<p>根据前面的定义，卷积输出的大小为： <span class="math display">\[
n_H = \lfloor \frac{n_{H_{prev}} - f + 2 \times pad}{stride} \rfloor +1
\]</span></p>
<p><span class="math display">\[
n_W = \lfloor \frac{n_{W_{prev}} - f + 2 \times pad}{stride} \rfloor +1
\]</span></p>
<p>全部的前向卷积过程的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_forward</span><span class="params">(A_prev, W, b, hparameters)</span>:</span>    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape (≈1 line)  </span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from W's shape (≈1 line)</span></span><br><span class="line">    (f, f, n_C_prev, n_C) = W.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve information from "hparameters" (≈2 lines)</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    pad = hparameters[<span class="string">'pad'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)</span></span><br><span class="line">    n_H = int((n_H_prev - f + <span class="number">2</span> * pad) / stride) + <span class="number">1</span></span><br><span class="line">    n_W = int((n_W_prev - f + <span class="number">2</span> * pad) / stride) + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the output volume Z with zeros. (≈1 line)</span></span><br><span class="line">    Z = np.zeros((m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create A_prev_pad by padding A_prev</span></span><br><span class="line">    A_prev_pad = zero_pad(A_prev, pad)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                               <span class="comment"># loop over the batch of training examples</span></span><br><span class="line">        a_prev_pad = A_prev_pad[i,:,:,:]                               <span class="comment"># Select ith training example's padded activation</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                           <span class="comment"># loop over vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):                       <span class="comment"># loop over horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):                   <span class="comment"># loop over channels (= #filters) of the output volume</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)</span></span><br><span class="line">                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)</span></span><br><span class="line">                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c], b[:,:,:,c])</span><br><span class="line">                                        </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(Z.shape == (m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save information in "cache" for the backprop</span></span><br><span class="line">    cache = (A_prev, W, b, hparameters)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Z, cache</span><br></pre></td></tr></table></figure>
<p>最后还需要对输出进行激活函数操作：<code>A[i, h, w, c] = activation(Z[i, h, w, c])</code>。</p>
<h4 id="参数">参数</h4>
<p>假设有 10 个 <span class="math inline">\(3\times 3\times 3\)</span> 的滤波器，那么单层卷积神经网络有多少参数呢？每个滤波器对应 <span class="math inline">\(3\times 3\times 3+1=28\)</span> 个参数，其中 <span class="math inline">\(3\times 3\times 3\)</span> 表示滤波器中的数值，1 表示滤波器的偏置项。因此 10 个滤波器就一共有 <span class="math inline">\(28\times 10=280\)</span> 个参数，不管图像的大小是多少都不会改变参数的个数。</p>
<h3 id="池化层">池化层</h3>
<p>在卷积层之后通常还有池化层，其目的是为了缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。其实池化层就是属于非线性空间滤波中的统计排序滤波器。该层一共有两个参数 <span class="math inline">\(f\)</span> 和 <span class="math inline">\(s\)</span>，分别表示滤波器的大小和步长，如果 <span class="math inline">\(f=s\)</span> 则是正常池化，如果 <span class="math inline">\(s&gt;f\)</span> 则是重叠池化（Overlapping），重叠池化有避免过拟合的作用。<span class="math inline">\(f=s=2\)</span> 的最大池化如下图所示：</p>
<p><img src="/2018/12/03/convolutional-neural-networks/max_pool.png"></p>
<p>由于池化层两个参数都是超参数，不需要训练，因此卷积层和池化层一起通常算一层。类似于卷积层，池化层的输出的图像大小为： <span class="math display">\[
n_H = \lfloor \frac{n_{H_{prev}} - f}{stride} \rfloor +1
\]</span></p>
<p><span class="math display">\[
n_W = \lfloor \frac{n_{W_{prev}} - f}{stride} \rfloor +1
\]</span></p>
<p><span class="math display">\[
n_C = n_{C_{prev}}
\]</span></p>
<p>类似于卷积层，池化层的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_forward</span><span class="params">(A_prev, hparameters, mode = <span class="string">"max"</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from the input shape</span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve hyperparameters from "hparameters"</span></span><br><span class="line">    f = hparameters[<span class="string">"f"</span>]</span><br><span class="line">    stride = hparameters[<span class="string">"stride"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the dimensions of the output</span></span><br><span class="line">    n_H = int(<span class="number">1</span> + (n_H_prev - f) / stride)</span><br><span class="line">    n_W = int(<span class="number">1</span> + (n_W_prev - f) / stride)</span><br><span class="line">    n_C = n_C_prev</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize output matrix A</span></span><br><span class="line">    A = np.zeros((m, n_H, n_W, n_C))              </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                         <span class="comment"># loop over the training examples</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                     <span class="comment"># loop on the vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):                 <span class="comment"># loop on the horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range (n_C):            <span class="comment"># loop over the channels of the output volume</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)</span></span><br><span class="line">                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.</span></span><br><span class="line">                    <span class="keyword">if</span> mode == <span class="string">"max"</span>:</span><br><span class="line">                        A[i, h, w, c] = np.max(a_prev_slice)</span><br><span class="line">                    <span class="keyword">elif</span> mode == <span class="string">"average"</span>:</span><br><span class="line">                        A[i, h, w, c] = np.mean(a_prev_slice)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Store the input and hparameters in "cache" for pool_backward()</span></span><br><span class="line">    cache = (A_prev, hparameters)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(A.shape == (m, n_H, n_W, n_C))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A, cache</span><br></pre></td></tr></table></figure>
<h3 id="多层卷积神经网络">多层卷积神经网络</h3>
<p>一个卷积层、一个激活层加上一个池化层算一层，通常还会在卷积神经网络后面加上一个全连接层，多层卷积神经网络的模型结构如下图所示：</p>
<p><img src="/2018/12/03/convolutional-neural-networks/model.png"></p>
<p>上图为两个（x2）卷积层和一个全连接层的神经网络，假设输入为 <span class="math inline">\(32\times 32\times 3\)</span> 的图像，参数如下所示：</p>
<ul>
<li>CONV1：8 个大小为 5 的滤波器，步长为 1；</li>
<li>POOL1：滤波器大小为 2，步长为 2；</li>
<li>CONV2：16 个大小为 5 的滤波器，步长为 1；</li>
<li>POOL2：滤波器大小为 2，步长为 2；</li>
<li>FC：128 个神经元节点；</li>
<li>SOFTMAX：10 个神经元节点（用于手写数字分类）。</li>
</ul>
<p>网络各层的参数个数如下表所示：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Activation Shape</th>
<th>Activation Size</th>
<th># parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Input</td>
<td>(32, 32, 3)</td>
<td>3,072</td>
<td>0</td>
</tr>
<tr class="even">
<td>CONV1(f=5, s=1)</td>
<td>(28, 28, 8)</td>
<td>6,272</td>
<td><span class="math inline">\(208=8\times (25+1)\)</span></td>
</tr>
<tr class="odd">
<td>POOL1(f=2, s=2)</td>
<td>(14, 14, 8)</td>
<td>1,568</td>
<td>0</td>
</tr>
<tr class="even">
<td>CONV2(f=5, s=1)</td>
<td>(10, 10, 16)</td>
<td>1,600</td>
<td><span class="math inline">\(416=16\times (25+1)\)</span></td>
</tr>
<tr class="odd">
<td>POOL2(f=2, s=2)</td>
<td>(5, 5, 16)</td>
<td>400</td>
<td>0</td>
</tr>
<tr class="even">
<td>FC</td>
<td>(128, 1)</td>
<td>128</td>
<td><span class="math inline">\(51,201=400\times 128+1\)</span></td>
</tr>
<tr class="odd">
<td>SOFTMAX</td>
<td>(10, 1)</td>
<td>10</td>
<td><span class="math inline">\(1281=128\times 10+1\)</span></td>
</tr>
</tbody>
</table>
<h2 id="反向传播">反向传播</h2>
<p>相比较于循环神经网络，卷积神经网络的反向传播就比较简单，因为卷积操作的过程就是加权求和（线性滤波）。卷积神经网络的反向传播分为两部分：卷积层和池化层。</p>
<h3 id="卷积层">卷积层</h3>
<p>类似是普通的深度神经网络，卷积层的反向传播主要计算 <span class="math inline">\(dA\)</span>、<span class="math inline">\(dW_c\)</span> 和 <span class="math inline">\(db\)</span>。</p>
<h4 id="计算-da">计算 dA</h4>
<p>给定一个滤波器 <span class="math inline">\(W_c\)</span>，卷积层关于代价函数的梯度为： <span class="math display">\[
dA+=\sum_{h=0}^{n_H}\sum_{w=0}^{n_W}W_c\times dZ_{hw}
\]</span> 其中 <span class="math inline">\(dZ_{hw}\)</span> 为卷积层 <span class="math inline">\(Z\)</span> 的第 <span class="math inline">\(h\)</span> 行的第 <span class="math inline">\(w\)</span> 列关于代价函数的梯度。因为在前向卷积的时候，不同的 <code>a_slice</code> 与同一个滤波器进行运算，因此在反向传播的时候也是用同一个 <span class="math inline">\(W_c\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]</span><br></pre></td></tr></table></figure>
<h4 id="计算-dw">计算 dW</h4>
<p><span class="math inline">\(dW_{c}\)</span> 是损失函数关于一个滤波器的导数，定义为： <span class="math display">\[
dW_c+=\sum_{h=0}^{n_H}\sum_{w=0}^{n_W} a_{slice} \times dZ_{hw}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dW[:,:,:,c] += a_slice * dZ[i, h, w, c]</span><br></pre></td></tr></table></figure>
<h4 id="计算-db">计算 db</h4>
<p><span class="math inline">\(db\)</span> 为滤波器中偏置关于损失函数的导数，定义为： <span class="math display">\[
db=\sum_h\sum_w dZ_{hw}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">db[:,:,:,c] += dZ[i, h, w, c]</span><br></pre></td></tr></table></figure>
<p>卷积层全部反向传播的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_backward</span><span class="params">(dZ, cache)</span>:</span>    </span><br><span class="line">    <span class="comment"># Retrieve information from "cache"</span></span><br><span class="line">    (A_prev, W, b, hparameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape</span></span><br><span class="line">    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from W's shape</span></span><br><span class="line">    (f, f, n_C_prev, n_C) = W.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve information from "hparameters"</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    pad = hparameters[<span class="string">'pad'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from dZ's shape</span></span><br><span class="line">    (m, n_H, n_W, n_C) = dZ.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize dA_prev, dW, db with the correct shapes</span></span><br><span class="line">    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           </span><br><span class="line">    dW = np.zeros((f, f, n_C_prev, n_C))</span><br><span class="line">    db = np.zeros((<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, n_C))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pad A_prev and dA_prev</span></span><br><span class="line">    A_prev_pad = zero_pad(A_prev, pad)</span><br><span class="line">    dA_prev_pad = zero_pad(dA_prev, pad)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                       <span class="comment"># loop over the training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># select ith training example from A_prev_pad and dA_prev_pad</span></span><br><span class="line">        a_prev_pad = A_prev_pad[i,:,:,:]</span><br><span class="line">        da_prev_pad = dA_prev_pad[i,:,:,:]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                   <span class="comment"># loop over vertical axis of the output volume</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):               <span class="comment"># loop over horizontal axis of the output volume</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):           <span class="comment"># loop over the channels of the output volume</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice"</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Use the corners to define the slice from a_prev_pad</span></span><br><span class="line">                    a_slice = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Update gradients for the window and the filter's parameters using the code formulas given above</span></span><br><span class="line">                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] +=  W[:,:,:,c] * dZ[i,h,w,c]</span><br><span class="line">                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]</span><br><span class="line">                    db[:,:,:,c] += dZ[i, h, w, c]</span><br><span class="line">                    </span><br><span class="line">        <span class="comment"># Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])</span></span><br><span class="line">        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad,pad:-pad,:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure>
<h3 id="池化层-1">池化层</h3>
<p>好在池化层中只有超参数，因此不需要学习。但是为了让梯度反向传播，还是需要计算 <span class="math inline">\(dZ\)</span>。由于池化层是非线性操作，因此最大池化需要计算一个 mask 矩阵用来记录最大元素的位置。例如滤波器大小为 2 的最大池化中的 mask 矩阵 <span class="math inline">\(M\)</span> 为： <span class="math display">\[
X = \begin{bmatrix}
1 &amp;&amp; 3 \\\
4 &amp;&amp; 2
\end{bmatrix} \quad \rightarrow  \quad M =\begin{bmatrix}
0 &amp;&amp; 0 \\\
1 &amp;&amp; 0
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_mask_from_window</span><span class="params">(x)</span>:</span></span><br><span class="line">    mask = (x==np.max(x))  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> mask</span><br></pre></td></tr></table></figure>
<p>最大池化的反向传播只需要让梯度乘上 mask 矩阵即可。而滤波器大小为 2 的平均池化的 mask 矩阵如下所示： <span class="math display">\[
dZ = 1 \quad \rightarrow  \quad dZ =\begin{bmatrix}
1/4 &amp;&amp; 1/4 \\\
1/4 &amp;&amp; 1/4
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute_value</span><span class="params">(dz, shape)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from shape (≈1 line)</span></span><br><span class="line">    (n_H, n_W) = shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the value to distribute on the matrix (≈1 line)</span></span><br><span class="line">    average = np.float(dz) / np.float(n_H * n_W)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a matrix where every entry is the "average" value (≈1 line)</span></span><br><span class="line">    a = np.ones((n_H, n_W)) * average</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure>
<p>池化层全部反向传播的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_backward</span><span class="params">(dA, cache, mode = <span class="string">"max"</span>)</span>:</span>    </span><br><span class="line">    <span class="comment"># Retrieve information from cache (≈1 line)</span></span><br><span class="line">    (A_prev, hparameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve hyperparameters from "hparameters" (≈2 lines)</span></span><br><span class="line">    stride = hparameters[<span class="string">'stride'</span>]</span><br><span class="line">    f = hparameters[<span class="string">'f'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)</span></span><br><span class="line">    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape</span><br><span class="line">    m, n_H, n_W, n_C = dA.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize dA_prev with zeros (≈1 line)</span></span><br><span class="line">    dA_prev = np.zeros((m,n_H_prev,n_W_prev,n_C_prev))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                       <span class="comment"># loop over the training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># select training example from A_prev (≈1 line)</span></span><br><span class="line">        a_prev = A_prev[i,:,:,:]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_H):                   <span class="comment"># loop on the vertical axis</span></span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> range(n_W):               <span class="comment"># loop on the horizontal axis</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> range(n_C):           <span class="comment"># loop over the channels (depth)</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Find the corners of the current "slice" (≈4 lines)</span></span><br><span class="line">                    vert_start = stride * h</span><br><span class="line">                    vert_end = vert_start + f</span><br><span class="line">                    horiz_start = stride * w</span><br><span class="line">                    horiz_end = horiz_start + f</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Compute the backward propagation in both modes.</span></span><br><span class="line">                    <span class="keyword">if</span> mode == <span class="string">"max"</span>:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Use the corners and "c" to define the current slice from a_prev (≈1 line)</span></span><br><span class="line">                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]</span><br><span class="line">                        <span class="comment"># Create the mask from a_prev_slice (≈1 line)</span></span><br><span class="line">                        mask = create_mask_from_window(a_prev_slice)</span><br><span class="line">                        <span class="comment"># Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)</span></span><br><span class="line">                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask,dA[i, h, w, c])</span><br><span class="line">                        </span><br><span class="line">                    <span class="keyword">elif</span> mode == <span class="string">"average"</span>:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># Get the value a from dA (≈1 line)</span></span><br><span class="line">                        da = dA[i, h, w, c]</span><br><span class="line">                        <span class="comment"># Define the shape of the filter as fxf (≈1 line)</span></span><br><span class="line">                        shape = (f, f)</span><br><span class="line">                        <span class="comment"># Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)</span></span><br><span class="line">                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)</span><br><span class="line">                            </span><br><span class="line">    <span class="comment"># Making sure your output shape is correct</span></span><br><span class="line">    <span class="keyword">assert</span>(dA_prev.shape == A_prev.shape)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev</span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<p>卷积神经网络听起来很难，但是理解后比循环神经网络简单多了。说到底就是卷积这个概念听起来难，其实也就是那么回事。之前一直不太理解池化层的操作，前几篇博客总结了滤波器后反而有意外的收获，池化也就是非线性空间滤波，只不过通常步长会大点，让输出的图像小点，从而加速计算；重叠池化也是在计算速度和过拟合之间的一个 trade-off。最后还有收获比较大的一点就是池化层中并没有参数需要学习，也就是不需要计算参数的梯度，同时最大池化需要记录最大值的位置用于计算上一层的梯度。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>深度卷积网络探究</title>
    <url>/2018/12/10/deep-convnet-probe/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>自己给自己加个油！还有两周多的内容就结束了，慢慢学了快一年了，博客写写停停，也算是坚持下来了。这一周的内容是深度卷积网络的实例探究，介绍了好些个经典的模型，慢慢扩展吧！</p>
<a id="more"></a>
<h2 id="卷积神经网络">卷积神经网络</h2>
<p>比较经典的卷积神经网络有：LeNet-5、AlexNet 和 VGGNet，下面将简单介绍这三种网络。随着网络的加深则带来梯度消失、梯度爆炸和参数过多等问题，最后介绍 <span class="math inline">\(1\times 1\)</span> 滤波器和谷歌的 Inception 网络，下一篇博客再结合着实验介绍残差网络 ResNet。</p>
<h3 id="lenet-5">LeNet-5</h3>
<p>LeNet-5 是卷积神经网络中比较适合入门的网络结构，也是年代比较久远的网络，由于采用的滤波器都是 <span class="math inline">\(5\times 5\)</span> 的，因此叫 LeNet-5。它在 1998年 由 Yann LeCuu 等人在论文 "Gradient-Based Learning Applied to Document Recognition"[2] 中提出，用于解决 mnist 数据集的字符识别问题，网络结构比较简单，如下图所示：</p>
<p><img src="/2018/12/10/deep-convnet-probe/LeNet-5.png"></p>
<p>LeNet-5 除了输入层以外由 7 层网络构成：</p>
<ol type="1">
<li><p>卷积层 Conv1：</p>
<p>输入为 <span class="math inline">\(32\times 32\)</span> 的灰度图，本层使用 6 个 <span class="math inline">\(5\times 5\)</span> 的滤波器，步长为 1，当时人们并不适用零填充，也就是使用 valid 卷积，因此输出结果为 <span class="math inline">\(28\times 28\times 6\)</span>；</p></li>
<li><p>池化层 Pool1：</p>
<p>虽然现在我们可能用最大池化更多一些，但是在这篇论文写成的那个年代，人们更喜欢使用平均池化。本层使用大小为 <span class="math inline">\(2\times 2\)</span> 的滤波器，步长为 2，因此图像的宽度和高度都会缩小一半，输出结果为 <span class="math inline">\(14\times 14\times 6\)</span>；</p></li>
<li><p>卷积层 Conv2：</p>
<p>输入为 <span class="math inline">\(14\times 14\times 6\)</span>，本层使用 16 个大小为 <span class="math inline">\(5\times 5\)</span> 的滤波器，步长为 1，输出结果为 <span class="math inline">\(10\times 10\times 16\)</span>；</p></li>
<li><p>池化层 Pool2：</p>
<p>同样是 <span class="math inline">\(2\times 2\)</span> 的滤波器做步长为 2 的平均池化，输出结果为 <span class="math inline">\(5\times 5\times 16\)</span>；</p></li>
<li><p>全连接层 FC1：</p>
<p>上一层变平后的 400 个神经元作为输入，本层包含 120 个神经元；</p></li>
<li><p>全连接层 FC2：</p>
<p>本层包含 84 个神经元。</p></li>
</ol>
<p>最后还可以加一个节点来预测输出，例如使用 softmax 来进行多分类，当时 LeNet-5 网络在输出层使用的是一种现在已经很少用到的分类器 Guassian Connection，LeNet-5 和上一个实验中的网络结构基本一致。只不过当时人们普遍使用的激活函数是 sigmod 函数和 tanh 函数，而不是 ReLU 函数。模型用的正是这两种激活函数，池化层后用的是 sigmoid 函数。</p>
<h3 id="alexnet">AlexNet</h3>
<p>AlexNet[3] 由 2012 年 ImageNet 竞赛冠军获得者 Alex Krizhevsky 设计，网络结构如下图所示：</p>
<p><img src="/2018/12/10/deep-convnet-probe/AlexNet.png"></p>
<p>AlexNet 中首次提出了局部响应归一化技术 LRN（Local Response Normalization，虽然被证明在 AlexNet 中作用不大，现在很少使用），在激活、池化后用来防止过拟合，其操作是对附近通道（附近取多少通道由参数 <code>local_size</code> 决定）上同一个位置的像素值进行归一化，因此不改变图像尺寸大小。虽然文章中的输入的图像是 <span class="math inline">\(224\times 224 \times 3\)</span>，但是根据公式可知 <span class="math inline">\(227\times 227\times 3\)</span> 的图像才能得到后面的结果。网络一共包含 5 个卷积层（5 个激活层、3 个池化层、2 个局部响应归一化层）和 3 个全连接层：</p>
<ol type="1">
<li><p>卷积层 Conv1：</p>
<ul>
<li>输入：<span class="math inline">\(227\times 227\times 3\)</span>；</li>
<li>卷积层：96 个大小为 <span class="math inline">\(11\times 11\times 3\)</span> 的滤波器，步长为 4，valid卷积，输出结果为 <span class="math inline">\(55\times 55\times 96\)</span>；</li>
<li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(55\times 55\times 96\)</span>；</li>
<li>池化层：最大（重叠）池化，大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器，步长为 2，输出结果为 <span class="math inline">\(27\times 27\times 96\)</span>；</li>
<li>局部响应归一化层：local_size 为 5，输出结果为 <span class="math inline">\(27\times 27\times 96\)</span>。</li>
</ul></li>
<li><p>卷积层 Conv2：</p>
<ul>
<li>输入：<span class="math inline">\(27\times 27\times 96\)</span>；</li>
<li>卷积层：256 个大小为 <span class="math inline">\(5\times 5\times 96\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(27\times 27\times 256\)</span>；</li>
<li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(27\times 27\times 256\)</span>；</li>
<li>池化层：最大池化，大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器，步长为 2，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>；</li>
<li>局部响应归一化层：local_size 为 5，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>。</li>
</ul></li>
<li><p>卷积层 Conv3：</p>
<ul>
<li>输入：<span class="math inline">\(13\times 13\times 256\)</span>；</li>
<li>卷积层：384 个大小为 <span class="math inline">\(3\times 3\times 256\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>；</li>
<li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>。</li>
</ul></li>
<li><p>卷积层 Conv4：</p>
<ul>
<li>输入：<span class="math inline">\(13\times 13\times 384\)</span>；</li>
<li>卷积层：384 个大小为 <span class="math inline">\(3\times 3\times 384\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>；</li>
<li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(13\times 13\times 384\)</span>。</li>
</ul></li>
<li><p>卷积层 Conv5：</p>
<ul>
<li>输入：<span class="math inline">\(13\times 13\times384\)</span>；</li>
<li>卷积层：256 个大小为 <span class="math inline">\(3\times 3\times 384\)</span> 的滤波器，步长为 1，same 卷积，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>；</li>
<li>激活层：ReLU 函数，输出结果为 <span class="math inline">\(13\times 13\times 256\)</span>；</li>
<li>池化层：最大池化，大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器，步长为 2，输出结果为 <span class="math inline">\(6\times 6\times 256\)</span>。</li>
</ul></li>
<li><p>全连接层 FC6：</p>
<ul>
<li>输入：$6=9216 $;</li>
<li>神经元：4096 个神经元，输出为 <span class="math inline">\(4096\times 1\)</span>；</li>
<li>Dropout：概率为 50%，输出为 <span class="math inline">\(4096\times 1\)</span>。</li>
</ul></li>
<li><p>全连接层 FC7：</p>
<ul>
<li>输入：<span class="math inline">\(4096\times 1\)</span>;</li>
<li>神经元：4096 个神经元，输出为 <span class="math inline">\(4096\times 1\)</span>；</li>
<li>Dropout：概率为 50%，输出为 <span class="math inline">\(4096\times 1\)</span>。</li>
</ul></li>
<li><p>全连接层 FC8：</p>
<ul>
<li>输入：<span class="math inline">\(4096\times 1\)</span>;</li>
<li>神经元：1000 个神经元，输出为 <span class="math inline">\(1000\times 1\)</span>，即 1000 中分类的概率。</li>
</ul></li>
</ol>
<p>AlexNet 和之前的网络相比，它有以下几点特定：</p>
<ul>
<li>使用了数据增广的方法，即对数据集中的图像进行水平翻转、随机裁剪、平移变换、颜色、光照、对比度变换。或者按照 RGB 三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做 PCA Jittering（抖动）；</li>
<li>首次应用了 Dropout 有效防止过拟合；</li>
<li>使用 ReLU 代替传统的 sigmoid 和 tanh 函数；</li>
<li>使用了局部响应归一化，虽然这一作用有争议；</li>
<li>使用了重叠池化，减小过拟合；</li>
<li>多 GPU 并行训练，将网络分成两部分训练，提高了训练速度，整个网络大约有 6000 万个参数。</li>
</ul>
<h3 id="vgg">VGG</h3>
<p>VGG 网络出自 "Very Deep Convolutional Networks for Large-Scale Image Recognition"[4]，作者一共实验了 A、A-LRN、B、C、D 和 E 六种网络结构，根据网络的层数可以分类为 VGG-11、VGG-13、VGG-16 和 VGG-19。这六种网络结构的详情如下表所示，其中 conv3-512 表示该层使用 512 个大小为 <span class="math inline">\(3\times 3\)</span> 的滤波器：</p>
<p><img src="/2018/12/10/deep-convnet-probe/VGG.png"></p>
<p>VGG 在 AlexNet 基础上对深度神经网络在深度和宽度上做了更多深入的研究，业界普遍认为更深的网络具有比浅网络更强的表达能力，更能刻画现实和完成更复杂的任务。通常 VGG 指的就是上表中网络结构 D。</p>
<p>VGG 与 AlexNet 相比，具有如下改进几点：</p>
<ul>
<li>作者实验发现深度网络中 LRN 的作用并不明显，于是去掉了 LRN 层；</li>
<li>VGG 用 <span class="math inline">\(3\times 3\)</span> 的滤波器，相比较于 AlexNet 中 <span class="math inline">\(11\times 11\)</span> 的滤波器，参数量更少；</li>
<li>池化层使用 <span class="math inline">\(2\times 2\)</span> 的滤波器也比 AlexNet 的 <span class="math inline">\(3\times 3\)</span> 滤波器小。</li>
</ul>
<p>VGG 主要采用增加卷积层的方法来加深网络，结果发现深度越深，网络学习能力越好，分类能力越强。为了更好的探究深度对网络的影响，必须要解决参数量的问题，作者分析认为 <span class="math inline">\(3\times 3\)</span> 的滤波器足以捕捉到横、竖以及斜对角像素的变化，使用大卷积核会带来参数量的爆炸不说，而且图像中会存在一些部分被多次卷积，可能会给特征提取带来困难。</p>
<h3 id="network-in-network">Network in Network</h3>
<p>传统的卷积层只是将前一层的特征进行了线性组合，然后经过一个非线性激活提取的特征就是低度非线性的。在<a href="2018/05/19/Neuron-network/#神经网络模型">单隐层神经网络</a>中我们知道，虽然单隐层神经网络几乎可以拟合任意函数，但是需要特别多神经元节点。类似的，传统的 CNN 就会使用大量的滤波器尽可能的提取更多的特征，这就会导致网络结构复杂和参数空间巨大。</p>
<h4 id="times-1-滤波器"><span class="math inline">\(1\times 1\)</span> 滤波器</h4>
<p>对于单通道的图像，<span class="math inline">\(1\times 1\)</span> 的滤波器可能没什么用，相当于让图像上的每一个像素值都乘以一个数。但是对于多通道的图像，这个操作实现的就是多个通道的线性组合，类似于全连接神经网络，可以起到降维或者升维（滤波器个数大于原图像通道数）的作用，从而减少运算量。举个比较形象的例子就是 RGB 图像转灰度图 <code>rgb2gray</code>，通过对三个通道的像素值的线性组合得到单通道的灰度图，只不过 <code>rgb2gray</code> 中使用的滤波器也是人工设置的，而且只有一个滤波器。</p>
<p>如下图所示，使用大小为 <span class="math inline">\(5\times 5\times 192\)</span> 的滤波器对 <span class="math inline">\(28\times 28\times 192\)</span> 的输入进行滤波，如果希望输出结果为 <span class="math inline">\(28\times 28\times 32\)</span>，那么就需要 32 个滤波器进行 Same 卷积。运算次数虽然和输入图像的大小无关，但是和输入图像的通道有关，通道越大和滤波器越大则运算次数越大，运算次数为 <span class="math inline">\((28\times 28\times 32)\times(5\times 5\times 192)\)</span>，大概需要 1.2 亿次。而先使用 <span class="math inline">\(1\times 1\)</span> 小滤波器压缩通道后再在小通道的图像使用大滤波器就可以解决这个问题，运算次数为： <span class="math display">\[
(28\times 28\times 16)\times(1\times 1\times 192)+(28\times 28\times 32)\times(5\times 5\times 16)
\]</span> 大概只需要 1204 万次运算，计算量是原来的十分之一左右。多个 <span class="math inline">\(1\times 1\)</span> 的滤波器配合激活函数还可以实现对原图像的多通道做非线性的组合，可以减少需要的滤波器的个数进而实现参数的减少化。这个思想来自于 Network in Network 中的多层感知卷积层 Mlpconv layer。</p>
<h4 id="多层感知卷积层">多层感知卷积层</h4>
<p>在 Network in Network[5] 中，作者在卷积后使用一个微小的神经网络（主要是多层感知器）对提取的特征进行进一步抽象。因为传统的卷积层只是一个线性的过程，即使层次比较深的网络层也只是对于浅层网络层学习到的特征进行整合。因此，在对特征进行高层次整合之前，进行进一步的抽象是必要的，即使用微网络进行进一步的抽象，这也是该文章名字的由来。网络的结构如下图所示：</p>
<p><img src="/2018/12/10/deep-convnet-probe/Network%20in%20Network.png"></p>
<p>假设这是一个 384 种类别的分类问题。在第一层网络中，输入为 <span class="math inline">\(224\times 224\times 3\)</span> 的图像，首先使用 96 个 <span class="math inline">\(11\times 11\times 3\)</span> 的滤波器进行卷积，每计算一个<strong>局部</strong>后可以得到一个 96 维的向量；然后将其输入一个多层感知机（图中第一列为输入层，第二列为隐藏层），本例子中隐藏层神经元节点数等于输入层的神经元节点数（一共有 <span class="math inline">\(96\times 96\)</span> 个参数），最后输出一张 <span class="math inline">\(55\times 55\times 96\)</span> 的图像。</p>
<p>这里的多层感知机就等同于 <span class="math inline">\(1\times 1\)</span> 滤波器，对特征进一步抽象，进而非线性激活函数不需要太多神经元节点就可以拟合处很复杂的函数，多添加几层隐藏层就相当于多进行几次 <span class="math inline">\(1\times 1\)</span> 卷积。感知机中隐藏层的神经元节点个数就相当于 <span class="math inline">\(1\times 1\)</span> 滤波器的个数，可以这个数来减少模型的参数。</p>
<h4 id="全局池化">全局池化</h4>
<p>作者还用全局平均池化取代网络的全连接层，避免全连接层参数过多而且容易过拟合。全局池化就是滤波器大小和原图像一致，因此每张大小为 <span class="math inline">\(W\times H\times C\)</span> 的图像，池化后的输出为 <span class="math inline">\(1\times 1\times C\)</span>。对大小为 <span class="math inline">\(13\times 13\times 384\)</span> 的图像进行全局平均池化就是每个通道的像素值求平均，最后得到一个 384 维的向量。</p>
<p>上图中最后一个多层感知机的隐藏层神经元节点数等于分类的类别数，主要是为了在全局平均池化的时候每一个通道（特征图）能够对应于一个输出类别，让模型的解释性更强，最后输入到 384 中分类的 Softmax 层中。</p>
<h3 id="googlenet">GoogLeNet</h3>
<p>GoogLeNet 是谷歌团队在 2014 年的 ILSVRC 比赛中使用的网络，这个名字也是为了向 LeNet 致敬。谷歌团队在 Going deeper with convolutions[6] 中提出 Inception 这种网络结构，也就是用 Inception 模块组成的网络都叫 Inception 网络，最后他们在比赛中使用的那个 22 层的 Inception 网络就叫 GoogLeNet，网络结构可以点击<a href="https://randy-1251769892.cos.ap-beijing.myqcloud.com/GoogLeNet.pdf" target="_blank" rel="noopener">查看全图</a>，由于模型的层数比较多，就不再一一介绍。下面重点介绍一下文章中提出的 Inception 模块的思想。</p>
<h4 id="inception">Inception</h4>
<p>Inception （盗梦空间）这个名字来自于电影名字是因为其中有一句台词：</p>
<blockquote>
<p>We need to go deeper</p>
</blockquote>
<p>文章指出提高深度神经网络性能最直接的方法是增大网络规模：增加网络层数和增加各层神经元数量。但是在样本较少的情况下，参数越多越容易导致网络过拟合；而且需要的计算资源会直线上升。根据 Hebbian 原理，解决这两个问题的根本途径是将全连接改成稀疏连接，例如 Dropout 就是随机使神经元失活，进而让连接变得稀疏。但是由于实际运算过程中都是基于矩阵优化的，因此很难减少运算的时间，所以目前视觉领域的机器学习系统仅仅是利用卷积的空域稀疏性。</p>
<p>Inception 结构的主要思想是找到网络的最优稀疏的结构，也就是说不需要人为决定使用哪个滤波器或者是否需要池化，而是由网络自行确定这些参数，给网络添加这些参数的所有可能值后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些滤波器组合。后来 <span class="math inline">\(1\times 1\)</span> 滤波器广泛使用后，就被应用到了 Inception 模块中。理解了 Inception 模块就能理解 Inception 网络，无非是很多个 Inception 模块组成了网络。自从 Inception 模块诞生以来，经过研究者们的不断发展而衍生了许多新的版本。比如 Inception V2、V3 和 V4，还有一个版本引入了跳跃连接的方法，即 ResNet 中防止梯度消失和梯度爆炸的思想。</p>
<h2 id="总结">总结</h2>
<p>了解了卷积神经网络的发展历程，感觉还是很有意思的。人们提出了很多想法，无非就是为了让模型更复杂又不能出现过拟合，或者让模型运算得更快一点，总之百变不离其中，就是提取特征。但是整体感觉下来好像还是缺点什么，或许就是这种数据科学确实没有一个很标准的答案吧！同时还是默默期待哪一天会出现这个时代的牛顿，给所有一切很自然的东西一个公式或者定理吧。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.</li>
<li>Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems. 2012.</li>
<li>Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</li>
<li>Lin M, Chen Q, Yan S. Network in network[J]. arXiv preprint arXiv:1312.4400, 2013.</li>
<li>Szegedy C, Liu W, Jia Y, et al. c[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 1-9.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>深度神经网络</title>
    <url>/2018/05/21/deep-neuron-network/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>为什么需要深度学习？为什么需要多个隐藏层？隐藏层中神经元的数量越多拟合能力不就越强吗？这个问题困惑了我好久，说白了就是书读的太少，想得太多。吴恩达用电路理论和二叉树解决了我这个困惑！</p>
<a id="more"></a>
<h2 id="电路理论和深度学习">电路理论和深度学习</h2>
<blockquote>
<p>There are functions you can compute with a "small" L-layer deep nerual network that shallower networks require exponentiall more hidden units to compute.</p>
</blockquote>
<p>也就是说有一些函数，一个很小的 L 层深度神经网络就能实现，而浅层神经网络需要的神经元的数量是指数级别的。例如异或操作，对于三维数据，深度神经网络的拟合为：<span class="math inline">\(x_1\oplus x_2\oplus x_3=(x_1\oplus x_2)\oplus x_3\)</span>，浅层神经网络拟合为：<span class="math inline">\(x_1\oplus x_2\oplus x_3=x_1\cdot x_2\cdot x_3+x&#39;_1\cdot x&#39;_2\cdot x_3+x&#39;_1\cdot x_2\cdot x&#39;_3+x_1\cdot x&#39;_2\cdot x&#39;_3\)</span>；所以深度神经网络的层数也就是二叉树的高度 <span class="math inline">\(O(logn)\)</span>，神经元的数量不会很大，而单隐层神经网络需要的神经元的个数则是 <span class="math inline">\(2^{n-1}\)</span> 个，指数爆炸！</p>
<h2 id="深度神经网络模型">深度神经网络模型</h2>
<p>深度神经网络模型和单隐层神经网络模型的模块一样，只不过深度神经网络模型的隐藏层不止一个。在单隐层神经网络的隐藏层中使用了 <code>Tanh</code> 激活函数，而现在更加常用的激活函数是 <code>ReLU</code> (线性整流)函数。</p>
<h3 id="relu">ReLU</h3>
<p>ReLU 函数是一个分段函数，其函数图如下图所示：</p>
<p><img src="/2018/05/21/deep-neuron-network/ReLU.png"> <span class="math display">\[
ReLU(x)=max(0, x)
\]</span> 这是一个非线性函数，当 <span class="math inline">\(x&lt;0\)</span> 时，<span class="math inline">\(ReLu(x)=0\)</span>，梯度为 0；当 <span class="math inline">\(x\geq 0\)</span> 时，<span class="math inline">\(ReLu(x)=x\)</span>，梯度为 1。</p>
<h4 id="squashing-函数">Squashing 函数</h4>
<p>第一次看到 ReLU 函数，就觉得它虽然是非线性的，但是它不是 Squashing 函数啊！可以通过两个 ReLU 神经元的叠加，构造一个 Squashing 函数：</p>
<p><span class="math display">\[
\Psi(x)=ReLU(x)-ReLU(x-1)=max(0, x)-max(0, x-1)
\]</span></p>
<p><img src="/2018/05/21/deep-neuron-network/squashing.png"></p>
<p>使用 ReLU 函数作为激活函数的最大好处是激活状态的神经元的梯度不会消失，且梯度固定可以加快学习速度；其次，对于<strong>每个样本数据</strong>，一部分神经元输出为 0 造成了网络的稀疏性，缓解了过拟合问题的发生。虽然<strong>每个样本数据</strong>经过神经网络后的输出都是输入的线性组合，但是不同的输入激活的神经元是不同的，正是因为这种变换引入了非线性。例如单隐层神经网络拟合 <span class="math inline">\(f(x)=x^2\)</span>:</p>
<ul>
<li>两个神经元：</li>
</ul>
<p><span class="math display">\[
h_1(x)=ReLU(x)+ReLU(-x)=|x|
\]</span></p>
<ul>
<li>四个神经元： <span class="math display">\[
h_2(x)=ReLU(x)+ReLU(-x)+2ReLU(x-1)+2ReLU(-x-1)
\]</span></li>
</ul>
<p>多个 ReLU 神经元叠加确实可以拟合出各种形状，所以只要神经元个数足够多，拟合实际问题中的函数就卓卓有余。</p>
<h4 id="神经元坏死">神经元坏死</h4>
<p>ReLU 函数也有其缺点，那就是神经元容易“坏死”。如果<strong>所有样本数据</strong>都不能激活某个神经元(即不管输入是什么，输出都一样)，那么 <font color="red">ReLU 函数的梯度 <span class="math inline">\(g&#39;()\)</span> 为 0</font>，在反向传播的时候参数就不会被更新，迭代后还是一样： <span class="math display">\[
dW^{[l]} \propto g&#39;(Z^{[l]})
\]</span> 学习率过大或者参数 <span class="math inline">\(w_1\)</span> 的梯度过大，<span class="math inline">\(w_1\)</span> 的变化就会很大，原来 <span class="math inline">\(w_1x_1+w_2x_2+b\)</span> 对于不同的样本数据，输出可能有正有负，现在很有可能就只出现负数。对于第一层隐藏层的神经元，一旦坏死就再也无法被激活；对于第二层及以后的神经元，由于它的输入(上一层的输出)也是别的神经元的输入，所以上一层的输出更新后有可能再次激活这个坏死的神经元。</p>
<p>ReLU 的变种 Leaky ReLU 可以一定程度上克服神经元坏死的问题。由于在使用深度学习模型的时候，训练数据的维度比较大，对于部分神经元坏死还是可以接受的。</p>
<h4 id="参数初始化">参数初始化</h4>
<p>既然 ReLU 函数避免了过饱和，那么在初始化参数的时候为什么还要从 (0, 1) 正态分布里抽样呢？首先分析一下以下几种情况：</p>
<ul>
<li><p><span class="math inline">\(W\)</span> 都初始化成绝对值大于 1 的数：最后输入 Sigmoid 函数的值就会指数爆炸💥，<span class="math inline">\(sigmoid(x)=\frac{1}{1+e^{-x}}\)</span>，而 <code>np.exp(710)</code> 溢出；代价函数中包含 <span class="math inline">\(log(1-a)\)</span>，其中 <span class="math inline">\(a=sigmoid(x)\)</span>，而 <code>np.exp(-37)=1</code> 导致代价函数包含 <span class="math inline">\(log(0)\)</span> 产生运行时警告。</p></li>
<li><p>因此 <span class="math inline">\(W\)</span> 需要在 <span class="math inline">\((-1, 1)\)</span> 之间采样，前面分析过不能都初始化为 0；如果全部在 <span class="math inline">\((-1, 0)\)</span> 或者 <span class="math inline">\((0, 1)\)</span> 之间采样则 ReLU 函数是线性的，学习能力较差。</p></li>
<li><p><span class="math inline">\(W\)</span> 都初始化成满足 <span class="math inline">\((0, 1)\)</span> 正态分布的绝对值<strong>特别小</strong>的数：<span class="math inline">\(dW^{[l]} \propto W^{[l+1]}\)</span>，在深度网络中梯度会指数级递减引发梯度消失的问题。</p></li>
<li><p><span class="math inline">\(Z=\sum\limits_{i = 0}^{n}w_ix_i\)</span>，神经元的个数 <span class="math inline">\(n\)</span> 越大，下一层神经网络的输入和输入的方差也就越大(<span class="math inline">\(w_i\)</span> 和 <span class="math inline">\(x_i\)</span> 同 0 均值分布)： <span class="math display">\[
\begin{align}
Var(Z) &amp;= Var(\sum\limits_{i = 0}^{n}w_ix_i) \\\
&amp;= \sum\limits_{i = 0}^{n}Var(w_ix_i) \\\
&amp;= \sum\limits_{i = 0}^{n}[E(w_i)]^2Var(x_i)+[E(x_i)]^2Var(w_i)+Var(x_i)Var(w_i) \\\
&amp;= \sum\limits_{i = 0}^{n}Var(x_i)Var(w_i) \\\
&amp;= nVar(w_i)Var(x_i)
\end{align}
\]</span> 所以 <span class="math inline">\(n\)</span> 越大我们希望 <span class="math inline">\(w_i\)</span> 越小，这样下一层神经网络的输入和该输入的方差都不会太大，输入就还是 0 附近比较小的数。既不会导致梯度消失，也不会导致梯度爆炸。</p></li>
</ul>
<p>因此参数既不能太大也不能太小，所以参数的初始化很重要！一种方法是让每层神经网络的输入的方差和输入层的方法一致，这种方法虽然不能彻底解决问题，但是很有效。即 <span class="math inline">\(Var(Z)=Var(x_i)\)</span>，所以 <span class="math inline">\(Var(w_i)=\frac{1}{n}\)</span>。因为 <span class="math inline">\(Var(cw)=c^2Var(w)\)</span>，所以在标准正态分布的基础上乘以 <span class="math inline">\(\frac{1}{\sqrt{n}}\)</span> 即可保证 <span class="math inline">\(w\)</span> 的方差为 <span class="math inline">\(\frac{1}{n}\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params[<span class="string">'W'</span> + str(l)] = np.random.randn(laye_dims[l], laye_dims[l<span class="number">-1</span>]) * np.sqrt(<span class="number">1</span>/layer_dims[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<h5 id="xavier-初始化">Xavier 初始化</h5>
<p>方法同时考虑了反向传播时的情形，此时的输入是前向传播的输出，因此 <span class="math inline">\(Var(w_i)=\frac{1}{n}=\frac{1}{n_{out}}\)</span>，于是结合以上两点要求，有 <span class="math inline">\(Var(w_i)=\frac{2}{n_{in}+n_{out}}\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params[<span class="string">'W'</span> + str(l)] = np.random.randn(laye_dims[l], laye_dims[l<span class="number">-1</span>]) * np.sqrt(<span class="number">2</span>/(layer_dims[l<span class="number">-1</span>]+layer_dims[l<span class="number">-1</span>]))</span><br></pre></td></tr></table></figure>
<p>在吴恩达的深度学习课程中建议如果使用 Tanh 激活函数，则初始化参数方差为 <span class="math inline">\(\frac{1}{n}\)</span> 或者 <span class="math inline">\(\frac{2}{n_{in}+n_{out}}\)</span>；如果使用 ReLU 激活函数，会发现效果并不好，因为 ReLU 激活函数有一部分神经元的输出是 0(即没有被激活)，于是何凯明等人提出了 MSRA 初始化的方法，也叫 He 初始化。</p>
<h5 id="he-初始化">He 初始化</h5>
<p>He 初始化的思想是：在 ReLU 网络中，假设有一般的神经元被激活，另一半输出为 0，所以要保持方差不变则需要初始化参数方差为 <span class="math inline">\(\frac{2}{n}\)</span>。还可以把分子当成一个超级参数来调节，但是这个超级参数并不是很重要，所以优先级可以放得比较低。由于没有考虑反向传播，所以在深度学习领域，还是使用 Xavier 初始化方法的比较多。</p>
<h3 id="模型结构">模型结构</h3>
<p>构建一个 L 层的深度神经网络模型主要分为以下几部分：</p>
<ol type="1">
<li>初始化 L 层神经网络的参数</li>
<li>实现前向传播模型(图中紫色部分)
<ul>
<li>计算每一层前向传播步骤的线性(LINEAR)部分，即计算 <span class="math inline">\(Z^{[l]}\)</span></li>
<li>使用激活(ACTIVATION)函数 <code>ReLU</code> 或者 <code>Sigmoid</code></li>
<li>将两个步骤结合到一个新的前向函数中：<code>[LINEAR-&gt;ACTIVATION]</code></li>
<li>前 L-1 层： <code>[LINEAR-&gt;ACTIVATION]</code>，最后一层： <code>[LINEAR-&gt;SIGMOID]</code></li>
</ul></li>
<li>计算损失</li>
<li>实现反向传播模型(图中红色部分)
<ul>
<li>计算每一层反向传播步骤的线性(LINEAR)部分</li>
<li>使用激活(ACTIVATION)函数 <code>ReLU</code> 或者 <code>Sigmoid</code> 的梯度</li>
<li>将两个步骤结合到一个新的反向函数中：<code>[LINEAR-&gt;ACTIVATION]</code></li>
<li>前 L-1 层： <code>[LINEAR-&gt;ACTIVATION]</code>，最后一层： <code>[LINEAR-&gt;SIGMOID]</code></li>
</ul></li>
<li>更新参数</li>
</ol>
<p><img src="/2018/05/21/deep-neuron-network/final%20outline.png"></p>
<h4 id="初始化模型参数">初始化模型参数</h4>
<p>实验中的训练数据是 209 张 <code>64*64*3</code> 的图片，变成向量后的 X 的维度是 (12288, 209)，因此模型参数的维度如下标所示：</p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 21%">
<col style="width: 14%">
<col style="width: 40%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(W\)</span> 的维度</th>
<th><span class="math inline">\(b\)</span> 的维度</th>
<th>激活函数的输入 <span class="math inline">\(Z^{l}\)</span></th>
<th>激活函数的维度</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Layer 1</td>
<td><span class="math inline">\((n^{[1]}, 12288)\)</span></td>
<td><span class="math inline">\((n^{[1]}, 1)\)</span></td>
<td><span class="math inline">\(Z^{[1]} = W^{[1]} X + b^{[1]}\)</span></td>
<td><span class="math inline">\((n^{[1]}, 209)\)</span></td>
</tr>
<tr class="even">
<td>Layer 1</td>
<td><span class="math inline">\((n^{[2]}, n^{[1]})\)</span></td>
<td><span class="math inline">\((n^{[2]}, 1)\)</span></td>
<td><span class="math inline">\(Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}\)</span></td>
<td><span class="math inline">\((n^{[2]}, 209)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td>Layer 1</td>
<td><span class="math inline">\((n^{[L-1]}, n^{[L-2]})\)</span></td>
<td><span class="math inline">\((n^{[L-1]}, 1)\)</span></td>
<td><span class="math inline">\(Z^{[L-1]} = W^{[L-1]} A^{[L-2]} + b^{[L-1]}\)</span></td>
<td><span class="math inline">\((n^{[L-1]}, 209)\)</span></td>
</tr>
<tr class="odd">
<td>Layer 1</td>
<td><span class="math inline">\((n^{[L]}, n^{[L-1]})\)</span></td>
<td><span class="math inline">\((n^{[L]}, 1)\)</span></td>
<td><span class="math inline">\(Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]}\)</span></td>
<td><span class="math inline">\((n^{[L]}, 209)\)</span></td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_deep</span><span class="params">(layer_dims)</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = len(layer_dims)            <span class="comment"># number of layers in the network</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l)] = np.random.randn(layer_dims[l], layer_dims[l<span class="number">-1</span>]) * np.sqrt(<span class="number">2</span>/layer_dims[l<span class="number">-1</span>])</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l)] = np.zeros((layer_dims[l], <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<p>参数 <code>layer_dims</code> 是一个数组，包含了定义的深度神经网络的每一层的神经元的个数。</p>
<h4 id="前向传播模块">前向传播模块</h4>
<p>在线性部分和激活函数部分，前向传播都会缓存所有输入，用于反向传播时计算梯度。</p>
<ul>
<li><p>线性前向 <span class="math display">\[
Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}, 其中 A^{[0]}=X
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_forward</span><span class="params">(A, W, b)</span>:</span></span><br><span class="line">    Z = np.dot(W, A) + b</span><br><span class="line"></span><br><span class="line">    cache = (A, W, b)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Z, cache</span><br></pre></td></tr></table></figure></li>
<li><p>线性-激活前向</p>
<ul>
<li>Sigmoid: <span class="math inline">\(g(Z)=\sigma(WA+b)=\frac{1}{1+e^{-(WA+b)}}\)</span></li>
<li>ReLU: <span class="math inline">\(g(Z)=ReLU(Z)=max(0, Z)\)</span></li>
</ul>
<p><span class="math display">\[
A^{[l]}=g(W^{[l]}A^{[l-1]}+b^{[l]})
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_forward</span><span class="params">(A_prev, W, b, activation)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> activation == <span class="string">"sigmoid"</span>:</span><br><span class="line">        Z, linear_cache = linear_forward(A_prev, W, b)</span><br><span class="line">        A, activation_cache = sigmoid(Z)</span><br><span class="line">    <span class="keyword">elif</span> activation == <span class="string">"relu"</span>:</span><br><span class="line">        Z, linear_cache = linear_forward(A_prev, W, b)</span><br><span class="line">        A, activation_cache = relu(Z)</span><br><span class="line">    </span><br><span class="line">    cache = (linear_cache, activation_cache)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A, cache</span><br></pre></td></tr></table></figure></li>
<li><p>L 层前向模型</p>
<p>循环使用激活函数是 ReLU 的 <code>linear_activation_forward</code> L-1 次，再使用激活函数是 Sigmoid 的 <code>linear_activation_forward</code> 1 次，就可以构建一个 L 层神经网络模型。在实验过程中，需要把每层的缓存都放到同一个缓存列表中，然后返回输出和缓存，用于计算代价函数和反向传播计算梯度。</p>
<p><span class="math display">\[
\hat Y=A^{[L]}=\sigma(W^{[L]}A^{[L-1]}+b^{[L]})
\]</span></p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_forward</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    caches = []</span><br><span class="line">    A = X</span><br><span class="line">    L = len(parameters) // <span class="number">2</span>                  <span class="comment"># number of layers in the neural network</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># [LINEAR -&gt; RELU]*(L-1)</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        A_prev = A </span><br><span class="line">        A, cache = linear_activation_forward(A_prev, parameters[<span class="string">'W'</span> + str(l)], parameters[<span class="string">'b'</span> + str(l)], activation = <span class="string">"relu"</span>)</span><br><span class="line">        caches.append(cache)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># LINEAR -&gt; SIGMOID</span></span><br><span class="line">    AL, cache = linear_activation_forward(A, parameters[<span class="string">'W'</span> + str(L)], parameters[<span class="string">'b'</span> + str(L)], activation = <span class="string">"sigmoid"</span>)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> AL, caches</span><br></pre></td></tr></table></figure>
<h4 id="代价函数">代价函数</h4>
<p><span class="math display">\[
J=-\frac{1}{m}\sum\limits_{i=1}^{m}\left(y^{(i)}\log(a^{[L]\(i\)}) + (1-y^{(i)})\log(1- a^{[L]\(i\)})\right)
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL, Y)</span>:</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]</span><br><span class="line">    cost = -np.sum(np.multiply(np.log(AL), Y) + np.multiply(np.log(<span class="number">1</span> - AL), <span class="number">1</span> - Y)) / m</span><br><span class="line">    cost = np.squeeze(cost)      <span class="comment"># To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h4 id="反向传播模型">反向传播模型</h4>
<p>反向传播是用来计算代价函数对参数的梯度，通过梯度下降算法更新参数后继续前向传播，使得代价更小。在计算梯度的时候需要用到前向传播缓存的输入：</p>
<ul>
<li><p>线性反向</p>
<p>假设已经计算出导数 <span class="math inline">\(dZ^{[l]}=\frac{\partial \mathcal{L} }{\partial Z^{[l]}}\)</span>，现在需要根据 $dZ^{[l]} $ 求 <span class="math inline">\(dW^{[l]}, db^{[l]}, dA^{[l-1]}\)</span>。</p>
<p><span class="math display">\[
dW^{[l]}=\frac{\partial \mathcal{L}}{\partial W^{[l]}} = \frac{1}{m}dZ^{[l]}A^{[l-1]\mathrm{T}}
\]</span></p></li>
</ul>
<p><span class="math display">\[
  db^{[l]}=\frac{\partial \mathcal{L} }{\partial b^{[l]}}=\frac{1}{m}\sum_{i = 1}^{m}dZ^{[l]\(i\)}
\]</span></p>
<p><span class="math display">\[
  dA^{[l-1]}=\frac{\partial \mathcal{L} }{\partial A^{[l-1]}}=W^{[l]\mathrm{T}}dZ^{[l]}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_backward</span><span class="params">(dZ, cache)</span>:</span></span><br><span class="line">    A_prev, W, b = cache</span><br><span class="line">    m = A_prev.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    dW = np.dot(dZ, A_prev.T) / m</span><br><span class="line">    db = np.sum(dZ, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span><br><span class="line">    dA_prev = np.dot(W.T, dZ)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure>
<ul>
<li><p>线性-激活反向 <span class="math display">\[
dZ^{[l]}= dA^{[l]} * g&#39;(Z^{[l]})
\]</span> ReLU 函数的导数就是一个简单的分段函数，实验直接在 <code>dnn_utils</code> 模块中实现，只要调用以下函数，传入 <span class="math inline">\(dA^{[l]}\)</span> 和前向传播过程中的缓存就可以直接返回 <span class="math inline">\(dZ^{[l]}\)</span>:</p>
<ul>
<li>Sigmoid: <code>dZ = sigmoid_backward(dA, activation_cache)</code></li>
<li>ReLU: <code>dZ = relu_backward(dA, activation_cache)</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_activation_backward</span><span class="params">(dA, cache, activation)</span>:</span></span><br><span class="line">    linear_cache, activation_cache = cache</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> activation == <span class="string">"relu"</span>:</span><br><span class="line">        dZ = relu_backward(dA, activation_cache)</span><br><span class="line">        dA_prev, dW, db = linear_backward(dZ, linear_cache)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">elif</span> activation == <span class="string">"sigmoid"</span>:</span><br><span class="line">        dZ = sigmoid_backward(dA, activation_cache)</span><br><span class="line">        dA_prev, dW, db = linear_backward(dZ, linear_cache)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dA_prev, dW, db</span><br></pre></td></tr></table></figure></li>
<li><p>L 层反向模型</p>
<p>在反向传播的时候，首先需要计算代价函数对模型输出 <span class="math inline">\(A^{[L]}\)</span>(即 <span class="math inline">\(\hat Y\)</span>) 的梯度(计算公式见<a href="/2018/05/19/Neuron-network/">单隐层神经网络</a>)，然后调用 <code>linear_activation_backward</code> 函数，最后返回计算出的梯度列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_model_backward</span><span class="params">(AL, Y, caches)</span>:</span></span><br><span class="line">      grads = &#123;&#125;</span><br><span class="line">      L = len(caches) <span class="comment"># the number of layers</span></span><br><span class="line">      m = AL.shape[<span class="number">1</span>]</span><br><span class="line">      Y = Y.reshape(AL.shape) <span class="comment"># after this line, Y is the same shape as AL</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># Initializing the backpropagation</span></span><br><span class="line">      dAL = -(np.divide(Y, AL) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - AL))</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># Lth layer (SIGMOID -&gt; LINEAR) gradients. Inputs: "dAL, current_cache". Outputs: "grads["dAL-1"], grads["dWL"], grads["dbL"]</span></span><br><span class="line">      current_cache = caches[L<span class="number">-1</span>]</span><br><span class="line">      grads[<span class="string">"dA"</span> + str(L)], grads[<span class="string">"dW"</span> + str(L)], grads[<span class="string">"db"</span> + str(L)] = linear_activation_backward(dAL, current_cache, activation = <span class="string">"sigmoid"</span>)</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># Loop from l=L-2 to l=0</span></span><br><span class="line">      <span class="keyword">for</span> l <span class="keyword">in</span> reversed(range(L<span class="number">-1</span>)):</span><br><span class="line">          <span class="comment"># lth layer: (RELU -&gt; LINEAR) gradients.</span></span><br><span class="line">          <span class="comment"># Inputs: "grads["dA" + str(l + 1)], current_cache". Outputs: "grads["dA" + str(l)] , grads["dW" + str(l + 1)] , grads["db" + str(l + 1)] </span></span><br><span class="line">          current_cache = caches[l]</span><br><span class="line">          dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[<span class="string">"dA"</span> + str(l + <span class="number">2</span>)], current_cache, activation = <span class="string">"relu"</span>)</span><br><span class="line">          grads[<span class="string">"dA"</span> + str(l + <span class="number">1</span>)] = dA_prev_temp</span><br><span class="line">          grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = dW_temp</span><br><span class="line">          grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = db_temp</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="更新参数">更新参数</h4>
<p><span class="math display">\[
W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]}
\]</span></p>
<p><span class="math display">\[
b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate)</span>:</span> </span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural network</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update rule for each parameter. Use a for loop.</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l+<span class="number">1</span>)] = parameters[<span class="string">"W"</span> + str(l+<span class="number">1</span>)] - learning_rate * grads[<span class="string">"dW"</span> + str(l+<span class="number">1</span>)]</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l+<span class="number">1</span>)] = parameters[<span class="string">"b"</span> + str(l+<span class="number">1</span>)] - learning_rate * grads[<span class="string">"db"</span> + str(l+<span class="number">1</span>)]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h3 id="l-层神经网络">L 层神经网络</h3>
<p>在实现 L 层神经网络的各个模块后，现在将它们组装成一个 L 层网络模型，通过 <code>layers_dims</code> 指定网络结构，设置学习率为 0.0075 迭代训练数据 3000 次，最后返回训练好的模型参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_layer_model</span><span class="params">(X, Y, layers_dims, learning_rate = <span class="number">0.0075</span>, num_iterations = <span class="number">3000</span>, print_cost=False)</span>:</span><span class="comment">#lr was 0.009</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    costs = []                         <span class="comment"># keep track of cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Parameters initialization. (≈ 1 line of code)</span></span><br><span class="line">    parameters = initialize_parameters_deep(layers_dims)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line">        AL, caches = L_model_forward(X, parameters)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute cost.</span></span><br><span class="line">        cost = compute_cost(AL, Y)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Backward propagation.</span></span><br><span class="line">        grads = L_model_backward(AL, Y, caches)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># Print the cost every 100 training example</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># plot the cost</span></span><br><span class="line">    plt.plot(np.squeeze(costs))</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p>[1] 吴恩达. DeepLearning.</p>
<p>[2] Christopher Olah. Neural Networks, Manifolds, and Topology. 2014</p>
<p>[3] X. Glorot, Y. Bengio, "Understanding the Difficulty of Training Deep Feedforward Neural Networks", <em>Proc. Conf. Artificial Intelligence and Statistics</em>, 2010.</p>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Emojify 文本情感分析</title>
    <url>/2018/08/31/emojify/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>写论文做实验的时候曾经想过用文本分类的模型，无奈样本太不均衡，所以最后用了自编码器提取特征。在 Coursera 的作业中，该实验分为两个小实验，一个是普通的文本分类，一个是使用 LSTM RNN 进行文本分类。</p>
<a id="more"></a>
<h2 id="baseline-模型-emojifier-v1">Baseline 模型: Emojifier-V1</h2>
<p>训练集 X 中包含 127 个句子，其标签为 0 到 4 分别对应一个 emoji 表情，如下图所示：</p>
<p><img src="/2018/08/31/emojify/data_set.png"></p>
<p>现在载入数据集，并且测试一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train, Y_train = read_csv(<span class="string">'data/train_emoji.csv'</span>)</span><br><span class="line">X_test, Y_test = read_csv(<span class="string">'data/tesss.csv'</span>)</span><br><span class="line">maxLen = len(max(X_train, key=len).split())</span><br><span class="line"></span><br><span class="line">index = <span class="number">1</span></span><br><span class="line">print(X_train[index], label_to_emoji(Y_train[index]))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">I am proud of your achievements 😄</span><br></pre></td></tr></table></figure>
<h3 id="emojifier-v1-概况">Emojifier-V1 概况</h3>
<p>Emojifier-V1 的概况如下图所示：</p>
<p><img src="/2018/08/31/emojify/emo_model.png"></p>
<p>该模型比较简单，首先去训练好的 Embedding 中找到每个单词的嵌入，然后对句子中所有单词的嵌入求平均，将其作为输入，输入到一个多分类的全连接网络中，最后预测句子的情感。</p>
<h3 id="实现-emojifier-v1">实现 Emojifier-V1</h3>
<p>此处不再细述多分类的过程，模型的主要内容如下所示： <span class="math display">\[
z^{(i)} = W \times avg^{(i)} + b
\]</span></p>
<p><span class="math display">\[
a^{(i)} = softmax(z^{(i)})
\]</span></p>
<p><span class="math display">\[
\mathcal{L}^{(i)} = - \sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)
\]</span></p>
<p>其中 <span class="math inline">\(Yoh\)</span> (Y one hot) 是输出的独热编码。最后模型在训练集和测试集上的准确率能够达到 97% 和 86% ，同时对于一些在训练集中没有出现过的单词 (例如: adore) 也能得到不错的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_my_sentences = np.array([<span class="string">"i adore you"</span>, <span class="string">"i love you"</span>, <span class="string">"funny lol"</span>, <span class="string">"lets play with a ball"</span>, <span class="string">"food is ready"</span>, <span class="string">"you are not happy"</span>])</span><br><span class="line">Y_my_labels = np.array([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">2</span>], [<span class="number">1</span>], [<span class="number">4</span>],[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)</span><br><span class="line">print_predictions(X_my_sentences, pred)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Accuracy: 0.8333333333333334</span><br><span class="line"></span><br><span class="line">i adore you ❤️</span><br><span class="line">i love you ❤️</span><br><span class="line">funny lol 😄</span><br><span class="line">lets play with a ball ⚾</span><br><span class="line">food is ready 🍴</span><br><span class="line">you are not happy ❤️</span><br></pre></td></tr></table></figure>
<p>但是该模型并不能分析 not happy 是表示不开心，而只是简单地学习了 happy 这个单词。输出模型的混淆矩阵看一下模型的表现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(Y_test.shape)</span><br><span class="line">print(<span class="string">'           '</span>+ label_to_emoji(<span class="number">0</span>)+ <span class="string">'    '</span> + label_to_emoji(<span class="number">1</span>) + <span class="string">'    '</span> +  label_to_emoji(<span class="number">2</span>)+ <span class="string">'    '</span> + label_to_emoji(<span class="number">3</span>)+<span class="string">'   '</span> + label_to_emoji(<span class="number">4</span>))</span><br><span class="line">print(pd.crosstab(Y_test, pred_test.reshape(<span class="number">56</span>,), rownames=[<span class="string">'Actual'</span>], colnames=[<span class="string">'Predicted'</span>], margins=<span class="literal">True</span>))</span><br><span class="line">plot_confusion_matrix(Y_test, pred_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(56,)</span><br><span class="line">           ❤️   ⚾   😄   😞  🍴</span><br><span class="line">Predicted  0.0  1.0  2.0  3.0  4.0  All</span><br><span class="line">Actual                                 </span><br><span class="line">0            6    0    0    1    0    7</span><br><span class="line">1            0    8    0    0    0    8</span><br><span class="line">2            2    0   16    0    0   18</span><br><span class="line">3            1    1    2   12    0   16</span><br><span class="line">4            0    0    1    0    6    7</span><br><span class="line">All          9    9   19   13    6   56</span><br></pre></td></tr></table></figure>
<p><img src="/2018/08/31/emojify/output.png"></p>
<p>矩阵对角线上的颜色比较深，表示模型的表现还不错。但是模型却无法分析 not xxx 这类的短语，因为嵌入矩阵中没有对应的表示，而且单纯地对所有单词的嵌入求平均会丢失输入的单词的顺序，因此需要更好的算法。</p>
<h2 id="emojifier-v2-在-keras-中使用-lstms">Emojifier-V2: 在 Keras 中使用 LSTMs</h2>
<p>Emojifier-V2 的概况如下图所示：</p>
<p><img src="/2018/08/31/emojify/emojifier-v2.png"></p>
<p>这是一个两层的 LSTM 序列分类器。这次实验使用 mini-batches 来训练 Keras，因此一个 batch 中的序列的长度应该相同，因此需要补 0。例如一个 batch 中的序列的最大长度为 5，那么 "I love you" 这个句子的表示为 <span class="math inline">\((e_{i}, e_{love}, e_{you}, \vec{0}, \vec{0})\)</span>。</p>
<h3 id="embedding-层">Embedding 层</h3>
<p>在 Keras 中，嵌入矩阵被表示成一个层，然后将词的索引匹配成嵌入向量。嵌入矩阵可以被训练出来，也可以用一个训练好的矩阵来初始化它。<code>Embedding()</code> 层输出是一个 (batch size, max input length, dimension of word vectors) 的矩阵。word_to_index 的实现如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentences_to_indices</span><span class="params">(X, word_to_index, max_len)</span>:</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]                                   <span class="comment"># number of training examples</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize X_indices as a numpy matrix of zeros and the correct shape</span></span><br><span class="line">    X_indices = np.zeros((m, max_len))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                               <span class="comment"># loop over training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Convert the ith training sentence in lower case and split is into words. You should get a list of words.</span></span><br><span class="line">        sentence_words = X[i].lower().split()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initialize j to 0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Loop over the words of sentence_words</span></span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> sentence_words:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Set the (i,j)th entry of X_indices to the index of the correct word.</span></span><br><span class="line">            X_indices[i, j] = word_to_index[w]</span><br><span class="line">            <span class="comment"># Increment j to j + 1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> X_indices</span><br></pre></td></tr></table></figure>
<p>接下来需要实现预训练的 Embedding 层，将训练好的嵌入矩阵设置到 <code>Embedding()</code> 层的权值中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretrained_embedding_layer</span><span class="params">(word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    vocab_len = len(word_to_index) + <span class="number">1</span>                  <span class="comment"># adding 1 to fit Keras embedding (requirement)</span></span><br><span class="line">    emb_dim = word_to_vec_map[<span class="string">"cucumber"</span>].shape[<span class="number">0</span>]      <span class="comment"># define dimensionality of your GloVe word vectors (= 50)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)</span></span><br><span class="line">    emb_matrix = np.zeros((vocab_len, emb_dim))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set each row "index" of the embedding matrix to be the word vector representation of the "index"th word of the vocabulary</span></span><br><span class="line">    <span class="keyword">for</span> word, index <span class="keyword">in</span> word_to_index.items():</span><br><span class="line">        emb_matrix[index, :] = word_to_vec_map[word]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Keras embedding layer with the correct output/input sizes, make it trainable.</span></span><br><span class="line">    <span class="comment"># Use Embedding(...). Make sure to set trainable=False.</span></span><br><span class="line">    embedding_layer = Embedding(vocab_len, emb_dim, trainable = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the "None".</span></span><br><span class="line">    embedding_layer.build((<span class="literal">None</span>,))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.</span></span><br><span class="line">    embedding_layer.set_weights([emb_matrix])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> embedding_layer</span><br></pre></td></tr></table></figure>
<h3 id="构建模型">构建模型</h3>
<p>接下来需要构建模型，模型分为：</p>
<ul>
<li>输入层: <code>Input((max_len, m), dtype='int32')</code></li>
<li>LSTM 层: <code>LSTM(hidden_units, return_sequence)(embeddings)</code></li>
<li>Dropout 层: <code>Dropout(keep_prob)(X)</code></li>
<li>全连接层: <code>Dense(output_dimension)(X)</code></li>
<li>激活层: <code>Activation(activation_func)(X)</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Emojify_V2</span><span class="params">(input_shape, word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    <span class="comment"># Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).</span></span><br><span class="line">    sentence_indices = Input(input_shape, dtype=<span class="string">'int32'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the embedding layer pretrained with GloVe Vectors (≈1 line)</span></span><br><span class="line">    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Propagate sentence_indices through your embedding layer, you get back the embeddings</span></span><br><span class="line">    embeddings = embedding_layer(sentence_indices)   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Propagate the embeddings through an LSTM layer with 128-dimensional hidden state</span></span><br><span class="line">    <span class="comment"># Be careful, the returned output should be a batch of sequences.</span></span><br><span class="line">    X = LSTM(<span class="number">128</span>, return_sequences=<span class="literal">True</span>)(embeddings)</span><br><span class="line">    <span class="comment"># Add dropout with a probability of 0.5</span></span><br><span class="line">    X = Dropout(<span class="number">0.5</span>)(X)</span><br><span class="line">    <span class="comment"># Propagate X trough another LSTM layer with 128-dimensional hidden state</span></span><br><span class="line">    <span class="comment"># Be careful, the returned output should be a single hidden state, not a batch of sequences.</span></span><br><span class="line">    X = LSTM(<span class="number">128</span>, return_sequences=<span class="literal">False</span>)(X)</span><br><span class="line">    <span class="comment"># Add dropout with a probability of 0.5</span></span><br><span class="line">    X = Dropout(<span class="number">0.5</span>)(X)</span><br><span class="line">    <span class="comment"># Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.</span></span><br><span class="line">    X = Dense(<span class="number">5</span>)(X)</span><br><span class="line">    <span class="comment"># Add a softmax activation</span></span><br><span class="line">    X = Activation(<span class="string">'softmax'</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Model instance which converts sentence_indices into X.</span></span><br><span class="line">    model = Model(inputs=sentence_indices, outputs=X)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>构建好模型后可以通过模型的 <code>summary()</code> 方法来检查模型的概要 (max_len = 10)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_1 (InputLayer)         (None, 10)                0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">embedding_2 (Embedding)      (None, 10, 50)            20000050  </span><br><span class="line">_________________________________________________________________</span><br><span class="line">lstm_1 (LSTM)                (None, 10, 128)           91648     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout)          (None, 10, 128)           0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">lstm_2 (LSTM)                (None, 128)               131584    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_2 (Dropout)          (None, 128)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 5)                 645       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">activation_1 (Activation)    (None, 5)                 0         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 20,223,927</span><br><span class="line">Trainable params: 223,877</span><br><span class="line">Non-trainable params: 20,000,050</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<p>由于嵌入矩阵是训练好的 <code>trainable = False</code>，因此有 400,001 * 50 = 20,000,050 个参数是 Non-trainable 参数。接下来需要编译模型，定义损失函数、优化器和评估指标，最后拟合模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)</span><br><span class="line">Y_train_oh = convert_to_one_hot(Y_train, C = <span class="number">5</span>)</span><br><span class="line">model.fit(X_train_indices, Y_train_oh, epochs = <span class="number">50</span>, batch_size = <span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>训练集和测试集上的准确率能接近 100% 和 91%。对于 not happy 也能准确预测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_test = np.array([<span class="string">'you are not happy'</span>])</span><br><span class="line">X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)</span><br><span class="line">print(x_test[<span class="number">0</span>] +<span class="string">' '</span>+  label_to_emoji(np.argmax(model.predict(X_test_indices))))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">you are not happy 😞</span><br></pre></td></tr></table></figure>
<p>因为 LSTM 网络具有长短期记忆，所以能够很好地预测某些单词的组合。</p>
<h2 id="总结">总结</h2>
<p>在 NLP 任务中，如果训练集比较小，比较适合直接用训练好的嵌入矩阵而不是自己训练一个。在 RNN 中，如果想用 mini-batches 提高效率(矩阵的运算比循环快)，那么就需要对样本进行补 0。<code>LSTM()</code> 的 <code>return_sequence</code> 参数决定返回所有的隐藏状态还是只返回最后一个时间步的隐藏状态。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>人脸识别</title>
    <url>/2019/01/12/face-recognition/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>人脸识别这部分内容的实验 idea 主要来自于 FaceNet，其中还有部分来自 DeepFace。网络结构没有什么特殊的地方，主要是其损失函数的构造。</p>
<a id="more"></a>
<h2 id="人脸识别">人脸识别</h2>
<p>人脸识别问题通常分为两类：</p>
<ul>
<li>人脸验证：例如苹果的 Face ID 技术，判断当前人脸是否为机主，这就是 1:1 匹配问题。</li>
<li>人脸识别：例如有些公司的门禁，判断当前人脸是否为公司员工，这就是 1:K 匹配问题。</li>
</ul>
<p>FaceNet [2] 神经网络可以将一张人脸图像编码成一个 128 维的向量，然后通过比较两个向量来判断是否属于同一个人。实验内容主要分为三部分：</p>
<ol type="1">
<li>实现三重损失函数</li>
<li>使用预训练的模型将人脸图像编码成 128 维向量</li>
<li>使用上述编码来进行人脸验证和人脸识别</li>
</ol>
<p>首先需要引入各种 package 和导入数据集，虽然在深度学习领域没有统一的标准，但是为了方便，这里使用的图像数据集是 "channels first" 的，即维度为 <span class="math inline">\((m, n_C, n_H, n_W)\)</span>。</p>
<h3 id="人脸验证">人脸验证</h3>
<p>人脸验证问题就是给定两张人脸图像，判断他们是否是同一个人。最简单的方法就是计算每个像素的差异，然后给定一个阈值，差异超过这个阈值就不是同一个人，但是如果同一个人在不同亮度下或者不同角度下照片的差异通常很大。因此需要对图像进行编码后分析而不是简单对像素进行分析，即使用神经网络提取图像特征进行对比。</p>
<h3 id="编码人脸">编码人脸</h3>
<p>实验使用 FaceNet 提取人脸特征，这个 ConvNet 网络的架构是 Inception 模型，模型细节可以参考 <a href="https://github.com/pengzhendong/DeepLearning/blob/master/4.%20Convolutional%20Neural%20Networks/Week%204/Face%20Recognition/inception_blocks.py" target="_blank" rel="noopener">inception_blocks.py</a>。输入模型的图像尺寸为 <span class="math inline">\(96\times 96\)</span>，即输入维度为 <span class="math inline">\((m, n_C, n_H, n_W) = (m, 3, 96, 96)\)</span>，输出为 <span class="math inline">\((m, 128)\)</span>。通过计算两个向量之间的距离，就可以判断对应的两张人脸图像是否属于同一个人。</p>
<p><img src="/2019/01/12/face-recognition/distance_kiank.png"></p>
<p>如果编码足够好，即模型提取人脸的特征足够好，那么对于同一个人的不同照片，最后计算的距离应该很小；对于不同人脸，计算出的距离应该很大。FaceNet 在训练过程中使用的三重损失函数就可以保证这个模型提取的特征足够好。</p>
<h4 id="三重损失">三重损失</h4>
<p>三重损失的思想是最小化不同人脸的编码距离，最大化同一个人脸的编码距离。给定一张图像 <span class="math inline">\(x\)</span>，定义其编码为 <span class="math inline">\(f(x)\)</span>，函数 <span class="math inline">\(f\)</span> 即神经网络计算的功能。给定三元组图像 <span class="math inline">\((A, P, N)\)</span>，其中：</p>
<ul>
<li>A: Anchor 图像，即人脸图像</li>
<li>P: Positive 图像，与 Anchor 图像为同一个人</li>
<li>N: Negative 图像，与 Anchor 图像不是同一个人</li>
</ul>
<p>对于训练集中的第 <span class="math inline">\(i\)</span> 个样本 <span class="math inline">\((A^{(i)}, P^{(i)}, N^{(i)})\)</span>，有： <span class="math display">\[
\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 + \alpha &lt; \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2
\]</span> 其中参数 <span class="math inline">\(\alpha\)</span> 是为了避免对于所有的图像，模型都编码为 0，这里手动设置为 0.2。因此可以构造三重代价函数： <span class="math display">\[
\mathcal{J} = \sum^{N}_{i=1} max\large( \small \underbrace{\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2}_\text{(1)} - \underbrace{\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2}_\text{(2)} + \alpha, 0 \large )
\]</span> 通常还会对编码进行归一化，即令 <span class="math inline">\(\mid \mid f(img)\mid \mid_2=1\)</span>。实现上述代价函数分为四个步骤：</p>
<ol type="1">
<li>计算 A 和 P 编码的距离：<span class="math inline">\(\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2\)</span></li>
<li>计算 A 和 N 编码的距离：<span class="math inline">\(\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2\)</span></li>
<li>对于每个三元组样本，计算损失函数：<span class="math inline">\(\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid - \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2 + \alpha\)</span></li>
<li>计算代价函数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(y_true, y_pred, alpha = <span class="number">0.2</span>)</span>:</span></span><br><span class="line">    anchor, positive, negative = y_pred[<span class="number">0</span>], y_pred[<span class="number">1</span>], y_pred[<span class="number">2</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Compute the (encoding) distance between the anchor and the positive</span></span><br><span class="line">    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)))</span><br><span class="line">    <span class="comment"># Step 2: Compute the (encoding) distance between the anchor and the negative</span></span><br><span class="line">    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)))</span><br><span class="line">    <span class="comment"># Step 3: subtract the two previous distances and add alpha.</span></span><br><span class="line">    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</span><br><span class="line">    <span class="comment"># Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.</span></span><br><span class="line">    loss = tf.maximum(tf.reduce_mean(basic_loss), <span class="number">0.0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h2 id="载入预训练模型">载入预训练模型</h2>
<p>训练 FaceNet 的过程就是最小化三重损失，由于 FaceNet 在训练的时候需要大量数据和时间，因此实验直接给了一个预训练的 ConvNet 模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">FRmodel = faceRecoModel(input_shape=(<span class="number">3</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br><span class="line">FRmodel.compile(optimizer = <span class="string">'adam'</span>, loss = triplet_loss, metrics = [<span class="string">'accuracy'</span>])</span><br><span class="line">load_weights_from_FaceNet(FRmodel)</span><br></pre></td></tr></table></figure>
<p>以下为模型在三个人的人脸图像上计算的编码距离，距离越小表示为同一个人的概率越大。</p>
<h2 id="模型应用">模型应用</h2>
<p>例如构建一个人脸验证系统，用户输入姓名，然后系统拍摄人脸，判断该用户是否是姓名对应那个人。与人脸识别不同的是，人脸识别系统不需要提供姓名，直接拍摄人脸，然后判断数据库中是否有该用户。</p>
<h3 id="人脸验证-1">人脸验证</h3>
<p>首先往数据库中存入数据集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">database = &#123;&#125;</span><br><span class="line">database[<span class="string">"danielle"</span>] = img_to_encoding(<span class="string">"images/danielle.png"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"younes"</span>] = img_to_encoding(<span class="string">"images/younes.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"tian"</span>] = img_to_encoding(<span class="string">"images/tian.jpg"</span>, FRmodel)</span><br></pre></td></tr></table></figure>
<p>实现验证过程主要分为以下几个步骤：</p>
<ol type="1">
<li>计算人脸图像的编码</li>
<li>计算该编码与数据库中<font color="red"><strong>指定</strong></font>的编码的距离</li>
<li>差异小于阈值 0.7 即判断为同一个人</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verify</span><span class="params">(image_path, identity, database, model)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)</span></span><br><span class="line">    encoding = img_to_encoding(image_path, model)</span><br><span class="line">    <span class="comment"># Step 2: Compute distance with identity's image (≈ 1 line)</span></span><br><span class="line">    dist = np.linalg.norm(encoding-database[identity])</span><br><span class="line">    <span class="comment"># Step 3: Return True if dist &lt; 0.7 (≈ 3 lines)</span></span><br><span class="line">    <span class="keyword">if</span> dist &lt; <span class="number">0.7</span>:</span><br><span class="line">        print(<span class="string">"It's "</span> + str(identity) + <span class="string">", welcome home!"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"It's not "</span> + str(identity) + <span class="string">", please go away"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3 id="人脸识别-1">人脸识别</h3>
<p>人脸识别和人脸验证的区别就是人脸验证需要提供其他信息，然后只需要判断用户是否为信息指定的那个人；人脸识别不需要提供其他信息，但是需要和数据库中所有数据进行比较，判断是否属于其中任何一个人。实现识别过程主要分为以下几个步骤：</p>
<ol type="1">
<li><p>计算人脸图像的编码（目标编码）</p></li>
<li><p>找到数据库中与目标编码距离最小的编码</p>
<ul>
<li>初始化 <code>min_dist</code> 为一个比较大的值，用于存储最小的距离</li>
<li>遍历数据库中所有编码
<ul>
<li>计算编码与目标编码的距离</li>
<li>如果距离小于 <code>min_dist</code>，记录新的距离和该编码对应的信息</li>
</ul></li>
</ul></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">who_is_it</span><span class="params">(image_path, database, model)</span>:</span></span><br><span class="line">    <span class="comment">## Step 1: Compute the target "encoding" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)</span></span><br><span class="line">    encoding = img_to_encoding(image_path, model)</span><br><span class="line">    <span class="comment">## Step 2: Find the closest encoding ##</span></span><br><span class="line">    <span class="comment"># Initialize "min_dist" to a large value, say 100 (≈1 line)</span></span><br><span class="line">    min_dist = <span class="number">100</span></span><br><span class="line">    <span class="comment"># Loop over the database dictionary's names and encodings.</span></span><br><span class="line">    <span class="keyword">for</span> (name, db_enc) <span class="keyword">in</span> database.items():</span><br><span class="line">        <span class="comment"># Compute L2 distance between the target "encoding" and the current "emb" from the database. (≈ 1 line)</span></span><br><span class="line">        dist = np.linalg.norm(encoding-db_enc)</span><br><span class="line">        <span class="comment"># If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)</span></span><br><span class="line">        <span class="keyword">if</span> dist &lt; min_dist:</span><br><span class="line">            min_dist = dist</span><br><span class="line">            identity = name</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> min_dist &gt; <span class="number">0.7</span>:</span><br><span class="line">        print(<span class="string">"Not in the database."</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"it's "</span> + str(identity) + <span class="string">", the distance is "</span> + str(min_dist))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> min_dist, identity</span><br></pre></td></tr></table></figure>
<p>通过对数据集的扩增，例如提供同一个用户在不同光照下照片等等可以提高系统的准确率；通过对图像的处理，例如裁剪图像只保留人脸等等可以提高系统的鲁棒性。</p>
<h2 id="总结">总结</h2>
<p>人脸验证是 1:1 匹配问题，只需要对比一张人脸图像；而人脸识别就比较难，1:K 匹配问题需要比较数据库中所有的人脸。最小化三重损失得到的网络可以有效提取人脸的特征。同样的编码既可以用来进行人脸验证，也可以用来进行人脸识别。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). <a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank" rel="noopener">FaceNet: A Unified Embedding for Face Recognition and Clustering</a></li>
<li>Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). <a href="https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf" target="_blank" rel="noopener">DeepFace: Closing the gap to human-level performance in face verification</a></li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>快速傅里叶变换</title>
    <url>/2018/10/29/fast-fourier-transform/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>终于下定决心要啃掉这块骨头。大四选修数字图像处理的时候，第一次接触傅里叶变换，然后实现了时间度复杂度为 <span class="math inline">\(O(n^2)\)</span> 的算法，后来才知道还有快速傅里叶变换，时间复杂度是 <span class="math inline">\(O(nlogn)\)</span>。</p>
<a id="more"></a>
<p>拉格朗日等数学家发现某些周期函数可以由三角函数的和表示，而傅里叶则猜测任意周期函数都可以写成三角函数的和，也就是高等数学中的<strong>傅里叶级数</strong>。大家当然都不相信啦，但又不能给出有力的论据。直到20年后（1829年）狄利克雷才给出了让人满意的答案：只有满足一定条件时，周期函数才能展开成傅里叶级数。这个条件被称为<strong>狄利克雷条件</strong>。傅里叶级数用吴文俊先生的话说就是：</p>
<blockquote>
<p>把质的困难转化成量的复杂</p>
</blockquote>
<p>而最早具有这种想法的人是泰勒，他在 1715 年研究出泰勒公式。泰勒级数把函数表达式转化为多项式函数来近似，是求导函数组成的特征函数和，反应变化剧烈程度。傅里叶级数是频谱叠加的三角函数和，反应变化频率本质属性。</p>
<blockquote>
<p>实函数的傅立叶级数和泰勒级数不过是观察复幂级数的两种不同方式</p>
</blockquote>
<h2 id="傅里叶级数">傅里叶级数</h2>
<p>傅里叶级数具体构造过程可以参考<a href="https://www.matongxue.com/madocs/619.html" target="_blank" rel="noopener">马同学高等数学</a>的文章。假设 <span class="math inline">\(f(x)\)</span> 的周期为 <span class="math inline">\(T\)</span>，并且满足狄利克雷条件，则构造结果如下所示： <span class="math display">\[
f(x)=\frac{a_0}{2}+\sum_{n=1}^{\infty}\Big(a_ncos(\frac{2\pi nx}{T})+b_nsin(\frac{2\pi nx}{T})\Big),a_0\in\mathbb{R}
\]</span> 这就是傅里叶级数，其中 <span class="math inline">\(a_n, b_n\)</span> 为傅里叶系数。利用三角函数的正交性等性质（详细推导过程可参考高数课本），可以推导出： <span class="math display">\[
\begin{cases}
a_n=\frac{2}{T}\int_{x_0}^{x_0+T}f(x)cos(\frac{2\pi nx}{T})dx \\\
b_n=\frac{2}{T}\int_{x_0}^{x_0+T}f(x)sin(\frac{2\pi nx}{T})dx
\end{cases}
\]</span> 举个简单的例子，有以周期为 <span class="math inline">\(2\pi\)</span> 的三角波函数，在一个周期内的表达式为： <span class="math display">\[
f(x)=\begin{cases}
1+\frac{x}{\pi}, &amp; -\pi\leq x&lt;0 \\\
1-\frac{x}{\pi}, &amp; 0\leq x&lt;\pi
\end{cases}
\]</span> 即 <span class="math inline">\(f(x)=1-2\times |nint(\frac{x}{2\pi})-\frac{x}{2\pi}|\)</span>，其中 <code>nint()</code> 为向下取整函数，在 Python 中相当于 <code>round()</code> 函数。由于 <span class="math inline">\(f(x)\)</span> 为偶函数，所以正弦分量的幅值 <span class="math inline">\(b_n=0\)</span>。解得:</p>
<p><span class="math display">\[
f(x)=\frac{1}{2}+\frac{4}{\pi^2}\Big(cos(x)+\frac{cos(3x)}{3^2}+\frac{cos(5x)}{5^2}+...\Big)
\]</span> 傅里叶级数实际上相当于是把 <span class="math inline">\(f(x)\)</span> 当做了基的向量。当 <span class="math inline">\(n\)</span> 取 5 时该函数的基为： <span class="math display">\[
\lbrace 1, cos(x), cos(2x), cos(3x), cos(5x)\rbrace
\]</span> 该函数相当于向量： <span class="math display">\[
(1, \frac{4}{\pi^2}, 0, \frac{4}{3^2\pi^2}, 0, \frac{4}{5^2\pi^2})
\]</span></p>
<p>根据这个向量就能得到函数的幅值频谱图，其中纵坐标为幅值，也就是上面的向量。横坐标为角频率（角速度的标量），也就是对应的基中的 <span class="math inline">\(\omega_n=\frac{2\pi n}{T}\)</span>，单位为 <span class="math inline">\(Hz\)</span>。</p>
<p><img src="/2018/10/29/fast-fourier-transform/5XSSNh.png"></p>
<p>非奇非偶函数既有正弦分量也有余弦分量，所以就需要有两个频域图。当 <span class="math inline">\(n\)</span> 取值越大，则越能逼近原函数。</p>
<h3 id="复数形式">复数形式</h3>
<p>傅里叶级数具有两个频域图，而另一种角度，即复数形式的傅里叶级数就可以结合正弦和余弦分量，详情可见<a href="https://www.matongxue.com/madocs/619.html" target="_blank" rel="noopener">马同学高等数学</a>。复数形式的傅里叶级数如下所示： <span class="math display">\[
f(x)=\sum_{n=-\infty}^{\infty}c_ne^{i\frac{2\pi nx}{T}}
\]</span> 其中 <span class="math display">\[
c_n=\frac{1}{T}\int_{x_0}^{x_0+T}f(x)e^{-i\frac{2\pi nx}{T}}dx
\]</span> 由于 <span class="math inline">\(c_n\)</span> 是复数，周期函数的频域图还是不好画，那复数形式有啥用？欸，先来看看非周期函数和傅里叶变换。</p>
<h2 id="傅里叶变换">傅里叶变换</h2>
<p>傅里叶级数只能用于周期函数，后来的数学家将其扩展到非周期函数上，其思想就是让周期 <span class="math inline">\(T\)</span> 趋于无穷。由傅里叶级数公式可知，两个相邻频域直接的差越小，即频率越密集，详情可见<a href="https://www.matongxue.com/madocs/712.html" target="_blank" rel="noopener">马同学高等数学</a>。因此时域上周期的函数其频域是离散的，在时域上非周期的函数其频域是连续的。对于非周期函数，周期趋于无穷，令 <span class="math inline">\(F(\omega_n)=T\times c_n\)</span>，有： <span class="math display">\[
\begin{align*} 
f(x)&amp;=\lim_{T\rightarrow \infty}\sum_{n=-\infty}^{\infty}\frac{1}{T}F(\omega_n)e^{i\frac{2\pi nx}{T}} \\\
&amp;=\lim_{T\rightarrow \infty}\frac{1}{2\pi}\sum_{n=-\infty}^{\infty}F(\omega_n)e^{i\omega_nx}(\omega_n-\omega_{n-1}) \\\
&amp;=\frac{1}{2\pi}\int_{-\infty}^{\infty}F(\omega)e^{i\omega x}d\omega \\\
\end{align*}
\]</span> 其中 <span class="math display">\[
F(\omega)=\int_{-\infty}^{\infty}f(x)e^{-i\omega x}dx
\]</span> ### 总结</p>
<p><span class="math inline">\(F(\omega)\)</span> 就是傅里叶变换，得到的就是频域曲线，即各频率分量的幅值。<span class="math inline">\(f(x)\)</span> 是傅里叶变换的逆变换，所以时域和频域就是看待同一个数学对象的两种角度，可以来回切换。</p>
<h2 id="离散时间傅里叶变换">离散时间傅里叶变换</h2>
<p>上面提及的傅里叶变换 <span class="math inline">\(F(\omega)\)</span> 是连续时间傅里叶变换，即信号在时域上是连续的。但是计算机存储的信号都是采样得到的离散的、有限长的信号。在数学上可以用原信号与脉冲函数（具有筛选性）的乘积表示采样，假设采样周期为 <span class="math inline">\(T\)</span>，即每隔时间 <span class="math inline">\(T\)</span> 进行一次采样，则 <span class="math inline">\(f[nT]\)</span> 相当于 <span class="math inline">\(f(x)\)</span> 在时间点 <span class="math inline">\(nT\)</span> 上的采样，即： <span class="math display">\[
\begin{align*}
f_{discrete}(x)&amp;=f(x)\sum_{n=-\infty}^{\infty}\delta(x-nT) \\\
&amp;=\sum_{n=-\infty}^{\infty}f[nT]\delta(x-nT) \\\
\end{align*}
\]</span> 所以 <span class="math display">\[
F(e^{i\omega})=\sum_{n=-\infty}^{\infty}f[nT]e^{-i\omega nT}
\]</span> 这就是离散时间傅里叶变换（DTFT），由于离散时间傅里叶变换可以被看作 <a href="https://zh.wikipedia.org/wiki/%E7%A6%BB%E6%95%A3%E6%97%B6%E9%97%B4%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2#DTFT%E4%B8%8EZ%E5%8F%98%E6%8D%A2" target="_blank" rel="noopener">Z 变换</a>的特例，因此通常用 <span class="math inline">\(F(e^{i\omega})\)</span> 表示离散时间傅里叶变换，其逆变换为： <span class="math display">\[
f[nT]=\frac{1}{2\pi}\int_{-\infty}^{\infty}F(e^{i\omega})e^{i\omega nT}d\omega
\]</span> 由于 <span class="math inline">\(e^{i\theta}\)</span> 的周期是 <span class="math inline">\(2\pi\)</span>，因此对于离散时间傅里叶变换，<span class="math inline">\(n\)</span> 为整数，只要采样周期 <span class="math inline">\(T\)</span> 设置为整数，就有： <span class="math display">\[
\begin{align*}
F(e^{i\omega})&amp;=\sum_{n=-\infty}^{\infty}f[nT]e^{-i\omega nT} \\\
&amp;=\sum_{n=-\infty}^{\infty}f[nT]e^{-i(\omega nT+2\pi MnT)} \\\
&amp;=\sum_{n=-\infty}^{\infty}f[nT]e^{-i(\omega+2\pi M)nT} \\\
&amp;=F(e^{i(\omega+2\pi M)}) \\\
\end{align*}
\]</span> 其中 <span class="math inline">\(M\)</span> 为整数，所以离散时间傅里叶变换是频率 <span class="math inline">\(\omega\)</span> 的周期函数，周期为 <span class="math inline">\(2\pi\)</span>。而对于连续时间傅里叶变换，时间是连续的时间 <span class="math inline">\(x\)</span>，则： <span class="math display">\[
\int_{-\infty}^{\infty}f(x)e^{-i\omega x}dx\neq\int_{-\infty}^{\infty}f(x)e^{-i(\omega +2\pi M)x}dx
\]</span> ### 总结</p>
<p>时域和频域具有以下关系：</p>
<table>
<thead>
<tr class="header">
<th>时域</th>
<th>频域</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>周期</td>
<td>离散</td>
</tr>
<tr class="even">
<td>非周期</td>
<td>连续</td>
</tr>
<tr class="odd">
<td>连续</td>
<td>非周期</td>
</tr>
<tr class="even">
<td>离散</td>
<td>周期</td>
</tr>
</tbody>
</table>
<p>即大部分的信号为：连续时间周期信号、连续时间非周期信号、离散时间非周期信号和离散时间周期信号。而计算机存储的信号为时域上采样得到的信号，因此在计算机中我们用不到连续时域信号，以下内容均默认为时域离散，即频域是周期的。</p>
<h2 id="离散傅里叶变换">离散傅里叶变换</h2>
<p>由于计算机只能处理有限长的信号，对于时域周期的信号，则可以对其一个周期内的信号进行傅里叶变换，然后扩展到整个时域上。对于无限长非周期信号就需要对信号进行截断，然后再当成是周期信号的一个周期来处理</p>
<p>例如在 <span class="math inline">\([0, L]\)</span> 对离散时域的信号进行<strong>截断</strong>，设采样周期为 <span class="math inline">\(T\)</span>，则时域的采样点数为 <span class="math inline">\(N=\frac{L}{T}\)</span>，有： <span class="math display">\[
f_{discrete}(x)=\sum_{n=0}^{N-1}f[nT]\delta(x-nT)
\]</span> 截断后的离散时间傅里叶变换为： <span class="math display">\[
F(e^{i\omega})=\sum_{n=0}^{N-1}f[nT]e^{-i\omega nT}
\]</span> 由于非周期信号的频域是连续的，也无法表示，所以也要在频域上采样，就是相当于以截断的这一段信号当成是周期信号的一个周期，对周期信号的一个周期进行傅里叶变换。根据<a href="https://zh.wikipedia.org/wiki/%E9%87%87%E6%A0%B7%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">采样定理</a>，频域的采样间隔应为 <span class="math inline">\(\frac{1}{L}\)</span>，频域采样点数为： <span class="math display">\[
\frac{1/T}{1/L}=N
\]</span> 即频域采样的点数和时域采样同为 <span class="math inline">\(N\)</span>，频域的采样点为 <span class="math inline">\(\lbrace\omega_n=2\pi k/NT\rbrace_{0\leq k&lt;N}\)</span>。这就是离散傅里叶变换（DFT），令 <span class="math inline">\(T=1\)</span> 并且将其归一化，得： <span class="math display">\[
F[k]=\sum_{n=0}^{N-1}f[n]e^{-i\frac{2\pi}{N}nk}, k=0, 1, ..., N-1
\]</span> 逆变换为： <span class="math display">\[
f[n]=\frac{1}{N}\sum_{k=0}^{N-1}F[k]e^{i\frac{2\pi}{N}nk}, n=0, 1, ..., N-1
\]</span></p>
<h3 id="总结">总结</h3>
<p>综上所述，计算机对现实中的信号的时域采样（离散化）得到了离散时间傅里叶变换（DTFT），这个过程中频域会被周期化；然后对信号进行截断，即只收集一段时间的信号；继而对频域进行采样（离散化）得到离散周期傅里叶级数（DFS），这个过程中时域会被周期化。最后只取一个周期进行分析，即只取一个周期内的 <span class="math inline">\(N\)</span> 个采样点。</p>
<h2 id="快速傅里叶变换">快速傅里叶变换</h2>
<p>1965年，Cooley 和 Tukey 提出了计算离散傅里叶变换（DFT）的快速算法，将 DFT 的运算量减少了几个数量级。快速傅里叶变换（FFT）中的”快速”等价于快速排序中的“快速”。也就是说，我们需要在计算机上实现排序，有各种各样的排序算法，快速排序这个算法比较好用。快速傅里叶变换也一样，利用了<strong>分治</strong>策略，减小了算法的时间复杂度。对于 <span class="math inline">\(N\)</span> 点信号进行离散傅里叶变换，令 <span class="math inline">\(W_N=e^{-i\frac{2\pi}{N}}\)</span>，有： <span class="math display">\[
F[k]=\sum_{n=0}^{N-1}f[n]W_N^{nk}, k=0, 1, ..., N-1
\]</span> 直接计算的话，算法的时间复杂度为 <span class="math inline">\(N^2\)</span>。快速傅里叶变换算法就能像快速排序算法一样，将时间复杂度从 <span class="math inline">\(N^2\)</span> 降到 <span class="math inline">\(Nlog_2N\)</span>。快速傅里叶变换是根据离散傅里叶变换的奇、偶、虚、实等特性，对离散傅立叶变换的算法进行改进获得的，它对傅里叶变换的理论并没有新的发现，但是对于在计算机中应用离散傅立叶变换，可以说是进了一大步。</p>
<p>大部分快速傅里叶变换是基于 2 的，即信号的长度为 2 的整数幂（不足则补 0）。快速傅里叶算法每次将长度为 <span class="math inline">\(N\)</span> 的信号分解为两个长度为 <span class="math inline">\(\frac{N}{2}\)</span> 的信号进行处理（按奇数和偶数），即： <span class="math display">\[
\begin{align*}
F[k]&amp;=\sum_{n=0}^{N-1}f[n]W_N^{nk} \\\
&amp;=\sum_{n=0}^{\frac{N}{2}-1}f[2n]W_N^{(2n)k}+\sum_{n=0}^{\frac{N}{2}-1}f[2n+1]W_N^{(2n+1)k} \\\
\end{align*}
\]</span> 因为 <span class="math display">\[
W_N^{(2n)k}=e^{-i\frac{2\pi}{N}(2n)k}=e^{-i\frac{2\pi}{\frac{N}{2}}nk}=W_{\frac{N}{2}}^{nk}
\]</span></p>
<p>所以 <span class="math display">\[
F[k]=E[k]+W_N^kO[k], 0\leq k\leq N-1
\]</span> 其中，偶数样本点信号的离散傅里叶变换为： <span class="math display">\[
E[k]=\sum_{n=0}^{\frac{N}{2}-1}f[2n]W_{\frac{N}{2}}^{nk}
\]</span> 奇数样本点信号的离散傅里叶变换为： <span class="math display">\[
O[k]=\sum_{n=0}^{\frac{N}{2}-1}f[2n+1]W_{\frac{N}{2}}^{nk}
\]</span> 由于 <span class="math inline">\(W_N^{nk}\)</span> 对 <span class="math inline">\(n\)</span> 和 <span class="math inline">\(k\)</span> 都具有周期性，即 <span class="math display">\[
W_N^{nk}=W_N^{(n+N)k}=W_N^{n(k+N)}
\]</span> 所以 <span class="math display">\[
\begin{cases}
E[k]=E[k+\frac{N}{2}] \\\
O[k]=O[k+\frac{N}{2}]
\end{cases}
\]</span></p>
<h3 id="蝶形图">蝶形图</h3>
<p>以 <span class="math inline">\(N=8\)</span> 为例，通过蝶形图可视化快速傅里叶具体计算过程，有：</p>
<p><span class="math display">\[
\begin{cases}
F[0]=E[0]+W_8^0O[0] \\\
... \\\
F[4]=E[4]+W_8^4O[4]=E[4-\frac{8}{2}]+W_8^4O[4-\frac{8}{2}]=E[0]+W_8^4O[0] \\\
...
\end{cases}
\]</span> 同理，可以继续分解直到最后，一共有 24 次加法操作。由于 <span class="math inline">\(W^0=1\)</span>，所以乘法操作的次数小于加法操作的次数。因此快速傅里叶变换的时间复杂度为 <span class="math inline">\(O(Nlog_2N)\)</span>。</p>
<h3 id="测试">测试</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFT</span><span class="params">(x)</span>:</span></span><br><span class="line">    x = np.asarray(x, dtype=float)</span><br><span class="line">    N = x.shape[<span class="number">0</span>]</span><br><span class="line">    n = np.arange(N)</span><br><span class="line">    k = n.reshape((N, <span class="number">1</span>))</span><br><span class="line">    M = np.exp(<span class="number">-2j</span> * np.pi * k * n / N)</span><br><span class="line">    <span class="keyword">return</span> np.dot(M, x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    x = np.random.random(<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    dft = DFT(x)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(end - start)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    fft = np.fft.fft(x)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(end - start)</span><br><span class="line"></span><br><span class="line">    ret = np.allclose(dft, fft)</span><br><span class="line">    print(ret)</span><br></pre></td></tr></table></figure>
<p>对于一个长度为 1024 的序列，手动实现的离散傅里叶变换算法需要的时间为 0.2748403549194336 秒，而<code>numpy</code> 的快速傅里叶变换算法只需要 0.0009996891021728516 秒，最终计算结果一致。</p>
<h2 id="总结-1">总结</h2>
<p>花了整整一周的时间终于总结完了快速傅里叶变换相关的内容，虽然复数部分不是很深入，但是目前至少能比较熟练得使用这个 20 世纪最伟大的算法了。以上内容之所以花了这么多时间，还是因为概念不清晰，了解傅里叶变换、离散时间傅里叶变换、离散傅里叶变换和快速傅里叶变换就花了不少时间，如果这次没有记录下来，我相信下次看到还是不会！</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>马同学高等数学. 如何理解傅立叶级数公式？. https://www.matongxue.com/madocs/619.html.</li>
<li>马同学高等数学. 从傅立叶级数到傅立叶变换. https://www.matongxue.com/madocs/712.html.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>特征缩放</title>
    <url>/2018/05/31/feature-scaling/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在机器学习中经常使用梯度下降算法来优化代价函数，得到局部最优解。但是梯度下降算法有时候效率并不高，有一些算法能够很大程度上提高梯度下降算法的性能。例如前面提到的小批量梯度下降，每次使用一部分样本更新参数，能够加速训练过程，还有<strong>特征缩放</strong>。</p>
<a id="more"></a>
<h2 id="特征缩放">特征缩放</h2>
<p>在实际应用中，我们得到的数据会存在缺失值、重复值等各种问题，所以数据的预处理就显得尤为重要。特征缩放是一种常用的数据处理方式，使用特征缩放能够加快梯度下降，提高收敛速度。Normalization 这个词翻译成归一化不太好理解，网上的各种资料更是滥用归一化和标准化 (Standardization)，下面只能结合着 <a href="http://scikit-learn.org/stable/modules/preprocessing.html#" target="_blank" rel="noopener">sklearn</a> 的官方文档给出自己的理解。</p>
<p>人们常说的归一化其实就是普通的特征缩放(scaling)，通过线性变换对数据进行缩放，简化计算的方式，将有量纲的输入，变换为无量纲。例如：房价预测问题中房间的大小 (30~100<span class="math inline">\(m^2\)</span>) 和房间数 (3~5)，不同量纲的特征会导致在梯度下降时”步伐“ (<span class="math inline">\(\alpha dw\)</span>) 不同，学习率太小收敛慢，学习率太大，有些特征(例如房间大小)的权值甚至可能不会收敛；在使用 Sigmoid 或者 Tanh 作为激活函数时也容易出现饱和现象。(详情参考：<a href="https://www.robertoreif.com/blog/2017/12/21/importance-of-feature-scaling-in-data-modeling-part-2" target="_blank" rel="noopener">Importance of Feature Scaling in Data Modeling (Part 2)</a>)</p>
<p>归一化有不同的策略，常用的归一化方法有以下几种：</p>
<ul>
<li>Mean Normalization</li>
</ul>
<p><span class="math display">\[
X&#39;=\frac{X-mean(X)}{S}
\]</span></p>
<p>Mean Normalization减去均值将数据中心化 (0 均值化)，再除以 <span class="math inline">\(S\)</span> 进行缩放。<span class="math inline">\(S\)</span> 可以取 <span class="math inline">\(max(X)-min(X)\)</span>，或者取标准差 <span class="math inline">\(std(X)\)</span>，这时也叫做 Z-score 归一化或者标准化 (Standardization)。使用 <code>sklearn</code> 实现标准化如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scaler = sklearn.preprocessing.StandardScaler().fit(x_train)</span><br><span class="line">x_train = scaler.transform(x_train)</span><br><span class="line">x_test = scaler.transform(x_test)</span><br></pre></td></tr></table></figure>
<p>或者可以直接对数据集使用 <code>x_train = preprocessing.scale(X_train)</code> 进行缩放，使用 <code>StandardScaler</code> 类是为了让测试集和训练集进行同样的缩放，缩放后的数据具有零均值和标准方差。</p>
<ul>
<li>Min-max Normalization</li>
</ul>
<p><span class="math display">\[
X&#39;=\frac{X-min(X)}{max(X)-min(X)}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scaler = preprocessing.MinMaxScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br></pre></td></tr></table></figure>
<p>数据经过 Min-max Normalization 会被缩放到 <code>[0, 1]</code>。使用标准化还是 Min-max 归一化？这个问题没有标准答案，需要具体问题具体分析，<strong>通常情况下使用标准化较多</strong>。数据存在较多异常值也考虑使用标准化；Min-max 常用于归一化图像的灰度值。决策树则不需要特征缩放！吴恩达给的建议是反正使用标准化也没有坏处，就都用上。</p>
<h2 id="归一化">归一化</h2>
<p>在 <code>sklearn</code> 中特征缩放都被称为标准化(Standardizatoin)，Z-score 也被称为去均值和方差按比例缩放，其他的都是将特征缩放到给定的最小值和最大值之间(Rescaling，按比例缩放)。而归一化指的是缩放单个样本以具有单位范数的过程，在量化任何样本间的相似度时非常有用。</p>
<p>使用以下代码可以将单个样本的一范数或者二范数归一化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preprocessing.normalize(X, norm=<span class="string">'l1'</span>)</span><br><span class="line">preprocessing.normalize(X, norm=<span class="string">'l2'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li><a href="https://www.quora.com/Why-does-mean-normalization-help-in-gradient-descent3" target="_blank" rel="noopener">Why does mean normalization help in gradient descent?</a></li>
<li><a href="https://www.robertoreif.com/blog/2017/12/16/importance-of-feature-scaling-in-data-modeling-part-1-h8nla" target="_blank" rel="noopener">Importance of Feature Scaling in Data Modeling (Part 1)</a></li>
<li><a href="https://www.robertoreif.com/blog/2017/12/21/importance-of-feature-scaling-in-data-modeling-part-2" target="_blank" rel="noopener">Importance of Feature Scaling in Data Modeling (Part 2)</a></li>
<li><a href="http://sklearn.apachecn.org/cn/0.19.0/modules/preprocessing.html" target="_blank" rel="noopener">Sklearn Preprocessing data</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度检验</title>
    <url>/2018/05/31/gradient-checking/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>神经网络反向传播计算各个参数的梯度，用于梯度下降更新参数。用链式法则求解各个参数的导数的过程中，梯度的计算很复杂，容易出错，而梯度检验可以帮助我们确保梯度的计算正确。</p>
<a id="more"></a>
<h2 id="数值微分">数值微分</h2>
<p>在反向传播中，链式法则需要人工推导，非常耗时且容易出错。梯度检验的原理是使用<a href="https://zh.wikipedia.org/zh/%E6%95%B8%E5%80%BC%E5%BE%AE%E5%88%86" target="_blank" rel="noopener">数值微分</a>来估计函数的导数，然后拿估计的值和真实值相比，如果数值微分和导数相差太大，则表示导数(梯度)计算错误。在数值上计算 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(x=x_0\)</span> 处的导数，可以由导数的定义 <span class="math display">\[
f&#39;(x_0) = \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}
\]</span> 得到。对于充分小的 <span class="math inline">\(h\)</span> 有 <span class="math display">\[
f&#39;(x_0) \approx \frac{f(x_0 + h) - f(x_0)}{h}
\]</span> 这就是向前差分公式，公式右边就是 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(x_0\)</span> 处的步长为 <span class="math inline">\(h\)</span> 的数值微分。通过 Taylor 展开也能构造出数值微分，而且能求出其截断误差。对称差分的一次项误差相消，对于很小的 <span class="math inline">\(h\)</span> 而言这个值比单边近似还要准确。例如求 <span class="math inline">\(f(x)=x^2\)</span> 在 <span class="math inline">\(x=3\)</span> 处的导数与数值微分：</p>
<ul>
<li>导数：<span class="math inline">\(f&#39;(3)=2\times 3=6\)</span></li>
<li>向前差分：<span class="math inline">\(\frac{(3+0.01)^2−3^2}{0.01}=6.1\)</span></li>
<li>对称差分：<span class="math inline">\(\frac{(3+0.01)^2−(3-0.01)^2}{0.02}=6.045\)</span></li>
</ul>
<h2 id="梯度检验">梯度检验</h2>
<p>代价函数关于参数的梯度的定义: <span class="math display">\[
\frac{\partial J}{\partial \boldsymbol{w}\_i} = \lim_{\varepsilon \to 0} \frac{J(\boldsymbol{w}\_i + \varepsilon) - J(\boldsymbol{w}\_i - \varepsilon)}{2 \varepsilon}
\]</span> 我们想要确保 <span class="math inline">\(\frac{\partial J}{\partial \boldsymbol{w}_i}\)</span> 的计算是正确的，只需要取 <span class="math inline">\(\varepsilon\)</span> 为一个很小的数(例如 <span class="math inline">\(10^{-7}\)</span>)，然后计算 <span class="math inline">\(\frac{J(\boldsymbol{w}_i + \varepsilon) - J(\boldsymbol{w}_i - \varepsilon)}{2 \varepsilon}\)</span> 是否约等于 <span class="math inline">\(\frac{\partial J}{\partial \boldsymbol{w}_i}\)</span>，实际操作中判断两个参数<strong>向量</strong>的欧氏距离是否足够小。</p>
<p>对于每个参数 <span class="math inline">\(\boldsymbol{w}_i\)</span>：</p>
<ul>
<li>使用前向传播计算代价函数 <span class="math inline">\(J(\boldsymbol{w}_i + \varepsilon)\)</span></li>
<li>使用前向传播计算代价函数 <span class="math inline">\(J(\boldsymbol{w}_i - \varepsilon)\)</span></li>
<li>计算梯度的近似值(数值微分) $ gradapprox[i]=$</li>
<li>使用链式法则计算反向传播梯度，缓存到变量 <span class="math inline">\(grad\)</span> 中</li>
</ul>
<p>使用以下公式计算梯度 <span class="math inline">\(grad\)</span> 和梯度的近似值 <span class="math inline">\(gradapprox\)</span> 的欧氏距离： <span class="math display">\[
difference = \frac {\mid\mid grad - gradapprox \mid\mid_2}{\mid\mid grad \mid\mid_2 + \mid\mid gradapprox \mid\mid_2}
\]</span> 如果欧氏距离 <span class="math inline">\(difference\)</span> 小于 <span class="math inline">\(10^{-7}\)</span> 则表示反向传播梯度计算正确，否则就值得注意了，因为很有可能反向传播的时候梯度计算有误。由于梯度检验比较耗时，所以一般只用于调试，检验正确后关闭梯度检验，而且梯度检验不能与 Dropout 同时使用，因为每次迭代过程中 Dropout 会使神经元结点随机失活，难以计算 Dropout 在梯度下降上的代价函数 <span class="math inline">\(J\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_check_n</span><span class="params">(parameters, gradients, X, Y, epsilon=<span class="number">1e-7</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Set-up variables</span></span><br><span class="line">    parameters_values, _ = dictionary_to_vector(parameters)</span><br><span class="line">    grad = gradients_to_vector(gradients)</span><br><span class="line">    num_parameters = parameters_values.shape[<span class="number">0</span>]</span><br><span class="line">    J_plus = np.zeros((num_parameters, <span class="number">1</span>))</span><br><span class="line">    J_minus = np.zeros((num_parameters, <span class="number">1</span>))</span><br><span class="line">    gradapprox = np.zeros((num_parameters, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute gradapprox</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_parameters):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute J_plus[i]. Inputs: "parameters_values, epsilon". Output = "J_plus[i]".</span></span><br><span class="line">        thetaplus =  np.copy(parameters_values)                                       <span class="comment"># Step 1</span></span><br><span class="line">        thetaplus[i][<span class="number">0</span>] = thetaplus[i][<span class="number">0</span>] + epsilon                                   <span class="comment"># Step 2</span></span><br><span class="line">        J_plus[i], _ =  forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))  <span class="comment"># Step 3</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute J_minus[i]. Inputs: "parameters_values, epsilon". Output = "J_minus[i]".</span></span><br><span class="line">        thetaminus = np.copy(parameters_values)                                       <span class="comment"># Step 1</span></span><br><span class="line">        thetaminus[i][<span class="number">0</span>] = thetaminus[i][<span class="number">0</span>] - epsilon                                 <span class="comment"># Step 2        </span></span><br><span class="line">        J_minus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus)) <span class="comment"># Step 3</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute gradapprox[i]</span></span><br><span class="line">        gradapprox[i] = (J_plus[i] - J_minus[i]) / (<span class="number">2</span> * epsilon)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compare gradapprox to backward propagation gradients by computing difference.</span></span><br><span class="line">    numerator = np.linalg.norm(grad - gradapprox)                                     <span class="comment"># Step 1'</span></span><br><span class="line">    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   <span class="comment"># Step 2'</span></span><br><span class="line">    difference = numerator / denominator                                              <span class="comment"># Step 3'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> difference &gt; <span class="number">1e-7</span>:</span><br><span class="line">        print(<span class="string">"\033[93m"</span> + <span class="string">"There is a mistake in the backward propagation! difference = "</span> + str(difference) + <span class="string">"\033[0m"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"\033[92m"</span> + <span class="string">"Your backward propagation works perfectly fine! difference = "</span> + str(difference) + <span class="string">"\033[0m"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> difference</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>关治, 陆金甫. 数值方法. 清华大学出版社. 2017.</li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 基础总结</title>
    <url>/2019/04/08/java-basis/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>五月份就该去实习了，趁着这一个多月无所事事，正好学着刷一下 LeetCode。一直以来算法相关内容都是弱点，本科的《数据结构与算法》学得也不是很好。大三暑假为了保研曾经刷过一段时间 poj，不太会总结，纯粹就是瞎刷。由于没有什么方向保研后就又放弃了，最近在慕课网上找了一套视频学习，发现效果很好。</p>
<a id="more"></a>
<p>视频链接：<a href="https://coding.imooc.com/class/82.html" target="_blank" rel="noopener">玩转算法面试</a>，刚刷完数组、查找表和链表，就在阿里巴巴的实习面试中排上用场了。由于 LeetCode 题目太多，无法每道题都写一篇博客，视频中推荐的题目就直接丢 <a href="https://github.com/pengzhendong/LeetCode" target="_blank" rel="noopener">Github</a> 了。在刷题过程中对 Java 的传值有些疑惑，顺便记录一下。</p>
<h2 id="基础类型">基础类型</h2>
<p>Java 一共有八种基础类型：<code>byte</code>/8、<code>char</code>/16、<code>short</code>/16、<code>int</code>/32、<code>float</code>/32、<code>long</code>/64、<code>double</code>/64 和 boolean/~。前七种类型的占用的<strong>位数</strong>明确给出，而 boolean 类型没有给出精确的定义，因为其在编译之后都使用 int 数据类型来代替，而 boolean 数组将会被编码成 byte 数组，因此 boolean 单独使用占 32 位，在数组中占 8 位。</p>
<p>Java 的八种基础类型对应八种包裹类型：<code>Byte</code>、 <code>Character</code>、<code>Short</code>、<code>Integer</code>、<code>Float</code>、<code>Long</code>、 <code>Double</code> 和 <code>Boolean</code>。这些包裹类型内部有一个对应类型的变量 <code>value</code> 用于保存数值。包裹类型会自动拆箱和装箱，即在计算数值时包裹类型会自动拆箱转为基础类型进行计算，当基础类型传入包裹类型时，又会自动包装成包裹类型。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer num = <span class="number">1</span>;     <span class="comment">// 装箱</span></span><br><span class="line"><span class="keyword">int</span> x = num;         <span class="comment">// 拆箱</span></span><br></pre></td></tr></table></figure>
<h2 id="存储区域">存储区域</h2>
<p>Java 有六大存储区域：</p>
<ul>
<li><p>寄存器：在处理器内部而不是内存中，速度最快，但是在 Java 中无法直接控制，也感受不到。</p></li>
<li><p>栈：存放八种基本类型、数组的引用和对象的引用（即数组和对象在堆内存中的首地址）。当在一段代码块定义一个变量时，就在栈中为这个变量分配内存空间，当该变量退出该作用域后，会自动释放掉为该变量所分配的内存空间。</p></li>
<li><p>堆：存放由 <code>new</code> 创建的数组和对象。在堆中产生了一个数组或对象后，在栈中定义一个特殊的变量，让栈中这个变量的取值等于数组或对象在堆内存中的首地址，栈中的这个变量就成了数组或对象的引用变量。引用变量就相当于是为数组或对象起的一个名称，以后就可以在程序中使用栈中的引用变量来访问堆中的数组或对象。<code>new</code> 一个数组则会返回其在堆中的首地址，将其赋值给栈中的变量 <code>nums</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span>[] nums = <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;<span class="number">1</span>, <span class="number">2</span>&#125;;</span><br></pre></td></tr></table></figure></li>
<li><p>静态存储区：又叫方法区，顾名思义包含的是 <code>static</code> 修饰的静态变量，即程序运行时一直存在的数据。</p></li>
<li><p>常量存储区：<code>static final</code> 修饰的常量值通常直接存放在程序代码内部，即在编译时被确定，并被保存在已编译的 .class 文件中的一些数据。</p></li>
<li><p>非 RAM 存储区：硬盘等。</p></li>
</ul>
<h2 id="缓存池">缓存池</h2>
<p>包裹类型的 value 被声明为 <code>final</code>，表示 value 初始化后无法重新赋值，即包裹类型内部没有改变 value 的方法。因此在自增等操作的时候，变量会指向新的对象：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer num = <span class="number">1</span>;</span><br><span class="line">num += <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>以上代码会被编译成：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer localInteger = Integer.valueOf(<span class="number">1</span>);</span><br><span class="line">localInteger = Integer.valueOf(localInteger.intValue() + <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>即会取出 num 的值加一，然后再返回一个新的对象。可是 <code>Integer.valueOf()</code> 和 <code>new Integer()</code> 有什么关系呢？通过查看其源代码可知：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Integer <span class="title">valueOf</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)</span><br><span class="line">        <span class="keyword">return</span> IntegerCache.cache[i + (-IntegerCache.low)];</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Integer(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原来除了 <code>Float</code> 和 <code>Double</code>，Java 为其他包裹类型提供了缓存池。 <code>Integer</code> 内部维护了一个 <code>IntegerCache</code> 静态类，这个类又维护了一个 <code>static final Integer</code> 数组（默认范围为：[-128, 127]，可配置），如果缓存池中有这个值对于的对象则直接返回，否则 <code>new</code> 一个返回（不会加入缓存池）。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer num1 = Integer.valueOf(<span class="number">1</span>);</span><br><span class="line">Integer num2 = <span class="keyword">new</span> Integer(<span class="number">1</span>);</span><br><span class="line">Integer num3 = Integer.valueOf(<span class="number">128</span>);</span><br></pre></td></tr></table></figure>
<p>如果通过反射机制修改对象的 value，那么指向这个对象的其它变量也会改变。下面代码中初始化了两个变量，编译后它们会通过 <code>valueOf()</code> 去缓存池中获取对应的对象，通过反射机制修改了 value 的值，缓存池中对象的值也会改变，最后导致 val 的值改变：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Integer num = <span class="number">1</span>;</span><br><span class="line">        Integer val = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = Integer.class.getDeclaredField(<span class="string">"value"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            field.set(num, <span class="number">2</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其他类型对应的缓冲池如下：</p>
<ul>
<li>Boolean: true &amp; false</li>
<li>Byte: 所有 byte 值</li>
<li>Short: [-128, 127]</li>
<li>Character: [, ]</li>
</ul>
<h2 id="string">String</h2>
<p>除了上述类型，<code>String</code> 类型也被声明为 <code>final</code>，因此它也不可继承。在 Java 8 中，<code>String</code> 内部使用 <code>char</code> 存储数据，在 Java 9 之后则改用 <code>byte</code> 数组，同时使用变量 <code>coder</code> 来标记使用了哪种编码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span>, <span class="title">Comparable</span>&lt;<span class="title">String</span>&gt;, <span class="title">CharSequence</span> </span>&#123;</span><br><span class="line">    <span class="comment">/** The value is used for character storage. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] value;</span><br><span class="line">    <span class="comment">/** The identifier of the encoding used to encode the bytes in &#123;<span class="doctag">@code</span> value&#125;. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span> coder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>value 被声明为 <code>final</code>，因此 value 数组初始化以后就不能再指向其他数组，即 <code>String</code> 类的内部没有改变 value 数组的方法。同样可以使用反射机制修改 <code>String</code> 的值，需要注意的是，当调用 <code>hashCode()</code> 一次以后就会保存哈希值，再次调用则不会重新计算：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h = hash;</span><br><span class="line">    <span class="keyword">if</span> (h == <span class="number">0</span> &amp;&amp; value.lenght &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        hash = h = isLatin1() ? StringLatin1.hashCode(value)</span><br><span class="line">        					  : StringUTF16.hashCode(value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面代码中 <code>addressOf(Object o)</code> 会将对象的引用转化成一个长整型地址；在主函数中定义了一个字符串 "Hello"，输出其地址和哈希值，用反射机制修改其内容为 "World" 后再次输出地址和哈希值：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"><span class="keyword">import</span> sun.misc.Unsafe;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Unsafe unsafe;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = Unsafe.class.getDeclaredField(<span class="string">"theUnsafe"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            unsafe = (Unsafe) field.get(<span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">addressOf</span><span class="params">(Object o)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Object[] array = <span class="keyword">new</span> Object[] &#123; o &#125;;</span><br><span class="line">        <span class="keyword">long</span> baseOffset = unsafe.arrayBaseOffset(Object[].class);</span><br><span class="line">        <span class="keyword">int</span> addressSize = unsafe.addressSize();</span><br><span class="line">        <span class="keyword">long</span> objectAddress;</span><br><span class="line">        <span class="keyword">switch</span> (addressSize) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">4</span>:</span><br><span class="line">                objectAddress = unsafe.getInt(array, baseOffset);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">8</span>:</span><br><span class="line">                objectAddress = unsafe.getLong(array, baseOffset);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">"Unsupported address size: "</span> + addressSize);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (objectAddress);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String str = <span class="string">"Hello"</span>;</span><br><span class="line">        System.out.println(<span class="string">"Address: "</span> + addressOf(str) + <span class="string">" Value: "</span> + str + <span class="string">" HashCode: "</span> + str.hashCode());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = String.class.getDeclaredField(<span class="string">"value"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            field.set(str, <span class="string">"World"</span>.getBytes());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"Address: "</span> + addressOf(str) + <span class="string">" Value: "</span> + str + <span class="string">" HashCode: "</span> + str.hashCode());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终输出结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Address: 2353254184 Value: Hello HashCode: 69609650</span><br><span class="line">Address: 2353254184 Value: World HashCode: 69609650</span><br></pre></td></tr></table></figure>
<p>可以看到只有字符串内容发生改变，而地址和哈希值都有发生变化。大部分情况下都是根据哈希值来识别一个字符串，所以反射修改字符串内容属于非常危险的操作！</p>
<h3 id="string-常量池">String 常量池</h3>
<p>String 常量池保存着所有字符串字面量 (literal strings)，即在编译时期就确定的字面量，还可以使用 <code>intern()</code> 方法将字符串添加到常量池中。</p>
<blockquote>
<p>When the intern method is invoked, if the pool already contains a string equal to this {<span class="citation" data-cites="code">@code</span> String} object as determined by the {<span class="citation" data-cites="link">@link</span> #equals(Object)} method, then the string from the pool is returned. Otherwise, this {<span class="citation" data-cites="code">@code</span> String} is added to the pool and a reference to this {<span class="citation" data-cites="code">@code</span> String} object is returned.</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str1 = <span class="string">"Hello"</span>;			<span class="comment">// 字面量赋值，"Hello" 为字面量</span></span><br><span class="line">String str2 = <span class="string">"Hel"</span> + <span class="string">"lo"</span>;		<span class="comment">// 在编译阶段优化成 String str2 = "Hello";</span></span><br><span class="line">String str3 = <span class="keyword">new</span> String(<span class="string">"World"</span>);	<span class="comment">// new 创建对象，"World" 为字面量</span></span><br><span class="line">String str4 = str2.intern();		<span class="comment">// 将 str2 的内容加入常量池，并且返回其在常量池中的引用</span></span><br></pre></td></tr></table></figure>
<p>在类加载阶段会将所有字面量加入常量池，即常量池中有 "Hello" 和 "World"。编译阶段 "Hel" + "lo" 会被优化成 "Hello"，因此 str1 和 str2 指向常量池中同一个字符串；str3 会根据字面量 "World" 的内容在堆中重新创建一个对象，<code>String</code> 的构造函数如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(String original)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.val = original.value;</span><br><span class="line">    <span class="keyword">this</span>.hash = original.hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>虽然在堆中重新构造了一个对象，但是并没有复制 value 数组的内容，而是指向同一个 <code>byte</code> 数组；将 str3 的内容加入常量池，常量池中有 "World"，所以直接返回其在常量池中的引用给 str4。</p>
<h2 id="传值">传值</h2>
<p>Java 与 C/C++ 最大的不同就是 Java 无法操作指针，上面的 <code>addressOf(Object o)</code> 函数也只能将一个对象的地址转化成长整型地址，并不能获取基本类型的地址。因此 Java Pass By Value，即传的都是值，只不过这个值有可能是对象的引用。</p>
<h3 id="基础类型-1">基础类型</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">changeInt</span><span class="params">(<span class="keyword">int</span> value)</span> </span>&#123; value += <span class="number">1</span>; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line">    changInt(num);</span><br><span class="line">    System.out.println(num);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用 <code>changeInt()</code> 的时候会将参数 num 拷贝一份，因此不会影响主函数中的 num 变量，即为值传递。</p>
<h3 id="包裹类型-string">包裹类型 &amp; String</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">changeStr</span><span class="params">(String value)</span> </span>&#123; value += <span class="string">"World"</span>; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String str = <span class="string">"Hello"</span>;</span><br><span class="line">    changStr(str);</span><br><span class="line">    System.out.println(str);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用 <code>changeStr()</code> 的时候会将参数 str （即常量池中 "Hello" 的地址）拷贝一份，因此 value 变量和 str 变量同样指向常量池中的 "Hello"。由于 <code>String</code> 不可变，对字符串进行拼接不会对原有字符串产生变动，而是直接生成一个新的字符串 "HelloWorld"，返回其地址给 value 变量。因此不会影响主函数中的 str 变量，所以也是值传递。</p>
<h3 id="容器类型">容器类型</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">changeList</span><span class="params">(List&lt;Integer&gt; value)</span> </span>&#123; value.add(<span class="number">1</span>); &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    List&lt;Integer&gt; list = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    changeList(list);</span><br><span class="line">    System.out.println(str);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用 <code>changeList()</code> 的时候会将参数 list （即堆中新建的 <code>LinkedList</code> 的地址）拷贝一份，因此 value 变量和 list 变量同样指向堆中的 <code>LinkedList</code>。因此在 <code>changeList()</code> 函数中对 value 的操作会影响主函数中的 list 变量，所以虽然是值传递（传的是 <code>LinkedList</code> 的地址），也可以认为传递的是引用。</p>
]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 中 Json 数组和 Json 对象文件的读取</title>
    <url>/2016/01/15/java-json/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>一个学期的学习终于落下帷幕。离家一年，归期将至反倒觉得乡近情更怯，这一年真的成长了很多，虽然能力还不够强大，但我坚信那是迟早的事。这一年里我收获了爱情，爱情的酸甜苦辣真的让人流连忘返，刚刚结束小学期课设的答辩，由于回宿舍无所事事，留下来写一篇博客倒也快哉~</p>
<p><i class="fa fa-map-marker fa-lg"></i> 记于 北京工业大学 软件学院 518</p>
<p>二零一六年一月十五日</p>
<hr>
<a id="more"></a>
<h2 id="下载-json-的包">下载 JSON 的包</h2>
<p>到 JSON 的<a href="http://www.json.org/json-zh.html" target="_blank" rel="noopener">官网</a>中下载对应的包文件，JSON 的 jar 包是一个beans, collections, maps, java arrays, XML 和 JSON 互相转换的包，主要就是用来解析Json数据。</p>
<h2 id="json-语法">Json 语法</h2>
<p>JSON 语法是 JavaScript 对象表示法语法的子集。</p>
<ul>
<li>数据在名称/值对中</li>
<li>数据由逗号分隔</li>
<li>花括号保存对象</li>
<li>方括号保存数组</li>
</ul>
<h2 id="读取文件">读取文件</h2>
<p>首先要将文件中的内容读取出来，即一个字符串。说白了，一个 JSON 文件存储的就是一个比较长的字符串，只不过这个字符串的格式比较特殊，我们能过通过 JSON 的包将其转换成我们所需要的格式。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadFile</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取文件,返回文件内容</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> path</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">ReadFile</span><span class="params">(String path)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        File file = <span class="keyword">new</span> File(path);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(!file.exists()||file.isDirectory()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            InputStreamReader read = <span class="keyword">new</span> InputStreamReader(<span class="keyword">new</span> FileInputStream(file),<span class="string">"UTF-8"</span>);</span><br><span class="line">            BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(read);</span><br><span class="line">            String lineTxt = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span> ((lineTxt = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                sb.append(lineTxt);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>ReadFile</strong> 的<code>ReadFile</code>静态方法需要提供一个文件的路径的参数，然后读取文件，返回一个字符串，即文件的内容。</p>
<h2 id="json-数组">Json 数组</h2>
<h3 id="简单的数组">简单的数组</h3>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  <span class="string">"pengzhendong"</span>,</span><br><span class="line">  <span class="string">"randy"</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JSONArray items = JSONArray.fromObject(result);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; items.size(); i++) &#123;</span><br><span class="line">    name = items.getString(i);</span><br><span class="line">    System.out.println(name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码将会遍历数组，输出数组中内容。</p>
<h3 id="对象数组">对象数组</h3>
<p>如果数组中的内容是对象的形式，则应该根据根据 key 获取属性值。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123; <span class="attr">"firstName"</span>:<span class="string">"Bill"</span> , <span class="attr">"lastName"</span>:<span class="string">"Gates"</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">"firstName"</span>:<span class="string">"George"</span> , <span class="attr">"lastName"</span>:<span class="string">"Bush"</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">"firstName"</span>:<span class="string">"Thomas"</span> , <span class="attr">"lastName"</span>: <span class="string">"Carter"</span> &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JSONArray items = JSONArray.fromObject(result);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; items.size(); i++) &#123;</span><br><span class="line"></span><br><span class="line">    firstName = items.getJSONObject(i).getString(<span class="string">"firstName"</span>);</span><br><span class="line">    lastName = items.getJSONObject(i).getString(<span class="string">"lastName"</span>);</span><br><span class="line">    System.out.println(firstName + <span class="string">" "</span> +lastName);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码将获取数组的长度，遍历 JSON 数组中的对象，根据 key 打印里面对象中的属性。</p>
<h2 id="json-对象">Json 对象</h2>
<h3 id="简单的对象">简单的对象</h3>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span>: <span class="string">"pengzhendong"</span>,</span><br><span class="line">  <span class="attr">"phone"</span>: <span class="number">110</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JSONObject objs = JSONObject.fromObject(result);</span><br><span class="line">Iterator iterator = objs.keys();</span><br><span class="line">String key = <span class="string">""</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">    key = (String) iterator.next();</span><br><span class="line">    result = objs.getString(key);</span><br><span class="line"></span><br><span class="line">    System.out.println(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码将会通过迭代查找 key，然后通过 key 获取 value。</p>
<h3 id="对象数组-1">对象数组</h3>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"id"</span>: <span class="string">"0001"</span>,</span><br><span class="line">  <span class="attr">"project"</span>: [</span><br><span class="line">    <span class="string">"math"</span>,</span><br><span class="line">    <span class="string">"english"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JSONObject obj = JSONObject.fromObject(result);</span><br><span class="line"></span><br><span class="line">JSONArray projects = JSONArray.fromObject(obj.getString(<span class="string">"project"</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; projects.size(); i++) &#123;</span><br><span class="line">    String project = projects.getString(i);</span><br><span class="line">    </span><br><span class="line">    System.out.println(project);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外还有各种嵌套的形式，总之只要学会简单的数组和对象形式的，然后根据具体的文件格式具体分析就差不多能解决问题了。</p>
]]></content>
      <tags>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript 中的函数式编程</title>
    <url>/2016/05/09/javascript-fp/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>之前接触过一些 Python，最近又频繁使用了 JavaScript，这两门语言都支持函数式编程，大学接触的几乎都是命令式编程，宣扬面向对象的思想，而函数式编程的思想更接近数学计算。</p>
<a id="more"></a>
<h2 id="函数式编程functional-programming">函数式编程(Functional Programming)</h2>
<p>在函数式编程语言中，函数是第一类的对象，不依赖于任何其他的对象而可以独立存在。可以将函数作为参数、返回值或者一个普通的变量等。</p>
<h2 id="作用域">作用域</h2>
<p>JavaScript 中没有像其他强类型语言中的模块作用域：</p>
<p>Java：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">	System.out.println(<span class="string">"hello zander"</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(i);</span><br></pre></td></tr></table></figure>
<p>因为在 <code>for</code> 循环中定义的 i ，而外部并没有定义，所以会报错</p>
<p>JavaScript：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">"hello zander"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">console</span>.log(i);</span><br></pre></td></tr></table></figure>
<p>上述代码不仅没有报错而且成功打印了 i 的值，这样给我们带来的麻烦比较多，当我们一个团队在开发大型项目时，不断累加的变量和方法，最后很容易出现各种冲突，所以私有变量对我们非常重要。如果想使用私有变量就可以使用匿名函数。</p>
<h2 id="匿名函数">匿名函数</h2>
<p>在函数式编程语言中，函数是可以没有名字的，因为我们有时需要用函数完成某件事，但是这个函数可能只是临时性的，那就没有理由专门为其生成一个顶层的函数对象。</p>
<h3 id="函数定义">函数定义</h3>
<p>在 JavaScript 定义一个函数有三种方式：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo</span>(<span class="params">name</span>) </span>&#123;</span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">"hello "</span> + name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> foo = <span class="function"><span class="keyword">function</span>(<span class="params">name</span>) </span>&#123;</span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">"hello "</span> + name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> foo = <span class="keyword">new</span> <span class="built_in">Function</span>(<span class="string">'name'</span>, <span class="string">'console.log("hello " + name);'</span>);</span><br></pre></td></tr></table></figure>
<p>后面两种方式都是定义了一个匿名函数，然后将匿名函数赋值给 <code>foo</code> 变量</p>
<h3 id="函数调用">函数调用</h3>
<ul>
<li>申明一个函数然后执行</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params">name</span>) </span>&#123; </span><br><span class="line">	<span class="keyword">var</span> i = <span class="number">10</span>;</span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">"hello "</span> + name); </span><br><span class="line">&#125;)(<span class="string">'zander'</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>优先表达式，用圆括号强制执行申明的函数</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params">name</span>) </span>&#123; </span><br><span class="line">	<span class="keyword">var</span> i = <span class="number">10</span>;</span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">"hello "</span> + name); </span><br><span class="line">&#125;(<span class="string">'zander'</span>));</span><br></pre></td></tr></table></figure>
<ul>
<li><code>void</code> 操作符</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="function"><span class="keyword">function</span>(<span class="params">name</span>) </span>&#123; </span><br><span class="line">	<span class="keyword">var</span> i = <span class="number">10</span>;</span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">"hello "</span> + name); </span><br><span class="line">&#125;(<span class="string">'zander'</span>);</span><br></pre></td></tr></table></figure>
<p>这时候如果再在函数外部访问函数内部的局部变量的话就会提示变量未定义</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">console</span>.log(i);</span><br></pre></td></tr></table></figure>
<p>函数内部声明的变量，只在函数内部起作用，而且当匿名函数执行结束时，其内部定义的任何变量都会被系统销毁。这样就模拟了块级作用域，可以避免数据污染和避免内存长驻。</p>
<blockquote>
<p>变量声明是如果不使用 var 关键字，那么它就是一个全局变量，即便它在函数内定义。</p>
</blockquote>
<h2 id="闭包">闭包</h2>
<blockquote>
<p>一个拥有许多变量和绑定了这些变量的环境的表达式（通常是一个函数），因而这些变量也是该表达式的一部分。</p>
</blockquote>
<p>一开始看这些官方的解释我也是整个人都懵<del>逼</del>了，但是通过动手实践，理解闭包的作用之后就差不多能理解了。</p>
<p>闭包通常用来创建内部变量，使得这些变量不能被外部随意修改，同时又可以通过指定的函数接口来操作，就像面向对象中的 <code>getter</code> 和 <code>setter</code>。</p>
<p>如果我们希望</p>
<ul>
<li>一个变量在内存中长驻</li>
<li>避免全局变量的污染</li>
<li>变量作为私有变量的存在</li>
</ul>
<p>那么就可以使用闭包</p>
<p>就像上一个例子中的局部变量 <code>i</code> ，我想记住它的值(在内存中长驻)，并且作为一个私有变量(只能通过 get 方法获取)，但是我又不想将它作为一个全局变量(避免全局变量的污染)，这时候就可以使用闭包：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">	<span class="comment">//i j 分别作为私有变量存在</span></span><br><span class="line">	<span class="keyword">var</span> i = <span class="number">10</span>;</span><br><span class="line">	<span class="keyword">var</span> j = <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">function</span> <span class="title">getI</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">		i++;            <span class="comment">//set</span></span><br><span class="line">		<span class="built_in">console</span>.log(i); <span class="comment">//get</span></span><br><span class="line">	&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">function</span> <span class="title">getJ</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">		j++;</span><br><span class="line">		<span class="built_in">console</span>.log(j);</span><br><span class="line">	&#125;;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">//闭包</span></span><br><span class="line">	<span class="keyword">return</span> &#123;</span><br><span class="line">		getI: getI,</span><br><span class="line">		getJ: getJ, </span><br><span class="line">	&#125;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> fun = foo();</span><br><span class="line">fun.getI(); <span class="comment">//第一次调用，运行结果 11</span></span><br><span class="line">fun.getI(); <span class="comment">//第二次调用，运行结果 12</span></span><br></pre></td></tr></table></figure>
<p>或许你有个迷惑，为什么不能直接返回这个值而是要返回一个函数？因为这样的话每次就都会对这个局部变量 i 进行初始化，不能记住 i 的值。</p>
<h3 id="缺点">缺点：</h3>
<p>闭包有一个非常严重的问题，那就是内存浪费问题，这个内存浪费不仅仅因为它常驻内存，更重要的是，对闭包的使用不当会造成无效内存的产生。</p>
<h2 id="柯里化currying">柯里化(Currying)</h2>
<blockquote>
<p>又称部分求值(Partial Evaluation)，把接受多个参数的函数变换成接受一个单一参数(最初函数的第一个参数)的函数，并且返回新函数来接受余下的参数而且返回结果。</p>
</blockquote>
<p>就像在一个多元方程中，逐步消元最终得到结果，例如下面的加法求 <code>foo(x, y) = x^2 + y^2</code> ，第一步将 x = 8 代入得到 <code>foo(y) = 64 + y^2</code> 然后代入 y = 6，最终得到结果为100</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> foo = <span class="function"><span class="keyword">function</span>(<span class="params">x</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params">y</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(x + y);</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> tem = foo(<span class="number">8</span>); <span class="comment">//tem = function(y) &#123; 64 + y^2; &#125;</span></span><br><span class="line">tem(<span class="number">6</span>); <span class="comment">//还可以继续调用 tem 函数求 64 + y^2</span></span><br><span class="line"><span class="comment">//或者</span></span><br><span class="line">foo(<span class="number">8</span>)(<span class="number">6</span>);</span><br></pre></td></tr></table></figure>
<p>现在对柯里化的感受就是能够使代码模块化，减少耦合增强其可维护性，例如像上面例子中，我后面要求很多 <code>64 + y^2</code> 的值(即第一个参数一样)，这时候就能够提高代码的适用性：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">tem(<span class="number">3</span>); <span class="comment">// 64 + 9</span></span><br><span class="line">tem(<span class="number">4</span>); <span class="comment">// 64 + 16</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title>用 LSTM 网络创作爵士独奏</title>
    <url>/2018/08/28/jazz-with-an-lstm-network/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>终于把论文投出去了，虽然中的概率很渺茫，但是我肖的态度确实好了不少。终于又可以闲下来好好学学深度学习了，论文的实验过程中用了 LSTM Autoencoder，正好趁着这个机会再强化一下。在上篇学习笔记中，由于恐龙名字不会很长，所以在生成恐龙名字的作业中使用 RNN 已经可以满足任务要求。本次作业是创作爵士独奏，普通 RNN 无法解决长期依赖问题，所以使用了 LSTM。</p>
<a id="more"></a>
<h2 id="数据集">数据集</h2>
<p>数据集是一首长达约8分钟的爵士音乐，下面是其中的一个小片段：</p>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/30s_seq.mp3" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<p>在这次实验中不用考虑和弦，只需要在数据集上训练出一个 RNN 模型，然后用来生成新的序列。首先加载数据 <code>data/original_metheny.mid</code>，然后将它处理成以下形状，每三十个值作为一个序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X, Y, n_values, indices_values = load_music_utils()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>训练样本的个数 <span class="math inline">\(m\)</span>: 60</p></li>
<li><p>序列的长度 <span class="math inline">\(T_x\)</span>: 30</p></li>
<li><p>不同的值的总数(独热向量的维度): 78</p></li>
<li><p>X 的形状: <span class="math inline">\((m, T_x, 78)\)</span></p></li>
<li><p>Y 的形状: <span class="math inline">\((T_x, m, 78)\)</span></p></li>
</ul>
<p>Y 实质上和 X 相同，只不过是偏移了一步。在训练过程中，给定序列 <span class="math inline">\(x^{\langle 1\rangle}, \ldots, x^{\langle t \rangle}\)</span>，模型则预测 <span class="math inline">\(y^{\langle t \rangle}\)</span>。在 RNN 中，数据的形状分为两种：time major <code>[max_time, batch_size, depth]</code> 和 batch major <code>[batch_size, max_time, depth]</code>。使用 <code>time_major=True</code> 效率更高，能够避免一些转置的操作，因此 Y 的形状是 time major。</p>
<h2 id="模型">模型</h2>
<p>模型的结构如下图所示：</p>
<p><img src="/2018/08/28/jazz-with-an-lstm-network/model.png"></p>
<p>每次从 <code>original_metheny.mid</code> 中随机选取 30 个值训练模型。与生成恐龙名字的模型类似，<span class="math inline">\(x^{\langle 1 \rangle} = \vec{0}\)</span> 作为输入的开始。</p>
<h3 id="构建模型">构建模型</h3>
<p>本次实验使用隐藏状态是 64 维的 LSTM，对于序列生成模型，在实验之前输入序列未知，每个时间步的输出生成下一个时间步的输入 <span class="math inline">\(x^{\langle t \rangle}=y^{\langle t-1 \rangle}\)</span>，因此需要使用 for 循环调用 LSTM 层 <span class="math inline">\(T_x\)</span> 次，且 LSTM 细胞共享参数。</p>
<ul>
<li>定义层对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reshapor = Reshape((<span class="number">1</span>, <span class="number">78</span>))</span><br><span class="line">LSTM_cell = LSTM(n_a, return_state = <span class="literal">True</span>)</span><br><span class="line">densor = Dense(n_values, activation=<span class="string">'softmax'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>实现 <code>djmodel()</code>
<ol type="1">
<li>创建空列表用于存储每个时间步的输出</li>
<li>循环 <span class="math inline">\(T_x\)</span> 个时间步
<ol type="1">
<li>使用 Keras的 Lambda 层：<code>x = Lambda(lambda x: X[:,t,:])(X)</code></li>
<li>Reshape x 的形状成 <span class="math inline">\((1, 78)\)</span></li>
<li>将 x 输入到一个 LSTM_cell 中：<code>a, _, c = LSTM_cell(input_x, initial_state=[previous hidden state, previous cell state])</code></li>
<li>输出经过激活函数和全连接层后，保存到输出列表中</li>
</ol></li>
</ol></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">djmodel</span><span class="params">(Tx, n_a, n_values)</span>:</span></span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    X = Input(shape=(Tx, n_values))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Create empty list to append the outputs while you iterate (≈1 line)</span></span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="comment"># Step 2: Loop</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Tx):</span><br><span class="line">        <span class="comment"># Step 2.A: select the "t"th time step vector from X. </span></span><br><span class="line">        x =  Lambda(<span class="keyword">lambda</span> x: X[:, t, :])(X)</span><br><span class="line">        <span class="comment"># Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)</span></span><br><span class="line">        x = reshapor(x)</span><br><span class="line">        <span class="comment"># Step 2.C: Perform one step of the LSTM_cell</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c])</span><br><span class="line">        <span class="comment"># Step 2.D: Apply densor to the hidden state output of LSTM_Cell</span></span><br><span class="line">        out = densor(a)</span><br><span class="line">        <span class="comment"># Step 2.E: add the output to "outputs"</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">    <span class="comment"># Step 3: Create model instance</span></span><br><span class="line">    model = Model(inputs=[X, a0, c0], outputs=outputs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>接下来使用 Adam 优化和一个分类的交叉熵损失训练模型 100 个 epochs：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = djmodel(Tx = <span class="number">30</span> , n_a = <span class="number">64</span>, n_values = <span class="number">78</span>)</span><br><span class="line">opt = Adam(lr=<span class="number">0.01</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.compile(optimizer=opt, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">m = <span class="number">60</span></span><br><span class="line">a0 = np.zeros((m, n_a))</span><br><span class="line">c0 = np.zeros((m, n_a))</span><br><span class="line">model.fit([X, a0, c0], list(Y), epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h3 id="生成">生成</h3>
<p><img src="/2018/08/28/jazz-with-an-lstm-network/music_generation.png"></p>
<p>在采样的每个时间步中，输出被用于生成音乐和作为下一个时间步的输入。实验步骤如下：</p>
<ol type="1">
<li>使用 LSTM_Cell，输入时上一个时间步的输出 <code>y</code> 和隐藏状态 <code>a</code></li>
<li>对当前时间步的隐藏状态 <code>a</code> 使用 <code>softmax</code> 函数，将输入加入输出列表中</li>
<li>对输出使用 <code>x = Lambda(one_hot)(out)</code> 转化成独热向量，输入下一个时间步</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">music_inference_model</span><span class="params">(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Define the input of your model with a shape </span></span><br><span class="line">    x0 = Input(shape=(<span class="number">1</span>, n_values))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define s0, initial hidden state for the decoder LSTM</span></span><br><span class="line">    a0 = Input(shape=(n_a,), name=<span class="string">'a0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_a,), name=<span class="string">'c0'</span>)</span><br><span class="line">    a = a0</span><br><span class="line">    c = c0</span><br><span class="line">    x = x0</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Create an empty list of "outputs" to later store your predicted values (≈1 line)</span></span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="comment"># Step 2: Loop over Ty and generate a value at every time step</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Ty):</span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of LSTM_cell (≈1 line)</span></span><br><span class="line">        a, _, c = LSTM_cell(x, initial_state=[a, c])</span><br><span class="line">        <span class="comment"># Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)</span></span><br><span class="line">        out = densor(a)</span><br><span class="line">        <span class="comment"># Step 2.C: Append the prediction "out" to "outputs". out.shape = (None, 78) (≈1 line)</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">        <span class="comment"># Step 2.D: Select the next value according to "out", and set "x" to be the one-hot representation of the</span></span><br><span class="line">        <span class="comment">#           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided </span></span><br><span class="line">        <span class="comment">#           the line of code you need to do this. </span></span><br><span class="line">        x = Lambda(one_hot)(out)</span><br><span class="line">    <span class="comment"># Step 3: Create model instance with the correct "inputs" and "outputs" (≈1 line)</span></span><br><span class="line">    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inference_model</span><br></pre></td></tr></table></figure>
<p>定义推断模型和初始化参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inference_model = music_inference_model(LSTM_cell, densor, n_values = <span class="number">78</span>, n_a = <span class="number">64</span>, Ty = <span class="number">50</span>)</span><br><span class="line">x_initializer = np.zeros((<span class="number">1</span>, <span class="number">1</span>, <span class="number">78</span>))</span><br><span class="line">a_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br><span class="line">c_initializer = np.zeros((<span class="number">1</span>, n_a))</span><br></pre></td></tr></table></figure>
<p>预测输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_and_sample</span><span class="params">(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, c_initializer = c_initializer)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.</span></span><br><span class="line">    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])</span><br><span class="line">    <span class="comment"># Step 2: Convert "pred" into an np.array() of indices with the maximum probabilities</span></span><br><span class="line">    indices = np.argmax(pred, axis = <span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )</span></span><br><span class="line">    results = to_categorical(indices, num_classes=<span class="number">78</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> results, indices</span><br><span class="line"></span><br><span class="line">results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)</span><br></pre></td></tr></table></figure>
<p>生成音乐：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out_stream = generate_music(inference_model)</span><br></pre></td></tr></table></figure>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/30s_trained_model.mp3" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<h2 id="总结">总结</h2>
<p>这篇博客写的有点简单，因为 Coursera 的资料也比较全面了，而且和恐龙名字生成模型也很类似。如果我再去仔细分析它各个工具的实现感觉进度有点慢，所以只是简单地实现了作业内容，再加上自己对整个作业的理解。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>线性回归</title>
    <url>/2018/03/10/linear-regression/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>不知不觉研一已经过去了一个学期，上学期真实忙得没有时间总结。天天忙着上课和做实验，随机过程和工程硕士数学确实有些收获，就是感觉上课的形式花的时间太多；模式识别和计算机网络体系结构做了几个实验，收获颇丰。说实话，在教学方面，清华的老师也强不到哪里去(听师兄说本部也差不多)，根本就不能吸引学生注意力，课堂气氛也不行。</p>
<a id="more"></a>
<p>上学期也算是入门了机器学习吧，跟着吴恩达在 Coursera 上的 Machine Learning 学了半个学期，也看了一些书和论文。现在总结一下，不然就连最简单的线性回归还是一知半解，毕竟只有写出来，讲出来才是自己的。</p>
<h2 id="线性回归">线性回归</h2>
<blockquote>
<p>给定数据集 <span class="math inline">\(\boldsymbol{D}=\lbrace(\boldsymbol{x}^{(i)}, y^{(i)}); i=1, …, m\rbrace\)</span>，其中 <span class="math inline">\(\boldsymbol{x}^{(i)}=(x^{(i)}_1; x^{(i)}_2; …; x^{(i)}_d)\)</span>，<span class="math inline">\(y^{(i)}\in\mathbb{R}\)</span>，线性回归就是试图去学习线性模型以尽可能准确地根据输入 <span class="math inline">\(\boldsymbol{x}\)</span> 预测输出 <span class="math inline">\(y\)</span>。</p>
</blockquote>
<p>线性回归并不陌生，例如高中的时候学过的父母身高预测法，假设父母的身高 <span class="math inline">\(\boldsymbol{x}=(x_1; x_2)\)</span> 和子女的身高 <span class="math inline">\(y\)</span> 之间存在某种线性的关系(其实还和子女的性别有关，对于性别这种离散且不存在“序”的值，可以用一个 2 维向量表示：男(0; 1)、女(1; 0))，线性回归就是要根据统计的数据去学习这个假设(hypothesis)存在的关系 <span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})=\theta_1x_1+\theta_2x_2+b=\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}+b\)</span>。</p>
<p>假设存在 <span class="math inline">\(x_0=1\)</span> 且令 <span class="math inline">\(\theta_{0}=b\)</span>，则<span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})=\theta_0x_0+\theta_1x_1+\theta_2x_2=\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}\)</span>，线性回归就是要找到 <span class="math inline">\(\boldsymbol{\theta}\)</span>，使得预测结果尽可能准确。</p>
<p>以下实验数据来自于吴恩达在 Coursera 的 Machine Learning 课程的实验 ex1。</p>
<h3 id="ex-1">Ex 1</h3>
<p>一个餐厅的 CEO 考虑在不同的城市开一家新店，所以希望能根据城市人口的数量(先不考虑其他因素，即一元线性回归)预测商铺的利润 <span class="math inline">\(y\)</span> ，以决定在哪座城市开店。</p>
<p><img src="/2018/03/10/linear-regression/data.png"></p>
<p>商铺利润 <span class="math inline">\(y\)</span> 和城市人口数量 <span class="math inline">\(x_1\)</span> 之间大体上呈线性关系，所以可以使用线性回归的方法学习出这个关系，即找到 <span class="math inline">\(\boldsymbol{\theta}\)</span>，那么给定一个新的城市人口数时候，就可以根据 <span class="math inline">\(\boldsymbol{x}\)</span> 尽准确预测可能出商铺利润 <span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})\)</span>。</p>
<h3 id="符号解释">符号解释</h3>
<ul>
<li><p><span class="math inline">\(\boldsymbol{x}^{(i)}\)</span>：“输入”变量，也叫做输入特征。例如 <span class="math inline">\(\boldsymbol{x}^{(i)}=(1; x^{(i)}_1)\)</span>, <span class="math inline">\(x^{(i)}_1\)</span> 就是第 <span class="math inline">\(i\)</span> 座城市的人口数量。 <span class="math display">\[
\boldsymbol{X}=\begin{bmatrix} - (\boldsymbol{x}^{(1)})^\mathrm{T} - \\\ . \\\ . \\\ . \\\ - (\boldsymbol{x}^{(m)})^\mathrm{T} - \end{bmatrix}=\begin{bmatrix} 1 &amp; x^{(1)}_1 \\\ . &amp; . \\\ . &amp; . \\\ . &amp; .\\\ 1 &amp; x^{(m)}_1 \end{bmatrix}\quad
\]</span></p></li>
<li><p><span class="math inline">\(y^{(i)}\)</span>：“输出”，也叫做目标变量。例如第 <span class="math inline">\(i\)</span> 座城市的利润。 <span class="math display">\[
\boldsymbol{y}=\begin{bmatrix} y^{(1)} \\\ . \\\ . \\\ . \\\ y^{(m)} \end{bmatrix}\quad
\]</span></p></li>
<li><p><span class="math inline">\((\boldsymbol{x}^{(i)}, y^{(i)})\)</span>：一个训练样本</p></li>
<li><p><span class="math inline">\(\boldsymbol{D}=\lbrace(\boldsymbol{x}^{(i)}, y^{(i)}); i=1,…,m)\rbrace\)</span>：<span class="math inline">\(m\)</span> 个训练样本组成的训练集，上标 <span class="math inline">\((i)\)</span> 表示样本在训练集中的索引，和指数没有关系</p></li>
</ul>
<p><span class="math display">\[
\boldsymbol{D}=\begin{bmatrix}\boldsymbol{X} &amp; \boldsymbol{y}\end{bmatrix}=\begin{bmatrix} 1 &amp; x^{(1)}_1 &amp; y^{(1)} \\\ . &amp; . &amp; . \\\ . &amp; . &amp; . \\\ . &amp; . &amp; . \\\ 1 &amp; x^{(m)}_1 &amp; y^{(m)} \end{bmatrix}\quad
\]</span></p>
<h2 id="性能度量">性能度量</h2>
<p>如何找到 <span class="math inline">\(\boldsymbol{\theta}\)</span> 就需要了解什么样的 <span class="math inline">\(\boldsymbol{\theta}\)</span> 能使预测结果更准确。如果 <span class="math inline">\(h_\boldsymbol{\theta1}(\boldsymbol{x})\)</span> 与真实的结果 <span class="math inline">\(y\)</span> 之间的<font color="red" size="4">差别</font>比 <span class="math inline">\(h_\boldsymbol{\theta2}(\boldsymbol{x})\)</span> 与真实的结果 <span class="math inline">\(y\)</span> 之间的差别更小，那么 <span class="math inline">\(\boldsymbol{\theta1}\)</span> 就比 <span class="math inline">\(\boldsymbol{\theta2}\)</span> 更好，能使预测结果更准确。</p>
<p><img src="/2018/03/10/linear-regression/predict.png"></p>
<p>例如上图中明显 <span class="math inline">\(\boldsymbol{\theta1}\)</span> 就比 <span class="math inline">\(\boldsymbol{\theta2}\)</span> 更好，因为直观上使用 <span class="math inline">\(\boldsymbol{\theta1}\)</span> 预测出来的利润 <span class="math inline">\(h_\boldsymbol{\theta1}(\boldsymbol{x})\)</span> 与真实利润 <span class="math inline">\(y\)</span> 之间的差别更小，但是如何用数学语言衡量 <span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})\)</span> 和 <span class="math inline">\(y\)</span> 之间的差别呢？</p>
<h3 id="损失函数代价函数和目标函数">损失函数、代价函数和目标函数</h3>
<blockquote>
<p><strong>损失函数</strong>是一种衡量<strong>损失</strong>和错误程度的<strong>函数</strong></p>
</blockquote>
<p>在机器学习领域，经常会出现损失函数、代价函数和目标函数，它们之间并没有严格的规定，然而它们的定义一般如下：</p>
<ol type="1">
<li>损失函数(Loss function)：定义在单个训练样本上，衡量一个样本的输出与真实值差别，例如：
<ul>
<li>平方损失(通常用于线性回归)：<span class="math inline">\(l_\boldsymbol{\theta}(i)=\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)^2\)</span></li>
<li>铰链损失(用于 SVM，像铰链)：<span class="math inline">\(l_\boldsymbol{\theta}(i) = \max\left(0, 1-h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})y^{(i)}\right)\)</span></li>
<li>...</li>
</ul></li>
<li>代价函数(Cost function)：定义在整个训练集上，即选定参数 <span class="math inline">\(\boldsymbol{\theta}\)</span> 后对数据进行估计所要支付的代价加上一些惩罚函数(例如正则化项)，例如：
<ul>
<li>均方误差(几何意义是“欧氏距离”)：<span class="math inline">\(MSE(\boldsymbol{\theta}) = \frac{1}{m} \sum_{i=1}^m\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)^2\)</span></li>
<li>SVM 的代价函数：<span class="math inline">\(SVM(\boldsymbol{\theta}) = \|\boldsymbol{\theta}\|^2 + C \sum_{i=1}^m \xi^{(i)}\)</span></li>
<li>...</li>
</ul></li>
<li>目标函数(Objective function)：代价函数的推广，即需要优化的函数。可能是最大化，也可能是最小化(此时就是代价函数)，例如：
<ul>
<li>似然函数：用最大似然估计评估模型参数(MLE)</li>
<li>后验：用最大后验估计模型参数</li>
<li>...</li>
</ul></li>
</ol>
<p>线性回归使用均方误差作为代价函数，因此可以算出中 <span class="math inline">\(MSE(\boldsymbol{\theta1})\)</span> 比 $MSE() $ 更小，即 <span class="math inline">\(\boldsymbol{\theta1}\)</span> 能使预测结果更准确。<span class="math inline">\(MSE(\boldsymbol{\theta1})\)</span> 为每个点到预测结果的距离（每个点与横坐标作垂线，与预测结果的交点）之和的平均：</p>
<p>但是在以均方误差作为性能度量的前提下，是不是还存在 <span class="math inline">\(\boldsymbol{\theta^{*}}\)</span> 能使预测结果 <span class="math inline">\(\boldsymbol{\theta1}\)</span> 的预测结果更准确？如何找到最准确的 <span class="math inline">\(\boldsymbol{\theta^{*}}\)</span> 是一个凸优化问题，更准确地说这是一个最小二乘问题。</p>
<p><span class="math display">\[\boldsymbol{\theta^{*}} = \arg \min_{\boldsymbol{\theta}}\frac{1}{m}\sum_{i=1}^m\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)^{2}\]</span></p>
<h2 id="最小二乘问题">最小二乘问题</h2>
<p>线性回归的代价函数是一个二次函数且半正定，所以这是一个最小二乘问题。所以最小化 <span class="math inline">\(MSE(\boldsymbol{\theta})\)</span> 求解 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的过程也叫做最小二乘“参数估计”。一元线性回归的代价函数图是一个“碗状”图。</p>
<h3 id="解析解">解析解</h3>
<p>求解线性最小二乘问题可以通过对代价函数求导，然后令导数为零可以得到 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的解析解，但是由于在求解过程中会涉及到矩阵求逆的计算，对于 <span class="math inline">\(n\)</span> 维的的输入变量 <span class="math inline">\(\boldsymbol{x}=(x_0; x_1; …; x_{n-1})\)</span>，时间复杂度为 <span class="math inline">\(O(n^3)\)</span>，因此当 <span class="math inline">\(n&gt;10000\)</span> 时不推荐使用。其解析解为：</p>
<p><span class="math display">\[\boldsymbol{\theta}=(\boldsymbol{X}^ \mathrm{T}\boldsymbol{X})^{-1}\boldsymbol{X}^ \mathrm{T}\vec{y}\]</span></p>
<p>对于多元线性回归(输入变量维数大于 2)，如果数据的组数少于输入变量维数，那么矩阵 <span class="math inline">\(\boldsymbol{X}^ \mathrm{T}\boldsymbol{X}\)</span> 显然不满秩。很好理解，未知数的个数大于方程的个数，那么这个方程的解就不唯一，就会有多个解能使均方误差最小化，常见的解决方法就是引入正则化项(详情见《凸优化》第六章)。</p>
<p>求解过程涉及求一阶偏导数，一阶偏导数以一定方式排列成的矩阵又叫做<strong>雅可比(Jacobian)矩阵</strong>，所以在机器学习中一般使用 <span class="math inline">\(J(\boldsymbol{\theta})\)</span> 表示代价函数。</p>
<h3 id="梯度下降算法">梯度下降算法</h3>
<p>当 <span class="math inline">\(n&gt;10000\)</span> 或者最小二乘问题是非线性的，可以考虑使用梯度下降算法。梯度下降是迭代法的一种，常用于求解最小二乘问题。在最小化代价函数时，可以通过梯度下降法来一步步的迭代求解(通过一个已经找到的 <span class="math inline">\(\boldsymbol{\theta}\)</span> 和迭代公式去算更好的 <span class="math inline">\(\boldsymbol{\theta}\)</span>)，最后得到最小化的代价函数和模型参数值 <span class="math inline">\(\boldsymbol{\theta}\)</span>。</p>
<p>梯度下降算法涉及到求代价函数 <span class="math inline">\(J(\boldsymbol{\theta}) = \frac{1}{m} \sum_{i=1}^m\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)^2\)</span> 的梯度(即<a href="https://www.zhihu.com/question/28684811/answer/159589897" target="_blank" rel="noopener">导数</a>)，为了计算方便，一般 <span class="math inline">\(J(\boldsymbol{\theta}) = \frac{1}{2m} \sum_{i=1}^m\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)^2\)</span>，根据链式求导法则得 <span class="math inline">\(J(\boldsymbol{\theta})\)</span> 在 <span class="math inline">\(\theta_j\)</span> 方向上的梯度的表达式为：</p>
<p><span class="math display">\[\nabla=\frac{\partial{J(\boldsymbol{\theta})}}{\partial{\theta_j}}=\frac{\partial{J(\boldsymbol{\theta})}}{\partial{h_\boldsymbol{\theta}(\boldsymbol{x})}}\frac{\partial{h_\boldsymbol{\theta}(\boldsymbol{x})}}{\partial{\theta_j}}=\frac{1}{m} \sum_{i=1}^m\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)x^{(i)}_j\]</span></p>
<p>所以梯度下降过程中，<span class="math inline">\(\theta_j\)</span> 的更新过程为：</p>
<p><span class="math display">\[\theta_j:=\theta_j-\alpha\frac{\partial{J(\boldsymbol{\theta})}}{\partial{\theta_j}}\]</span></p>
<p>其中 <span class="math inline">\(\alpha\)</span> 为学习率，即梯度下降的“步伐”大小，太大会错误最小值导致梯度上升，太小会导致下降速度太慢，一般开始的时候稍微大些然后逐渐变小，当一次迭代梯度下降小于 <span class="math inline">\(10^{-3}\)</span> 的时候就可以说是收敛了。其中 <span class="math inline">\(m\)</span> 为梯度下降时使用的样本个数，根据 <span class="math inline">\(m\)</span> 取值的不同梯度下降算法分为以下三种：</p>
<ol type="1">
<li>批量梯度下降</li>
<li>随机梯度下降</li>
<li>小批量梯度下降</li>
</ol>
<h4 id="批量梯度下降batch-gradient-descent简称-bgd">批量梯度下降(Batch Gradient Descent，简称 BGD)</h4>
<p>梯度下降的时候使用所有样本来更新参数 <span class="math inline">\(\boldsymbol{\theta}\)</span>，最后会收敛到全局最优解，也易于并行实现。但是如果样本数目过多的时候，训练过程会很慢。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iteration</span><br><span class="line">    h = X * theta;</span><br><span class="line">    theta = theta - (alpha/m) * X' * (h - y);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h4 id="随机梯度下降stochastic-gradient-descent简称-sgd">随机梯度下降(Stochastic Gradient Descent，简称 SGD)</h4>
<p>梯度下降的时候使用一个样本来更新参数 <span class="math inline">\(\boldsymbol{\theta}\)</span>，不一定能收敛到全局最优解，也不易于并行实现，但是训练过程会很快。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iteration</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m</span><br><span class="line">    	h = X(<span class="built_in">i</span>, :) * theta;</span><br><span class="line">    	theta = theta - alpha * X(<span class="built_in">i</span>, :)' * (h - y(<span class="built_in">i</span>));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>批量梯度下降和随机梯度下降的时间复杂度一样，但是对于迭代同样的次数，随机梯度下降中的参数更新的次数较多，所以收敛的速度就快。但是由于随机梯度下降计算的梯度是对于这一次所选取的这一个样本的平方损失的梯度，而不是全部样本的均方误差的梯度，所以计算的梯度可能不准确，所以最后不一定能收敛到全局最优点。</p>
<p>在数据量很大的情况下，单个样本的平方损失可能会很接近于全部样本的均方误差，那么随机梯度下降计算的梯度就会很准确，同时收敛的速度也很快。</p>
<h4 id="小批量梯度下降mini-batch-gradient-descent简称-mbgd">小批量梯度下降(Mini-batch Gradient Descent，简称 MBGD)</h4>
<p>结合了批量梯度下降和随机梯度下降，在梯度下降的时候使用一部分样本来更新参数 <span class="math inline">\(\boldsymbol{\theta}\)</span>。所以在数据集比较小的时候采用批量梯度下降算法，数据集比较大的时候采用随机梯度下降算法，一般情况下使用小批量梯度下降算法。</p>
<h2 id="总结">总结</h2>
<p>线性回归主要就是观察数据，发现它满足一定的线性关系，然后就去找出这个关系，让预测尽可能地准确。一般都是使用小批量梯度下降算法，通过最小化代价函数算出模型的参数，得到的模型就可以用来对新的数据进行预测。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] 周志华. 机器学习. 清华大学出版社. 2016.</p>
<p>[2] 吴恩达. 机器学习.</p>
<p>[4] Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</p>
<p>[4] Stephen Boyd, Lieven Vandenberghe. 凸优化. 清华大学出版社. 2017.</p>
<p>[5] 关治, 陆金甫. 数值方法. 清华大学出版社. 2017.</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Logistic 回归和 Softmax 回归</title>
    <url>/2018/04/26/logistic-regression/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>最近在看吴恩达的 DeepLearning，学习了不少关于深度学习的知识，正好参考着作业的内容总结一下，挖这个坑必须得填，哈哈。</p>
<a id="more"></a>
<p>几乎所有深度学习的书都是从 <strong>Logistic Regression</strong> 开始讲，因为这是一个最简单的“神经网络”。以前看到网上有不少人把这个词组翻译为“逻辑回归”，但是看到西瓜书🍉上说 logistic != logic ，作者把这个翻译为对数几率回归，简称对率回归。对率回归可以解决线性二分类问题，推广成 Softmax 回归可以解决线性多分类问题。</p>
<h2 id="logistic-回归">Logistic 回归</h2>
<p>线性回归预测的 y 是连续的值，对于二分类问题，我们希望预测的 y 只能取 0/1 两个值。例如假设肿瘤是否是恶性肿瘤只和肿瘤的大小有关，然后给定肿瘤的大小，判断它是否是恶性肿瘤，1 表示正例(是)，0 表示负例(否)。</p>
<blockquote>
<p>分类是监督学习的一个核心问题，在监督学习中，当输出变量 Y 取有限个离散值时，预测问题便成为分类问题。这时，输入变量 X 可以是离散的，也可以是连续的。监督学习从数据中学习一个分类模型或分类决策函数，称为分类器(classifier)。分类器对新的输入进行输出的预测(prediction)，称为分类(classification)。</p>
</blockquote>
<p>如果使用线性回归解决二分类任务，因为输出会有大于 1 和小于 0 的数，解决这个问题只需要将线性回归的预测值 <span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})=\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}\)</span> 映射到值域为 (0, 1) 的空间上，即：</p>
<p><span class="math display">\[h_\boldsymbol{\theta}(\boldsymbol{x})=g(\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x})=\frac{1}{1+e^{-\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}}}\]</span></p>
<p>因此 <span class="math inline">\(ln\frac{h_\boldsymbol{\theta}(\boldsymbol{x})}{1-h_\boldsymbol{\theta}(\boldsymbol{x})}=\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}\)</span>，实际上是在用线性回归模型的预测结果去逼近样本真实标记为正例和反例的可能性的比值，即真实标记的对数几率。<span class="math inline">\(g(z)\)</span> 也叫做 <code>Logistic function</code> 或者 <code>Sigmoid function</code>。</p>
<p><img src="/2018/04/26/logistic-regression/sigmoid.png"></p>
<p>该函数的导数为：</p>
<p><span class="math display">\[g&#39;(z)=\frac{d}{dz}\frac{1}{1+e^{-z}}=\frac{e^{-z}}{(1+e^{-z})^2}=g(z)\left(1-g(z)\right)\]</span></p>
<p><span class="math inline">\(z\)</span> 趋于正无穷时，<span class="math inline">\(g(z)\)</span> 趋于 1；<span class="math inline">\(z\)</span> 趋于负无穷时，<span class="math inline">\(g(z)\)</span> 趋于 0。</p>
<p><span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x}) \geq 0.5\)</span> 即 <span class="math inline">\(\boldsymbol{\theta}^\mathrm{T}\boldsymbol{x}\geq0\)</span> 表示是恶性肿瘤的可能性大于等于 50%，因此可以给定一个阈值例如就是 0.5，恶性肿瘤的可能性大于等于 50% 就判定是恶性肿瘤，否则判定不是恶性肿瘤。即 <span class="math display">\[
y =
\begin{cases}
0 &amp; h_\boldsymbol{\theta}(\boldsymbol{x}) &lt; 0.5 \\\
1 &amp; h_\boldsymbol{\theta}(\boldsymbol{x}) \geq 0.5
\end{cases}
\]</span> 在判定是否为恶性肿瘤的时候，医生会更加注重召回率而不是准确率，“宁可杀错也不放过”，所以阈值可能会更小一些，例如只要有 40% 可能性就要判定为恶性肿瘤，然后进行治疗。</p>
<p>在对率回归中如果像线性回归模型一样将平方损失作为损失函数，那么目标函数为：</p>
<p><span class="math display">\[E_{\theta}=\sum_{i=1}^m(y^{(i)}-\frac{1}{1+e^{-\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}^{(i)}}})^2\]</span></p>
<p>这是一个非凸函数，不容易求解，容易得到局部最优值。在对率回归中，经常使用最大似然的方法估计模型的参数，因此损失函数是基于最大似然估计推导得到的对数似然损失函数。</p>
<h2 id="两大学派的争论">两大学派的争论</h2>
<p>在学习最大似然估计之前先了解一下频率学派和贝叶斯学派对世界的认知。对事物建模时，用 <span class="math inline">\(\theta\)</span> 表示模型的参数，解决问题的本质就是求 <span class="math inline">\(\theta\)</span>。例如通过抛硬币估计硬币正面朝上的概率 <span class="math inline">\(P(head)=\theta\)</span>。</p>
<p>概率和似然都是指可能性，但是在统计学中，概率和似然有截然不同的用法。</p>
<ul>
<li>概率：描述了已知参数 <span class="math inline">\(\theta\)</span> 时的随机变量的输出结果。例如已知参数 <span class="math inline">\(\theta=0.5\)</span> ，求抛 m 次硬币出现 n 次正面朝上的概率。</li>
<li>似然：描述已知随机变量输出结果时，未知参数 <span class="math inline">\(\theta\)</span> 的可能取值。例如已知抛 100 次硬币出现 50 次正面朝上，求参数 <span class="math inline">\(\theta=x\)</span> 的似然程度。</li>
</ul>
<h3 id="频率学派">频率学派</h3>
<p>根据随机重复事件的<strong>频率</strong>来考察<strong>概率</strong>。抛 10 次有 4 次正面朝上，则 <span class="math inline">\(\theta=0.4\)</span>。当数据量趋于无穷时就可以得到精准的估计，当缺乏数据时则可能出现严重的偏差(过拟合)，例如对于一枚均匀的硬币，抛 10 次有 10 次正面朝上(这种情况的概率是 <span class="math inline">\(\frac{1}{2^{10}}\)</span>)，频率学派会直接估计 <span class="math inline">\(\theta=1\)</span>，然后预测抛这个硬币 100% 正面朝上。</p>
<h3 id="贝叶斯学派">贝叶斯学派</h3>
<p>根据先验(Prior)概率和似然函数(Likelihood function)，计算后验(Posterior)概率。</p>
<p>贝叶斯公式如下：</p>
<p><span class="math display">\[P(\theta|X)=\frac{P(X|\theta)P(\theta)}{P(X)}\]</span></p>
<p>假设抛 10 次硬币是一次实验，<span class="math inline">\(P(X)\)</span> 相当于是一个归一化项，所以 <span class="math inline">\(P(\theta|X)\propto{P(X|\theta)P(\theta)}\)</span>。</p>
<h4 id="先验概率-ptheta">先验概率 <span class="math inline">\(P(\theta)\)</span></h4>
<p>观测到数据之前，一些关于参数 <span class="math inline">\(\theta\)</span> 的假设，即参数 <span class="math inline">\(\theta\)</span> 取某个值的概率。所以 <span class="math inline">\(\theta\)</span> 是一个随机变量，符合一定的概率分布。当先验分布是均匀分布时，贝叶斯方法等价于频率方法。一般伯努利分布把先验分布选择为 Beta 分布，因为它正比于 <span class="math inline">\(\theta\)</span> 和 <span class="math inline">\(1-\theta\)</span> 的幂指数，那么后验分布就会有和先验分布相同的函数形式(共轭性)，接下来观测到更多数据时后验分布就可以扮演先验分布的角色(详情见 PRML 2.1.1)。</p>
<p>下图为 Beta 分布的函数分布图，表示关于参数 <span class="math inline">\(\theta\)</span> 的假设。例如普通的硬币，Beta 分布的超参数 a 和 b 可以取 10，即抛 20 次硬币应该会有 10 次正面朝上和 10 次反面朝上。从图中可以看出，参数 <span class="math inline">\(\theta\)</span> 取 0.5 时先验概率最大，取其他值时先验概率比较小。</p>
<blockquote>
<p>可以简单地把先验概率中的超参数 a 和 b 分别看出 x = 1 和 x = 0 的有效观测次数。</p>
</blockquote>
<p><img src="/2018/04/26/logistic-regression/beta1.png"></p>
<p>如果对关于参数 <span class="math inline">\(\theta\)</span> 的假设的把握更大，即抛 100 次硬币应该会有 50 次正面朝上和 50 次反面朝上。那么参数 <span class="math inline">\(\theta\)</span> 取 0.5 的概率就更大，取其他值的概率就更小。</p>
<p><img src="/2018/04/26/logistic-regression/beta2.png"></p>
<h4 id="似然函数-pxtheta">似然函数 <span class="math inline">\(P(X|\theta)\)</span></h4>
<p>假设参数 <span class="math inline">\(\theta\)</span> 已知后观测到已有数据的概率，是关于参数 <span class="math inline">\(\theta\)</span> 的函数。例如抛 10 次硬币有 2 次正面朝上，那么似然函数</p>
<p><span class="math display">\[P(X|\theta)=\binom{10}{2}\theta^2(1-\theta)^8\]</span></p>
<p>函数图像如下图所示，从图中可以看出，参数 <span class="math inline">\(\theta\)</span> 取 0.2 时似然程度最大，取其他值时似然程度比较小。</p>
<p><img src="/2018/04/26/logistic-regression/beta3.png"></p>
<h4 id="后验概率-pthetax">后验概率 <span class="math inline">\(P(\theta|X)\)</span></h4>
<p>通过似然函数修正后，参数 <span class="math inline">\(\theta\)</span> 取某个值的概率。参数 <span class="math inline">\(\theta\)</span> 的概率分布就是后验分布。</p>
<p>对于先验分布为超参数 a = b = 10 的 Beta 分布，似然函数 <span class="math inline">\(P(X|\theta)=\binom{10}{2}\theta^2(1-\theta)^8\)</span> ，可以算出对应的后验分布是超参数为 a = 12，b = 18 的 Beta 分布。</p>
<blockquote>
<p>定量地描述不确定性，并且根据少量新的数据对不确定性进行精确的修改，对接下来要采取的动作进行修改，或者对最终的决策进行修改。</p>
</blockquote>
<p>在贝叶斯学派和频率学派的观点中，似然函数都起着重要的作用，然而使用的方式有着本质的不同。频率学家观点认为参数 <span class="math inline">\(\theta\)</span> 是一个固定的参数，频率学派广泛使用最大似然估计，参数 <span class="math inline">\(\theta\)</span> 的值就是使似然函数 <span class="math inline">\(P(X|\theta)\)</span> 达到最大值的 <span class="math inline">\(\theta\)</span> 的值；贝叶斯学派则广泛使用最大后验估计，参数 <span class="math inline">\(\theta\)</span> 的值就是使后验分布 <span class="math inline">\(P(\theta|X)\propto{P(X|\theta)P(\theta)}\)</span> 达到最大值的 <span class="math inline">\(\theta\)</span> 的值。</p>
<p>贝叶斯观点的优点是包含了先验概率，相当于加了正则化项，避免产生过拟合。一个带有合理的先验分布的贝叶斯方法不会预测抛一枚普通的硬币会 100% 正面朝上，但是如果先验分布选择不好，贝叶斯方法也会有很大的可能给出错误的结果。</p>
<h3 id="最大似然估计mle">最大似然估计(MLE)</h3>
<p>Maximun Likelihood Estimation 是频率学派广泛用的估计方法。假设数据 <span class="math inline">\(X\)</span>是独立同分发布的一组抽样。那么 MLE 对 <span class="math inline">\(\theta\)</span> 的估计方法可以如下推导： <span class="math display">\[
\begin{align}
\hat\\theta_{MLE} &amp; = \arg \max P(X;\theta) \\\
 &amp; = \arg \min -log P(X;\theta)
\end{align}
\]</span></p>
<p>这里之所以用 <span class="math inline">\(P(X;\theta)\)</span> 而不是 <span class="math inline">\(P(X|\theta)\)</span> 是因为频率学派认为参数 <span class="math inline">\(\theta\)</span> 是固定的值(只是当前未知)而不是随机变量。最后要优化的函数被称为 Negative Log Likelihood (NLL)。</p>
<h3 id="最大后验估计map">最大后验估计(MAP)</h3>
<p>Maximum A Posteriori 是贝叶斯学派广泛使用的估计方法。假设数据 <span class="math inline">\(X\)</span> 是独立同分发布的一组抽样。那么 MAP 对 <span class="math inline">\(\theta\)</span> 的估计方法可以如下推导： <span class="math display">\[
\begin{align}
\hat\\theta_{MAP} &amp; = \arg \max P(\theta|X) \\\
 &amp; = \arg \min - log P(\theta|X) \\\
 &amp; = \arg \min - log P(X|\theta)-log P(\theta)+log P(X) \\\
 &amp; = \arg \min - log P(X|\theta)-log P(\theta)
\end{align}
\]</span></p>
<p>MLE 和 MAP 在优化时的不同就是在于先验项 <span class="math inline">\(-log P(\theta)\)</span>。假设在某次实验中，先验分布是标准高斯分布，即参数 <span class="math inline">\(\theta\)</span> 满足标准高斯分布，则 <span class="math inline">\(P(\theta) = Ce^{-\frac{\theta^2}{2}}\)</span>，<span class="math inline">\(-log P(\theta) = C + \frac{\theta^2}{2}\)</span>。所以在 MAP 中选择标准高斯分布作为先验分布时就等价于在 MLE 中采用了 L2 的正则化项。</p>
<h2 id="代价函数">代价函数</h2>
<p>由于无法使用均方误差作为代价函数，所以分析当真实标签为 1 时，我们希望 <span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})\)</span> 尽可能接近于 <span class="math inline">\(1^-\)</span> ，即 <span class="math inline">\(-log(h_\boldsymbol{\theta}(\boldsymbol{x}))\)</span> 尽可能接近于 <span class="math inline">\(0^+\)</span>，也就是最小化负对数。</p>
<p><img src="/2018/04/26/logistic-regression/cost.png"></p>
<p>同理可构造损失函数如下：</p>
<p><span class="math display">\[
loss\left(h_\boldsymbol{\theta}(\boldsymbol{x}), y\right) =
\begin{cases}
-log\left(h_\boldsymbol{\theta}(\boldsymbol{x})\right) &amp; y=1 \\\
-log\left(1-h_\boldsymbol{\theta}(\boldsymbol{x})\right) &amp; y=0
\end{cases}
\]</span> 合并得损失函数为：<span class="math inline">\(loss\left(h_\boldsymbol{\theta}(\boldsymbol{x}), y\right)=-ylog\left(h_\boldsymbol{\theta}(\boldsymbol{x})\right)-(1-y)log\left(1-h_\boldsymbol{\theta}(\boldsymbol{x})\right)\)</span></p>
<p>所以对数似然代价函数为： <span class="math display">\[
J(\boldsymbol{\theta}) =-\frac{1}{m}\sum_{i=1}^m\Big(y^{(i)}log\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})\right)+(1-y^{(i)})log\left(1-h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})\right)\Big)
\]</span> 由 Sigmoid 函数的性质可知 <span class="math inline">\(\frac{\partial{h_\boldsymbol{\theta}(\boldsymbol{x})}}{\partial{\theta_j}}=h_\boldsymbol{\theta}(\boldsymbol{x})(1-h_\boldsymbol{\theta}(\boldsymbol{x}))x_j\)</span> ，所以在梯度下降求最优值时需要用到的梯度可以推导为： <span class="math display">\[
\begin{align}
\nabla_{\theta_j}J(\boldsymbol{\theta}) &amp; = \frac{\partial{J(\boldsymbol{\theta})}}{\partial{\theta_j}} \\\
&amp; = -\frac{1}{m}\sum_{i=1}^m\left(\frac{y^{(i)}}{h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})}\frac{\partial{h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})}}{\partial{\theta_j}}-\frac{1-y^{(i)}}{1-h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})}\frac{\partial{h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})}}{\partial{\theta_j}}\right) \\\
&amp; = \frac{1}{m}\sum_{i=1}^m\left(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})-y^{(i)}\right)x^{(i)}_j
\end{align}
\]</span> 化简后发现和线性回归模型的代价函数一样。</p>
<h2 id="softmax-回归">Softmax 回归</h2>
<p>Softmax 回归是对率回归的推广，当类别数 K=2 的时候，Softmax 回归退化为对率回归。由于在模型中使用了 Softmax 函数，比较温和(soft)地输出样本属于各个类别的概率，而不是直接最可能属于的类别，因此叫做 Softmax 回归。</p>
<p>Softmax 函数或称<strong>归一化指数函数</strong>，是 Sigmoid 函数的一种推广。它能将一个含任意实数的 K 维向量 <span class="math inline">\(\boldsymbol{z}\)</span> “压缩”到另一个 K 维实向量 <span class="math inline">\(\sigma(\boldsymbol{z})\)</span> 中，使得每一个元素的范围都在 (0, 1) 之间，并且所有元素的和为 1。该函数的形式通常按下面的式子给出： <span class="math display">\[
\sigma(\boldsymbol{z})=\frac{1}{\sum_{i=1}^ke^{z_i}}\begin{bmatrix}
e^{z_1} \\\ 
e^{z_2} \\\ 
... \\\ 
e^{z_k}
\end{bmatrix}\quad
\]</span> Softmax 回归模型对于诸如 MNIST 手写数字分类等问题很有用。对于二分类问题，类标记 <span class="math inline">\(y\in\lbrace0, 1\rbrace\)</span>；而在 K(K &gt; 2) 分类问题中则是 <span class="math inline">\(y\in\lbrace1, 2, …, k\rbrace\)</span>。例如，在 MNIST 数字识别任务中，10 个数字对应 K=10 个不同的类别。</p>
<p>对率回归的假设函数 <span class="math inline">\(h_\boldsymbol{\theta}(\boldsymbol{x})=g(\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x})=\frac{1}{1+e^{-\boldsymbol{\theta}^ \mathrm{T}\boldsymbol{x}}}\)</span> 计算的是样本属于正例的概率，由于只有两类，所以可以直接根据阈值进行判断。而 Softmax 回归则需要输出一个 K 维向量(元素和为 1，<strong>归一化</strong>)来表示样本属于每个类的概率，因此需要的模型参数也就更多。最后判断属于哪一类时则可以取最大的概率值对应的类别。 <span class="math display">\[
h_\boldsymbol{\Theta}(\boldsymbol{x})=\begin{bmatrix}
p(y=1|\boldsymbol{x};\boldsymbol{\Theta}) \\\ 
p(y=2|\boldsymbol{x};\boldsymbol{\Theta}) \\\ 
... \\\ 
p(y=k|\boldsymbol{x};\boldsymbol{\Theta})
\end{bmatrix}=\frac{1}{\sum_{i=1}^ke^{\boldsymbol{\theta}^\mathrm{T}_i\boldsymbol{x}}}\begin{bmatrix}
e^{\boldsymbol{\theta}^\mathrm{T}_1\boldsymbol{x}} \\\ 
e^{\boldsymbol{\theta}^\mathrm{T}_2\boldsymbol{x}} \\\ 
... \\\ 
e^{\boldsymbol{\theta}^\mathrm{T}_k\boldsymbol{x}}
\end{bmatrix}\quad
其中 \boldsymbol{\Theta}=\begin{bmatrix}
-\boldsymbol{\theta}^\mathrm{T}_1- \\\ 
-\boldsymbol{\theta}^\mathrm{T}_2- \\\ 
... \\\ 
-\boldsymbol{\theta}^\mathrm{T}_k-
\end{bmatrix}
\]</span></p>
<h3 id="代价函数-1">代价函数</h3>
<blockquote>
<p>示性函数：1{值为真的表达式} = 1</p>
</blockquote>
<p>对数似然代价函数 <span class="math inline">\(J(\boldsymbol{\theta}) =-\frac{1}{m} \sum_{i=1}^m(y^{(i)}log(h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)}))+(1-y^{(i)})log(1-h_\boldsymbol{\theta}(\boldsymbol{x}^{(i)})))\)</span> 可以推广为： <span class="math display">\[
J(\boldsymbol{\Theta}) =-\frac{1}{m}\sum_{i=1}^m\sum_{j=0}^11\lbrace y^{(i)}=j\rbrace logp(y^{(i)}=j|\boldsymbol{x}^{(i)};\boldsymbol{\Theta})
\]</span> 和对数依然一样可以理解为当真实标签为 j 时，要让预测为 j 类的概率值 <span class="math inline">\(p(y^{(i)}=j|\boldsymbol{x}^{(i)};\boldsymbol{\Theta})\)</span> 尽可能接近 <span class="math inline">\(1^-\)</span>。因此 Softmax 回归的代价函数为： <span class="math display">\[
J(\boldsymbol{\Theta}) =-\frac{1}{m}\sum_{i=1}^m\sum_{j=1}^k1\lbrace y^{(i)}=j\rbrace log\frac{e^{\boldsymbol{\theta}\_j^\mathrm{T}\boldsymbol{x}^{(i)}}}{\sum_{l=1}^ke^{\boldsymbol{\theta}^\mathrm{T}_l\boldsymbol{x}^{(i)}}}
\]</span></p>
<p>计算梯度公式如下： <span class="math display">\[
\begin{align}
\frac{\partial{J(\boldsymbol{\Theta})}}{\partial{\boldsymbol{\theta}\_j}} = -\frac{1}{m} \sum_{i=1}^m\left(\boldsymbol{x}^{(i)}(1\lbrace y^{(i)}=j\rbrace-\frac{e^{\boldsymbol{\theta}\_j^\mathrm{T}\boldsymbol{x}^{(i)}}}{\sum_{l=1}^ke^{\boldsymbol{\theta}^\mathrm{T}_l\boldsymbol{x}^{(i)}}})\right)
\end{align}
\]</span></p>
<p>在使用中一般会添加权重衰减项(正则项) <span class="math inline">\(\frac{\lambda}{2}\sum_{i=1}^k\sum_{j=0}^n\theta^2_{ij}\)</span> 惩罚过大的参数值，其在 <span class="math inline">\(\theta_j\)</span> 方向上的梯度为 <span class="math inline">\(\lambda\theta_j\)</span>。</p>
<h2 id="神经网络">* 神经网络</h2>
<blockquote>
<p>神经网络中最基本的成分是神经元模型，在生物神经网络是，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个“阈值”，那么它就会被激活，即“兴奋”起来，向其他神经元发送化学物质。</p>
</blockquote>
<p>根据神经元的定义，可以将对率回归看成是一个很简单的神经网络模型。即只有输入层和输出层，如下图所示(来自<a href="http://playground.tensorflow.org/#activation=sigmoid&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-gauss&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=40&amp;networkShape=&amp;seed=0.49707&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;stepButton_hide=false&amp;noise_hide=false" target="_blank" rel="noopener">Tensorflow</a>)：</p>
<figure>
<img src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/logistic-regression.gif" alt="Logistic regression"><figcaption aria-hidden="true">Logistic regression</figcaption>
</figure>
<p>有隐藏层的神经网络的输出层就是一个对率回归，也就是一个线性分类器。输入层和中间的隐藏层可以看成特征提取的过程，就是把对率回归的输出当作特征，然后再将它送入下一个对率回归，一层层变换。由于激活函数是非线性函数，所以通过特征提取，就可以把原本线性不可分的数据变得线性可分。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] 周志华. 机器学习. 清华大学出版社. 2016.</p>
<p>[2] 吴恩达. DeepLearning.</p>
<p>[3] Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</p>
<p>[4] Stephen Boyd, Lieven Vandenberghe. 凸优化. 清华大学出版社. 2017.</p>
<p>[5] Christopher M.Bishop. Pattern Recognition and Machine Learning. 2006.</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>自然机器翻译</title>
    <url>/2018/09/10/neural-machine-translation/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>将人类可读的日期格式翻译成机器可读的日期格式，这个想法真的很有意思。这篇博客记录了如何使用 attention 机制来进行机器翻译。</p>
<a id="more"></a>
<h2 id="数据集">数据集</h2>
<p>首先来看一下数据集，即人类和机器可读的日期格式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">m = <span class="number">10000</span></span><br><span class="line">dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)</span><br><span class="line">dataset[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[(&apos;9 may 1998&apos;, &apos;1998-05-09&apos;),</span><br><span class="line"> (&apos;10.09.70&apos;, &apos;1970-09-10&apos;),</span><br><span class="line"> (&apos;4/28/90&apos;, &apos;1990-04-28&apos;),</span><br><span class="line"> (&apos;thursday january 26 1995&apos;, &apos;1995-01-26&apos;),</span><br><span class="line"> (&apos;monday march 7 1983&apos;, &apos;1983-03-07&apos;),</span><br><span class="line"> (&apos;sunday may 22 1988&apos;, &apos;1988-05-22&apos;),</span><br><span class="line"> (&apos;tuesday july 8 2008&apos;, &apos;2008-07-08&apos;),</span><br><span class="line"> (&apos;08 sep 1999&apos;, &apos;1999-09-08&apos;),</span><br><span class="line"> (&apos;1 jan 1981&apos;, &apos;1981-01-01&apos;),</span><br><span class="line"> (&apos;monday may 22 1995&apos;, &apos;1995-05-22&apos;)]</span><br></pre></td></tr></table></figure>
<p>二元组的第一个元素是人类可读的日期格式，第二个是对应的机器可读的日期格式。假设人可读日期格式的最大长度为 30，机器的为 10，数据处理如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Tx = <span class="number">30</span></span><br><span class="line">Ty = <span class="number">10</span></span><br><span class="line">X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)</span><br></pre></td></tr></table></figure>
<ul>
<li>X.shape: (10000, 30)</li>
<li>Y.shape: (10000, 10)</li>
<li>Xoh.shape: (10000, 30, 37)</li>
<li>Yoh.shape: (10000, 10, 11)</li>
</ul>
<p>一共有 10000 个样本，将样本以字符级别变成独热向量。人类可读的日期格式包含 26 个字母、10 个数字和 1 个分隔符；机器可读的日期格式包含 10 个数字和 1 个分割符。</p>
<h2 id="attention-机制">Attention 机制</h2>
<p>Attention 机制如下图左图所示；右图为一个 attention 步，计算的 attention 变量 <span class="math inline">\(\alpha^{\langle t, t&#39; \rangle}\)</span> 将被用来计算每个时间步 <span class="math inline">\(t\)</span> 的上下文变量 <span class="math inline">\(context^{\langle t \rangle}\)</span>。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Attention 机制</th>
<th style="text-align: center;">Attention step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><img src="/2018/09/10/neural-machine-translation/attn_model.png"></td>
<td style="text-align: center;"><img src="/2018/09/10/neural-machine-translation/attn_mechanism.png"></td>
</tr>
</tbody>
</table>
<p>值得注意的是左图中有两个 LSTM 网络，下面在 attention 机制之前的是一个双向的 LSTM 网络，被称为 pre-attention Bi-LSTM；上面在 attention 机制之后的是一个单向的 LSTM 网络，被称为 post-attention LSTM。pre-attention Bi-LSTM 一共有 <span class="math inline">\(T_x\)</span> 个时间步，post-attention LSTM 一共有 <span class="math inline">\(T_y\)</span> 个时间步。</p>
<p>Post-attention LSTM 会将隐藏状态 <span class="math inline">\(s^{\langle t \rangle}\)</span> (与生成型模型不同，前一个字符和下一个字符之间没有很强的依赖，因此不是输出而是隐藏状态)和细胞的状态 <span class="math inline">\(c^{\langle t \rangle}\)</span> 传输给下一个时间步。模型的实现如下所示：</p>
<ol type="1">
<li><p><strong><code>one_step_attention()</code></strong>：在时间步 <span class="math inline">\(t\)</span>，给定 pre-attention Bi-LSTM 的隐藏状态 <span class="math inline">\([a^{\langle 1 \rangle},a^{\langle 2 \rangle}, ..., a^{\langle T_x \rangle}]\)</span> 和 post-attention LSTM 上一个时间步的隐藏状态 <span class="math inline">\(s^{\langle t-1 \rangle}\)</span>。<code>one_step_attention()</code> 计算将会计算 attention 的权值和上下文变量： <span class="math display">\[
context^{\langle t \rangle} = \sum_{t&#39; = 0}^{T_x} \alpha^{\langle t,t&#39;\rangle}a^{\langle t&#39;\rangle}
\]</span> Keras 实现 <strong><code>one_step_attention()</code></strong> 代码如下所示： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">repeator = RepeatVector(Tx)</span><br><span class="line">concatenator = Concatenate(axis=<span class="number">-1</span>)</span><br><span class="line">densor1 = Dense(<span class="number">10</span>, activation = <span class="string">"tanh"</span>)</span><br><span class="line">densor2 = Dense(<span class="number">1</span>, activation = <span class="string">"relu"</span>)</span><br><span class="line">activator = Activation(softmax, name=<span class="string">'attention_weights'</span>) <span class="comment"># We are using a custom softmax(axis = 1) loaded in this notebook</span></span><br><span class="line">dotor = Dot(axes = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_step_attention</span><span class="params">(a, s_prev)</span>:</span></span><br><span class="line">    <span class="comment"># Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states "a" (≈ 1 line)</span></span><br><span class="line">    s_prev = repeator(s_prev)</span><br><span class="line">    <span class="comment"># Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)</span></span><br><span class="line">    concat = concatenator([a, s_prev])</span><br><span class="line">    <span class="comment"># Use densor1 to propagate concat through a small fully-connected neural network to compute the "intermediate energies" variable e. (≈1 lines)</span></span><br><span class="line">    e = densor1(concat)</span><br><span class="line">    <span class="comment"># Use densor2 to propagate e through a small fully-connected neural network to compute the "energies" variable energies. (≈1 lines)</span></span><br><span class="line">    energies = densor2(e)</span><br><span class="line">    <span class="comment"># Use "activator" on "energies" to compute the attention weights "alphas" (≈ 1 line)</span></span><br><span class="line">    alphas = activator(energies)</span><br><span class="line">    <span class="comment"># Use dotor together with "alphas" and "a" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)</span></span><br><span class="line">    context = dotor([alphas, a])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure></p></li>
<li><p><strong><code>model()</code></strong>：实现整个模型。首先运行 Bi-LSTM 获取 <span class="math inline">\([a^{\langle 1 \rangle},a^{\langle 2 \rangle}, ..., a^{\langle T_x \rangle}]\)</span>。然后运行 <code>one_step_attention()</code> <span class="math inline">\(T_y\)</span> 个时间步（每个时间步共享权值参数），对于每一个时间步，首先计算上下文变量，然后运行 post-attention LSTM，其输出经过带有 softmax 激活函数的全连接层网络后生成预测 <span class="math inline">\(\hat{y}^{\langle t \rangle}\)</span>。 Keras 实现 <strong><code>model()</code></strong> 代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_a = <span class="number">32</span></span><br><span class="line">n_s = <span class="number">64</span></span><br><span class="line">post_activation_LSTM_cell = LSTM(n_s, return_state = <span class="literal">True</span>)</span><br><span class="line">output_layer = Dense(len(machine_vocab), activation=softmax)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size)</span>:</span></span><br><span class="line">    <span class="comment"># Define the inputs of your model with a shape (Tx,)</span></span><br><span class="line">    <span class="comment"># Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)</span></span><br><span class="line">    X = Input(shape=(Tx, human_vocab_size))</span><br><span class="line">    s0 = Input(shape=(n_s,), name=<span class="string">'s0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_s,), name=<span class="string">'c0'</span>)</span><br><span class="line">    s = s0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize empty list of outputs</span></span><br><span class="line">    outputs = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)</span></span><br><span class="line">    a = Bidirectional(LSTM(n_a, return_sequences=<span class="literal">True</span>), input_shape=(m, Tx, n_a * <span class="number">2</span>))(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Iterate for Ty steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(Ty):</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)</span></span><br><span class="line">        context = one_step_attention(a, s)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.B: Apply the post-attention LSTM cell to the "context" vector.</span></span><br><span class="line">        <span class="comment"># Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)</span></span><br><span class="line">        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)</span></span><br><span class="line">        out = output_layer(s)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.D: Append "out" to the "outputs" list (≈ 1 line)</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)</span></span><br><span class="line">    model = Model(inputs=[X, s0, c0], outputs=outputs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></li>
</ol>
<p>然后可以使用 <span class="math inline">\(summary()\)</span> 查看模型概况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<h2 id="优化">优化</h2>
<p>创建完模型后则需要需要定义损失函数、优化器和度量标准：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.005</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=opt, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>最后定义拟合模型的输入和输出，拟合模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s0 = np.zeros((m, n_s))</span><br><span class="line">c0 = np.zeros((m, n_s))</span><br><span class="line">outputs = list(Yoh.swapaxes(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">model.fit([Xoh, s0, c0], outputs, epochs=<span class="number">1</span>, batch_size=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h2 id="可视化-attention">可视化 Attention</h2>
<p>可以通过输出 attention 层的输出 <span class="math inline">\(\alpha^{\langle t, t&#39; \rangle}\)</span> 来可视化 Attention (实现细节可看 <code>mnt_utils.py</code>)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, <span class="string">"Tuesday 09 Oct 1993"</span>, num = <span class="number">7</span>, n_s = <span class="number">64</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/09/10/neural-machine-translation/output.png"></p>
<p>可以看到输出忽略了 "Tuesday"，在输出日期的时候，注意力明显也是放在输入的日期上，虽然图中月份部分翻译的注意力不是很明显。</p>
<h2 id="总结">总结</h2>
<p>机器翻译模型可以将输入的序列匹配成别的序列，注意力机制则可以允许网络在输出时聚焦于与输入相关的部分。总之，这个实验更加强化了 Encoder-Decoder 模型，首先将序列编码成一个定长表示，然后再解码成其他序列。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Master Method(主定理)</title>
    <url>/2016/07/30/master-method/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>大二学习数据结构的时候记得老师并没有详细讲如何求时间复杂度，在学习&lt;<算法导论>&gt;的时候，视频里面的老师花了很多精力来讲如何求时间复杂度，学到了一个定理，觉得很有必要自己推导一遍并且记录下来。</算法导论></p>
<a id="more"></a>
<h2 id="主定理">主定理</h2>
<blockquote>
<p>在算法分析中，主定理提供了用渐进符号表示许多由分治法得到的递推关系的方法。</p>
</blockquote>
<h3 id="渐进符号">渐进符号</h3>
<p>学习算法分析之前，首先要学习几个渐进符号的概念，分别是大O和小o、大Ω和小ω，还有一个大Θ。</p>
<h4 id="渐进上界-οo">渐进上界: Ο(O)</h4>
<p><span class="math display">\[
 f(n) = {O(g(n))}
\]</span></p>
<p><span class="math inline">\(∃ c, n\)</span><sub><span class="math inline">\(&lt;\)</span></sub>(<span class="math inline">\(c, n\)</span><sub><span class="math inline">\(&lt;\)</span></sub>为正数常数)，使得 <span class="math inline">\(∀ n ≥ n\)</span><sub><span class="math inline">\(&lt;\)</span></sub> 时，<span class="math inline">\(0 ≤ f(n) ≤ cg(n)\)</span>，该符号渐进给出了一个函数的上界，类似于小于等于。</p>
<h4 id="渐进下界-ωomega">渐进下界: Ω(Omega)</h4>
<p><span class="math display">\[
 f(n) = {Ω(g(n))}
\]</span></p>
<p><span class="math inline">\(∃ c, n\)</span><sub><span class="math inline">\(&lt;\)</span></sub>(<span class="math inline">\(c, n\)</span><sub><span class="math inline">\(&lt;\)</span></sub> 为正数常数)，使得 <span class="math inline">\(∀ n ≥ n\)</span><sub><span class="math inline">\(&lt;\)</span></sub> 时，<span class="math inline">\(0 ≤ cg(n) ≤ f(n)\)</span>，该符号渐进给出了一个函数的下界，类似于大于等于。</p>
<h4 id="渐进确界-θtheta">渐进确界: Θ(Theta)</h4>
<p><span class="math display">\[
 f(n) = {Θ(g(n))}
\]</span></p>
<p><span class="math inline">\(∃ c\)</span><sub><span class="math inline">\(&lt;\)</span></sub>, <span class="math inline">\(c\)</span><sub><span class="math inline">\(&lt;\)</span></sub>, <span class="math inline">\(n\)</span><sub><span class="math inline">\(&lt;\)</span></sub>(c$<sub><span class="math inline">\(1\)</span></sub>, <span class="math inline">\(c\)</span><sub><span class="math inline">\(2\)</span></sub>, <span class="math inline">\(n\)</span><sub><span class="math inline">\(0\)</span></sub>为正数常数)，使得 <span class="math inline">\(∀ n ≥ n\)</span><sub><span class="math inline">\(0\)</span></sub> 时，<span class="math inline">\(0 ≤ c\)</span><sub><span class="math inline">\(1\)</span></sub><span class="math inline">\(g(n) ≤ f(n) ≤ c\)</span><sub><span class="math inline">\(2\)</span></sub><span class="math inline">\(g(n)\)</span>，该符号渐进给出了一个函数的上界和下界，<span class="math inline">\(Θ(g(n)) = O(g(n)) ∩ Ω(g(n))\)</span>。</p>
<h4 id="非渐进紧确上界-οo">非渐进紧确上界: ο(O)</h4>
<p><span class="math display">\[
 f(n) = {o(g(n))}
\]</span></p>
<p><span class="math inline">\(∃ c, n\)</span><sub><span class="math inline">\(0\)</span></sub>(<span class="math inline">\(c, n\)</span><sub><span class="math inline">\(0\)</span></sub> 为正数常数)，使得 <span class="math inline">\(∀ n ≥ n\)</span><sub><span class="math inline">\(0\)</span></sub> 时，<span class="math inline">\(0 ≤ f(n) &lt; cg(n)\)</span>，该符号渐进给出了一个函数的非渐近紧确的上界，类似于小于。</p>
<h4 id="ωomega">ω(Omega)</h4>
<p><span class="math display">\[
f(n) = {ω(g(n))}
\]</span></p>
<p><span class="math inline">\(∃ c, n\)</span><sub><span class="math inline">\(&lt;\)</span></sub>(<span class="math inline">\(c, n\)</span><sub><span class="math inline">\(&lt;\)</span></sub> 为正数常数)，使得 <span class="math inline">\(∀ n ≥ n\)</span><sub><span class="math inline">\(&lt;\)</span></sub> 时，<span class="math inline">\(0 ≤ cg(n) &lt; f(n)\)</span>，该符号渐进给出了一个函数的非渐近紧确的上界，类似于大于。</p>
<h3 id="递归方程">递归方程</h3>
<p><span class="math display">\[
T(n) = aT(\frac{n}b) + f(n), a ≥ 1，b &gt; 1, f(n)为函数，T(n)为非负整数
\]</span></p>
<p>在分治法中我们需要将一个问题规模为 <span class="math inline">\(n\)</span> 的大问题，分解成 <span class="math inline">\(a\)</span> 个递归小问题，每个子问题的问题规模为 <span class="math inline">\(n/b\)</span>，<span class="math inline">\(f(n)\)</span> 为递推以外进行的计算工作，例如合并子问题的结果。</p>
<h3 id="递归树">递归树</h3>
<p>令树的高度为 <span class="math inline">\(h\)</span>，则</p>
<p><span class="math display">\[
\frac{n}{b^h} = 1 → h = \log_{b}n
\]</span></p>
叶子节点数为:
<center>
<span class="math inline">\(a\)</span><sup><span class="math inline">\(h\)</span></sup> = <span class="math inline">\(a\)</span><sup><span class="math inline">\(log\)</span><sub><span class="math inline">\(b\)</span></sub><sup><span class="math inline">\(n\)</span></sup></sup> = <span class="math inline">\(a\)</span><sup><span class="math inline">\(log\)</span><sub><span class="math inline">\(a\)</span></sub><sup><span class="math inline">\(n\)</span><sup></sup></sup>/<span class="math inline">\(log\)</span><sub><span class="math inline">\(a\)</span></sub><sup><span class="math inline">\(b\)</span><sup></sup></sup></sup> = <span class="math inline">\(n\)</span><sup><span class="math inline">\(1\)</span>/<span class="math inline">\(log\)</span><sub><span class="math inline">\(a\)</span></sub><sup><span class="math inline">\(b\)</span><sup></sup></sup></sup> = <span class="math inline">\(n\)</span><sup><span class="math inline">\(log\)</span><sub><span class="math inline">\(b\)</span></sub><sup><span class="math inline">\(a\)</span></sup></sup>
</center>
<h4 id="fn-为多项式">1. f(n) 为多项式</h4>
<p>因为 <span class="math inline">\(f(n)\)</span> 是多项式，设 <span class="math inline">\(f(n) = O(n\)</span><sup><span class="math inline">\(k\)</span></sup><span class="math inline">\(), k ≥ 0\)</span>. 则</p>
<p><span class="math display">\[
\begin{align} 
T(n) &amp; = n^k + a(\frac{n}{b})^k + a^2(\frac{n}{b^2})^k + ... + a^h(\frac{n}{b^h})^k \\\
&amp; = n^k(1 + (\frac{a}{b^k}) + (\frac{a}{b^k})^2 + ... + (\frac{a}{b^k})^h) \\\
\end{align}
\]</span></p>
<p>括号中间为等比数列前 <span class="math inline">\(h + 1\)</span> 项和 <span class="math inline">\(S\)</span><sub><span class="math inline">\(h + 1\)</span></sub>，首项 <span class="math inline">\(a\)</span><sub><span class="math inline">\(1\)</span></sub> 为1，公比 <span class="math inline">\(q\)</span> 为 <span class="math inline">\(a/b\)</span><sup><span class="math inline">\(k\)</span></sup>.</p>
<p>等比数列前 <span class="math inline">\(n\)</span> 项和公式为</p>
<p><span class="math display">\[
f(n) =
\begin{cases}
a_1\frac{1 - q^n}{1 - q} &amp; \text{$q$  ≠ 1} \\\
na_1 &amp; \text{$q$ = 1}  \\\
\end{cases}
\]</span></p>
<p>所以 1.当 <span class="math inline">\(q = 1\)</span> 时，即 <span class="math inline">\(a/b\)</span><sup><span class="math inline">\(k\)</span></sup> <span class="math inline">\(= 1\)</span></p>
<p><span class="math display">\[
\begin{align} 
T(n) &amp; = n^k(h+1) \\\
 &amp; = O(n^kh) \\\ 
 &amp; = O(n^k\log_{b}n) &amp; \text{代入 $h$} \\\
\end{align}
\]</span></p>
<p>2.当 <span class="math inline">\(q ≠ 1\)</span> 时，即 <span class="math inline">\(a/b\)</span><sup><span class="math inline">\(k\)</span></sup> <span class="math inline">\(≠ 1\)</span></p>
<p><span class="math display">\[
\begin{align} 
T(n) &amp; = n^k\frac{1 - (a/b^k)^{h+1}}{1 - a/b^k} \\\
 &amp; ≥ \frac{n^k - n^k(a/b^k)^h}{1 - a/b^k} \\\
 &amp; = \frac{n^k - n^{\log_{b}a}}{1 - a/b^k} &amp; \text{代入 $h$} \\\
\end{align}
\]</span></p>
<ul>
<li>如果 k &gt; <span class="math inline">\(log\)</span><sub><span class="math inline">\(b\)</span></sub><sup><span class="math inline">\(a\)</span></sup>，则</li>
</ul>
<p><span class="math display">\[
T(n) = O(n^k)
\]</span></p>
<ul>
<li>如果 k &lt; <span class="math inline">\(log\)</span><sub><span class="math inline">\(b\)</span></sub><sup><span class="math inline">\(a\)</span></sup>，则</li>
</ul>
<p><span class="math display">\[
T(n) = O(n^{\log_{b}a})
\]</span></p>
<h4 id="fn-为一般函数">2. f(n) 为一般函数</h4>
<p>当 <span class="math inline">\(f(n)\)</span> 为一般函数时有时候不一定能求出最终的解，通过递归树和等差等比数列的求和公式有些情况下还是可以求出最终解。</p>
<p><span class="math display">\[
T(n) = aT(n/b) + nlgn
\]</span></p>
<p>由递归树得:</p>
<p><span class="math display">\[
\begin{align}
T(n) &amp; = nlgn + a\frac{n}{b}(lgn - lgb) + a^2\frac{n}{b^2}(lgn - lgb^2) + ... + a^h\frac{n}{b^h}(lgn - lgb^h) \\\
 &amp; = n[lgn + \frac{a}{b}(lgn - lgb) + (\frac{a}{b})^2(lgn - 2lgb) + ... + (\frac{a}{b})^h(lgn - hlgb)] \\\
\end{align}
\]</span></p>
<ul>
<li>当 <span class="math inline">\(a = b\)</span> 时</li>
</ul>
<p><span class="math display">\[
\begin{align}
T(n) &amp; = n[(h + 1)lgn - h\frac{lgb + hlgb}{2}] \\\
 &amp; = O(n(lgn)^2)
\end{align}
\]</span></p>
<ul>
<li>当 <span class="math inline">\(a ≠ b\)</span> 时，得到一个等差等比数列相乘的数列，通过错位相减法计算:</li>
</ul>
<p><span class="math display">\[
\begin{align}
\frac{T(n)}{n} - lgn &amp; = \frac{a}{b}(lgn - lgb) + (\frac{a}{b})^2(lgn - 2lgb) + ... + (\frac{a}{b})^h(lgn - hlgb) &amp; ①\\\
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{align}
(\frac{a}{b})(\frac{T(n)}{n} - lgn) &amp; =  (\frac{a}{b})^2(lgn - lgb) + (\frac{a}{b})^3(lgn - 2lgb) + ... + (\frac{a}{b})^{h + 1}(lgn - hlgb) &amp; ②\\\
\end{align}
\]</span></p>
<p>① - ②， 得</p>
<p><span class="math display">\[
\begin{align}
(1 - \frac{a}{b})(\frac{T(n)}{n} - lgn) &amp; = \frac{a}{b}(lgn - lgb) - lgb[(\frac{a}{b})^2 + (\frac{a}{b})^3 + ... + (\frac{a}{b})^h] - (\frac{a}{b})^{h + 1}(lgn - hlgb) \\\
 &amp; = \frac{a}{b}(lgn - lgb) - lgb[(\frac{a}{b})^2\frac{1 - (a / b) ^ {h - 1}}{1 - a / b})] - (\frac{a}{b})^{h + 1}(lgn - hlgb) \\\
\end{align}
\]</span></p>
<p>化简得:</p>
<p><span class="math display">\[
T(n) = O(nlgn - n^{\log_{b}a}lgn)
\]</span></p>
<ul>
<li>当 <span class="math inline">\(a &gt; b\)</span> 时</li>
</ul>
<p><span class="math display">\[
T(n) = O(n^{\log_{b}a}lgn)
\]</span></p>
<ul>
<li>当 <span class="math inline">\(a &lt; b\)</span> 时</li>
</ul>
<p><span class="math display">\[
T(n) = O(nlgn)
\]</span></p>
]]></content>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>风格迁移</title>
    <url>/2019/01/14/neural-style-transfer/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>我觉得卷积神经网络最神奇的应用就是风格迁移！大部分应用的思想都相差无几，重点就是如何构造损失函数，将我们的目标用损失函数的方式表示，让模型按照指定的方向去学习。</p>
<a id="more"></a>
<h2 id="可视化">可视化</h2>
<p>在学习风格迁移之前，首先了解一下卷积神经网络的可视化。训练好的 CNN 模型的隐藏层中的每一个滤波器对应一种特征，每一个滤波器与输入的图像进行卷积运算后经过激活层。如果输入的图像具有该滤波器对应的特征，那么经过激活层后就会被激活，即输出特征图对应的数值大于 0。可视化过程涉及到反卷积和反池化，具体过程可参考 Visualizing and Understanding Convolutional Networks [2]。<a href="https://github.com/yosinski/deep-visualization-toolbox" target="_blank" rel="noopener">DeepVis Toolbox</a> 是一个开源的可视化工具，可视化结果如下图所示：</p>
<p><img src="/2019/01/14/neural-style-transfer/example_bvlc-googlenet_bus.png"></p>
<p>图中可视化的是 GoogleNet，输入为一张公交车的图像，每个小方块表示一个滤波器。将滤波器反卷积和反池化回原图像，结果如左下角所示。</p>
<h2 id="风格迁移">风格迁移</h2>
<p>给定一张内容图像 C 和一张风格图像 S，风格迁移模型生成一张具有 C 的内容和 S 的风格图像 G。如下图所示：</p>
<p><img src="/2019/01/14/neural-style-transfer/perspolis_vangogh.png"></p>
<h3 id="迁移学习">迁移学习</h3>
<p>风格迁移任务中，需要提取图像的内容特征和风格特征，然后根据特征生成图像（初始化为一张随机噪声图）。通过构造损失函数，令模型学习生成的图像 G 具有 C 的内容和 S 的风格，训练完毕后给定任意两张图像都能生成它们的风格迁移图像。实验使用了迁移学习提取图像特征，首先在 ImageNet 上预训练了一个用于分类的 VGG-19 网络，然后直接应用过来提取图像特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = load_vgg_model(<span class="string">"pretrained-model/imagenet-vgg-verydeep-19.mat"</span>)</span><br></pre></td></tr></table></figure>
<p>使用 <code>tf.assign</code> 函数为模型输入数据，获取模型中间隐藏层的输出如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model[<span class="string">"input"</span>].assign(image)</span><br><span class="line">sess.run(model[<span class="string">"conv4_2"</span>])</span><br></pre></td></tr></table></figure>
<h3 id="代价函数">代价函数</h3>
<p>风格迁移的代价函数分为两部分：内容代价函数 <span class="math inline">\(J_{content}(C,G)\)</span> 和风格代价函数 <span class="math inline">\(J_{style}(S,G)\)</span>。完整的代价函数为： <span class="math display">\[
J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)
\]</span></p>
<p>其中 <span class="math inline">\(\alpha\)</span> 和 <span class="math inline">\(\beta\)</span> 是超参数，代码实现如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_cost</span><span class="params">(J_content, J_style, alpha = <span class="number">10</span>, beta = <span class="number">40</span>)</span>:</span></span><br><span class="line">    J = alpha * J_content + beta * J_style</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J</span><br></pre></td></tr></table></figure>
<h4 id="内容代价函数">内容代价函数</h4>
<p>由可视化可知，通常浅层的滤波器提取的特征都是一些简单的特征，例如边角和纹理；比较深的、靠近全连接层的滤波器提取的特征就比较高级，例如一些复杂的纹理或者对象的类别。因此我们需要将比较中间的卷积层的输出作为图像的内容特征，假设选择的层数为 <span class="math inline">\(l\)</span>，图像 C 经过该层激活函数后的输出为 <span class="math inline">\(a^{[l](C)}\)</span>，为了表示方便，后续内容将省略层数，用 <span class="math inline">\(a^{(C)}\)</span> 表示图像 C 的内容特征，同时后续内容实验会测试不同 <span class="math inline">\(l\)</span> 取值的影响。</p>
<p>那么如何衡量生成的图像 G 和 C 之间的内容匹配了多少？内容代价函数比较简单，就是计算 C 和 G 的内容特征图每个像素点的差异，然后进行归一化。计算公式如下所示： <span class="math display">\[
J_{content}(C,G) =  \frac{1}{4 \times n_H \times n_W \times n_C}\sum _{ \text{all entries}} (a^{(C)} - a^{(G)})^2
\]</span> 其中 <span class="math inline">\(n_H\)</span>、<span class="math inline">\(n_W\)</span> 和 <span class="math inline">\(n_C\)</span> 分别表示特征图的高、宽和通道数。为了<strong>便于理解</strong>，将 3 维的特征图展开成两维，如下所示：</p>
<p><img src="/2019/01/14/neural-style-transfer/reshape_loss.png"></p>
<p>由于 <code>reshape</code> 只是修改维度，而不改变填充顺序，因此需要先使用 <code>transpose</code> 对矩阵进行转置。使用 Tensorflow 实现内容代码函数分为以下三个步骤：</p>
<ol type="1">
<li>获取图像维度</li>
<li>展开 <span class="math inline">\(a_C\)</span> 和 <span class="math inline">\(a_G\)</span></li>
<li>计算内容损失</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_content_cost</span><span class="params">(a_C, a_G)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from a_G (≈1 line)</span></span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    <span class="comment"># Reshape a_C and a_G (≈2 lines)</span></span><br><span class="line">    a_C_unrolled = tf.reshape(tf.transpose(a_C, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]), [n_C, n_H * n_W, m])</span><br><span class="line">    a_G_unrolled = tf.reshape(tf.transpose(a_G, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]), [n_C, n_H * n_W, m])</span><br><span class="line">    <span class="comment"># compute the cost with tensorflow (≈1 line)</span></span><br><span class="line">    J_content = (<span class="number">1</span>/ (<span class="number">4</span>* n_H * n_W * n_C)) * tf.reduce_sum(tf.pow((a_G_unrolled - a_C_unrolled), <span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J_content</span><br></pre></td></tr></table></figure>
<p>计算过程中展开和不展开并不会影响矩阵元素之间的计算，而且 <code>transpose</code> 函数默认的参数 <code>perm</code> 可以省略。</p>
<h4 id="风格代价函数">风格代价函数</h4>
<p>图像的风格定义为 <span class="math inline">\(l\)</span> 层中各个通道之间激活项的相关系数，即风格矩阵（也叫 Gram 矩阵）。这里有个小问题就是风格矩阵用 <span class="math inline">\(G\)</span> 表示，生成的图像也是用 <span class="math inline">\(G\)</span> 表示。</p>
<h5 id="gram-矩阵">Gram 矩阵</h5>
<p>给定展开成两维的特征图矩阵，其由 <span class="math inline">\(n_C\)</span> 个横向量<span class="math inline">\((v_{1},\dots ,v_{n_H\times n_W})\)</span> 组成。根据定义，Gram 矩阵中每个元素的值 <span class="math inline">\({\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j}) }\)</span>，即 <span class="math inline">\(G_{ij}\)</span> 衡量滤波器 <span class="math inline">\(i\)</span> 的激活值 <span class="math inline">\(v_i\)</span> 和滤波器 <span class="math inline">\(j\)</span> 的激活值 <span class="math inline">\(v_j\)</span> 的相似性，如下图所示：</p>
<p><img src="/2019/01/14/neural-style-transfer/NST_GM.png"></p>
<p>输出的 Gram 矩阵的维度为 <span class="math inline">\((n_C, n_C)\)</span>，值得注意的是 <span class="math inline">\(G_{ii} = v_{i}^T v_{i}\)</span> 衡量的是图像中滤波器 <span class="math inline">\(i\)</span> 对应的特征的活跃性。假设 <span class="math inline">\(i\)</span> 对应水平纹理，<span class="math inline">\(G_{ii}\)</span> 的值越大就表示图像中水平纹理越多。通过计算各种特征之间的 <span class="math inline">\(G_{ij}\)</span> 即这些特征同时出现的可能性，就可以衡量一张图像的风格。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(A)</span>:</span></span><br><span class="line">    GA = tf.matmul(A, tf.transpose(A))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> GA</span><br></pre></td></tr></table></figure>
<h5 id="风格代价">风格代价</h5>
<p>我们的目标是最小化风格图像 S 和生成图像 G 之间的 Gram 矩阵的距离，这里只考虑第 <span class="math inline">\(l\)</span> 个隐藏层的风格（考虑的层数越多，风格越相似），其对应的风格代价计算公式如下所示： <span class="math display">\[
J_{style}^{[l]}(S,G)=\frac{1}{4\times {n_C}^2\times (n_H\times n_W)^2}\sum _{i=1}^{n_C}\sum_{j=1}^{n_C}(G^{(S)}\_{ij}-G^{(G)}\_{ij})^2
\]</span> 计算过程分为四个步骤：</p>
<ol type="1">
<li>获取风格矩阵的维度</li>
<li>展开 <span class="math inline">\(a_S\)</span> 和 <span class="math inline">\(a_G\)</span></li>
<li>计算 S 和 G 的风格矩阵</li>
<li>计算风格代价</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_layer_style_cost</span><span class="params">(a_S, a_G)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve dimensions from a_G (≈1 line)</span></span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Reshape the images to have them of shape (n_H*n_W, n_C) (≈2 lines)</span></span><br><span class="line">    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]))</span><br><span class="line">    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Computing gram_matrices for both images S and G (≈2 lines)</span></span><br><span class="line">    GS = gram_matrix(a_S)</span><br><span class="line">    GG = gram_matrix(a_G)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Computing the loss (≈1 line)</span></span><br><span class="line">    J_style_layer = (<span class="number">1.</span>/(<span class="number">4</span> * n_C**<span class="number">2</span> * (n_H*n_W)**<span class="number">2</span>)) * tf.reduce_sum(tf.pow((GS - GG), <span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J_style_layer</span><br></pre></td></tr></table></figure>
<h5 id="风格权值">风格权值</h5>
<p>综合考虑每个隐藏层的风格会令实验效果更好，因此对每个隐藏层的风格代价一个权值，进行加权平均：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">STYLE_LAYERS = [</span><br><span class="line">    (<span class="string">'conv1_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv2_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv3_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv4_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv5_1'</span>, <span class="number">0.2</span>)]</span><br></pre></td></tr></table></figure>
<p>整体的风格代价函数为： <span class="math display">\[
J_{style}(S,G) = \sum_{l} \lambda^{[l]} J^{[l]}_{style}(S,G)
\]</span> 其中 <span class="math inline">\(\lambda^{[l]}\)</span> 就是给定的 <code>STYLE_LAYERS[l]</code>。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_style_cost</span><span class="params">(model, STYLE_LAYERS)</span>:</span></span><br><span class="line">    <span class="comment"># initialize the overall style cost</span></span><br><span class="line">    J_style = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> layer_name, coeff <span class="keyword">in</span> STYLE_LAYERS:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select the output tensor of the currently selected layer</span></span><br><span class="line">        out = model[layer_name]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out</span></span><br><span class="line">        a_S = sess.run(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that when we run the session, this will be the activations drawn from the appropriate layer, with G as input.</span></span><br><span class="line">        a_G = out</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute style_cost for the current layer</span></span><br><span class="line">        J_style_layer = compute_layer_style_cost(a_S, a_G)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add coeff * J_style_layer of this layer to overall style cost</span></span><br><span class="line">        J_style += coeff * J_style_layer</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> J_style</span><br></pre></td></tr></table></figure>
<p>在循环中 <code>a_S</code> 和 <code>a_G</code> 都是选择同一隐藏层的激活值，但是前者使用了 <code>sess.run</code> 而后者没有。因此后续需要将生成的图像 G 作为输入，然后运行对话才可以得到具体 <code>a_G</code> 的值。</p>
<h3 id="解决优化问题">解决优化问题</h3>
<p>最后需要结合上述代码，实现风格迁移。实验分为以下几个步骤：</p>
<ol type="1">
<li><p>创建交互式会话</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reset the graph</span></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="comment"># Start interactive session</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure></li>
<li><p>载入 VGG19 模型、内容图像和风格图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = load_vgg_model(<span class="string">"pretrained-model/imagenet-vgg-verydeep-19.mat"</span>)</span><br><span class="line"></span><br><span class="line">content_image = scipy.misc.imread(<span class="string">"images/louvre_small.jpg"</span>)</span><br><span class="line">content_image = reshape_and_normalize_image(content_image)</span><br><span class="line">style_image = scipy.misc.imread(<span class="string">"images/monet.jpg"</span>)</span><br><span class="line">style_image = reshape_and_normalize_image(style_image)</span><br></pre></td></tr></table></figure></li>
<li><p>随机初始化生成图像（通过对内容图像添加大量噪声而不是完全随机，可以让生成的图像内容快速匹配）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">generated_image = generate_noise_image(content_image)</span><br><span class="line">imshow(generated_image[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>构建 Tensorflow 图模型</p>
<ul>
<li><p>通过 VGG19 模型运行内容图像，计算内容代价</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Assign the content image to be the input of the VGG model.  </span></span><br><span class="line">sess.run(model[<span class="string">'input'</span>].assign(content_image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select the output tensor of layer conv4_2</span></span><br><span class="line">out = model[<span class="string">'conv4_2'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a_C to be the hidden layer activation from the layer we have selected</span></span><br><span class="line">a_C = sess.run(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that when we run the session, this will be the activations drawn from the appropriate layer, with G as input.</span></span><br><span class="line">a_G = out</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the content cost</span></span><br><span class="line">J_content = compute_content_cost(a_C, a_G)</span><br></pre></td></tr></table></figure></li>
<li><p>通过 VGG19 模型运行风格图像，计算风格代价</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Assign the input of the model to be the "style" image </span></span><br><span class="line">sess.run(model[<span class="string">'input'</span>].assign(style_image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the style cost</span></span><br><span class="line">J_style = compute_style_cost(model, STYLE_LAYERS)</span><br></pre></td></tr></table></figure></li>
<li><p>计算整体代价、定义优化器和学习率</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">J = total_cost(J_content, J_style, alpha = <span class="number">10</span>, beta = <span class="number">40</span>)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(<span class="number">2.0</span>)</span><br><span class="line">train_step = optimizer.minimize(J)</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>初始化图模型，迭代输入<strong>生成的图像</strong>，更新生成的图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_nn</span><span class="params">(sess, input_image, num_iterations = <span class="number">200</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize global variables (you need to run the session on the initializer)</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the noisy input image (initial generated image) through the model. Use assign().</span></span><br><span class="line">    sess.run(model[<span class="string">'input'</span>].assign(input_image))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        <span class="comment"># Run the session on the train_step to minimize the total cost</span></span><br><span class="line">        sess.run(train_step)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the generated image by running the session on the current model['input']</span></span><br><span class="line">        generated_image = sess.run(model[<span class="string">'input'</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print every 20 iteration.</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            Jt, Jc, Js = sess.run([J, J_content, J_style])</span><br><span class="line">            print(<span class="string">"Iteration "</span> + str(i) + <span class="string">" :"</span>)</span><br><span class="line">            print(<span class="string">"total cost = "</span> + str(Jt))</span><br><span class="line">            print(<span class="string">"content cost = "</span> + str(Jc))</span><br><span class="line">            print(<span class="string">"style cost = "</span> + str(Js))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># save current generated image in the "/output" directory</span></span><br><span class="line">            save_image(<span class="string">"output/"</span> + str(i) + <span class="string">".png"</span>, generated_image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># save last generated image</span></span><br><span class="line">    save_image(<span class="string">'output/generated_image.jpg'</span>, generated_image)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> generated_image</span><br></pre></td></tr></table></figure></li>
</ol>
<p>运行模型 <code>model_nn(sess, generated_image)</code> 后即可得到保存在输出文件夹中的生成图像，实验为了节省时间直接设定好了所有超参数，例如风格权值 <code>STYLE_LAYERS</code>、迭代的次数和 <span class="math inline">\((\alpha, \beta)\)</span>。</p>
<h2 id="总结">总结</h2>
<p>深度学习具有各种各样的模型，这次实验是首次对图像的像素值进行更新优化而不是权值，由于不需要手动实现反向传播所以不算很难，但是还需要多了解 Tensorflow 的文档。收获比较大的就是将直观感觉用数学语言描述出来，即如何表示一张图像的内容和风格！然后才能设计合适的代价函数，让模型学习出我们想要的内容。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Matthew D Zeiler, Rob Fergus, (2013). Visualizing and Understanding Convolutional Networks(https://arxiv.org/abs/1311.2901)</li>
<li>Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style (<a href="https://arxiv.org/abs/1508.06576" class="uri" target="_blank" rel="noopener">https://arxiv.org/abs/1508.06576</a>)</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>单隐层神经网络</title>
    <url>/2018/05/19/neuron-network/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>Logistic 回归和 Softmax 回归解决的是线性分类问题，即不同类别之间可以被线性平面分隔开，所以相当于没有隐藏层的神经网络。对于线性不可分的数据，由于线性模型无法理解任何两个特征间的相互作用，所以就需要有隐藏层(使用了非线性激活函数)的神经网络提取特征，将线性不可分的数据变得线性可分。</p>
<a id="more"></a>
<p>从输入层到输出层，向前计算代价函数的过程称为前向传播。从输出层到输出层，向后使用链式法则计算梯度的过程称为反向传播，得到梯度后就可以使用梯度下降算法更新模型的参数。最后可以得到比 Logistic 回归复杂得多的模型，拟合能力强但是也容易过拟合，由于代价函数不是凸函数，所以会给优化带来一些困难。</p>
<h2 id="单隐层神经网络">单隐层神经网络</h2>
<p>单隐层神经网络相当于由多个对率回归模型组成。中间的隐藏层可以看成特征提取的过程，由于对率回归使用了非线性激活函数，所以通过特征提取，就可以把原本线性不可分的数据变得线性可分，最后通过输出层进行线性分类。</p>
<h3 id="特征提取">特征提取</h3>
<blockquote>
<p>隐藏层 <span class="math inline">\(\vec z=\sigma(W\vec x+\vec b)\)</span>，其中 <span class="math inline">\(\vec x\)</span> 是输入向量，<span class="math inline">\(\vec z\)</span> 是输出向量，<span class="math inline">\(W\)</span> 是权重矩阵，<span class="math inline">\(\vec b\)</span> 是偏移向量，<span class="math inline">\(\sigma()\)</span> 是激活函数。每一层仅仅是把输入 <span class="math inline">\(\vec x\)</span> 经过简单的操作得到 <span class="math inline">\(\vec y\)</span>。</p>
</blockquote>
<p>在线性代数或者计算机图形学中学过，空间中的物体乘以一个矩阵就可以对物体进行放大/缩小、升维/降维或者旋转；加上一个向量就可以进行平移；这里的非线性激活函数还可以让物体变弯曲，如果使用线性函数作为激活函数，那么无论神经网络有多少层，输出都是输入的线性组合。</p>
<p><img src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/hidden-layer.gif"></p>
<p>因此每层神经网络的作用就是对输入使用线性变换和非线性变换，通过最小化代价函数使得在输出空间中尽量线性可分；</p>
<p><img src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/success.gif"></p>
<p>如果神经网络学习的效果不好，就会导致在输出空间中不能线性可分。</p>
<p><img src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/fail.gif"></p>
<p>可以在斯坦福大学的网站中体验单隐层神经网络的运行过程 <a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" target="_blank" rel="noopener">ConvNetJS demo: Classify toy 2D data</a></p>
<h2 id="单隐层分类平面数据">单隐层分类平面数据</h2>
<p>以下内容基于 Deeplearning.ai 的 Neural Networks and DeepLearning 第三周的课程实验 <code>Planar data classification with one hidden layer</code>。</p>
<h3 id="数据集">数据集</h3>
<p>实验中通过添加噪声生成了一些非线性可分的二维数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># planar_utils.py 生成数据部分代码</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    ix = range(N*j,N*(j+<span class="number">1</span>))</span><br><span class="line">    t = np.linspace(j*<span class="number">3.12</span>,(j+<span class="number">1</span>)*<span class="number">3.12</span>,N) + np.random.randn(N)*<span class="number">0.2</span> <span class="comment"># theta</span></span><br><span class="line">    r = a*np.sin(<span class="number">4</span>*t) + np.random.randn(N)*<span class="number">0.2</span> <span class="comment"># radius</span></span><br><span class="line">    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]</span><br><span class="line">    Y[ix] = j</span><br></pre></td></tr></table></figure>
<p>实验中使用了 <code>sklearn.linear_model.LogisticRegressionCV()</code> 数据进行分类，由于数据线性不可分，因此测试集的准确率只有 47%，因此需要使用多层神经网络进行分类。</p>
<h3 id="神经网络模型">神经网络模型</h3>
<p>实验生成的数据是平面(二维)数据，因此输入是一个二维的向量，隐藏层具有四个神经元并且隐藏层使用的激活函数是 <code>Tanh</code> 函数，最后一层需要输出属于哪一类的概率，所以只能使用 Sigmoid 激活函数。</p>
<ul>
<li><p>Tanh 函数是双曲正切函数</p>
<p><img src="/2018/05/19/neuron-network/tanh.png"></p>
<p><span class="math display">\[
tanh(x)=\frac{sinhx}{coshx}=\frac{e^x-e^{-x}}{e^x+e^{-x}}
\]</span></p></li>
</ul>
<p><span class="math display">\[
  tanh&#39;(x)=sech^2x=1-tanh^2x
  \]</span></p>
<p>Tanh 和 Sigmoid 函数可以通过缩放平移重合，为什么 Tanh 函数表现更好？Deep Learning 中给出的解释是：因为 Tanh 函数经过原点，且在原点附近梯度比 Sigmoid 函数的梯度大，所以在训练过程中优化会比较容易。</p>
<p>Tanh 和 Sigmoid 函数能否拟合任意函数呢？不能！首先来看一下什么叫 <code>Squashing</code> (压扁；压制)函数：</p>
<blockquote>
<p>A function <span class="math inline">\(\Psi: R\to[0, 1]\)</span> is a squashing function if it is non-decreasing, <span class="math inline">\(\lim\limits_{\lambda \to \infty }{\Psi(\lambda)}=1\)</span> and <span class="math inline">\(\lim\limits_{\lambda \to -\infty }{\Psi(\lambda)}=0\)</span>.</p>
</blockquote>
<p>显然 Tanh 函数通过缩放平移和 Sigmoid 函数满足这个定义，那么 Squashing 函数有什么性质呢？Hornik 等人在 1989 年中的一篇文章中说道：即使单隐层神经网络，用任意的 Squashing 函数作为激活函数，当神经元数量足够多时，可以拟合任意的博雷尔可测(Borel measurable)函数。那么博雷尔不可测函数又是什么意思呢？</p>
<p>定义集合 <span class="math inline">\(S\)</span> 为一个博雷尔不可测集合，有 <span class="math display">\[
  f(x) =
  \begin{cases}
  0 &amp; x \not\in S \\\
  1 &amp; x \in S
  \end{cases}
  \]</span> 则函数 <span class="math inline">\(f(x)\)</span> 就是博雷尔不可测函数。那么博雷尔不可测集合又是什么呢？这就触及到我的知识盲区了，总之用 Squashing 函数拟合实际问题中的函数是绰绰有余的，也不难想象足够多的 Squashing 函数的线性组合确实能拟合很多函数了。</p>
<ul>
<li>模型结构：</li>
</ul>
<p>对于一个样本数据 <span class="math inline">\(x^{(i)}\)</span>，有： <span class="math display">\[
z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\tag{1}
\]</span></p>
<p><span class="math display">\[
a^{[1] (i)} = \tanh(z^{[1] (i)})\tag{2}
\]</span></p>
<p><span class="math display">\[
z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\tag{3}
\]</span></p>
<p><span class="math display">\[
\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})\tag{4}
\]</span></p>
<p><span class="math display">\[
y^{(i)}\_{prediction} =
\begin{cases}
1 &amp; \mbox{if}\quad a^{[2]\(i\)} &gt; 0.5 \\\
0 &amp; \mbox{otherwise} 
\end{cases}\tag{5}
\]</span></p>
<p>给定所有样本数据，代价函数为： <span class="math display">\[
J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \left(y^{(i)}\log(a^{[2] (i)}) + (1-y^{(i)})\log(1- a^{[2] (i)})\right)\tag{6}
\]</span> 这里的 <span class="math inline">\(a^{[2] (i)}\)</span> 就是最后一层(不算输入层即第二层)神经网络的输出，类似于对率回归中的 <span class="math inline">\(h_\theta(x^{(i)})\)</span>。</p>
<p>构建神经网络模型主要分为以下几部分：</p>
<ol type="1">
<li>定义神经网络结构(神经元的个数、隐藏层的层数等)</li>
<li>初始化模型参数</li>
<li>循环
<ul>
<li>实现前向传播(实现公式 1~4，得到预测值 <span class="math inline">\(\hat y\)</span>，即 <span class="math inline">\(a^{[2]}\)</span>)</li>
<li>计算代价(根据前向传播得到的预测值和测试集的标签，实现公式 6，得到代价)</li>
<li>实现反向传播，计算梯度</li>
<li>梯度下降更新模型参数</li>
</ul></li>
</ol>
<h4 id="定义神经网络结构">定义神经网络结构</h4>
<p>在生成的实验数据中，<code>X.shape = (2, 400)</code>、<code>y.shape = (1, 400)</code>，因此输入层的神经元个数 <span class="math inline">\(n^{[x]}=2\)</span>；隐藏层的神经元个数定义为 <span class="math inline">\(n^{[h]}=4\)</span>；输出层神经元的个数 <span class="math inline">\(n^{[y]}=1\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_sizes</span><span class="params">(X, Y)</span>:</span></span><br><span class="line">    n_x = X.shape[<span class="number">0</span>] <span class="comment"># size of input layer</span></span><br><span class="line">    n_h = <span class="number">4</span></span><br><span class="line">    n_y = Y.shape[<span class="number">0</span>] <span class="comment"># size of output layer</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (n_x, n_h, n_y)</span><br></pre></td></tr></table></figure>
<h4 id="初始化模型参数">初始化模型参数</h4>
<p>使用 <code>np.random.randn(a, b)</code> 初始化一个形状为 <code>(a, b)</code> 的矩阵，使其元素为标准正态分布中的样本。使用 <code>np.zeros((a, b))</code> 初始化一个形状为 <code>(a, b)</code> 的矩阵，使其各元素值为 0。</p>
<ul>
<li>如果权值全部初始化为相同的数，那么隐藏层中神经元的输出就都是一样的，通过归纳法可以归纳出这些隐藏层的神经元一直在计算完全一样的函数，所以需要随机初始化打破对称性；</li>
<li>如果权值全部初始化为 0，更加糟糕的是不管输入是什么，隐藏层中神经元的输出就都是 0；</li>
<li>如果初始化为比较大的数，那么就会导致激活函数输出的值比较大，梯度较小，梯度下降的速度较慢，所以需要初始化为 0 附近的随机数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">(n_x, n_h, n_y)</span>:</span></span><br><span class="line">    W1 = np.random.randn(n_h, n_x) * <span class="number">0.01</span></span><br><span class="line">    b1 = np.zeros((n_h, <span class="number">1</span>))</span><br><span class="line">    W2 = np.random.randn(n_y, n_h) * <span class="number">0.01</span></span><br><span class="line">    b2 = np.zeros((n_y, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;</span><br></pre></td></tr></table></figure>
<h4 id="循环">循环</h4>
<h5 id="前向传播">前向传播</h5>
<p>在前向传播计算预测值时需要缓存中间变量 <span class="math inline">\(A^{[1]}\)</span>，用于反向传播计算梯度 <span class="math inline">\(dW^{[2]}\)</span>。在实验中也缓存了所有中间变量包括 <span class="math inline">\(Z^{[1]}\)</span> 和 <span class="math inline">\(Z^{[2]}\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(X, parameters)</span>:</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line"></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = np.Tanh(Z1)</span><br><span class="line">    Z2 = np.dot(W2, A1) + b2</span><br><span class="line">    A2 = Sigmoid(Z2)</span><br><span class="line">    </span><br><span class="line">    cache = &#123;<span class="string">"Z1"</span>: Z1,</span><br><span class="line">             <span class="string">"A1"</span>: A1,</span><br><span class="line">             <span class="string">"Z2"</span>: Z2,</span><br><span class="line">             <span class="string">"A2"</span>: A2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A2, cache</span><br></pre></td></tr></table></figure>
<h5 id="计算代价">计算代价</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(A2, Y, parameters)</span>:</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>] <span class="comment"># number of example</span></span><br><span class="line"></span><br><span class="line">    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(<span class="number">1</span> - A2), <span class="number">1</span> - Y)</span><br><span class="line">    cost = - (<span class="number">1.0</span> / m) * np.sum(logprobs)</span><br><span class="line">    cost = np.squeeze(cost)     <span class="comment"># makes sure cost is the dimension we expect. </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h5 id="反向传播">反向传播</h5>
<p>为了快速计算，实验对所有样本数据使用向量化编程。同时为了表示简单，以下求导公式省去上标 <code>(i)</code>。所以对于一个样本数据的输入、隐藏层输入、隐藏层输出和标签分别用小写字母 <code>x</code>、<code>z</code>、<code>a</code> 和 <code>y</code> 表示；所有样本数据则对应大写字母 <code>X</code>、<code>Z</code>、<code>A</code> 和 <code>Y</code>。</p>
<ul>
<li>对于一个样本数据 <span class="math inline">\(x\)</span> (随机梯度下降)，有：</li>
</ul>
<p><span class="math display">\[
\mathscr{l}(\hat y, y)=-\left(y^{(i)}\log(a^{[2] (i)}) + (1-y^{(i)})\log(1- a^{[2] (i)})\right)
\]</span></p>
<p><span class="math display">\[
\begin{align}
dz^{[2]}=\frac{\partial{\mathscr{l}(\hat y, y)}}{\partial{z^{[2]}}} &amp; = -\left(\frac{y}{a^{[2]}}\sigma&#39;(z^{[2]})+\frac{1-y^{(i)}}{1-a^{[2]}}\sigma&#39;(z^{[2]})\right) \\\
&amp; = a^{[2]}-y
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{align}
dW^{[2]}=\frac{\partial{\mathscr{l}(\hat y, y)}}{\partial{z^{[2]}}}\frac{\partial{z^{[2]}}}{\partial{W^{[2]}}}
&amp; = dz^{[2]}a^{[1]\mathrm{T}}
\end{align}
\]</span></p>
<p><span class="math display">\[
db^{[2]}=\frac{\partial{\mathscr{l}(\hat y, y)}}{\partial{z^{[2]}}}\frac{\partial{z^{[2]}}}{\partial{b^{[2]}}}=dz^{[2]}
\]</span></p>
<p><span class="math display">\[
\begin{align}
dz^{[1]} = W^{[2]\mathrm{T}}dz^{[2]}*\left(1-tanh^2(z)\right) = W^{[2]\mathrm{T}}dz^{[2]}*(1-a^{[1]2})
\end{align}
\]</span></p>
<p><span class="math display">\[
dW^{[1]}=dz^{[1]}x^{\mathrm{T}}
\]</span></p>
<p><span class="math display">\[
db^{[1]}=dz^{[1]}
\]</span></p>
<p>导数写在左边还是右边？是否需要转置？点乘还是叉乘？在矩阵求导中有<a href="https://en.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">两种布局</a>：分子布局和分母布局，不同布局求导规则不一样 。但是在实验中，我们已知各个变量和导数的维度，所以只需要根据数据的维度计算选择布局即可(<span class="math inline">\(dfoo.shape=foo.shape\)</span>)。例如： <span class="math display">\[
dz^{[1]}=da^{[1]}*\frac{\partial{a^{[1]}}}{\partial{z^{[1]}}}=W^{[2]\mathrm{T}}dz^{[2]}*(1-a^{[1]2})
\]</span> <span class="math inline">\(m\)</span> 表示样本数量(<span class="math inline">\(m = 1\)</span>)，由于 <span class="math inline">\(a^{[1]}\)</span> 和 <span class="math inline">\(z^{[1]}\)</span> 只是进行了一个非线性变换，具有相同的维度，所以用点乘；所以只需要求 <span class="math inline">\(da^{[1]}\)</span> 且满足 <span class="math inline">\(da^{[1]}.shape=(n^{[h]}, m)\)</span>： <span class="math display">\[
(n^{[h]}, m) = (n^{[y]}, n^{[h]})^{\mathrm{T}}(n^{[y]}, m) = (n^{[h]}, n^{[y]})(n^{[y]}, m)
\]</span></p>
<ul>
<li>对于所有样本数据，有：</li>
</ul>
<p><span class="math display">\[
dZ^{[2]}=A^{[2]}-Y
\]</span></p>
<p><span class="math display">\[
dW^{[2]}=\frac{1}{m}dZ^{[2]}A^{[1]\mathrm{T}}
\]</span></p>
<p><span class="math display">\[
db^{[2]}=\frac{1}{m}\sum\limits_{i = 0}^{m}dZ^{[2]}
\]</span></p>
<p><span class="math display">\[
dZ^{[1]}=W^{[2]\mathrm{T}}dZ^{[2]}*(1-A^{[1]2})
\]</span> <span class="math display">\[
dW^{[1]}=\frac{1}{m}dZ^{[1]}X^{\mathrm{T}}
\]</span></p>
<p><span class="math display">\[
db^{[1]}=\frac{1}{m}\sum\limits_{i = 0}^{m}dZ^{[1]}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(parameters, cache, X, Y)</span>:</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    A1 = cache[<span class="string">'A1'</span>]</span><br><span class="line">    A2 = cache[<span class="string">'A2'</span>]</span><br><span class="line"></span><br><span class="line">    dZ2 = A2 - Y</span><br><span class="line">    dW2 = (<span class="number">1.0</span> / m) * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = (<span class="number">1.0</span> / m) * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dZ1 = np.dot(W2.T, dZ2) * (<span class="number">1</span> - np.power(A1, <span class="number">2</span>))</span><br><span class="line">    dW1 = (<span class="number">1.0</span> / m) * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = (<span class="number">1.0</span> / m) * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    grads = &#123;<span class="string">"dW1"</span>: dW1,</span><br><span class="line">             <span class="string">"db1"</span>: db1,</span><br><span class="line">             <span class="string">"dW2"</span>: dW2,</span><br><span class="line">             <span class="string">"db2"</span>: db2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure>
<h5 id="梯度下降更新模型参数">梯度下降更新模型参数</h5>
<blockquote>
<p>梯度下降规则：<span class="math inline">\(\theta = \theta - \alpha \frac{\partial J }{ \partial \theta }\)</span></p>
</blockquote>
<p>在<a href="/2018/03/10/Linear-regression/">线性回归</a>中总结过，在梯度下降中好的学习率可以快速收敛，不好的学习率则会发散(实验中默认学习率为1.2)，如下图所示：</p>
<p><img src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/sgd.gif"></p>
<p><img src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/sgd_bad.gif"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span><span class="params">(parameters, grads, learning_rate = <span class="number">1.2</span>)</span>:</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line"></span><br><span class="line">    dW1 = grads[<span class="string">"dW1"</span>]</span><br><span class="line">    db1 = grads[<span class="string">"db1"</span>]</span><br><span class="line">    dW2 = grads[<span class="string">"dW2"</span>]</span><br><span class="line">    db2 = grads[<span class="string">"db2"</span>]</span><br><span class="line"></span><br><span class="line">    W1 = W1 - learning_rate * dW1</span><br><span class="line">    b1 = b1 - learning_rate * db1</span><br><span class="line">    W2 = W2 - learning_rate * dW2</span><br><span class="line">    b2 = b2 - learning_rate * db2</span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">"W1"</span>: W1,</span><br><span class="line">                  <span class="string">"b1"</span>: b1,</span><br><span class="line">                  <span class="string">"W2"</span>: W2,</span><br><span class="line">                  <span class="string">"b2"</span>: b2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h3 id="集成模型">集成模型</h3>
<p>集成单隐层神经网络的所有模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model</span><span class="params">(X, Y, n_h, num_iterations = <span class="number">10000</span>, print_cost=False)</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    n_x = layer_sizes(X, Y)[<span class="number">0</span>]</span><br><span class="line">    n_y = layer_sizes(X, Y)[<span class="number">2</span>]</span><br><span class="line">    </span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_iterations):</span><br><span class="line">        A2, cache = forward_propagation(X, parameters)</span><br><span class="line">        cost = compute_cost(A2, Y, parameters)</span><br><span class="line">        grads = backward_propagation(parameters, cache, X, Y)</span><br><span class="line">        parameters = update_parameters(parameters, grads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<h3 id="预测">预测</h3>
<p>最后要根据神经网络的输出和阈值，预测输出，即实现公式 5：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(parameters, X)</span>:</span></span><br><span class="line">    A2, cache = forward_propagation(X, parameters)</span><br><span class="line">    predictions = A2 &gt; <span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure>
<h3 id="评估分析">评估分析</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parameters = nn_model(X, Y, n_h = <span class="number">4</span>, num_iterations = <span class="number">10000</span>, print_cost=<span class="literal">True</span>)</span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict(parameters, x.T), X, Y)</span><br><span class="line">plt.title(<span class="string">"Decision Boundary for hidden layer size "</span> + str(<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p>对实验数据进行学习分类，最后输出分类准确率高达 90%，通过调节隐藏层神经元个数，可以发现模型越大(隐藏层神经元越多)，则模型的拟合能力越强，但是达到一定程度后就会对训练集产生过拟合(可以添加正则化项避免过拟合)。本次实验数据结果发现隐藏层神经元个数为 5 的时候拟合能力最好。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] 吴恩达. DeepLearning.</p>
<p>[2] Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</p>
<p>[3] Hornik, K., Stinchcombe, M., &amp; White, H. (1989). Multilayer feedforward networks are universal approximators. <em>Neural networks</em>, <em>2</em>(5), 359-366.</p>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测</title>
    <url>/2018/12/19/object-detection/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>最近看了几篇关于漏洞检测的文章，将图像处理领域中的目标检测的思想运用到软件的漏洞检测中。话是这么说，但是通篇看下来，其实和目标检测关系并不大，说到底还是对代码行进行分类，判断是否有漏洞。借着这个机会，正好总结一些深度学习课程中的目标检测。</p>
<a id="more"></a>
<h2 id="概念">概念</h2>
<p>在学习目标检测之前首先来了解一下计算机视觉领域中的一些方向和概念，分别是图像分类、定位、语义分割、目标检测和实例分割。</p>
<ul>
<li><p>图像分类</p>
<p>图像分类指用事先确定好的类别来描述图片，例如二分类判断一张图片中是否有猫或者多分类判断图片中手势表示的数字，前面实验中的任务就是图像分类。经典的网络模型就是 LeNet、AlexNet 和 VGG 等等。</p></li>
<li><p>分类 + 定位</p>
<p>定位任务不仅要识别出图像中的目标是什么，还要给出其在图像中的位置信息。通常用一个矩形框把识别的目标框出来（有时候也有多个<strong>固定数量</strong>的目标），而我们通常采用两种方式在图像中表示一个矩形框：</p>
<ol type="1">
<li>(x1, y1, x2, y2)： 即给出矩形框左上角和右下角的坐标；</li>
<li>(x, y, w, h)：即给出矩形框的中心坐标和矩形框的长宽。</li>
</ol></li>
<li><p>目标检测</p>
<p>一幅图像中有多个目标而且目标的<strong>数量不固定</strong>，检测任务要尽可能多的将图像中的目标用矩形框定位出来，相当于对多个目标的定位。目标检测在计算机视觉领域中占据了核心地位，后面的实验也是围绕着目标检测展开。</p></li>
<li><p>语义分割</p>
<p>语义分割也叫语义场景标注，是对图像中所有像素进行分类，和目标检测任务不同的是同一个类别的不同实例不需要分割出来。例如图像中有多只猫，那么这些组成猫的像素就都分为同一类。</p></li>
<li><p>实例分割</p>
<p>实例分割要求更严格，相对于目标检测来说不再是用矩形框框出目标，相对于语义分割来说不再是对像素进行简单分类。而是要从像素层面上将目标和背景完全分离出来，分割的结果往往是找出目标的轮廓线。</p></li>
</ul>
<h2 id="目标定位">目标定位</h2>
<p>目标定位不仅关注特定目标的类别信息，还要求获得这一目标的位置信息。假设需要定位三类物体，网络最后则输出一个 8 维的向量，第一维表示图像中存在需要定位的目标的概率；第二到第五维表示目标的位置（中心和长宽）；最后三维则表示目标的类别。在训练的过程中，如果第一维为 0 则可以忽略其他维度，即损失函数与其他维度无关。可以对不同的维度使用不同的损失函数，例如对离散的分类结果使用交叉熵损失，对位置信息使用回归损失。</p>
<h3 id="landmark-定位">Landmark 定位</h3>
<p>除了对目标进行分类和定位之外，我们还可以对目标的关键特征点（Landmark）进行定位，即已知固定数量的目标，给出每个目标的位置。例如人脸识别，可以对人脸的一部分特征点的坐标进行定位检测，并且标记出来，如下图所示：</p>
<p><img src="/2018/12/19/object-detection/face.png"></p>
<p>该模型一共检测人脸 64 处特征点，加上是否是人脸的标志位，输出标签一共有 128+1 个值，通过检测人脸特征点可以进行情绪分类或者对脸部进行瘦脸美颜。除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示：</p>
<p><img src="/2018/12/19/object-detection/gesture.png"></p>
<h2 id="目标检测">目标检测</h2>
<p>目标检测的一种简单方法是滑动窗口算法，这种算法训练了一个 CNN 分类模型，只不过训练集的图像尺寸较小，尽量仅包含相应目标。模型训练完成后，在测试图片上选择大小适宜的窗口、合适的步长，进行从左到右、从上到下的滑动。每个窗口区域都输入之前训练好的模型进行识别判断。若判断有目标，则此窗口即为目标区域；若判断没有目标，则此窗口为非目标区域。不同大小的窗口如下图所示：</p>
<p><img src="/2018/12/19/object-detection/windows.png"></p>
<p>滑动窗口算法原理简单，但是滑动窗口的大小和步长都需要人为直观设定。滑动窗口过小或过大，步长过大均会降低目标检测正确率。而且每次滑动窗区域都要进行一次 CNN 网络计算，如果滑动窗口和步长较小，整个目标检测算法运行时间会很长。</p>
<h3 id="滑动窗口的卷积实现">滑动窗口的卷积实现</h3>
<p>窗口在滑动动过程中，其框中的像素会输入到模型中进行卷积运算。由于窗口之间重复的内容比较多，因此会有大量的重复运算。而使用卷积的方式实现滑动窗口算法则可以提高网络的运行速度，节约重复运算成本。</p>
<p>单个滑动窗口区域进入 CNN 网络模型进行识别判断时，模型包含全连接层。如果滤波器的大小和输入的图像一致，那么卷积层的操作过程就相当于全连接层，因此我们可以将全连接层转变成为卷积层，如下图所示：</p>
<p><img src="/2018/12/19/object-detection/1.png"></p>
<p>全连接层参数个数为 <span class="math inline">\((5\times 5\times 16)\times 400\)</span>，使用卷积层替换后一共需要 400 个 <span class="math inline">\(5\times 5\times 16\)</span> 的滤波器。参数个数与全连接层一样，输出也一样。那么卷积实现如何能够节约重复运算成本呢？我们逆向地去思考一下，一个窗口区域图像的目标检测如上图所示，那么一张完整的图像的目标检测呢？假设一张图像在滑动窗口的过程中一共产生 4 个区域，全连接层的形式就只能判断 4 次；而使用卷积实现的方式我们就可以输入整张图像，然后输出 <span class="math inline">\(2\times 2\)</span> 个 4 维向量，即只需要运行模型一次。如下图所示：</p>
<p><img src="/2018/12/19/object-detection/2.png"></p>
<p>窗口的大小为 <span class="math inline">\(14\times 14\)</span>，最后输出一个 4 维的向量。一张大一点的图像 <span class="math inline">\(16\times 16\)</span>，步长为 2，滑动窗口可以产生 4 个区域，因此通过模型可以输出一个 <span class="math inline">\(2\times 2\)</span> 的 4 维向量；一张更大的图像 <span class="math inline">\(28\times 28\)</span>，步长为 2，滑动窗口可以产生 64 个区域，模型输出一个 <span class="math inline">\(8\times 8\)</span> 的 4 维向量。因此通过卷积的形式实现滑动窗口算法，可以有效利用卷积的特点减少区域内容的重复计算，提高网络的运行速度，节约重复运算成本。</p>
<h3 id="边界框预测">边界框预测</h3>
<p>卷积方式实现的滑动窗口算法，使得在预测时计算的效率大大提高。但是其存在的问题是：不能输出最精准的边界框（Bounding Box）。如图所示，滑动窗口算法产生的滑窗（蓝色）不能完全涵盖目标，即不能输出精确的边界框。</p>
<p><img src="/2018/12/19/object-detection/bounding.png"></p>
<h4 id="交并比">交并比</h4>
<p>交并比（Intersection over Union，简称 IoU）通过计算两个边界框的交集和并集的比来评价对象检测算法，也就是上图中红框和蓝框的交集和并集之比。在目标检测任务中，通常约定交并比大于等于 0.5 就说检测正确。如果两个框完全重合，那么交并比就为 1。</p>
<h4 id="选择性搜索算法">选择性搜索算法</h4>
<p>如果暴力枚举各种各样的滑窗参数（大小和步长），那么也可以找到精确的边界框，但是这样时间开销比较大。那么应该如何优化呢？有人提出使用<strong>提议区域的方法</strong>（Region proposal method）创建目标检测的兴趣区域（Regions of Interest，简称 RoI），例如一张图像选 2000 个 RoI，这些区域之间可以互相重叠或者包含，然后再直接对这些区域进行识别判断。</p>
<p><strong>选择性搜索</strong>（Selective Search，简称 SS）[2] 算法就是一种提议区域的方法，它的主要观点是图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。首先，对输入图像进行分割算法产生许多小的子区域。其次，根据这些子区域之间相似性（相似性标准主要有颜色、纹理、大小等等）进行区域合并，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做外切矩形，生成 RoI。</p>
<p>基于以上思路，人们提出了区域卷积神经网络（Region-based CNN 或 Regions with CNN features，简称 R-CNN）[3]。下面将简单介绍 R-CNN 和它的一系列改进方法：Fast R-CNN [4]、Faster R-CNN [5] 以及掩码 R-CNN（Mask R-CNN）[6]，效果更好的 YOLO(You Only Look Once) [7] 算法将结合着课程实验介绍和实现。</p>
<h3 id="r-cnn">R-CNN</h3>
<p>目标检测 <span class="math inline">\(k\)</span> 种类别的 R-CNN 主要分为以下四个步骤：</p>
<ol type="1">
<li>对输入图像使用 SS 来选取大约 2000 个高质量的 RoI 。这些区域通常是在多个尺度下选取的，并具有不同的形状和大小，每个区域将被标注类别和真实边界框；</li>
<li>选取一个预训练的卷积神经网络，对模型进行微调使其分类数为 <span class="math inline">\(k+1\)</span>。将每个 RoI 裁剪缩放为网络需要的输入尺寸，并通过 CNN 前向传播计算和保存 RoI 的特征；</li>
<li>将每个 RoI 的特征连同其标注的类别作为一个样本，训练 <span class="math inline">\(k\)</span> 个 SVM 对目标分类。其中每个 SVM 用来判断样本是否属于某一个类别；</li>
<li>将每个 RoI 的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框。</li>
</ol>
<p>这个模型和我在自己论文中的思想有一定的相似性，都是单独训练几个模型：用于特征提取的模型和用于分类的模型。模型思路比较简单但是实现比较麻烦，这里值得注意的就是回归模型预测真实边界框，通过 SS 算法得到的边界框可能还不够精确。R-CNN 的主要性能瓶颈在于需要对每个 RoI 独立提取特征。由于这些区域通常有大量重叠，独立的特征提取会导致大量的重复计算。</p>
<h3 id="fast-r-cnn">Fast R-CNN</h3>
<p>为了使 R-CNN 更快，Girshick 提出了 Fast R-CNN。一个主要改进在于只对整个图像做卷积神经网络的前向计算；其次三个独立模型合并为了一个联合训练框架并共享计算结果（end-to-end 的形式）。它的主要计算步骤如下：</p>
<ol type="1">
<li>与 R-CNN 相比，Fast R-CNN 用来提取特征的 CNN 的输入是整个图像，而且这个网络通常会参与训练，即更新模型参数；</li>
<li>SS 在原图像上生成 <span class="math inline">\(n\)</span> 个 RoI，这些形状各异的区域需要映射到 CNN 的输出上；</li>
<li>将映射后的区域输入全连接层的时候需要固定的形状，与 R-CNN 裁剪缩放操作不同的是，Fast R-CNN 引入 RoI 池化层，将 CNN 输出的特征图和 SS 输出的 RoI 作为输入，提取 RoI 固定形状的特征；</li>
<li>通过全连接层将输出形状变换为 <span class="math inline">\(n×d\)</span>，其中 <span class="math inline">\(d\)</span> 为隐藏层节点个数；</li>
<li>类别预测时，将全连接层的输出的形状再变换为 <span class="math inline">\(n×q\)</span> 并使用 softmax 回归（q 为类别个数）。边界框预测时，将全连接层的输出的形状再变换为 <span class="math inline">\(n×4\)</span> 。也就是说，我们为每个 RoI 预测类别和边界框。</li>
</ol>
<p>Fast R-CNN 中提出的 RoI 池化层对每个区域的输出形状是可以直接指定的，例如指定每个区域输出的高和宽为 <span class="math inline">\((2, 2)\)</span>。假设某一 RoI 的高和宽为 <span class="math inline">\((5, 7)\)</span>，该窗口将被划分为形状为 <span class="math inline">\((2, 2)\)</span> 的子窗口网格，且每个子窗口的大小大约为 <span class="math inline">\((5/2)×(7/2)\)</span>。任一子窗口的高和宽要取整，其中的最大元素作为该子窗口的输出。因此，RoI 池化层可从形状各异的 RoI 中提取出形状相同的特征。</p>
<h3 id="faster-r-cnn">Faster R-CNN</h3>
<p>Fast R-CNN 存在的瓶颈是 SS，通常需要生成很多 RoI。Faster R-CNN 提出将 SS 替换成区域提议网络（Region Proposal Network，简称 RPN），通过训练的方式来获得只与检测目标类别有关的高质量区域，从而减少提议区域的生成数量，并保证目标检测的精度。</p>
<p>与 Fast R-CNN 相比，只有生成 RoI 的方法从 SS 变成了 RPN 而其他部分均保持不变。RPN 和最后的分类器的损失函数都是由两部分组成：分类的损失和边界框的回归损失。只不过 RPN 只需要进行二分类，即分析窗口中内容为目标还是背景，而不需要判断目标的类别。</p>
<p>文章使用了两种 CNN 来提取特征：Zeiler and Fergus（简称 ZF）网络和 Simonyan and Zisserman 网络（即 VGG-16）。前者输出的特征图为 256 通道，后者输出的特征图为 512 通道，以下内容均基于 VGG-16 网络作为卷积层。首先将输入 VGG-16 网络的图像缩放成 <span class="math inline">\(800\times 600\)</span>，网络下采样后 16 倍后输出的特征图大小为 <span class="math inline">\(50\times 37\times 512\)</span>，然后将其输入 RPN 网络提取感兴趣区域。</p>
<h4 id="rpn">RPN</h4>
<p>特征图中一共有 <span class="math inline">\(50\times 37\)</span> 个 512 维的向量，每一个 512 维特征向量都对应原图在卷积过程中滑窗产生的区域，如<a href="#滑动窗口的卷积实现">滑动窗口的卷积实现</a>所示。 相当于是将大小为 <span class="math inline">\(800\times 600\)</span> 的图像分割成 <span class="math inline">\(50\times 37\)</span> 个大小一样的区域，由于 VGG-16 卷积层的步长不等于滤波器的大小，因此这些区域之间有重叠但是覆盖了整张图像，最后 VGG-16 为每个区域提取了一个 512 维的特征向量，RPN 网络就是要找到每个区域中目标的边界框。</p>
<h5 id="锚框">锚框</h5>
<blockquote>
<p>以每个像素为中心生成多个大小和宽高比（aspect ratio）不同的边界框，这些边界框被称为锚框（anchor box）。</p>
</blockquote>
<p>如果多个待检测目标的中心在同一个区域内，我们首先根据数据集手工对原图上每一个区域生成各种各样形状和大小的锚框，保证锚框可以框住所有种类的目标。作者为每个区域手动指定了 <span class="math inline">\(k=9\)</span> 种不同大小和比例的锚框。</p>
<p>一共有 <span class="math inline">\(50\times 37\times 9=16650\)</span> 个锚框，基本上覆盖了所有可能出现的目标。这些人工指定锚框的内容大部分只有背景而且也很难精确地框中目标，给定一张人工标注好的图像，任何一个生成的锚框如果和人工标注的目标的边界框之间的 IoU &gt; 0.7，就可以认为该锚框的真实标签为前景并且得到其真实的边界框；IoU &lt; 0.3 则认为该锚框的真实标签为背景；其余的不参与训练。得到了锚框的真实标签，我们就可以对其进行训练，因此一个区域需要输出 <span class="math inline">\(2k\)</span> 个分数来进行二分类和 <span class="math inline">\(4k\)</span> 个值来进行边界框回归。</p>
<h5 id="提议区域">提议区域</h5>
<p>模型训练完毕后，我们就可以使用模型的前向传播部分对新的数据进行处理，步骤如下所示：</p>
<ol type="1">
<li>输入新的特征图，生成锚框，对所有的锚框进行边界框回归和分类；</li>
<li>对所有的锚框按照其为前景的分数进行排序，取前 6000 个；</li>
<li>对回归后的锚框进行处理，例如去除过长度或者宽度过小的锚框；</li>
<li>进行非极大值抑制，然后再次对所有的锚框按照其为前景的分数进行排序，取前 300 个作为提议区域输出。</li>
</ol>
<h5 id="非极大值抑制">非极大值抑制</h5>
<p>在对锚框进行边界框回归后，对于同一个目标，可能有多个边界框与其对应，于是我们就要用到非极大值抑制，来抑制那些冗余的框，其过程如下所示：</p>
<ol type="1">
<li>将所有框的得分排序，选中最高分及其对应的框，例如上图中 0.9；</li>
<li>遍历其余的框，如果和当前最高分框的 IoU 大于一定阈值（通常取 0.5），我们就将框删除，例如上图中 0.6;</li>
<li>从未处理的框中继续选一个得分最高的，例如上图中 0.8，重复上述过程。</li>
</ol>
<p>RPN 作为 Faster R-CNN 的一部分，是和整个模型一起训练得到的。即 Faster R-CNN 的目标函数既包括目标检测中的类别和边界框预测，也包括 RPN 中锚框的二元类别和边界框预测。最终 RPN 能够学习到如何生成高质量的RoI，从而在减少 RoI 数量的情况下也能保证目标检测的精度。</p>
<h3 id="mask-r-cnn">Mask R-CNN</h3>
<p>如果训练数据还标注了每个目标在图像上的像素级位置，那么 Mask R-CNN 能有效利用这些详尽的标注信息进一步提升目标检测的精度，例如进行实例分割，在每一个像素上都表示出来目标所属的具体类别。</p>
<p>Mask R-CNN 在 Faster R-CNN 的基础上做了修改，引入一个全卷积网络。即增加了一个分支，用于输出一个二值掩膜，如下图所示，最后输出一个 80 通道的 <span class="math inline">\(14\times 14\)</span> 的二值矩阵，分别表示是否 80 个分类中的某一类。</p>
<h4 id="roialign">RoIAlign</h4>
<p>RoI 池化层有两个步骤会产生区域不匹配的问题，假设 CNN 下采样倍数为 32，原图中 RoI 的大小为 <span class="math inline">\(665\times 665\)</span>，经过网络后对应的区域大小为 <span class="math inline">\(\frac{665}{32}\times \frac{665}{32}\)</span>，向下取整会产生区域不匹配问题，即映射回原图大小不一致；将 RoI 的特征图输入全连接网络之前需要固定形状，在划分 bins （对应图中的 sections）的时候如果无法整除也需要向下取整，再次产生区域不匹配的问题，对于目标检测比较小的目标、语义分割和实例分割任务影响就会比较大。因此作者提出了 RoIAlign，全程可以使用浮点数操作，不存在取整过程。假设原图大小为 <span class="math inline">\(800\times 800\)</span>，RoIAlign 的步骤如下所示：</p>
<p><img src="/2018/12/19/object-detection/5WG68S.jpg"></p>
<ol type="1">
<li>计算 RoI 在特征图中的边长，不取整，即边长为 <span class="math inline">\(\frac{665}{32}=20.78\)</span>；</li>
<li>假设输入全连接网络的特征为 <span class="math inline">\(7\times 7\)</span>，每个 bin 的大小不取整，即边长为 <span class="math inline">\(\frac{20.78}{7}=2.97\)</span>；</li>
<li>RoI 池化层得到的 bin 的边长是整数，然后输出整数。而 RoIAlign 需要对区域采样，例如采样点数为 4，用须线把 bin 平均分成 4 份，每一份取中心点位置的像素，即 <font color="red">x</font> 处的像素值；</li>
<li>每个 <font color="red">x</font> 处的像素值为其最邻近的四个值通过双线性插值得到。</li>
</ol>
<h5 id="双线性差值">双线性差值</h5>
<p>数值分析这门课学得最熟的也就是插值法了，首先是线性插值，给定 <span class="math inline">\((x_0, y_0)\)</span> 和 <span class="math inline">\((x_1, y_1)\)</span>，估计 <span class="math inline">\([x_0, x_1]\)</span> 区间内某一位置 <span class="math inline">\(x\)</span> 在直线上的 <span class="math inline">\(y\)</span> 值： <span class="math display">\[
y = \frac{x_1 - x}{x_1 - x_0}y_0 +\frac{x - x_0}{x_1 - x_0}y_1
\]</span> 双线性插值就是相继在两个坐标轴上做线性差值，先分别对 <font color="red">x</font> 上方两个像素值和下方的两个像素值在 <span class="math inline">\(x\)</span> 轴上进行线性插值得到 <span class="math inline">\(R_1\)</span> 和 <span class="math inline">\(R_2\)</span>，再由 <span class="math inline">\(R_1\)</span> 和 <span class="math inline">\(R_2\)</span> 在 $y $ 轴上进行线性插值得到最终结果。</p>
<h2 id="总结">总结</h2>
<p>粗略学习了以下 R-CNN 以及一些列的改进，首先是 R-CNN 使用选择性搜索算法，先找出一些边界框再分别输入 CNN，避免了滑动窗口算法边界框不准确的问题；其次是 Fast R-CNN 将整张图片输入 CNN 提取特征后再把边界框映射过去，避免了 R-CNN 再分析边界框的过程中重复运算的问题；然后是 Faster R-CNN 直接在网络里面学习找出高质量的边界框，避免了 Fast R-CNN 中选择性搜索算法盲目找边界框；最后是 Mask R-CNN 改进了 RoI 池化层，避免了 Faster R-CNN 中区域不匹配的问题，同时添加了一个分支用于掩码预测每一个像素的分类，最后可以做到语义分割和实例分割。</p>
<p>以上图片来自于《动手学深度学习》，发现这是大神李沐写的，该花点时间好好提升一下自己的代码水平了。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Van de Sande K E A, Uijlings J R R, Gevers T, et al. Segmentation as selective search for object recognition[C]//Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 2011: 1879-1886.</li>
<li>R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR, 2014.</li>
<li>Girshick, R. (2015). Fast r-cnn. arXiv preprint arXiv:1504.08083.</li>
<li>Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).</li>
<li>He, K., Gkioxari, G., Doll á r, P., &amp; Girshick, R. (2017, October). Mask R-CNN. In Computer Vision (ICCV), 2017 IEEE International Conference on (pp. 2980-2988). IEEE.</li>
<li>Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 779-788.</li>
<li>J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015. 1, 3, 6</li>
<li>《动手学深度学习》. http://zh.diveintodeeplearning.org/index.html</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>循环神经网络</title>
    <url>/2018/06/20/recurrent-neural-network/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>按照吴恩达 Deeplearning 系列课程，应该是先学卷积神经网络，但是自己的实验中要用到递归神经网络，感觉不能再拖了，就先学习一下序列模型这一章节。在普通的神经网络中，一般都是输入一个向量，然后输出一个向量或者通过 Sigmoid 函数后输出一个值。</p>
<a id="more"></a>
<h2 id="循环神经网络">循环神经网络</h2>
<p>循环神经网络 (Recurrent neural network) 是一类用于处理<strong>序列数据</strong>的神经网络。在普通的神经网络中，前一个输入和后一个输入没有关系；而在有时候需要网络在处理当前输入的时候，记住之前的输入的相关信息。如果将整个序列当成一个整体输入普通神经网络的话，则会遇到输入的长度不同(可通过填充解决)和参数量大的问题。</p>
<p>根据处理的问题，网络按结构可以分为以下几种：</p>
<ul>
<li>一对一：非 RNN 结构，例如图片分类</li>
<li>一对多：序列输出，例如生成图片的描述</li>
<li>多对一：序列输入，例如评论的情感分类</li>
<li>多对多：
<ul>
<li>序列输入和序列输出，例如机器翻译</li>
<li>同步序列输入和输出，例如视频的帧分类</li>
</ul></li>
<li>递归神经网络 (Recursive nerual network) 是空间上的展开，处理的是树状结构信息(例如语法树)；循环神经网络是时间上的展开(也叫时间递归神经网络)，处理的是序列结构信息； RNN 一般指循环神经网络。</li>
</ul>
<h2 id="前向传播">前向传播</h2>
<p>在同步序列输入和输出结构中，有 <span class="math inline">\(T_x=T_y\)</span> ，其结构如下图所示：</p>
<p><img src="/2018/06/20/recurrent-neural-network/rnn.png"></p>
<p>一共有 <span class="math inline">\(T_x\)</span> 个时间步，所以只需要实现一个时间步，然后循环 <span class="math inline">\(T_x\)</span> 次则可以实现 RNN 的前向传播。</p>
<h3 id="rnn-细胞">RNN 细胞</h3>
<p>一个循环神经网络可以看成是单个细胞(即时间步)的循环，所有细胞共享参数。细胞内部结构如下图所示：</p>
<p><img src="/2018/06/20/recurrent-neural-network/rnn_step_forward.png"></p>
<p>细胞的输入有当前(第 <span class="math inline">\(t\)</span> 个时间步)的输入 <span class="math inline">\(x^{\langle t\rangle}\)</span> 和之前的隐藏状态 <span class="math inline">\(a^{\langle t-1\rangle}\)</span> (包含了以前的信息)，输出有 <span class="math inline">\(a^{\langle t\rangle}\)</span> 和 <span class="math inline">\(\hat y^{\langle t\rangle}\)</span> 。在前向传播过程中，需要缓存各种值用于反向传播计算参数梯度，实现 RNN 细胞代码主要分为以下几个步骤：</p>
<ol type="1">
<li>用 <span class="math inline">\(tanh\)</span> 激活函数计算隐藏状态：<span class="math inline">\(a^{\langle t\rangle}=tanh(W_{aa}a^{\langle t-1\rangle}+W_{ax}x^{\langle t\rangle}+b_a)\)</span></li>
<li>用新的隐藏状态 <span class="math inline">\(a^{\langle t \rangle}\)</span> 计算预测值 <span class="math inline">\(\hat y^{\langle t\rangle}=softmax(W_{ya}a^{\langle t\rangle}+b_y)\)</span></li>
<li>缓存 <span class="math inline">\(a^{\langle t\rangle}, a^{\langle t-1\rangle}, x^{\langle t\rangle}\)</span></li>
<li>返回 <span class="math inline">\(a^{\langle t\rangle}, \hat y^{\langle t\rangle}\)</span> 和缓存</li>
</ol>
<p>一共有 <span class="math inline">\(m\)</span> 个样本数据，其中 <span class="math inline">\(x^{\langle t\rangle}\)</span> 的维度为 <span class="math inline">\((n_x, m)\)</span>，<span class="math inline">\(a^{\langle t\rangle}\)</span> 的维度为 <span class="math inline">\((n_a, m)\)</span>。代码中使用 <code>_prev</code> 表示上一个时间步 <span class="math inline">\(\langle t-1\rangle\)</span> ，<code>_next</code> 和 <code>t</code> 表示当前时间步 <span class="math inline">\(\langle t\rangle\)</span>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell_forward</span><span class="params">(xt, a_prev, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve parameters from "parameters"</span></span><br><span class="line">    Wax = parameters[<span class="string">"Wax"</span>]</span><br><span class="line">    Waa = parameters[<span class="string">"Waa"</span>]</span><br><span class="line">    Wya = parameters[<span class="string">"Wya"</span>]</span><br><span class="line">    ba = parameters[<span class="string">"ba"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute next activation state using the formula given above</span></span><br><span class="line">    a_next = np.tanh(np.dot(Wax, xt) + np.dot(Waa, a_prev) + ba)</span><br><span class="line">    <span class="comment"># compute output of the current cell using the formula given above</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wya, a_next) + by)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store values you need for backward propagation in cache</span></span><br><span class="line">    cache = (a_next, a_prev, xt, parameters)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a_next, yt_pred, cache</span><br></pre></td></tr></table></figure>
<h3 id="rnn-前向传播">RNN 前向传播</h3>
<p><img src="/2018/06/20/recurrent-neural-network/cell_rnn.png"></p>
<p>RNN 的前向传播主要分为以下几个步骤：</p>
<ol type="1">
<li>创建零向量 <span class="math inline">\(\boldsymbol{a}\)</span> 用于存储<strong>所有</strong>隐藏状态</li>
<li>初始化隐藏状态 <span class="math inline">\(a_0\)</span></li>
<li>循环所有时间步，当前时间步为 <span class="math inline">\(t\)</span>
<ul>
<li>使用 <code>run_cell_forward</code> 函数更新隐藏状态 <span class="math inline">\(a^{\langle t\rangle}\)</span> 和缓存</li>
<li>存储 <span class="math inline">\(a^{\langle t\rangle}\)</span> 到 <span class="math inline">\(\boldsymbol{a}\)</span> 中的第 <span class="math inline">\(t\)</span> 个位置</li>
<li>存储预测值 <span class="math inline">\(\hat y^{\langle t\rangle}\)</span> 到 <span class="math inline">\(\boldsymbol{\hat y}\)</span> 中</li>
<li>添加缓存到缓存列表中</li>
</ul></li>
<li>返回 <span class="math inline">\(\boldsymbol{a}, \boldsymbol{\hat y}\)</span> 和缓存列表</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(x, a0, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize "caches" which will contain the list of all caches</span></span><br><span class="line">    caches = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of x and Wy</span></span><br><span class="line">    n_x, m, T_x = x.shape</span><br><span class="line">    n_y, n_a = parameters[<span class="string">"Wya"</span>].shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize "a" and "y" with zeros</span></span><br><span class="line">    a = np.zeros((n_a, m, T_x))</span><br><span class="line">    y_pred = np.zeros((n_y, m, T_x))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize a_next</span></span><br><span class="line">    a_next = a0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop over all time-steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T_x):</span><br><span class="line">        <span class="comment"># Update next hidden state, compute the prediction, get the cache</span></span><br><span class="line">        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t], a_next, parameters)</span><br><span class="line">        <span class="comment"># Save the value of the new "next" hidden state in a</span></span><br><span class="line">        a[:,:,t] = a_next</span><br><span class="line">        <span class="comment"># Save the value of the prediction in y</span></span><br><span class="line">        y_pred[:,:,t] = yt_pred</span><br><span class="line">        <span class="comment"># Append "cache" to "caches"</span></span><br><span class="line">        caches.append(cache)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    caches = (caches, x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> a, y_pred, caches</span><br></pre></td></tr></table></figure>
<h3 id="长期依赖">长期依赖</h3>
<p>循环神经网络具有长期依赖的问题，在经过许多阶段传播后的梯度倾向于消失(大部分情况)或爆炸(很少而且容易发现，但对优化过程影响很大，可以使用梯度截断的方法解决)，因此只能学习到短期的依赖关系。以一个简单的、缺少非线性激活函数和输入 <span class="math inline">\(x\)</span> 的循环神经网络为例： <span class="math display">\[
a^{\langle t\rangle}=W_{aa}a^{\langle t-1\rangle}
\]</span></p>
<p><span class="math display">\[
a^{\langle t\rangle}=W_{aa}^ta^{\langle 0\rangle}
\]</span> 类似于深度神经网络，当 <span class="math inline">\(W_{aa}\)</span> 的特征值小于 1 时就会导致隐藏状态约等于 0。即 RNN 会忘了很久以前的信息，如果不需要用很久以前的信息(有意义的信息都在前<strong>几个</strong>时间步)就能估计输出 <span class="math inline">\(\hat y^{\langle t\rangle}\)</span> ，那么 RNN 效果也不错。而 LSTM 则可以很好得解决这个问题，可以记住更多时间步以前的信息。目前实际应用中最有效的序列模型称为门控 RNN (gated RNN)。包括基于长短期记忆 (Long Short-Term Memory, LSTM) 和基于门控循环单元 (gated recurrent unit, GRU) 网络。</p>
<h3 id="lstm-细胞">LSTM 细胞</h3>
<p>基于长短期记忆 (LSTM) 的网络的细胞结构如下图所示：</p>
<p><img src="/2018/06/20/recurrent-neural-network/LSTM.png"></p>
<p><strong>LSTM 最关键的地方就在于细胞的状态 <span class="math inline">\(c^{\langle t\rangle}\)</span>，即上图中上面横穿的水平线，这种结构能够很轻松地实现信息从整个细胞中穿过而不做改变(没有经过 <span class="math inline">\(tanh\)</span> 激活函数)，从而实现了长时期的记忆保留</strong>。可以参考反向传播时的分析，LSTM 通过门 (gates) 的结构来实现给细胞的状态添加或者删除信息。</p>
<h4 id="遗忘门">遗忘门</h4>
<p>假如我们希望用 LSTM 来跟踪主语是单数还是复数，如果主语从单数变成复数，我们需要忘记之前存储的状态。在 LSTM 中使用遗忘门 (<strong>F</strong>orget gate) 实现这一点： <span class="math display">\[
\Gamma_f^{\langle t\rangle}=\sigma(W_f[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_f)\tag{1}
\]</span> 其中 <span class="math inline">\(W_f\)</span> 是控制遗忘门行为的权重，遗忘门的输出 <span class="math inline">\(\Gamma_f^{\langle t \rangle}\)</span> 最后要作用于细胞的状态 (<span class="math inline">\(\Gamma_f^{\langle t\rangle}*c^{\langle t-1\rangle}\)</span>)，因此使用 <span class="math inline">\(sigmoid\)</span> 激活函数保证输出是一个 0，1 之间的向量，表示让 <span class="math inline">\(c^{\langle t-1\rangle}\)</span> 各部分信息通过的比例，0 表示不让任何信息通过，1 表示让所有信息通过。</p>
<h4 id="更新门">更新门</h4>
<p>类似于遗忘门，更新门 (<strong>U</strong>pdate gate) 也可以叫输入门 (<strong>I</strong>nput gate)，决定让多少新的信息加入到细胞状态中： <span class="math display">\[
\Gamma_u^{\langle t\rangle}=\sigma(W_u[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_u)\tag{2}
\]</span> 更新门的输出 <span class="math inline">\(\Gamma_u^{\langle t\rangle}\)</span> 要作用于新的信息 <span class="math inline">\(\tilde{c}^{\langle t\rangle}\)</span>，生成更新内容 <span class="math inline">\(\Gamma_u^{\langle t\rangle}*\tilde{c}^{\langle t\rangle}\)</span>，然后再添加到细胞的状态上： <span class="math display">\[
\tilde{c}^{\langle t\rangle}=\tanh(W_c[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_c)\tag{3}
\]</span></p>
<p><span class="math display">\[
c^{\langle t\rangle}=\Gamma_f^{\langle t\rangle}*c^{\langle t-1\rangle}+\Gamma_u^{\langle t\rangle}*\tilde{c}^{\langle t\rangle}\tag{4}
\]</span></p>
<h4 id="输出门">输出门</h4>
<p>输出门 (<strong>O</strong>utput gate) 的输出如下所示： <span class="math display">\[
\Gamma_o^{\langle t\rangle}=\sigma(W_o[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_o)\tag{5}
\]</span> 最后细胞的隐藏状态为： <span class="math display">\[
a^{\langle t \rangle}=\Gamma_o^{\langle t\rangle}*\tanh(c^{\langle t\rangle})\tag{6}
\]</span> 遗忘门、更新门和输出门的输入只取决于 <span class="math inline">\(a^{\langle t-1\rangle}\)</span> 和 <span class="math inline">\(x^{\langle t\rangle}\)</span>，如果还取决与上一个细胞的状态 <span class="math inline">\(c^{\langle t-1\rangle}\)</span> 则称为<strong>窥孔连接</strong>。类似于 RNN 细胞需要缓存各种值用于反向传播计算参数梯度，实现 LSTM 细胞代码主要分为以下几个步骤：</p>
<ol type="1">
<li>连接 <span class="math inline">\(a^{\langle t-1\rangle}\)</span> 和 <span class="math inline">\(x^{\langle t \rangle}\)</span> 到一个矩阵中：<span class="math inline">\(concat = \begin{bmatrix} a^{\langle t-1 \rangle} \\\ x^{\langle t \rangle} \end{bmatrix}\)</span></li>
<li>实现公式 <span class="math inline">\((1)-(6)\)</span></li>
<li>计算预测值 <span class="math inline">\(y^{\langle t \rangle}\)</span></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell_forward</span><span class="params">(xt, a_prev, c_prev, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve parameters from "parameters"</span></span><br><span class="line">    Wf = parameters[<span class="string">"Wf"</span>]</span><br><span class="line">    bf = parameters[<span class="string">"bf"</span>]</span><br><span class="line">    Wu = parameters[<span class="string">"Wu"</span>]</span><br><span class="line">    bu = parameters[<span class="string">"bu"</span>]</span><br><span class="line">    Wc = parameters[<span class="string">"Wc"</span>]</span><br><span class="line">    bc = parameters[<span class="string">"bc"</span>]</span><br><span class="line">    Wo = parameters[<span class="string">"Wo"</span>]</span><br><span class="line">    bo = parameters[<span class="string">"bo"</span>]</span><br><span class="line">    Wy = parameters[<span class="string">"Wy"</span>]</span><br><span class="line">    by = parameters[<span class="string">"by"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of xt and Wy</span></span><br><span class="line">    n_x, m = xt.shape</span><br><span class="line">    n_y, n_a = Wy.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Concatenate a_prev and xt</span></span><br><span class="line">    concat = np.zeros([n_a + n_x, m])</span><br><span class="line">    concat[:n_a,:] = a_prev</span><br><span class="line">    concat[n_a:,:] = xt</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute values for ft, ut, cct, c_next, ot, a_next using the formulas</span></span><br><span class="line">    ft = sigmoid(np.dot(Wf, concat) + bf)</span><br><span class="line">    ut = sigmoid(np.dot(Wu, concat) + bu)</span><br><span class="line">    cct = np.tanh(np.dot(Wc, concat) + bc)</span><br><span class="line">    c_next = ft * c_prev + ut * cct</span><br><span class="line">    ot = sigmoid(np.dot(Wo, concat) + bo)</span><br><span class="line">    a_next = ot * np.tanh(c_next)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute prediction of the LSTM cell</span></span><br><span class="line">    yt_pred = softmax(np.dot(Wy, a_next) + by)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    cache = (a_next, c_next, a_prev, c_prev, ft, ut, cct, ot, xt, parameters)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a_next, c_next, yt_pred, cache</span><br></pre></td></tr></table></figure>
<h3 id="lstm-前向传播">LSTM 前向传播</h3>
<p><img src="/2018/06/20/recurrent-neural-network/LSTM_rnn.png"></p>
<p>类似于 RNN 前向传播，只不过多了一个细胞的状态，所以需要初始化为 0 向量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span><span class="params">(x, a0, parameters)</span>:</span></span><br><span class="line">    <span class="comment"># Initialize "caches", which will track the list of all the caches</span></span><br><span class="line">    caches = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from shapes of xt and Wy</span></span><br><span class="line">    n_x, m, T_x = x.shape</span><br><span class="line">    n_y, n_a = parameters[<span class="string">'Wy'</span>].shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize "a", "c" and "y" with zeros</span></span><br><span class="line">    a = np.zeros([n_a, m, T_x])</span><br><span class="line">    c = np.zeros([n_a, m, T_x])</span><br><span class="line">    y = np.zeros([n_y, m, T_x])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize a_next and c_next</span></span><br><span class="line">    a_next = a0</span><br><span class="line">    c_next = np.zeros([n_a, m])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop over all time-steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T_x):</span><br><span class="line">        <span class="comment"># Update next hidden state, next memory state, compute the prediction, get the cache</span></span><br><span class="line">        a_next, c_next, yt, cache = lstm_cell_forward(x[:,:,t], a_next, c_next, parameters)</span><br><span class="line">        <span class="comment"># Save the value of the new "next" hidden state in a</span></span><br><span class="line">        a[:,:,t] = a_next</span><br><span class="line">        <span class="comment"># Save the value of the prediction in y</span></span><br><span class="line">        y[:,:,t] = yt</span><br><span class="line">        <span class="comment"># Save the value of the next cell state</span></span><br><span class="line">        c[:,:,t]  = c_next</span><br><span class="line">        <span class="comment"># Append the cache into caches</span></span><br><span class="line">        caches.append(cache)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># store values needed for backward propagation in cache</span></span><br><span class="line">    caches = (caches, x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a, y, c, caches</span><br></pre></td></tr></table></figure>
<h2 id="反向传播">反向传播</h2>
<p>在 DeepLearning 课程作业中，RNN 反向传播直接忽略了细胞的输出，没有考虑细胞的输出的误差对参数的梯度，降低了作业的难度，在 LSTM 反向传播中考虑了细胞的输出的误差对参数的梯度。</p>
<p>在预测输出的时候，RNN 使用了 Softmax 函数，关于 Softmax 函数的求导过程可以参考 <a href="/2018/04/26/Logistic-regression">Logistic 回归和 Softmax 回归</a>。RNN 在时间步上反向传播，因此也叫做 BackPropagation Through Time(BPTT) 算法。</p>
<h3 id="简单版-rnn-细胞">简单版 RNN 细胞</h3>
<p>没有输出只有隐藏状态的 RNN 细胞的反向传播过程如下图所示：</p>
<p><img src="/2018/06/20/recurrent-neural-network/rnn_cell_backprop.png"></p>
<p>由链式求导公式、复合求导公式和矩阵的求导公式或者参考<a href="/2018/05/19/Neuron-network">单隐层神经网络</a>可以推导出右边的表达式，其代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell_backward</span><span class="params">(da_next, cache)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve values from cache</span></span><br><span class="line">    (a_next, a_prev, xt, parameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve values from parameters</span></span><br><span class="line">    Wax = parameters[<span class="string">"Wax"</span>]</span><br><span class="line">    Waa = parameters[<span class="string">"Waa"</span>]</span><br><span class="line">    ba = parameters[<span class="string">"ba"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient of tanh with respect to a_next</span></span><br><span class="line">    dtanh = (<span class="number">1</span>-a_next * a_next) * da_next  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient of the loss with respect to Wax</span></span><br><span class="line">    dxt = np.dot(Wax.T,dtanh)</span><br><span class="line">    dWax = np.dot(dtanh, xt.T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient with respect to Waa</span></span><br><span class="line">    da_prev = np.dot(Waa.T,dtanh)</span><br><span class="line">    dWaa = np.dot(dtanh, a_prev.T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the gradient with respect to b</span></span><br><span class="line">    dba = np.sum(dtanh, keepdims=<span class="literal">True</span>, axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dxt"</span>: dxt, <span class="string">"da_prev"</span>: da_prev, <span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa, <span class="string">"dba"</span>: dba&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h3 id="rnn-反向传播">RNN 反向传播</h3>
<p>在 RNN 反向传播中不但要计算参数的梯度，也要计算 <span class="math inline">\(a^{\langle t\rangle}\)</span> 的梯度，这样才能将梯度反向传播到前一个 RNN 细胞，代码中还保存了输入的梯度到 <span class="math inline">\(dx\)</span> 中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(da, caches)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve values from the first cache (t=1) of caches</span></span><br><span class="line">    (caches, x) = caches</span><br><span class="line">    (a1, a0, x1, parameters) = caches[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from da's and x1's shapes</span></span><br><span class="line">    n_a, m, T_x = da.shape</span><br><span class="line">    n_x, m = x1.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the gradients with the right sizes</span></span><br><span class="line">    dx = np.zeros([n_x, m, T_x])</span><br><span class="line">    dWax = np.zeros([n_a, n_x])</span><br><span class="line">    dWaa = np.zeros([n_a, n_a])</span><br><span class="line">    dba = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    da0 = np.zeros([n_a, m])</span><br><span class="line">    da_prevt = np.zeros([n_a, m])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop through all the time steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T_x)):</span><br><span class="line">        <span class="comment"># Compute gradients at time step t. Choose wisely the "da_next" and the "cache" to use in the backward propagation step.</span></span><br><span class="line">        gradients = rnn_cell_backward(da[:,:,t] + da_prevt, caches[t])</span><br><span class="line">        <span class="comment"># Retrieve derivatives from gradients</span></span><br><span class="line">        dxt, da_prevt, dWaxt, dWaat, dbat = gradients[<span class="string">"dxt"</span>], gradients[<span class="string">"da_prev"</span>], gradients[<span class="string">"dWax"</span>], gradients[<span class="string">"dWaa"</span>], gradients[<span class="string">"dba"</span>]</span><br><span class="line">        <span class="comment"># Increment global derivatives w.r.t parameters by adding their derivative at time-step t</span></span><br><span class="line">        dx[:,:,t] = dxt</span><br><span class="line">        dWax += dWaxt</span><br><span class="line">        dWaa += dWaat</span><br><span class="line">        dba += dbat</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Set da0 to the gradient of a which has been backpropagated through all time-steps</span></span><br><span class="line">    da0 = da_prevt</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dx"</span>: dx, <span class="string">"da0"</span>: da0, <span class="string">"dWax"</span>: dWax, <span class="string">"dWaa"</span>: dWaa,<span class="string">"dba"</span>: dba&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h3 id="完整版-rnn-细胞">完整版 RNN 细胞</h3>
<p>完整的 RNN 细胞有输出，代价函数是所有时间步的输出的损失函数的和，对参数 <span class="math inline">\(W_{ya}\)</span> 和 <span class="math inline">\(b_y\)</span> 的求导比较简单，因为它们当前梯度只和当前时间步的损失函数相关： <span class="math display">\[
J=\sum_{t=1}^{T_x}J^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
\frac{\partial J}{\partial W_{ya}}=\sum_{t=1}^{T_x}(\hat y^{\langle t\rangle}-y^{\langle t\rangle})a^{\langle t\rangle T}
\]</span></p>
<p><span class="math display">\[
\frac{\partial J}{\partial b_y}=\sum_{t=1}^{T_x}\hat y^{\langle t\rangle}-y^{\langle t\rangle}
\]</span></p>
<p>参数 <span class="math inline">\(W_{aa}, b_a\)</span> 和 <span class="math inline">\(W_{ax}\)</span> 的梯度就比较复杂，因为它们的当前梯度不仅和当前时间步的损失函数相关，还和后面的时间步的损失函数相关。首先定义当前时间步的隐藏状态的梯度 <span class="math inline">\(\delta^{\langle t\rangle}\)</span>，其递推公式如下所示： <span class="math display">\[
\begin{align}
\delta^{\langle t\rangle}&amp;=\frac{\partial J}{\partial a^{\langle t\rangle}}=\frac{\sum_{i=t}^{T_x}\partial J^{\langle i\rangle}}{\partial a^{\langle t\rangle}} \\\
&amp;=\frac{\partial J^{\langle t\rangle}}{\partial a^{\langle t\rangle}}+\frac{\sum_{i=t+1}^{T_x}\partial J^{\langle i\rangle}}{\partial a^{\langle t+1\rangle}}\frac{\partial a^{\langle t+1\rangle}}{\partial a^{\langle t\rangle}} \\\
&amp;=W_{ya}^T(\hat y^{\langle t\rangle}-y^{\langle t\rangle})+W_{aa}^T\delta^{\langle t+1\rangle}diag(1-a^{\langle t+1\rangle2})\tag{1}
\end{align}
\]</span> 隐藏状态在时间步方向上的代价函数的梯度(即不考虑当前时间步的输出) 为 <span class="math inline">\(\delta^{\langle T_x\rangle}\prod_{i=t+1}^{T_x}W_{aa}^Tdiag(1-a^{\langle i\rangle2})\)</span>，当参数 <span class="math inline">\(W_{aa}^T\)</span> 小于 1 时就产生了梯度消失，即使使用 <span class="math inline">\(ReLU\)</span> 函数作为激活函数，梯度为 <span class="math inline">\(\delta^{\langle T_x\rangle}\prod_{i=t+1}^{T_x}W_{aa}^T\)</span>，也不能解决长期依赖问题。隐藏状态在最后一个时间步 <span class="math inline">\(\langle T_{x}\rangle\)</span> 梯度只由该时间步的损失函数相关，因为后面不再有损失函数，所以有： <span class="math display">\[
\delta^{\langle T_x\rangle}=\frac{\partial J}{\partial a^{\langle T_x\rangle}}=\frac{\partial J^{\langle T_x\rangle}}{\partial a^{\langle T_x\rangle}}=W_{ya}^T(\hat y^{\langle t\rangle}-y^{\langle t\rangle})\tag{2}
\]</span> 根据 <span class="math inline">\((1)\)</span> 和 <span class="math inline">\((2)\)</span> 递推公式可以求得 <span class="math inline">\(\delta^{\langle t\rangle}\)</span>，有了 <span class="math inline">\(\delta^{\langle t\rangle}\)</span> 就可以很轻松地求解参数 <span class="math inline">\(W_{aa}, b_a\)</span> 和 <span class="math inline">\(W_{ax}\)</span> 的梯度： <span class="math display">\[
\frac{\partial J}{\partial W_{aa}}=\sum_{t=1}^{T_x}\frac{\partial J}{\partial a^{\langle t\rangle}}\frac{\partial a^{\langle t\rangle}}{\partial W_{aa}}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})\delta^{\langle t\rangle}a^{\langle t-1\rangle T}
\]</span></p>
<p><span class="math display">\[
\frac{\partial J}{\partial b_a}=\sum_{t=1}^{T_x}\frac{\partial J}{\partial a^{\langle t\rangle}}\frac{\partial a^{\langle t\rangle}}{\partial b_a}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})\delta^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
\frac{\partial J}{\partial W_{ax}}=\sum_{t=1}^{T_x}\frac{\partial J}{\partial a^{\langle t\rangle}}\frac{\partial a^{\langle t\rangle}}{\partial W_{ax}}=\sum_{t=1}^{T_x}diag(1-a^{\langle t\rangle2})\delta^{\langle t\rangle}x^{\langle t\rangle T}
\]</span></p>
<h3 id="lstm-细胞-1">LSTM 细胞</h3>
<p>LSTM 的细胞结构比较复杂，反向传播的公式也比较难，关于隐藏状态的梯度公式和普通 RNN 类似。参数的梯度不仅和当前时间步的损失函数相关(通过隐藏状态 <span class="math inline">\(a^{\langle t\rangle}\)</span>)，还和后面的时间步的损失函数相关(通过细胞的状态 <span class="math inline">\(c^{\langle t\rangle}\)</span>)。定义当前时间步的细胞状态的梯度 <span class="math inline">\(\delta^{\langle t\rangle}\)</span>，其递推公式如下所示： <span class="math display">\[
\begin{align}
\delta^{\langle t\rangle}&amp;=\frac{\partial J}{\partial c^{\langle t\rangle}}=\frac{\sum_{i=t}^{T_x}\partial J^{\langle i\rangle}}{\partial c^{\langle t\rangle}} \\\
&amp;=\frac{\partial J^{\langle t\rangle}}{\partial c^{\langle t\rangle}}+\frac{\sum_{i=t+1}^{T_x}\partial J^{\langle i\rangle}}{\partial c^{\langle t+1\rangle}}\frac{\partial c^{\langle t+1\rangle}}{\partial c^{\langle t\rangle}} \\\
&amp;=\frac{\partial J^{\langle t\rangle}}{\partial c^{\langle t\rangle}}+\delta^{\langle t+1\rangle}\Gamma_f^{\langle t\rangle}
\end{align}
\]</span> 细胞状态在时间步方向上的代价函数的梯度为 <span class="math inline">\(\delta^{\langle T_x\rangle}\prod_{i=t+1}^k\Gamma_f^{\langle i\rangle}\)</span>，因为最原始的 LSTM 没有遗忘门，即 <span class="math inline">\(\Gamma_f^{\langle t\rangle}=1\)</span>，所以不存在梯度消失问题。目前流行的深度学习框架中 <span class="math inline">\(b_f\)</span> 一般会设置的大一些，这样遗忘门的输出 <span class="math inline">\(\Gamma_f^{\langle t\rangle}=\sigma(W_f[a^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_f)\)</span> 就会约等于 1，可以减缓梯度消失，所以即使遗忘门的输出很小，那也是当前时间步的输入导致的模型的选择，不是多层嵌套导致的梯度消失。</p>
<p>LSTM 细胞的梯度主要分为两部分：门的梯度和参数的梯度，参数的梯度公式如下：</p>
<ul>
<li><p>门的梯度 <span class="math display">\[
d\Gamma_o^{\langle t \rangle}=da^{\langle t\rangle}*\tanh(c^{\langle t\rangle})
\]</span></p>
<p><span class="math display">\[
d\tilde c^{\langle t\rangle}=dc^{\langle t\rangle}*\Gamma_u^{\langle t \rangle}+\Gamma_o^{\langle t\rangle}\big(1-\tanh(c^{\langle t\rangle})^2\big)*\Gamma_u^{\langle t \rangle}*da^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
d\Gamma_u^{\langle t \rangle}=dc^{\langle t\rangle}*\tilde c^{\langle t\rangle}+\Gamma_o^{\langle t\rangle}\big(1-\tanh(c^{\langle t\rangle})^2\big)*\tilde c^{\langle t\rangle}*da^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
d\Gamma_f^{\langle t\rangle}=dc^{\langle t\rangle}*c^{\langle t-1\rangle}+\Gamma_o^{\langle t\rangle}\big(1-\tanh(c^{\langle t\rangle})^2\big)*c^{\langle t-1\rangle}*da^{\langle t\rangle}
\]</span></p></li>
<li><p>参数的梯度 <span class="math display">\[
dW_f = d\Gamma_f^{\langle t\rangle}*\Gamma_f^{\langle t\rangle}*(1-\Gamma_f^{\langle t\rangle})\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T
\]</span></p>
<p><span class="math display">\[
dW_u=d\Gamma_u^{\langle t \rangle}*\Gamma_u^{\langle t\rangle}*(1-\Gamma_u^{\langle t\rangle})*\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T
\]</span></p>
<p><span class="math display">\[
dW_c=d\tilde c^{\langle t \rangle}*(1-\tilde c^{\langle t\rangle 2})*\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T
\]</span></p>
<p><span class="math display">\[
dW_o=d\Gamma_o^{\langle t\rangle}*\Gamma_o^{\langle t\rangle}*(1-\Gamma_o^{\langle t\rangle})*\begin{bmatrix} a^{\langle t-1\rangle} \\\ x^{\langle t\rangle}\end{bmatrix}^T
\]</span></p></li>
</ul>
<p><span class="math inline">\(b_f, b_u, b_c, b_o\)</span> 的梯度只需要将 <span class="math inline">\(\Gamma_f^{\langle t\rangle}, \Gamma_u^{\langle t\rangle}, \tilde c^{\langle t\rangle}, \Gamma_o^{\langle t\rangle}\)</span> 的梯度沿水平方向 (axis=1) 累加即可，当前时间步的输入、上一个时间步的细胞状态和隐藏状态的梯度如下所示： <span class="math display">\[
\begin{align}
da^{\langle t-1\rangle} &amp;= W_f^T*d\Gamma_f^{\langle t\rangle}*\Gamma_f^{\langle t\rangle}*(1-\Gamma_f^{\langle t\rangle})  \\\
&amp;+ W_u^T * d\Gamma_u^{\langle t \rangle}*\Gamma_u^{\langle t\rangle}*(1-\Gamma_u^{\langle t\rangle}) \\\
&amp;+ W_c^T * d\tilde c^{\langle t \rangle}*(1-\tilde c^{\langle t\rangle 2})  \\\
&amp;+ W_o^T * d\Gamma_o^{\langle t\rangle}*\Gamma_o^{\langle t\rangle}*(1-\Gamma_o^{\langle t\rangle})
\end{align}
\]</span></p>
<p><span class="math display">\[
dc^{\langle t-1\rangle} = dc^{\langle t\rangle}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} * (1- \tanh(c^{\langle t-1\rangle})^2)*\Gamma_f^{\langle t \rangle}*da^{\langle t\rangle}
\]</span></p>
<p><span class="math display">\[
\begin{align}
dx^{\langle t \rangle} &amp;= W_f^T*d\Gamma_f^{\langle t\rangle}*\Gamma_f^{\langle t\rangle}*(1-\Gamma_f^{\langle t\rangle}) \\\
&amp;+ W_u^T * d\Gamma_u^{\langle t \rangle}*\Gamma_u^{\langle t\rangle}*(1-\Gamma_u^{\langle t\rangle}) \\\
&amp;+ W_c^T * d\tilde c^{\langle t \rangle}*(1-\tilde c^{\langle t\rangle 2}) \\\
&amp;+ W_o^T * d\Gamma_o^{\langle t\rangle}*\Gamma_o^{\langle t\rangle}*(1-\Gamma_o^{\langle t\rangle})
\end{align}
\]</span></p>
<p>DeepLearning 的目前最新版本作业中的公式和代码的表示有些小问题，这里已经修正。其代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell_backward</span><span class="params">(da_next, dc_next, cache)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve information from "cache"</span></span><br><span class="line">    (a_next, c_next, a_prev, c_prev, ft, ut, cct, ot, xt, parameters) = cache</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from xt's and a_next's shape</span></span><br><span class="line">    n_x, m = xt.shape</span><br><span class="line">    n_a, m = a_next.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute gates related derivatives, you can find their values can be found by looking carefully at equations (7) to (10)</span></span><br><span class="line">    dot = da_next * np.tanh(c_next)</span><br><span class="line">    dcct = (dc_next * ut + ot * (<span class="number">1</span> - np.square(np.tanh(c_next))) * ut * da_next)</span><br><span class="line">    dut = (dc_next * cct + ot * (<span class="number">1</span> - np.square(np.tanh(c_next))) * cct * da_next)</span><br><span class="line">    dft = (dc_next * c_prev + ot * (<span class="number">1</span> - np.square(np.tanh(c_next))) * c_prev * da_next)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute parameters related derivatives. Use equations (11)-(14)</span></span><br><span class="line">    concat = np.concatenate((a_prev, xt), axis=<span class="number">0</span>).T</span><br><span class="line">    dWf = np.dot(dft * ft * (<span class="number">1</span> - ft), concat)</span><br><span class="line">    dWu = np.dot(dut * ut * (<span class="number">1</span> - ut), concat)</span><br><span class="line">    dWc = np.dot(dcct * (<span class="number">1</span> - np.square(cct)), concat)</span><br><span class="line">    dWo = np.dot(dot * ot * (<span class="number">1</span> - ot), concat)</span><br><span class="line">    dbf = np.sum(dft * ft * (<span class="number">1</span> - ft), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  </span><br><span class="line">    dbu = np.sum(dut * ut * (<span class="number">1</span> - ut), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  </span><br><span class="line">    dbc = np.sum(dcct * (<span class="number">1</span> - np.square(cct)), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  </span><br><span class="line">    dbo = np.sum(dot * ot * (<span class="number">1</span> - ot),axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (15)-(17).</span></span><br><span class="line">    da_prev = np.dot(parameters[<span class="string">"Wf"</span>][:, :n_a].T, dft * ft * (<span class="number">1</span> - ft)) + np.dot(parameters[<span class="string">"Wc"</span>][:, :n_a].T, dcct * (<span class="number">1</span> - np.square(cct))) + np.dot(parameters[<span class="string">"Wu"</span>][:, :n_a].T, dut * ut * (<span class="number">1</span> - ut)) + np.dot(parameters[<span class="string">"Wo"</span>][:, :n_a].T, dot * ot * (<span class="number">1</span> - ot))</span><br><span class="line">    dc_prev = dc_next*ft+ot*(<span class="number">1</span>-np.square(np.tanh(c_next)))*ft*da_next</span><br><span class="line">    dxt = np.dot(parameters[<span class="string">"Wf"</span>][:, n_a:].T, dft * ft * (<span class="number">1</span> - ft)) + np.dot(parameters[<span class="string">"Wc"</span>][:, n_a:].T, dcct * (<span class="number">1</span> - np.square(cct))) + np.dot(parameters[<span class="string">"Wu"</span>][:, n_a:].T, dut * ut * (<span class="number">1</span> - ut)) + np.dot(parameters[<span class="string">"Wo"</span>][:, n_a:].T, dot * ot * (<span class="number">1</span> - ot))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save gradients in dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dxt"</span>: dxt, <span class="string">"da_prev"</span>: da_prev, <span class="string">"dc_prev"</span>: dc_prev, <span class="string">"dWf"</span>: dWf,<span class="string">"dbf"</span>: dbf, <span class="string">"dWu"</span>: dWu,<span class="string">"dbu"</span>: dbu,</span><br><span class="line">                <span class="string">"dWc"</span>: dWc,<span class="string">"dbc"</span>: dbc, <span class="string">"dWo"</span>: dWo,<span class="string">"dbo"</span>: dbo&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h3 id="lstm-反向传播">LSTM 反向传播</h3>
<p>类似于 RNN 的反向传播，最后一个时间步的细胞状态和隐藏状态的梯度为 0，其代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span><span class="params">(da, caches)</span>:</span></span><br><span class="line">    <span class="comment"># Retrieve values from the first cache (t=1) of caches.</span></span><br><span class="line">    (caches, x) = caches</span><br><span class="line">    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from da's and x1's shapes (≈2 lines)</span></span><br><span class="line">    n_a, m, T_x = da.shape</span><br><span class="line">    n_x, m = x1.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the gradients with the right sizes (≈12 lines)</span></span><br><span class="line">    dx = np.zeros([n_x, m, T_x])</span><br><span class="line">    da0 = np.zeros([n_a, m])</span><br><span class="line">    da_prevt = np.zeros([n_a, m])</span><br><span class="line">    dc_prevt = np.zeros([n_a, m])</span><br><span class="line">    dWf = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWu = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWc = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dWo = np.zeros([n_a, n_a + n_x])</span><br><span class="line">    dbf = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbu = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbc = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    dbo = np.zeros([n_a, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># loop back over the whole sequence</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T_x)):</span><br><span class="line">        <span class="comment"># Compute all gradients using lstm_cell_backward</span></span><br><span class="line">        gradients = lstm_cell_backward(da[:,:,t],dc_prevt,caches[t])</span><br><span class="line">        <span class="comment"># Store or add the gradient to the parameters' previous step's gradient</span></span><br><span class="line">        dx[:,:,t] = gradients[<span class="string">'dxt'</span>]</span><br><span class="line">        dWf = dWf+gradients[<span class="string">'dWf'</span>]</span><br><span class="line">        dWu = dWu+gradients[<span class="string">'dWu'</span>]</span><br><span class="line">        dWc = dWc+gradients[<span class="string">'dWc'</span>]</span><br><span class="line">        dWo = dWo+gradients[<span class="string">'dWo'</span>]</span><br><span class="line">        dbf = dbf+gradients[<span class="string">'dbf'</span>]</span><br><span class="line">        dbu = dbu+gradients[<span class="string">'dbu'</span>]</span><br><span class="line">        dbc = dbc+gradients[<span class="string">'dbc'</span>]</span><br><span class="line">        dbo = dbo+gradients[<span class="string">'dbo'</span>]</span><br><span class="line">    <span class="comment"># Set the first activation's gradient to the backpropagated gradient da_prev.</span></span><br><span class="line">    da0 = gradients[<span class="string">'da_prev'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Store the gradients in a python dictionary</span></span><br><span class="line">    gradients = &#123;<span class="string">"dx"</span>: dx, <span class="string">"da0"</span>: da0, <span class="string">"dWf"</span>: dWf,<span class="string">"dbf"</span>: dbf, <span class="string">"dWu"</span>: dWu,<span class="string">"dbu"</span>: dbu,</span><br><span class="line">                <span class="string">"dWc"</span>: dWc,<span class="string">"dbc"</span>: dbc, <span class="string">"dWo"</span>: dWo,<span class="string">"dbo"</span>: dbo&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h2 id="激活函数选择">激活函数选择</h2>
<ul>
<li>在 RNN 中，使用 <span class="math inline">\(tanh\)</span> 函数作为激活函数是因为 RNN 主要存在梯度消失问题。相比于 <span class="math inline">\(sigmoid\)</span> 激活函数，<span class="math inline">\(tanh\)</span> 函数的二阶导数在 0 之前持续很长的范围，更加有利于保持梯度在激活函数的线性区域。</li>
<li>在 RNN 中，参数 <span class="math inline">\(W_{ax}\)</span> 和 <span class="math inline">\(W_{aa}\)</span> 参与了每个时间步的运算，即使使用 <span class="math inline">\(ReLU\)</span> 函数作为激活函数，当参数 <span class="math inline">\(W\)</span> 小于 1 时也会产生梯度消失问题，而且 <span class="math inline">\(ReLU\)</span> 函数还会导致模型的输出过大，<span class="math inline">\(tanh\)</span> 函数则可以控制输出范围在 <span class="math inline">\((-1, 1)\)</span>。</li>
<li>在 LSTM 的门单元中，使用 <span class="math inline">\(sigmoid\)</span> 函数作为激活函数是因为要保证门的输出是一个 0，1 之间的向量，例如遗忘门 的输出表示让 <span class="math inline">\(c^{\langle t-1\rangle}\)</span> 各部分信息通过的比例，0 表示不让任何信息通过，1 表示让所有信息通过。</li>
</ul>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs" target="_blank" rel="noopener">Understanding LSTM Networks</a></li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>优化算法</title>
    <url>/2018/06/06/optimization-algorithms/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>单单通过特征缩放提高梯度下降的收敛速度并不够，有时候还需要改进梯度下降算法。例如动量梯度下降 (Grandient descent with Momentum)、RMSprop 算法和 Adam 优化算法(Adam optimization algorithm)。</p>
<a id="more"></a>
<h2 id="动量梯度下降法">动量梯度下降法</h2>
<p>在大数据时代，使用批量梯度下降会非常耗时，而小批量梯度下降每次只使用小批量的数据，在梯度下降过程中并不是每次迭代都向着整体最优化的方向。动量梯度下降法 (Gradient descent with Momentum) 则可以帮助梯度下降尽可能保持向着整体最优化的方向，可以加速算法的收敛，动量梯度下降法使用指数加权平均，在计算当前梯度的同时也使用了之前迭代过程的梯度。</p>
<h3 id="指数加权平均">指数加权平均</h3>
<p><a href="https://zh.wikipedia.org/wiki/%E7%A7%BB%E5%8B%95%E5%B9%B3%E5%9D%87#%E6%8C%87%E6%95%B8%E7%A7%BB%E5%8B%95%E5%B9%B3%E5%9D%87" target="_blank" rel="noopener">指数加权平均</a>（Exponential weighted average，简称 EXWA 或者 EWA）也叫指数移动平均（Exponential moving average，简称 EXMA 或者 EMA），是以指数式递减加权的移动平均。各数值的加权影响力随时间而指数式递减，越近期的数据加权影响力越重，但较旧的数据也给予一定的加权值。 <span class="math display">\[
v_t=\beta v_{t-1}+(1-\beta)\theta_t
\]</span> 其中 <span class="math inline">\(v_t\)</span> 表示指数加权平均值 (<span class="math inline">\(v_0=0\)</span>)，<span class="math inline">\(\theta_t\)</span> 表示当前数据，<span class="math inline">\(\beta\)</span> 为参数，其取值范围为 <span class="math inline">\([0, 1)\)</span>。例如 <span class="math inline">\(\beta=0.9\)</span>，有： <span class="math display">\[
\begin{align}
v_{100} &amp;= (1-\beta)\theta_{100}+(1-\beta)\beta\theta_{99}+(1-\beta)\beta^2\theta_{98}+...+(1-\beta)\beta^{99}\theta_{1} \\\
&amp;= 0.1\theta_{100}+(0.1\times 0.9)\theta_{99}+(0.1\times 0.9^2)\theta_{98}+...+(0.1\times 0.9^{99})\theta_{1}
\end{align}
\]</span> 越旧的数据权值越小，如何给 <span class="math inline">\(\beta\)</span> 一个直观的感觉呢？当权值 <span class="math inline">\(\beta^n\)</span> 小于 <span class="math inline">\(\frac{1}{e}\)</span> 就可以说只关注了前 <span class="math inline">\(n\)</span> 个数据，因为更旧的数据权值只有不到 <span class="math inline">\(\frac{1}{e}\)</span>： <span class="math display">\[
\lim_{x \to 0}(1+x)^{-\frac{1}{x}}=\frac{1}{e}
\]</span> 令 <span class="math inline">\(x=\beta-1\)</span>，得 <span class="math display">\[
\lim_{\beta \to 1}(\beta)^{\frac{1}{1-\beta}}=\frac{1}{e}
\]</span></p>
<p>因此可以<strong>简单地</strong>认为 <span class="math inline">\(v_t\)</span> 是前 <span class="math inline">\(\frac{1}{1-\beta}\)</span> 个数据的指数加权平均(并不是严格的数学证明)。<span class="math inline">\(\beta\)</span> 越大表示当前数据所占的权值越小，即求出来的平均值对当前数据越不敏感，则曲线越平坦。</p>
<h4 id="偏差修正">偏差修正</h4>
<p>由于默认 <span class="math inline">\(v_0=0\)</span>，所以对一开始的数据计算移动平均数作为估计就不太准确。可以用 <span class="math inline">\(\frac{v_{t}}{1- \beta^{t}}\)</span> 作为估计值，当随着 <span class="math inline">\(t\)</span> 增加，<span class="math inline">\(\beta^{t}\)</span> 接近于 0。</p>
<h3 id="动量梯度下降">动量梯度下降</h3>
<p>动量梯度下降的基本想法就是计算梯度的指数加权平均数，并利用该梯度更新权重。在每次迭代中，参数的更新公式如下所示：</p>
<p><span class="math display">\[
v_{dW}=\beta v_{dW}+(1-\beta)dW
\]</span></p>
<p><span class="math display">\[
W=W-\alpha v_{dW}
\]</span></p>
<p>使用动量梯度下降法，由于每次都尽量朝着整体最优化的方向更新参数，所以算法的速度回比较快。</p>
<h2 id="rmsprop">RMSprop</h2>
<p>RMSprop(root mean square prop) 算法，也可以加速梯度下降。如上图 without momentum 中，<span class="math inline">\(w_2\)</span> 方向上的梯度要大于 <span class="math inline">\(w_1\)</span> 方向上的梯度(因为 <span class="math inline">\(w_2\)</span> 方向上一步跨得比较大，<span class="math inline">\(W=W-\alpha dW\)</span>)，RMSprop 算法通过让学习率除以一个衰减系数(历史梯度平方和的平方根)，使得每个参数的学习率不同。在参数空间更为平缓的方向(衰减系数较小)，获得更大的步伐，从而加快训练速度。 <span class="math display">\[
S_{dW}= \beta S_{dW} + (1 - \beta)({dW})^{2}
\]</span></p>
<p><span class="math display">\[
W=W-\frac{\alpha}{\sqrt{S_{dw}}+\varepsilon}dW
\]</span></p>
<p>其中 <span class="math inline">\(\varepsilon\)</span> 是为了避免分母为 0。</p>
<h2 id="adam-优化算法">Adam 优化算法</h2>
<p>Adam(Adaptive Moment Estimation) 优化算法基本上就是将 Momentum 和 RMSprop 结合在一起： <span class="math display">\[
v_{dW}= \beta_{1}v_{dW} + ( 1 - \beta_{1})dW
\]</span></p>
<p><span class="math display">\[
S_{dW}=\beta_{2}S_{dW} + ( 1 - \beta_{2}){(dW)}^{2}
\]</span></p>
<p>偏差修正： <span class="math display">\[
v_{dW}^{\text{corrected}}= \frac{v_{dW}}{1 - \beta_{1}^{t}}
\]</span></p>
<p><span class="math display">\[
S_{dW}^{\text{corrected}} =\frac{S_{dW}}{1 - \beta_{2}^{t}}
\]</span></p>
<p>权值更新： <span class="math display">\[
W= W - \frac{\alpha}{\sqrt{S_{dW}^{\text{corrected}}} +\varepsilon}v_{dW}^{\text{corrected}}
\]</span> Adam 算法结合了 Momentum 和 RMSprop 梯度下降法，是一种极其常用的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构。其中超参数学习率 <span class="math inline">\(\alpha\)</span> 很重要，也经常需要调试；<span class="math inline">\(\beta_{1}\)</span>常用的缺省值为 0.9；Adam 论文作者推荐使用 0.999 作为超参数 <span class="math inline">\(\beta_{2}\)</span> 的默认值；<span class="math inline">\(\varepsilon\)</span> 建议为 <span class="math inline">\(10^{-8}\)</span>。但是在使用 Adam 的时候，人们往往使用缺省值即可。</p>
<h2 id="学习率衰减">学习率衰减</h2>
<p>随时间慢慢减少学习率也可以加快学习算法，我们将之称为学习率衰减。因为在学习初期，模型可以承受较大的步伐，当开始收敛的时候，则需要逐渐减小步伐，否则容易错过最优值。</p>
<p>使用小批量梯度下降进行训练，每遍历一次训练集称为一个 <code>epoch</code> (一代)，学习率可以随着 epoch 的变大而减小： <span class="math display">\[
\alpha=\frac{1}{1+\text{decay_rate}*\text{epoch_num}}\alpha_0
\]</span> 其中 decay_rate 是衰减率(需要调整的超参数)，epoch_num 是代数，<span class="math inline">\(\alpha_0\)</span> 是出事学习率。除了这个公式，还可以用其他的公式使学习率递减或者通过手动的方式调整学习率： <span class="math display">\[
\alpha=0.95^\text{epoch_num}\alpha_0
\]</span></p>
<p><span class="math display">\[
\alpha=\frac{k}{\sqrt{\text{epoch_num}}}\alpha_0
\]</span></p>
<p><span class="math display">\[
\alpha=\frac{k}{\sqrt{t}}\alpha_0
\]</span></p>
<h2 id="局部最优问题">局部最优问题</h2>
<p>在深度学习研究早期，人们总是担心优化算法会被困在一些局部最优点处。而事实上，在神经网络中上图所示的局部最优点出现的可能性很小，梯度为 0 时，通常是<strong>鞍点</strong>，因为代价函数梯度为 0 时，那么在每个方向(权值)上，它可能是凸函数，也可能是凹函数。在一个 <span class="math inline">\(n\)</span> 维的高维空间中，如果想要得到局部最优，那么 <span class="math inline">\(n\)</span> 个方向上都需要一样，发生这种情况的概率是 <span class="math inline">\(\frac{1}{2^n}\)</span>。而大部分情况却是一部分方向是凸函数，一部分方向是凹函数，即鞍点。但问题是在鞍点处，会有平稳段，即曲面很平坦，下降速度慢，而 Adam 算法正好可以加快速度，尽早走出平稳段。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li><a href="https://jermwatt.github.io/mlrefined/blog_posts/13_Multilayer_perceptrons/13_5_Momentum_methods.html" target="_blank" rel="noopener">Momentum methods</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>递归</title>
    <url>/2016/09/14/recursion/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>难得有点空闲时间总结一下这段时间刷过的算法题，就从递归开始。</p>
<a id="more"></a>
<h2 id="递归">递归</h2>
<blockquote>
<p>递归函数是一种可以调用自身的函数，每次成功调用都使得输入变得更加精细。</p>
</blockquote>
<h3 id="基本递归">基本递归</h3>
<p><code>n! = n * (n - 1) * (n - 2) * ... * 2 * 1</code></p>
<p>数学中的阶乘就是一个可以使用递归的很好的例子，如果不使用递归，我们也能通过 while 循环来依次乘以小于 n 的数。如果使用递归，我们就可以将 n! 定义为 <code>n * (n - 1)!</code>，将问题的规模缩小，直到 n = 1。</p>
<p><span class="math display">\[
F(n) =
\begin{cases}
1 &amp; \text{$n$  = 0、1} \\\
nF(n - 1) &amp; \text{$n$ &gt; 1}  \\\
\end{cases}
\]</span></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> <span class="title">F</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span> || n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> n * F(n - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> result = F(<span class="number">65</span>);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; result &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>递归过程包括两个阶段: 递推和回归。</p>
<h4 id="递推">递推</h4>
<p>在递推阶段，每一个递归调用通过进一步调用自己来缩小问题规模，当满足终止条件时，即问题规模已不能再缩小时，递推结束。例如当 n = 1 或者 n = 0 时，它们的阶乘就是 1，此时函数只要返回 1 就行。递归函数必须拥有至少一个终止条件，否则会陷入死循环。</p>
<h4 id="回归">回归</h4>
<p>递推结束后，处理过程就会进入回归阶段，函数以逆序的方式回归，直到最初调用的函数为止。当调用 $ F(n) $ 时，会在栈中分配一块空间来保存与这个调用先关的信息，称为活跃记录。因为递推阶段结束后还有回归阶段，所以在终止条件之前调用了几次函数本身就会生成几个活跃记录，在回归阶段的时候才逐渐将栈中的活跃记录销毁(后建先销)，因此会花费大量空间和时间来生成销毁活跃记录。这个问题在尾递归中可能得到解决。</p>
<p><span class="math display">\[
F(4) = (4 × (3 × (2 × 1)))
\]</span></p>
<h3 id="尾递归">尾递归</h3>
<blockquote>
<p>如果一个函数中所有递归形式的调用都出现在函数的末尾，我们称这个递归函数是尾递归的。</p>
</blockquote>
<p>就是说整个递归过程只有递推阶段，推到最后就能直接得到结果不用再回归。所以从理论上来说不需要保留原来的活跃记录，如果能覆盖当前的活跃记录而不是在栈中去创建一个新的，这就是尾递归的优化。但是，这是编译器的工作，它能优化就能提高效率；它不优化，尾递归就并没有什么卵用。 C 语言和 C++ 就有尾递归优化，Java 和 Python 就没有， 听说它们不做尾递归优化是为了抛出异常时有完整的 stack trace 。</p>
<p>根据尾递归的定义可以想到应该在调用递归前先计算一下部分结果，然后把它作为第二个参数传给函数，部分结果初始化为1。</p>
<p><span class="math display">\[
F(n, a) =
\begin{cases}
a &amp; \text{$n$  = 0、1} \\\
F(n - 1, na) &amp; \text{$n$ &gt; 1}  \\\
\end{cases}
\]</span></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> <span class="title">F</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> part_result)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span> || n == <span class="number">0</span>) <span class="keyword">return</span> part_result;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> F(n - <span class="number">1</span>, n * part_result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> result = F(<span class="number">65</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; result &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在尾递归中，每次调用函数本身时都会把当前的计算的部分结果传过去，避免了回归的过程。这时如果能覆盖之前的活跃记录而不是压栈再去新建一个记录就能达到优化的效果。</p>
<center>
$ F(4, 1) = (((4 × 3) × 2) × 1) $
</center>
<h3 id="运行时间测试">运行时间测试</h3>
<p>由于大数阶乘数字比较大，数字超过65就会溢出，所以使用的测试数据比较小，运行时间差距不大，但是还是有区别，优化后的运行时间的最大值也不会超过未优化的最小值。(<code>-O2</code> 参数是 <code>-O1</code> 的进阶，是推荐的优化等级，编译器会试图提高代码性能而不会增大体积和大量占用的编译时间)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//记录程序开始时间    </span></span><br><span class="line"><span class="keyword">clock_t</span> tStart = clock();</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> result = F(<span class="number">65</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; result &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="comment">//显示程序运行时间</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Time taken: %.3fms\n"</span>, (<span class="keyword">double</span>)(clock() - tStart) / CLOCKS_PER_SEC * <span class="number">1000</span>);</span><br></pre></td></tr></table></figure>
<h3 id="运行空间测试">运行空间测试</h3>
<p>由于测试数据较小，所以在主函数中定义一个大型的数组，尽可能地占用栈的空间，达到使优化后的运行时不会出现段错误，而未优化的运行时由于活跃记录的增加而出现段错误。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> unused[<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024</span>];    <span class="comment">//为了占用栈空间</span></span><br></pre></td></tr></table></figure>
<h2 id="分析">分析</h2>
<h3 id="未优化">未优化</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ g++ main.cpp -S</span><br></pre></td></tr></table></figure>
<p>通过以上命令编译代码，不进行尾递归优化，生成 <code>main.s</code> 文件，截取其中部分汇编代码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## BB#0:</span><br><span class="line">	pushq	%rbp</span><br><span class="line">Ltmp3:</span><br><span class="line">	.cfi_def_cfa_offset 16</span><br><span class="line">Ltmp4:</span><br><span class="line">	.cfi_offset %rbp, -16</span><br><span class="line">	movq	%rsp, %rbp</span><br><span class="line">Ltmp5:</span><br><span class="line">	.cfi_def_cfa_register %rbp</span><br><span class="line">	subq	$16, %rsp</span><br><span class="line">	movl	$65, %edi</span><br><span class="line">	movl	$1, %eax</span><br><span class="line">	movl	%eax, %esi</span><br><span class="line">	movl	$0, -4(%rbp)</span><br><span class="line">	callq	__Z1Fiy</span><br></pre></td></tr></table></figure>
<p>凭借现在遗留的汇编知识大致可以看出在调用函数 <span class="math inline">\(F(n)\)</span> <code>callq    __Z1Fiy</code> 之前会进行压栈 <code>pushq %rbp</code> ，所以会保留当前活跃记录。</p>
<h3 id="优化">优化</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ g++ main.cpp -O2 -S</span><br></pre></td></tr></table></figure>
<p>通过以上命令编译代码，进行尾递归优化，截取其中部分汇编代码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LBB0_6:                                 ## %tailrecurse</span><br><span class="line">                                        ## =&gt;This Inner Loop Header: Depth=1</span><br><span class="line">	leaq	(%rax,%rdx), %rdi</span><br><span class="line">	imulq	%rsi, %rdi</span><br><span class="line">	leaq	-1(%rax,%rdx), %rsi</span><br><span class="line">	leaq	-2(%rax,%rdx), %rcx</span><br><span class="line">	imulq	%rsi, %rcx</span><br><span class="line">	imulq	%rdi, %rcx</span><br><span class="line">	leaq	-3(%rax,%rdx), %rdi</span><br><span class="line">	leaq	-4(%rax,%rdx), %rsi</span><br><span class="line">	imulq	%rdi, %rsi</span><br><span class="line">	leaq	-5(%rax,%rdx), %rdi</span><br><span class="line">	imulq	%rsi, %rdi</span><br><span class="line">	imulq	%rcx, %rdi</span><br><span class="line">	leaq	-6(%rax,%rdx), %rcx</span><br><span class="line">	leaq	-7(%rax,%rdx), %rsi</span><br><span class="line">	imulq	%rcx, %rsi</span><br><span class="line">	imulq	%rdi, %rsi</span><br><span class="line">	addq	$-8, %rdx</span><br><span class="line">	leal	(%r8,%rdx), %ecx</span><br><span class="line">	cmpl	$1, %ecx</span><br><span class="line">	ja	LBB0_6</span><br></pre></td></tr></table></figure>
<p>可见代码会被尾递归优化，并且自动加上注释，在代码中不会有压栈的行为，而是跳回去使用当前活跃记录 <code>ja LBB0_6</code>。</p>
<h2 id="总结">总结</h2>
<p>递归能把一个大的问题转化成一个规模较小的问题，递归只需少量的程序就能描述出解题过程所需要的多次重复计算，减少了程序的代码量，用递归思想写出的程序往往十分简洁易懂。</p>
<p>但是递归算法的运行效率较低。在递归调用的过程当中系统为每一层的返回点、局部量等开辟了栈来存储。递归次数过多容易造成栈溢出等，即使进行了尾递归优化也会存在生成活跃记录和覆盖活跃记录的操作。</p>
<h2 id="拓展">拓展</h2>
<p>从尾递归优化的思想可以得到启发，如果在 $ Fa() $ 的末尾调用了 $ Fb() $，那么这就属于尾调用，就可以不用将当前的活跃记录压栈，而是直接新建一个，由于这里两个函数不同，不像尾递归，所以不能直接覆盖活跃记录，但是也可以达到优化的效果。</p>
]]></content>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>正则化</title>
    <url>/2018/05/29/regularization/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在机器学习中，当训练数据太少或者模型过于复杂等情况，当模型学习了数据的噪声的细节，那么模型在未知的数据表现就会不好，即泛化误差比训练误差大，这就是过拟合。模型选择的典型方法是正则化，使用正则化技术可以很大程度上减缓过拟合问题。</p>
<a id="more"></a>
<h2 id="没有免费的午餐定理nfl">“没有免费的午餐”定理(NFL)</h2>
<p>“没有免费的午餐”定理表明，在机器学习中无论是瞎猜还是一些很牛的算法，它的期望性能都相同。也就是说，考虑<strong>所有可能</strong>的目标函数，没有哪个算法比其他算法高效。如果要想在某些问题上得到性能的提高，必须在一些问题上付出同等代价！就像算法的时间复杂度和空间复杂度。</p>
<p>符号说明：</p>
<ul>
<li><span class="math inline">\(\mathcal{X}\)</span>：样本空间(离散)</li>
<li><span class="math inline">\(\mathcal{H}\)</span>：假设空间(离散)，例如在线性回归中我们假设数据满足某种线性关系</li>
<li><span class="math inline">\(P(h|X, \mathcal{L}a)\)</span>：算法 <span class="math inline">\(\mathcal{L}a\)</span> 基于训练数据 <span class="math inline">\(X\)</span> 产生假设 <span class="math inline">\(h\)</span> 的概率</li>
<li><span class="math inline">\(f\)</span>：真实目标函数</li>
<li><span class="math inline">\(E_{ote}(\mathcal{L}a|X, f)\)</span>：算法 <span class="math inline">\(\mathcal{L}a\)</span> 的训练集外误差(Off-trainning error)，即算法 <span class="math inline">\(\mathcal{L}a\)</span> 在x 训练集之外的所有样本上的误差</li>
</ul>
<p>对于一个特定问题，即真实目标函数确定，算法 <span class="math inline">\(\mathcal{L}a\)</span> 的训练集外误差为： <span class="math display">\[
E_{ote}(\mathcal{L}a|X, f) = \sum_{h}\sum_{x\in \mathcal{X}-X}P(x)1\lbrace h(x)\neq f(x)\rbrace P(h|X, \mathcal{L}a)
\]</span> 对于二分类问题，真实目标函数一共有 <span class="math inline">\(2^{\lvert\mathcal{X}\rvert}\)</span> 个，且均匀分布。对于一个真实目标函数，一个假设 <span class="math inline">\(h\)</span> 的输出有 <span class="math inline">\(\frac{1}{2}\)</span> 的可能与真实目标函数相等。 所以对于所有可能的目标函数，算法 <span class="math inline">\(\mathcal{L}a\)</span> 的训练集外误差为： <span class="math display">\[
\begin{align}
\sum_{f}E_{ote}(\mathcal{L}a|X, f) &amp;= \sum_{f}\sum_{h}\sum_{x\in \mathcal{X}-X}P(x)1\lbrace h(x)\neq f(x)\rbrace P(h|X, \mathcal{L}a) \\\
&amp;= \sum_{x\in \mathcal{X}-X}P(x)\sum_{h}P(h|X, \mathcal{L}a)\sum_{f}1\lbrace h(x)\neq f(x)\rbrace \\\
&amp;= \sum_{x\in \mathcal{X}-X}P(x)\sum_{h}P(h|X, \mathcal{L}a)\frac{1}{2}2^{\lvert\mathcal{X}\rvert} \\\
&amp;= 2^{\lvert\mathcal{X}\rvert-1}\sum_{x\in \mathcal{X}-X}P(x)\cdot 1
\end{align}
\]</span></p>
<p>对于所有可能的目标函数，一个算法最终的总误差和这个算法无关。没有任何一个算法能够解决所有问题，在现实生活中我们有一套先验知识来判断哪些更优，这些先验知识包含简单性(“奥卡姆剃刀”原理)，平滑性等等，所以我们就应该更具这些先验知识来具体问题具体分析。</p>
<blockquote>
<p>NFL定理最重要的寓意是让我们清楚地认识到：脱离具体问题，空泛地谈论”什么学习算法更好“毫无意义。因为若考虑所有潜在的问题，则所有的算法一样好，要谈论算法的相对优劣，必须要针对具体问题；在某些问题上表现好的学习算法，在另一问题上却可能不尽如人意，学习算法自身的归纳偏好与问题是否相配，往往会起到决定性作用.</p>
</blockquote>
<h2 id="奥卡姆剃刀原理">“奥卡姆剃刀”原理</h2>
<blockquote>
<p>如无必要，勿增实体。</p>
</blockquote>
<p>意思是相比较于复杂的假设，我们更倾向于选择简单的、参数少的假设。如果线性回归和高阶的多项式回归在某个问题上的表现相似(例如训练误差相同)，那么我们应该选择较为简单的线性回归。从贝叶斯估计的角度来看，简单的模型有较大的先验概率，毕竟一个高阶多项式随机采样的数据呈线性的概率太小了。</p>
<h2 id="正则化">正则化</h2>
<p>大部分正则化通过在代价函数上加一个正则项或者惩罚项，让算法在训练过程中尽量学习一个简单的模型，即满足“奥卡姆剃刀”原理，这样就可以减缓过拟合的发生。正则化项大概有以下几类：</p>
<ul>
<li>L0 正则化：L0 正则化的值是模型参数中非零参数的个数(0范数)。稀疏的参数可以让模型变得简单，但是 L0 正则化难于求解。</li>
<li>L1(Lasso) 正则化：L1 正则化的值是模型各个参数的绝对值之和(1范数)，也会获得稀疏的参数。</li>
<li>L2(Ridge) 正则化：L2 正则化的值是模型各个参数的平方之和(2范数的平方，平方是为了易于优化)，也称为权重衰减，因为最后会获得值很小的参数。</li>
<li>Dropout：在深度学习的训练过程中，按照一定的概率随机让一些神经元结点失活。</li>
<li>数据增广：例如通过对图像进行旋转、扭曲等操作，获得更多的训练数据。</li>
<li>Early stop：在泛化误差上升之前，停止网络的训练，缺点是会导致 <span class="math inline">\(J\)</span> 被优化得不够小。</li>
<li>...</li>
</ul>
<h3 id="l1-正则化">L1 正则化</h3>
<p><span class="math display">\[
J(\boldsymbol{w})=\frac{1}{m}\sum_{i=1}^m\mathcal{L}(\hat y^{(i)}, y^{(i)})+\frac{\lambda}{m}\Vert\boldsymbol{w}\Vert_1
\]</span></p>
<p><span class="math display">\[
dw_i=\frac{\partial J}{\partial w_i}=\frac{\lambda}{2m}sign(w_i)=\pm\frac{\lambda}{m}
\]</span></p>
<p><span class="math display">\[
w_i=w_i-\alpha dw_i=w_i\mp\frac{\alpha\lambda}{m}
\]</span></p>
<p>通过梯度下降最小化代价函数时，更新参数 <span class="math inline">\(w_i\)</span> 每次都会加减一个固定的数，往 0 逼近，多次迭代后则有可能变成成 0，稀疏的参数可以用于特征选择。</p>
<h3 id="l2-正则化">L2 正则化</h3>
<p><span class="math display">\[
J(\boldsymbol{w})=\frac{1}{m}\sum_{i=1}^m\mathcal{L}(\hat y^{(i)}, y^{(i)})+\frac{\lambda}{2m}\Vert\boldsymbol{w}\Vert_2^2
\]</span></p>
<p><span class="math display">\[
dw_i=\frac{\partial J}{\partial w_i}=\frac{\lambda}{m}w_i
\]</span></p>
<p><span class="math display">\[
w_i=w_i-\alpha dw_i=(1-\frac{\alpha\lambda}{m})w_i
\]</span></p>
<p>通过梯度下降最小化代价函数时，更新参数 <span class="math inline">\(w_i\)</span> 每次都会乘以 <span class="math inline">\((1-\frac{\alpha\lambda}{m})\)</span> 这个小于 1 的数(权重衰减)，往 0 逼近，多次迭代后也只能是更加逼近 0 而不会等于 0。Xavier <a href="https://www.quora.com/What-is-the-difference-between-L1-and-L2-regularization-How-does-it-solve-the-problem-of-overfitting-Which-regularizer-to-use-and-when" target="_blank" rel="noopener">表示</a>，除非需要稀疏的参数进行特征选择，在实际应用中，L2 总是比 L1 好，所以推荐使用 L2 正则化。</p>
<p>惩罚参数 <span class="math inline">\(\lambda\)</span> 增大则参数 <span class="math inline">\(\boldsymbol{w}\)</span> 减小。在神经网络中，如果参数值逼近 0，则该神经元结点对结果的影响也逼近 0，因此可以有效减缓过拟合。如果一个神经网络的激活函数是 Tanh 函数，而且所有参数值都逼近 0，那么神经元结点的输入就约等于输出(Tanh 函数原点处大致呈线性)，最终不管网络多深，都只能计算线性函数。</p>
<h4 id="前向传播">前向传播</h4>
<p><span class="math display">\[
J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L]\(i\)}\right) + (1-y^{(i)})\log\left(1- a^{[L]\(i\)}\right) \large{)} }_\text{cross-entropy cost} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W_{k,j}^{[l]2} }_\text{L2 regularization cost}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost_with_regularization</span><span class="params">(A3, Y, parameters, lambd)</span>:</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]</span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    </span><br><span class="line">    cross_entropy_cost = compute_cost(A3, Y) <span class="comment"># This gives you the cross-entropy part of the cost</span></span><br><span class="line">    L2_regularization_cost = lambd * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) / (<span class="number">2</span> * m)</span><br><span class="line">    </span><br><span class="line">    cost = cross_entropy_cost + L2_regularization_cost</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h4 id="反向传播">反向传播</h4>
<p><span class="math display">\[
\frac{d}{dW} ( \frac{1}{2}\frac{\lambda}{m}  W^2) = \frac{\lambda}{m} W
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_with_regularization</span><span class="params">(X, Y, cache, lambd)</span>:</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache</span><br><span class="line">    </span><br><span class="line">    dZ3 = A3 - Y</span><br><span class="line">    dW3 = <span class="number">1.</span> / m * np.dot(dZ3, A2.T) + (lambd * W3) / m</span><br><span class="line">    db3 = <span class="number">1.</span> / m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dA2 = np.dot(W3.T, dZ3)</span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>))</span><br><span class="line">    dW2 = <span class="number">1.</span> / m * np.dot(dZ2, A1.T) + (lambd * W2) / m</span><br><span class="line">    db2 = <span class="number">1.</span> / m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dA1 = np.dot(W2.T, dZ2)</span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = <span class="number">1.</span> / m * np.dot(dZ1, X.T) + (lambd * W1) / m</span><br><span class="line">    db1 = <span class="number">1.</span> / m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3, <span class="string">"dA2"</span>: dA2,</span><br><span class="line">                 <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2, <span class="string">"dA1"</span>: dA1, </span><br><span class="line">                 <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h3 id="dropout">Dropout</h3>
<p>Dropout 也就是随机失活，通常用于计算机视觉领域，因为特征比较多。每个神经元结点都以固定的概率 <code>keep-prob</code> 随机保留，但是在 Dropout 后为了不影响 <span class="math inline">\(Z\)</span> 的期望而导致梯度消失，<span class="math inline">\(Z=Z/keep-prob\)</span>，神经网络的训练过程如下所示：</p>
<video width="620" height="440" src=" https://randy-1251769892.cos.ap-beijing.myqcloud.com/dropout.mp4" type="video/mp4" controls>
</video>
<p>对于整个网络来说，随机失活后导致网络规模变小，减缓了过拟合的发生。对于每一个神经元结点，由于它的输入随时都有可能失活，因此训练后任何一个输入的权重都不会太大，由于这个神经元自己本身也可能失活，因此 Dropout 将产生<strong>类似</strong> L2 正则化的权重衰减的效果，但是只有当 Dropout 用于线性回归时才<strong>相当于</strong> L2 权重衰减。</p>
<p>Dropout 也可以被近似认为是集成大量深层神经网络的 Bagging 方法(结合多个模型降低泛化误差)，不太一样的地方是 Bagging 中所有模型都是独立的，而 Dropout 中所有模型共享参数。当可用训练样本太少时(例如 5000)，Dropout 的效果不会很好。</p>
<h4 id="前向传播-1">前向传播</h4>
<p>在前向传播时，需要生成失活矩阵 <code>D</code>，前向传播后需要缓存 <code>D</code> 用于反向传播。需要注意的是，Dropout 会导致代价函数不明确，因此可以先不 Dropout 观察代价函数是否下降，然后在开启 Dropout；同时在测试的时候不能开启 Dropout 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation_with_dropout</span><span class="params">(X, parameters, keep_prob=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># retrieve parameters</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    b3 = parameters[<span class="string">"b3"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = relu(Z1)</span><br><span class="line">    D1 = np.random.rand(A1.shape[<span class="number">0</span>], A1.shape[<span class="number">1</span>])     <span class="comment"># Step 1: initialize matrix D1 = np.random.rand(..., ...)</span></span><br><span class="line">    D1 = D1 &lt; keep_prob                            <span class="comment"># Step 2: convert entries of D1 to 0 or 1 (using keep_prob as the threshold)</span></span><br><span class="line">    A1 = A1 * D1                                      <span class="comment"># Step 3: shut down some neurons of A1</span></span><br><span class="line">    A1 = A1 / keep_prob                               <span class="comment"># Step 4: scale the value of neurons that haven't been shut down</span></span><br><span class="line">    Z2 = np.dot(W2, A1) + b2</span><br><span class="line">    A2 = relu(Z2)</span><br><span class="line">    D2 = np.random.rand(A2.shape[<span class="number">0</span>], A2.shape[<span class="number">1</span>])     <span class="comment"># Step 1: initialize matrix D2 = np.random.rand(..., ...)</span></span><br><span class="line">    D2 = D2 &lt; keep_prob                           <span class="comment"># Step 2: convert entries of D2 to 0 or 1 (using keep_prob as the threshold)                           </span></span><br><span class="line">    A2 = A2 * D2                                      <span class="comment"># Step 3: shut down some neurons of A2</span></span><br><span class="line">    A2 = A2 / keep_prob                               <span class="comment"># Step 4: scale the value of neurons that haven't been shut down</span></span><br><span class="line">    Z3 = np.dot(W3, A2) + b3</span><br><span class="line">    A3 = sigmoid(Z3)</span><br><span class="line">    </span><br><span class="line">    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A3, cache</span><br></pre></td></tr></table></figure>
<h4 id="反向传播-1">反向传播</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_with_dropout</span><span class="params">(X, Y, cache, keep_prob)</span>:</span> </span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache</span><br><span class="line">    </span><br><span class="line">    dZ3 = A3 - Y</span><br><span class="line">    dW3 = <span class="number">1.</span> / m * np.dot(dZ3, A2.T)</span><br><span class="line">    db3 = <span class="number">1.</span> / m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dA2 = np.dot(W3.T, dZ3)</span><br><span class="line">    dA2 = dA2 * D2              <span class="comment"># Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation</span></span><br><span class="line">    dA2 = dA2 / keep_prob              <span class="comment"># Step 2: Scale the value of neurons that haven't been shut down</span></span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>))</span><br><span class="line">    dW2 = <span class="number">1.</span> / m * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = <span class="number">1.</span> / m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dA1 = np.dot(W2.T, dZ2)</span><br><span class="line">    dA1 = dA1 * D1              <span class="comment"># Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation</span></span><br><span class="line">    dA1 = dA1 / keep_prob              <span class="comment"># Step 2: Scale the value of neurons that haven't been shut down</span></span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = <span class="number">1.</span> / m * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = <span class="number">1.</span> / m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,<span class="string">"dA2"</span>: dA2,</span><br><span class="line">                 <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2, <span class="string">"dA1"</span>: dA1, </span><br><span class="line">                 <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.</li>
<li>周志华. 机器学习. 清华大学出版社. 2016.</li>
<li>李航. 统计学习方法. 清华大学出版社. 2017.</li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>残差网络 ResNet</title>
    <url>/2018/12/12/resnet/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>稳稳地被拒了，现在再回顾自己写的内容，发现确实有不少地方似懂非懂的，特别是调用了别人代码的地方。继续我的 deeplearning 总结吧！由于实验中有 ResNet 的实现，所以将它单独作为一篇总结。</p>
<a id="more"></a>
<h2 id="深度神经网络的问题">深度神经网络的问题</h2>
<p>神经网络越深拟合能力就越强，也可以学到不同级别抽象的特征，但是太深就会导致梯度消失等问题，阻碍了网络的收敛。这个问题前面也介绍过，通常是通过标准初始化层和中间的标准化层来解决。这样虽然可以让网络收敛，但是准确度会随着网络的加深而变得饱和，然后退化，一个 20 层和一个 56 层的网络的训练误差和测试误差如下图所示：</p>
<p><img src="/2018/12/12/resnet/vanishing_grad_kiank.png"></p>
<h2 id="残差网络-resnet">残差网络 ResNet</h2>
<p>ResNet[2] 的主要思想就是通过远跳连接（也叫捷径连接）来解决网络过深的问题，远跳连接允许在反向传播的时候，梯度直接传播给更前面的层，结构如下图所示：</p>
<p><img src="/2018/12/12/resnet/skip_connection_kiank.png"></p>
<p>左图为普通的神经网络块的传输，其前向传播的计算步骤为： <span class="math display">\[
z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}
\]</span></p>
<p><span class="math display">\[
a^{[l+1]}=g(z^{[l+1]})
\]</span></p>
<p><span class="math display">\[
z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}
\]</span></p>
<p><span class="math display">\[
a^{[l+2]}=g(z^{[l+2]})
\]</span></p>
<p>右图为一个残差块，通过增加了一个恒等映射，把当前输出不添加任何参数直接传给下一层网络。残差块的堆叠可以构建非常深的网络，其前向传播的计算步骤只有最后一步与上述步骤不同： <span class="math display">\[
a^{[l+2]}=g(z^{[l+2]}+a^{[l]})
\]</span></p>
<h3 id="resnet-原理">ResNet 原理</h3>
<p>残差网络看起来似乎同容易理解，但是还要理解为什么有了它就不怕增加网络的深度了。假设网络中均使用 ReLU 激活函数且最后的输出 <span class="math inline">\(a\geq 0\)</span>，则： <span class="math display">\[
a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})
\]</span> 如果我们使用 L2 正则化项或者权重衰减，那么就可以压缩 <span class="math inline">\(W\)</span> 和 <span class="math inline">\(b\)</span> 的值，进而使网络的拟合能力逼近于更浅的网络。例如当 <span class="math inline">\(W^{[l+2]}=0\)</span> 和 <span class="math inline">\(b^{[l+2]}=0\)</span> 时，有： <span class="math display">\[
a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}
\]</span> 所以在增加了残差块后更深的网络的性能也并不逊色于没有增加残差块简单的网络，尽管增加了网络的深度，但是并不会影响网络的性能。同时如果增加的网络结构能够学习到一些有用的信息，那么就会提升网络的性能。</p>
<h2 id="代码实现">代码实现</h2>
<p>实验同样是用 Keras 来实现，首先需要载入需要用到的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> layer_utils</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> resnets_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> imshow</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line">K.set_image_data_format(<span class="string">'channels_last'</span>)</span><br><span class="line">K.set_learning_phase(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="残差块">残差块</h3>
<p>同时由于结构 <span class="math inline">\(a^{[l+2]}=g(z^{[l+2]}+a^{[l]})\)</span>，ResNet 在设计中使用了很多 Same 卷积来保持图像大小相同。在通道不一致的时候，对增加的通道可以用 0 填充或者使用线性投影来保证维度一致（<span class="math inline">\(1\times 1\)</span> 滤波器）。因此残差块分为两种 Identity block 和 Convolutional block，前者维度一致，后者在捷径上添加了一个卷积层用来调节输出的维度。</p>
<h4 id="identity-block">Identity Block</h4>
<p>实验实现的 Identity block 远跳了两层，同时使用了批标准化来加速网络的训练过程，结构如下图所示：</p>
<p><img src="/2018/12/12/resnet/idblock3_kiank.png"></p>
<p>实现以上残差块的步骤如下所示：</p>
<ol type="1">
<li>主路径的第一部分
<ul>
<li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_1\)</span> 大小为 (1, 1) 和步长为 (1, 1)，valid 卷积并且命名为 <code>conv_name_base + '2a'</code>；</li>
<li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '2a'</code>；</li>
<li>使用 ReLU 激活函数，不需要命名并且没有超参数。</li>
</ul></li>
<li>主路径的第二部分
<ul>
<li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_2\)</span> 大小为 <span class="math inline">\((f, f)\)</span> 和步长为 (1, 1)，same 卷积并且命名为 <code>conv_name_base + '2b'</code>；</li>
<li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '2b'</code>；</li>
<li>使用 ReLU 激活函数。</li>
</ul></li>
<li>主路径的第三部分
<ul>
<li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_3\)</span> 大小为 (1, 1)​ 和步长为 (1, 1)，same 卷积并且命名为 <code>conv_name_base + '2c'</code>；</li>
<li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '2c'</code>；</li>
</ul></li>
<li>最后一步
<ul>
<li>输入需要加上远跳连接；</li>
<li>使用 ReLU 激活函数。</li>
</ul></li>
</ol>
<p>因此一共有三个卷积层，对应三组滤波器，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_block</span><span class="params">(X, f, filters, stage, block)</span>:</span></span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the input value. You'll need this later to add back to the main path. </span></span><br><span class="line">    X_shortcut = X</span><br><span class="line"></span><br><span class="line">    <span class="comment"># First component of main path</span></span><br><span class="line">    X = Conv2D(filters=F1, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2a'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2a'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, name=conv_name_base + <span class="string">'2b'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2b'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(filters=F3, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2c'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2c'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>
<h4 id="convolutional-block">Convolutional Block</h4>
<p>在输入和输出维度不匹配的时候可以 Convolutional block，与 Identity block 的不同之处就在于在捷径上也有一个卷积层，其结构如下图所示：</p>
<p><img src="/2018/12/12/resnet/convblock_kiank.png"></p>
<p>捷径上的卷积层可以用来调节 <span class="math inline">\(x\)</span> 的大小和通道数，调节通道数即上面提到的线性映射。实现步骤如下所示：</p>
<ol type="1">
<li>主路径的第一、二和三部分和 Identity block 一致</li>
<li>捷径
<ul>
<li>卷积层 Conv2D，其滤波器 <span class="math inline">\(F_3\)</span> 大小为 (1, 1)​ 和步长为 <span class="math inline">\((s, s)\)</span>，same 卷积并且命名为 <code>conv_name_base + '1'</code>。需要注意的是用的滤波器和主路径第三部分的滤波器一样，只是步长不一样，此处只是为了调节 <span class="math inline">\(x\)</span> 的形状；</li>
<li>在通道的维度上进行批标准化，命名为 <code>bn_name_base + '1'</code>；</li>
</ul></li>
<li>最后一步
<ul>
<li>将捷径的输出添加到主路径上；</li>
<li>使用 ReLU 激活函数。</li>
</ul></li>
</ol>
<p>因此一共有四个卷积层，对应三组滤波器，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolutional_block</span><span class="params">(X, f, filters, stage, block, s=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the input value</span></span><br><span class="line">    X_shortcut = X</span><br><span class="line"></span><br><span class="line">    <span class="comment">##### MAIN PATH #####</span></span><br><span class="line">    <span class="comment"># First component of main path </span></span><br><span class="line">    X = Conv2D(filters=F1, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(s, s), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2a'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2a'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, name=conv_name_base + <span class="string">'2b'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2b'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(filters=F3, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'2c'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'2c'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">##### SHORTCUT PATH #### (≈2 lines)</span></span><br><span class="line">    X_shortcut = Conv2D(filters=F3, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(s, s), padding=<span class="string">'valid'</span>, name=conv_name_base + <span class="string">'1'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X_shortcut)</span><br><span class="line">    X_shortcut = BatchNormalization(axis=<span class="number">3</span>, name=bn_name_base + <span class="string">'1'</span>)(X_shortcut)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>
<h3 id="构建-resnet-模型">构建 ResNet 模型</h3>
<p>50 层的 ResNet-50 网络结构一共分为 5 个阶段（stage），如下图所示：</p>
<p><img src="/2018/12/12/resnet/resnet_kiank.png"></p>
<p>ResNet-50 模型的细节为：</p>
<ul>
<li>零填充的大小为 (3, 3)</li>
<li>阶段一：
<ul>
<li>二维卷积使用 64 个大小为 (7, 7) 步长为 (2, 2) 的滤波器，命名为 <code>conv1</code>；</li>
<li>批标准化应用于通道的维度；</li>
<li>最大池化窗口大小为 (3, 3)，步长为 (2, 2)。</li>
</ul></li>
<li>阶段二：
<ul>
<li>Convolutional block 使用的三组滤波器的数量分别为 [64, 64, 256]，f=3，s=1，块被命名为 <code>a</code>；</li>
<li>两个 Identity block 使用的三组滤波器的数量分别为 [64, 64, 256]，f=3，块被命名为 <code>b</code> 和 <code>c</code>。</li>
</ul></li>
<li>阶段三：
<ul>
<li>Convolutional block 使用的三组滤波器的数量分别为 [128, 128, 512]，f=3，s=2，块被命名为 <code>a</code>；</li>
<li>三个 Identity block 使用的三组滤波器的数量分别为 [128, 128, 512]，f=3，块被命名为 <code>b</code>、<code>c</code> 和 <code>d</code>。</li>
</ul></li>
<li>阶段四：
<ul>
<li>Convolutional block 使用的三组滤波器的数量分别为 [256, 256, 1024]，f=3，s=2，块被命名为 <code>a</code>；</li>
<li>五个 Identity block 使用的三组滤波器的数量分别为 [256, 256, 1024]，f=3，块被命名为 <code>b</code>、<code>c</code>、<code>d</code>、<code>e</code> 和 <code>f</code>。</li>
</ul></li>
<li>阶段五：
<ul>
<li>Convolutional block 使用的三组滤波器的数量分别为 [512, 512, 2048]，f=3，s=2，块被命名为 <code>a</code>；</li>
<li>两个 Identity block 使用的三组滤波器的数量分别为 [512, 512, 2048]，f=3，块被命名为 <code>b</code> 和 <code>c</code>。</li>
</ul></li>
<li>二维平均池化层使用的窗口大小为 (2, 2)，命名为 <code>avg_pool</code></li>
<li>变平</li>
<li>全连接（Dense）层将 input 的神经元节点数降为类别数，用于 Softmax 分类，命名为 <code>'fc' + str(classes)</code></li>
</ul>
<p>代码实现如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ResNet50</span><span class="params">(input_shape=<span class="params">(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span>, classes=<span class="number">6</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Define the input as a tensor with shape input_shape</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero-Padding</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 1</span></span><br><span class="line">    X = Conv2D(<span class="number">64</span>, (<span class="number">7</span>, <span class="number">7</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'conv1'</span>, kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis=<span class="number">3</span>, name=<span class="string">'bn_conv1'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    X = MaxPooling2D((<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 2</span></span><br><span class="line">    X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'a'</span>, s=<span class="number">1</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'c'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 3 (≈4 lines)</span></span><br><span class="line">    X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'a'</span>, s=<span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'c'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'d'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 4 (≈6 lines)</span></span><br><span class="line">    X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'a'</span>, s=<span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'c'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'d'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'e'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'f'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 5 (≈3 lines)</span></span><br><span class="line">    X = X = convolutional_block(X, f=<span class="number">3</span>, filters=[<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'a'</span>, s=<span class="number">2</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'c'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AVGPOOL (≈1 line). Use "X = AveragePooling2D(...)(X)"</span></span><br><span class="line">    X = AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># output layer</span></span><br><span class="line">    X = Flatten()(X)</span><br><span class="line">    X = Dense(classes, activation=<span class="string">'softmax'</span>, name=<span class="string">'fc'</span> + str(classes), kernel_initializer=glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create model</span></span><br><span class="line">    model = Model(inputs=X_input, outputs=X, name=<span class="string">'ResNet50'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>编译训练模型，用于前面实验的手势分类，这是一个六分类的问题，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = ResNet50(input_shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>), classes=<span class="number">6</span>)</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize image vectors</span></span><br><span class="line">X_train = X_train_orig / <span class="number">255.</span></span><br><span class="line">X_test = X_test_orig / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert training and test labels to one hot matrices</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line">model.fit(X_train, Y_train, epochs = <span class="number">2</span>, batch_size = <span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">preds = model.evaluate(X_test, Y_test)</span><br><span class="line">print(<span class="string">"Loss = "</span> + str(preds[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"Test Accuracy = "</span> + str(preds[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<p>运行两个 epoch 就到使测试的准确率达到 87%，最后可以使用 <code>model.summary()</code> 查看模型概况和使用以下代码绘制模型图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot_model(model, to_file=<span class="string">'model.png'</span>)</span><br><span class="line">SVG(model_to_dot(model).create(prog=<span class="string">'dot'</span>, format=<span class="string">'svg'</span>))</span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<p>残差网络中的远跳连接解决了深度网络存在梯度消失等问题。为了解决输入和输出维度不匹配，作者提出了两种残差块，一种通过在捷径上使用卷积层调节输出的维度。最后就是将这些块堆叠起来形成深度残差网络。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>WAV 文件</title>
    <url>/2018/10/22/wav-file/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>距离上一篇博客已经过去了一个半月，这段时间看了几篇关于 Learning to Rank 的文章，老肖就很固执地想让我用到代码错误检测中去，我还是想再慢慢学一下推荐算法，看能不能做点小工作。同时这段时间想搭一个 BBS，于是升级重构了一下 phphub，算是捡起 Laravel 再学习了一下吧！深度学习也不能落下，继续搞起来。</p>
<a id="more"></a>
<h2 id="wav-文件">WAV 文件</h2>
<p>在触发词检测实验之前，先来学习一下 WAV 文件。根据百度百科的解释：</p>
<blockquote>
<p>WAV 为微软公司开发的一种声音文件格式，它符合RIFF (Resource Interchange File Format) 文件规范，用于保存 Windows 平台的音频信息资源，被 Windows 平台及其应用程序所广泛支持，该格式也支持 MSADPCM，CCITT A LAW 等多种压缩运算法，支持多种音频数字，取样频率和声道，标准格式化的 WAV 文件和 CD 格式一样，也是 44.1K 的取样频率，16 位量化数字，因此在声音文件质量和 CD 相差无几！</p>
</blockquote>
<p>表示 WAV 文件使用的是 44.1K 的采样频率，16位量化数字（即采样位数为 16）。音频文件记录的是空气压力随时间的变化，表示麦克风检测到的微小气压变化。在 DeepLearning 触发词检测实验提供的数据中，我们查看 <code>example_train.wav</code> 文件的属性可知：</p>
<ul>
<li>文件大小：1764044 字节</li>
<li>时长：00:00:10</li>
<li>比特率：1411 kbps</li>
</ul>
<p>这些值是怎么计算出来的呢？首先需要了解一下 WAV 格式文件的几个参数：</p>
<h3 id="采样频率">采样频率</h3>
<blockquote>
<p>指每秒钟取得声音样本的次数。采样的过程就是抽取某点的频率值，在一秒中内抽取的点越多，获取得频率信息更丰富，采样频率越高，声音的还原也就越真实越自然，但同时它占的资源比较多。</p>
</blockquote>
<p>现实的时间是连续的，而电脑却做不到在每个时刻都能记录声音，所以只能通过采样。由于人耳的分辨率很有限，太高的频率并不能分辨出来。22050 赫兹的采样频率是常用的，44100 赫兹已是 CD 音质，超过 48000 赫兹或 96000 赫兹的采样对人耳已经没有意义。实验数据的采样频率为 44100 赫兹，即每秒获取声音样本 44100 次。</p>
<h3 id="通道数">通道数</h3>
<blockquote>
<p>声音的通道的数目。常见的单声道和立体声（双声道），现在发展到了四声环绕（四声道）和5.1声道。</p>
</blockquote>
<p>实验数据为双声道音频，所以采样就是双份的，即一次采样包含两帧。</p>
<h3 id="采样位数">采样位数</h3>
<blockquote>
<p>声卡处理声音的解析度。这个数值越大，解析度就越高，录制和回放的声音就越真实。 采样位数也叫采样大小或量化位数。它是用来衡量声音波动变化的一个参数，也就是声卡的分辨率。它的数值越大，分辨率也就越高，录制和回放的声音就越真实。</p>
</blockquote>
<p>类似于图像的位数，位数越大，色彩越鲜艳，表达能力越强。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line">rate, data = wavfile.read(<span class="string">'example_train.wav'</span>)</span><br></pre></td></tr></table></figure>
<p>使用 <code>wavfile.read()</code> 获取 WAV 文件的采样频率和数据，<code>data.shape</code> 为：<code>(441000, 2)</code>。表示 10 秒音频一共获取声音样本 44100 × 10 次，每次采样包含两个声道（这里两个声道的声音一样）。<code>data</code> 的取值范围为 <code>(-32768, 32767)</code>，即 <span class="math inline">\(2^{16}\)</span>，表示每次的采样位数为 16。</p>
<h3 id="比特率">比特率</h3>
<blockquote>
<p>每秒平均传输的<strong>千比特</strong>数</p>
</blockquote>
<p><span class="math display">\[
比特率 = 采样频率 × 通道数 × 采样位数 / 1000
\]</span></p>
<p>根据以上公式可以计算出比特率为 1411.2 kbps，与文件属性一致。</p>
<h3 id="波形数据传输速率">波形数据传输速率</h3>
<blockquote>
<p>每秒平均传输的<strong>字节</strong>数</p>
</blockquote>
<p><span class="math display">\[
波形传输速率 = 采样频率 × 通道数 × 采样位数 / 8
\]</span></p>
<p>根据以上公式可以算出波形传输速率为 176400 字节每秒。</p>
<h3 id="文件大小">文件大小</h3>
<p><span class="math display">\[
文件大小 = 波形数据传输速率 × 音频文件时长
\]</span></p>
<p>根据以上公式可以算出文件大小为 176400,000 字节，即约为 1.68 MB，与文件属性一致。</p>
<h3 id="音频文件时长">音频文件时长</h3>
<p>也可以根据文件大小和波形数据传输速率计算出音频文件的时长： <span class="math display">\[
音频文件时长 = 文件大小 / 波形数据传输速率
\]</span> 同样可以验证音频文件的时长为 10 秒，在 Windows 操作系统中按整数显示音频文件的时长。</p>
]]></content>
      <tags>
        <tag>WAV</tag>
      </tags>
  </entry>
  <entry>
    <title>触发词检测</title>
    <url>/2018/11/15/trigger-word-detection/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>花了一些时间填补了 WAV 文件的基础知识和快速傅里叶变换算法的内容。终于可以继续学习深度学习啦！前段时间买了个小米的小爱同学，用来睡前关灯还是挺方便的，这次的实验就是研究小爱同学究竟是如何被唤醒的。</p>
<a id="more"></a>
<h2 id="触发词检测">触发词检测</h2>
<p>这次的任务是收集语音数据集并且实现触发词（也称关键字或者唤醒字）检测。举个例子：小米的小爱同学，在检测到触发词“小爱同学”后，就会被唤醒。这里的触发词是 “activate”。</p>
<h3 id="数据合成创建语音数据集">数据合成：创建语音数据集</h3>
<p>在真实场景中，还会有其他声音，例如负面词（一些其他的词）和环境背景噪声（会和触发词混合在一起出现）。很难收集大量的音频，通常都是单独下载背景噪声然后将触发词、负面词与背景噪声混合。</p>
<ul>
<li>正面词</li>
</ul>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/activate.wav" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<ul>
<li>负面词</li>
</ul>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/negative.wav" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<ul>
<li>背景噪声</li>
</ul>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/background.wav" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<h4 id="波形图">波形图</h4>
<p>声音是弹性介质中压力变化形式的机械能，这些压力变化来自振动源的波传播。声音在介质中传播时，会造成介质的压缩和稀疏，从而引起原有环境压强的变化。压缩是比环境压力更高的时段，稀疏是压力低于环境压力的时段。</p>
<p><img src="/2018/11/15/trigger-word-detection/voice.png"></p>
<p>波形图 (Waveform) 如上所示，总压强等于环境静态压强（即标准大气压 <span class="math inline">\(P\)</span>: <span class="math inline">\(10^5\)</span> Pa）加上声音扰动带来的动态压强（即声压 <span class="math inline">\(P_A\)</span>）。① 时段声压为 0 即为无声阶段；② 时段有声音扰动；③ 为大气压；④ 为瞬时声压。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fs = <span class="number">44100</span></span><br><span class="line">rate, data = wavfile.read(<span class="string">'audio_examples/example_train.wav'</span>)</span><br><span class="line">time = np.linspace(<span class="number">0</span>, len(data)/fs, num=len(data))</span><br><span class="line">plt.xlabel(<span class="string">'time/s'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'$P_A$'</span>)</span><br><span class="line">plt.plot(time, data) </span><br><span class="line"> </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/11/15/trigger-word-detection/wav.png"></p>
<p>这里的 WAV 文件使用的是 16 位量化数字，因此声压的取值范围是 (-32768, 32767)，音频时长为 10 秒。波形图看不出声音的特征，因此需要对其使用傅里叶变换，得到频谱图再分析声音的特征。</p>
<h2 id="波形图-1">波形图</h2>
<p>通过傅立叶变换可以得到信号的频谱，傅立叶变换有一个假设就是信号是平稳的，即信号的统计特性不随时间变化。声音信号就不是平稳信号，在很长的一段时间内，有很多信号会出现，然后立即消失。如果将这信号全部进行傅立叶变换，就不能反映声音随时间的变化。</p>
<h3 id="短时傅里叶变换">短时傅里叶变换</h3>
<p>声音信号虽然不是平稳信号，但在较短的一段时间内可以看作是平稳的，所以解决方案是取一小段进行傅立叶变换，即短时傅立叶变换（Short-time Fourier transform）。</p>
<h4 id="窗函数">窗函数</h4>
<p>从一段长的信号截取一段信号（通常在0.02~0.05s，称为一帧），相当于将原始信号乘以一个方窗，而方窗的傅里叶变换并不是理想的冲击函数，所以用 <code>sinc</code> 函数，<code>sinc</code> 较高的副瓣意味着在真实频点以外，副瓣的位置上的频谱也会不为零。如果在副瓣的位置上恰好有一个幅度很小的信号，就会被完全淹没。解决方案是使用窗函数，代替简单地截取一段信号，在窗的边缘，信号会乘上一个很小的数。这又会导致边缘数据并没有充分被利用，两个相邻窗之间的信号没有完全反映到频谱当中。因此解决办法是两个相邻的窗有一定的重叠，同时如果需要恢复成为时间序列，也能弥补窗函数带来的影响。总之一句话就是取一小段信号进行短时傅里叶变换会导致数据丢失，因此两个相邻的窗口之间需要有一定的重叠，重叠取加可以选择为窗长度的 50% 或者 25%。</p>
<h4 id="声谱图">声谱图</h4>
<p>语音的时域分析和频域分析是两种语音分析方法，但是这两种分析方法都有局限性。时域分析对语音信号的频率没有直观的了解，而频域分析出的特征中又没有语音信号随时间变化的关系。<strong>声谱图</strong>（语谱图）是一种三位频谱，表示语音频谱随着时间变化的图形。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> wavfile</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">rate, data = wavfile.read(<span class="string">'audio_examples/example_train.wav'</span>)</span><br><span class="line">nfft = <span class="number">200</span>     <span class="comment"># 截取的信号长度，即窗长</span></span><br><span class="line">fs = <span class="number">44100</span>     <span class="comment"># 采样频率</span></span><br><span class="line">noverlap = <span class="number">120</span> <span class="comment"># 重叠长度</span></span><br><span class="line">pxx, freqs, bins, im = plt.specgram(data[:,<span class="number">0</span>], nfft, fs, noverlap = noverlap)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/11/15/trigger-word-detection/spectrogram.png"></p>
<p>横坐标为时间，纵坐标为频率。任意给定频率成分，在给定时刻的强弱用相应点的色调的浓淡来表示，颜色越深表示语音能量越强（声音更加响亮）。10 秒音频输出 <code>pxx</code> 的时间步长度为：<span class="math inline">\(5511=\frac{10\times fs-nfft}{nfft-overlap}+1\)</span>，在原始音频中一共有 441000 个时间步，而在声谱图中一共有 5511 个时间步，因此前者每个时间步代表 0.000023 秒，后者代表 0.0018 秒。也就是说 10 秒的时间可以被离散成不同的数值，例如 GRU 的输出离散成 1375 个时间步，也就是每个时间步 0.0072 秒，模型的输出就表示这个 0.0072 秒内是否有人说过触发词。</p>
<h2 id="生成训练示例">生成训练示例</h2>
<p>为了合成一个训练样本，需要：</p>
<ul>
<li>随机选择一个 10 秒的背景音频剪辑</li>
<li>随机将 0-4 个正面音频片段插入此 10 秒剪辑中</li>
<li>随机将 0-2 个反面音频片段插入此 10 秒剪辑中</li>
</ul>
<p>通常使用 <code>pydub</code> 来处理音频。 Pydub 将原始音频文件转换为 Pydub 数据结构列表，使用 1ms 作为离散化间隔，因此 10 秒剪辑一共有 10,000 个时间步。我们希望在背景噪声中插入多个触发词和负面，同时不希望这些词重叠（声音合成而不是声音拼接，最终输出音频还是 10 秒）。</p>
<p>首先初始化背景噪声的标签，因为里面还没有触发词，所以对于所有的 <span class="math inline">\(t\)</span>，有 <span class="math inline">\(y^{\langle t \rangle}=0\)</span>。在插入触发词的时候，还需要更新标签 <span class="math inline">\(y^{\langle t \rangle}\)</span>。假设在第 5 秒的时候插入了触发词（即输出的第 <span class="math inline">\(687=int(1375\times\frac{5}{10})\)</span> 个时间步），那么我们希望模型在接下来一小段时间内能检测到就行，我们选择 50 个时间步，也就是 <span class="math inline">\(y^{\langle 688 \rangle} = y^{\langle 689 \rangle} = \cdots = y^{\langle 737 \rangle} = 1\)</span>。如下图所示，每个触发词后 50 个时间步的标签都是 1：</p>
<p><img src="/2018/11/15/trigger-word-detection/label_diagram.png"></p>
<p>合成训练数据还有一个好处就是容易生成标签，如果在录制声音的时候手动标记是非常耗时的。</p>
<h3 id="辅助函数">辅助函数</h3>
<p>为了实现训练集的合成，还需要以下辅助函数，这些函数都使用 1 毫秒离散化间隔，即 10 秒的音频总是被离散化成 10,000 步。</p>
<ol type="1">
<li><p><code>get_random_time_segment(segment_ms)</code> 从背景音频中选择指定长度的随机时间片段；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_random_time_segment</span><span class="params">(segment_ms)</span>:</span></span><br><span class="line">    segment_start = np.random.randint(low=<span class="number">0</span>, high=<span class="number">10000</span>-segment_ms) <span class="comment"># 防止超出 10s</span></span><br><span class="line">    segment_end = segment_start + segment_ms - <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (segment_start, segment_end)</span><br></pre></td></tr></table></figure></li>
<li><p><code>is_overlapping(segment_time, existing_segments)</code> 判断时间片是否与先前的时间片重叠；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_overlapping</span><span class="params">(segment_time, previous_segments)</span>:</span></span><br><span class="line">    segment_start, segment_end = segment_time</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Initialize overlap as a "False" flag.</span></span><br><span class="line">    overlap = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: loop over the previous_segments start and end times.</span></span><br><span class="line">    <span class="comment"># Compare start/end times and set the flag to True if there is an overlap.</span></span><br><span class="line">    <span class="keyword">for</span> previous_start, previous_end <span class="keyword">in</span> previous_segments:</span><br><span class="line">        <span class="keyword">if</span> segment_start &lt;= previous_end <span class="keyword">and</span> segment_end &gt;= previous_start:</span><br><span class="line">            overlap = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> overlap</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">overlap1 = is_overlapping((<span class="number">950</span>, <span class="number">1430</span>), [(<span class="number">2000</span>, <span class="number">2550</span>), (<span class="number">260</span>, <span class="number">949</span>)])</span><br><span class="line">overlap2 = is_overlapping((<span class="number">2305</span>, <span class="number">2950</span>), [(<span class="number">824</span>, <span class="number">1532</span>), (<span class="number">1900</span>, <span class="number">2305</span>), (<span class="number">3424</span>, <span class="number">3656</span>)])</span><br><span class="line">assertFalse(overlap1)</span><br><span class="line">assertTrue(overlap2)</span><br></pre></td></tr></table></figure></li>
<li><p><code>insert_audio_clip(background, audio_clip, existing_times)</code> 使用上述两个辅助函数在背景音频的随机时间处插入一个音频时间片，需要完成 4 步：</p>
<ol type="1">
<li>以毫秒为单位随机选择时间片；</li>
<li>确保时间片与先前的时间片都不重叠，否则返回上一个步骤重新选择时间片；</li>
<li>将新时间片添加到现有时间片列表中，以跟踪插入的所有时间片；</li>
<li>使用 pydub 将音频重叠在背景噪声中（使用 overlay 函数）。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_audio_clip</span><span class="params">(background, audio_clip, previous_segments)</span>:</span></span><br><span class="line">    <span class="comment"># Get the duration of the audio clip in ms</span></span><br><span class="line">    segment_ms = len(audio_clip)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Use one of the helper functions to pick a random time segment onto which to insert </span></span><br><span class="line">    <span class="comment"># the new audio clip. (≈ 1 line)</span></span><br><span class="line">    segment_time = get_random_time_segment(segment_ms)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Check if the new segment_time overlaps with one of the previous_segments. If so, keep </span></span><br><span class="line">    <span class="comment"># picking new segment_time at random until it doesn't overlap. (≈ 2 lines)</span></span><br><span class="line">    <span class="keyword">while</span> is_overlapping(segment_time, previous_segments):</span><br><span class="line">        segment_time = get_random_time_segment(segment_ms)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Add the new segment_time to the list of previous_segments (≈ 1 line)</span></span><br><span class="line">    previous_segments.append(segment_time)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 4: Superpose audio segment and background</span></span><br><span class="line">    new_background = background.overlay(audio_clip, position = segment_time[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> new_background, segment_time</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">5</span>)</span><br><span class="line">audio_clip, segment_time = insert_audio_clip(backgrounds[<span class="number">0</span>], activates[<span class="number">0</span>], [(<span class="number">3790</span>, <span class="number">4400</span>)])</span><br><span class="line">audio_clip.export(<span class="string">"insert_test.wav"</span>, format=<span class="string">"wav"</span>)</span><br><span class="line">print(<span class="string">"Segment Time: "</span>, segment_time)</span><br><span class="line">IPython.display.Audio(<span class="string">"insert_test.wav"</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/insert_test.wav" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<ol start="4" type="1">
<li><p><code>insert_ones(y, segment_end_ms)</code> 在 ”activate” 之后插入 1 到标签向量 <span class="math inline">\(y\)</span> 中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_ones</span><span class="params">(y, segment_end_ms)</span>:</span></span><br><span class="line">    <span class="comment"># duration of the background (in terms of spectrogram time-steps)</span></span><br><span class="line">    segment_end_y = int(segment_end_ms * Ty / <span class="number">10000.0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Add 1 to the correct index in the background label (y)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(segment_end_y + <span class="number">1</span>, segment_end_y + <span class="number">51</span>):</span><br><span class="line">        <span class="keyword">if</span> i &lt; Ty:</span><br><span class="line">            y[<span class="number">0</span>, i] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<p>注意标签一共有 1375 个时间步，因此不能越界。测试一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = insert_ones(np.zeros((<span class="number">1</span>, Ty)), <span class="number">9700</span>)</span><br><span class="line">plt.plot(insert_ones(arr1, <span class="number">4251</span>)[<span class="number">0</span>,:])</span><br><span class="line">print(<span class="string">"sanity checks:"</span>, arr1[<span class="number">0</span>][<span class="number">1333</span>], arr1[<span class="number">0</span>][<span class="number">634</span>], arr1[<span class="number">0</span>][<span class="number">635</span>])</span><br></pre></td></tr></table></figure>
<p>sanity checks: 0.0 1.0 0.0</p>
<p><img src="/2018/11/15/trigger-word-detection/output1.png"></p></li>
</ol>
<h3 id="生成训练样本">生成训练样本</h3>
<p>实现 <code>create_training_example()</code> 来生成所有训练样本：</p>
<ol type="1">
<li>将标签向量 <span class="math inline">\(y\)</span> 初始化为零值的 <span class="math inline">\((1，T_y)\)</span> numpy 数组；</li>
<li>将已存在时间片集合初始化为空列表；</li>
<li>随机选择 0 至 4 个 “activate” 音频剪辑，并将其插入 10 秒剪辑，记着将标签插入标签向量 <span class="math inline">\(y\)</span> 中的正确位置；</li>
<li>随机选择 0 到 2 个负面音频片段，并将它们插入 10 秒片段。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_training_example</span><span class="params">(background, activates, negatives)</span>:</span></span><br><span class="line">    <span class="comment"># Set the random seed</span></span><br><span class="line">    np.random.seed(<span class="number">18</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Make background quieter</span></span><br><span class="line">    background = background - <span class="number">20</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Initialize y (label vector) of zeros (≈ 1 line)</span></span><br><span class="line">    y = np.zeros((<span class="number">1</span>, Ty))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Initialize segment times as empty list (≈ 1 line)</span></span><br><span class="line">    previous_segments = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Select 0-4 random "activate" audio clips from the entire list of "activates" recordings</span></span><br><span class="line">    number_of_activates = np.random.randint(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">    random_indices = np.random.randint(len(activates), size=number_of_activates)</span><br><span class="line">    random_activates = [activates[i] <span class="keyword">for</span> i <span class="keyword">in</span> random_indices]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Loop over randomly selected "activate" clips and insert in background</span></span><br><span class="line">    <span class="keyword">for</span> random_activate <span class="keyword">in</span> random_activates:</span><br><span class="line">        <span class="comment"># Insert the audio clip on the background</span></span><br><span class="line">        background, segment_time = insert_audio_clip(background, random_activate, previous_segments)</span><br><span class="line">        <span class="comment"># Retrieve segment_start and segment_end from segment_time</span></span><br><span class="line">        segment_start, segment_end = segment_time</span><br><span class="line">        <span class="comment"># Insert labels in "y"</span></span><br><span class="line">        y = insert_ones(y, segment_end_ms=segment_end)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select 0-2 random negatives audio recordings from the entire list of "negatives" recordings</span></span><br><span class="line">    number_of_negatives = np.random.randint(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">    random_indices = np.random.randint(len(negatives), size=number_of_negatives)</span><br><span class="line">    random_negatives = [negatives[i] <span class="keyword">for</span> i <span class="keyword">in</span> random_indices]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 4: Loop over randomly selected negative clips and insert in background</span></span><br><span class="line">    <span class="keyword">for</span> random_negative <span class="keyword">in</span> random_negatives:</span><br><span class="line">        <span class="comment"># Insert the audio clip on the background </span></span><br><span class="line">        background, _ = insert_audio_clip(background, random_negative, previous_segments)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Standardize the volume of the audio clip </span></span><br><span class="line">    background = match_target_amplitude(background, <span class="number">-20.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Export new training example </span></span><br><span class="line">    file_handle = background.export(<span class="string">"train"</span> + <span class="string">".wav"</span>, format=<span class="string">"wav"</span>)</span><br><span class="line">    print(<span class="string">"File (train.wav) was saved in your directory."</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<h2 id="开发测试集">开发测试集</h2>
<p>为了测试模型，实验记录了 25 个样本的开发集。虽然训练数据是合成的，但是开发集应该与实际输入具有相同的分布，因此实验手工标记了 25 个 10 秒钟的音频剪辑。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load preprocessed training examples</span></span><br><span class="line">X = np.load(<span class="string">"./XY_train/X.npy"</span>)</span><br><span class="line">Y = np.load(<span class="string">"./XY_train/Y.npy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load preprocessed dev set examples</span></span><br><span class="line">X_dev = np.load(<span class="string">"./XY_dev/X_dev.npy"</span>)</span><br><span class="line">Y_dev = np.load(<span class="string">"./XY_dev/Y_dev.npy"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型">模型</h2>
<p>实验模型使用一维的卷积层、GRU 层和全连接层，首先载入相关的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model, Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> GRU, Bidirectional, BatchNormalization, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br></pre></td></tr></table></figure>
<h3 id="构建模型">构建模型</h3>
<p>模型结构如下图所示：</p>
<p><img src="/2018/11/15/trigger-word-detection/model.png"></p>
<p>该模型的一个关键步骤是一维卷积步骤，它的输入是 5511 个时间步的频谱，然后输出一个 1375 个时间步的输出。从计算的角度而言，卷积层有助于加速模型，经过卷积层后 GRU 仅处理 1375 个时间步而不是 5511 个时间步。两层 GRU 从左往右读入绪论，然后使用全连接神经网络加 Sigmoid 层对 <span class="math inline">\(y^{\langle t \rangle}\)</span> 进行预测，判断用户是否刚刚说过 “activate”。</p>
<p>注意：这里使用的是单向 RNN，因为如果想要使用双向 RNN，那么就必须等待整个 10 秒的音频被记录下来后从能确定音频片段是都具有 “activate”。</p>
<p>可以通过以下 4 个步骤来实现模型：</p>
<ol type="1">
<li><p>使用 <code>Conv1D()</code> 来实现卷积层，有 196 个卷积核，每个卷积核的大小为 15(<code>kernel_size=15</code>)，并且步长为 4；</p></li>
<li><p>用 <code>X = GRU(units = 128, return_sequences = True)(X)</code> 实现 GRU 层，设置 <code>return_sequences=True</code> 确保所有时间步的隐藏状态都会喂给下一层，同时记得添加 Dropout 和 BatchNorm 层；</p></li>
<li><p>第二个 GRU 层，和上一个步骤类似，只不过多了一个 Dropout 层；</p></li>
<li><p>创建全连接层：</p>
<p><code>X = TimeDistributed(Dense(1, activation = "sigmoid"))(X)</code></p>
<p>这样全连接层后面就会跟一个 Sigmoid 层，TimeDistributed 可以让每个时间步的全连接层的参数一样。</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">    X_input = Input(shape = input_shape)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: CONV layer</span></span><br><span class="line">    X = Conv1D(<span class="number">196</span>, <span class="number">15</span>, strides=<span class="number">4</span>)(X_input)             <span class="comment"># CONV1D</span></span><br><span class="line">    X = BatchNormalization()(X)                         <span class="comment"># Batch normalization</span></span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)                           <span class="comment"># ReLu activation</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: First GRU Laye</span></span><br><span class="line">    X = GRU(units = <span class="number">128</span>, return_sequences=<span class="literal">True</span>)(X)      <span class="comment"># GRU (use 128 units and return the sequences)</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line">    X = BatchNormalization()(X)                         <span class="comment"># Batch normalization</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Second GRU Layer</span></span><br><span class="line">    X = GRU(units = <span class="number">128</span>, return_sequences=<span class="literal">True</span>)(X)      <span class="comment"># GRU (use 128 units and return the sequences)</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line">    X = BatchNormalization()(X)                         <span class="comment"># Batch normalization</span></span><br><span class="line">    X = Dropout(<span class="number">0.8</span>)(X)                                 <span class="comment"># dropout (use 0.8)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 4: Time-distributed dense layer</span></span><br><span class="line">    X = TimeDistributed(Dense(<span class="number">1</span>, activation = <span class="string">"sigmoid"</span>))(X) <span class="comment"># time distributed  (sigmoid)</span></span><br><span class="line"></span><br><span class="line">    model = Model(inputs = X_input, outputs = X)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = model(input_shape = (Tx, n_freq))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<h3 id="拟合测试模型">拟合&amp;测试模型</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.0001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=opt, metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line">model.fit(X, Y, batch_size = <span class="number">5</span>, epochs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">loss, acc = model.evaluate(X_dev, Y_dev)</span><br><span class="line">print(<span class="string">"Dev set accuracy = "</span>, acc)</span><br></pre></td></tr></table></figure>
<p>这个问题的样本不太均衡，因为神经网络很有可能就将所有的数据判断为 0，即不是触发词。因此需要定义更多有用的指标，例如 F1 分数或者 Precision/Recall。</p>
<h3 id="预测">预测</h3>
<p>模型训练完成后就可以用来对真实音频进行预测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect_triggerword</span><span class="params">(filename)</span>:</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x = graph_spectrogram(filename)</span><br><span class="line">    <span class="comment"># the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model</span></span><br><span class="line">    x  = x.swapaxes(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">    predictions = model.predict(x)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(predictions[<span class="number">0</span>,:,<span class="number">0</span>])</span><br><span class="line">    plt.ylabel(<span class="string">'probability'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure>
<p>计算出在每个输出步骤检测到 “activate” 这个词的概率，当概率超过某个阈值时，就可以触发鸣响。此外，在检测到触发词后，对于后面连续的许多值，标签可能都接近于 1，但是我们只想响一次，因此可以设置每 75 个输出时间步最多响一次，类似于计算机视觉的非最大抑制作用。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chime_file = <span class="string">"audio_examples/chime.wav"</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chime_on_activate</span><span class="params">(filename, predictions, threshold)</span>:</span></span><br><span class="line">    audio_clip = AudioSegment.from_wav(filename)</span><br><span class="line">    chime = AudioSegment.from_wav(chime_file)</span><br><span class="line">    Ty = predictions.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># Step 1: Initialize the number of consecutive output steps to 0</span></span><br><span class="line">    consecutive_timesteps = <span class="number">0</span></span><br><span class="line">    <span class="comment"># Step 2: Loop over the output steps in the y</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Ty):</span><br><span class="line">        <span class="comment"># Step 3: Increment consecutive output steps</span></span><br><span class="line">        consecutive_timesteps += <span class="number">1</span></span><br><span class="line">        <span class="comment"># Step 4: If prediction is higher than the threshold and more than 75 consecutive output steps have passed</span></span><br><span class="line">        <span class="keyword">if</span> predictions[<span class="number">0</span>,i,<span class="number">0</span>] &gt; threshold <span class="keyword">and</span> consecutive_timesteps &gt; <span class="number">75</span>:</span><br><span class="line">            <span class="comment"># Step 5: Superpose audio and background using pydub</span></span><br><span class="line">            audio_clip = audio_clip.overlay(chime, position = ((i / Ty) * audio_clip.duration_seconds)*<span class="number">1000</span>)</span><br><span class="line">            <span class="comment"># Step 6: Reset consecutive output steps to 0</span></span><br><span class="line">            consecutive_timesteps = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    audio_clip.export(<span class="string">"chime_output.wav"</span>, format=<span class="string">'wav'</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="测试例子">测试例子</h4>
<p>原音频：</p>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/my_audio.wav" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<p>接下来对该音频进行预测，如果检测到 “activate”，就发出鸣响：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">filename  = <span class="string">"audio_examples/my_audio.wav"</span><span class="string">"</span></span><br><span class="line"><span class="string">prediction = detect_triggerword(filename)</span></span><br><span class="line"><span class="string">chime_on_activate(filename, prediction, 0.5)</span></span><br><span class="line"><span class="string">IPython.display.Audio("</span>./chime_output.wav<span class="string">")</span></span><br></pre></td></tr></table></figure>
<p><img src="/2018/11/15/trigger-word-detection/output2.png"></p>
<center>
<audio controls controlslist="nodownload">
<source src="https://randy-1251769892.cos.ap-beijing.myqcloud.com/chime_output.wav" type="audio/mpeg">
Your browser does not support the audio element.</audio>
</center>
<p>Sigmoid 的输出大于 0.5，表示检测到了触发词，因此添加了鸣响。</p>
<h2 id="总结">总结</h2>
<p>终于完成了 Sequence 系列的实验，对触发词检测的流程有了个大致的了解，但是还是感觉神经网络就像炼丹，知道模型的结构这么设置有什么好处，但是还是不知道为什么要这么设置，都是靠直觉？</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>meelo. 短时傅里叶变换解析. https://www.cnblogs.com/meelo/p/5640009.html</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>词向量表示</title>
    <url>/2018/08/31/word-vector-representation/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>实验和上一篇博客都使用了 Embedding，这篇博客正好可以加深对词向量和嵌入矩阵的理解。发现吴恩达课程里面很多内容他说在实验里有，但是我却没找到，例如本节中的负采样，难道他也喜欢挖坑不喜欢填？</p>
<a id="more"></a>
<h2 id="词汇表征">词汇表征</h2>
<p>在自然语言处理领域一个很重要的概念就是词嵌入 (Word Embeddings)，这是语言表示的一种方式，可以让算法理解一些<strong>类似</strong>的词。在使用词嵌入以前，通常用的都是词汇表，也就是将一个个单词变成独热向量，但是这样的表示没有办法让模型理解相似的词，引用夏树涛老师的一句话就是：独热向量的欧氏距离是没有意义的！</p>
<p>因此很有必要使用特征化的表示来表示每个词，也就是学习给每个词进行分类，例如词汇量为 5 的词汇表对应的嵌入矩阵如下所示：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Man</th>
<th>Woman</th>
<th>King</th>
<th>Queen</th>
<th>Apple</th>
<th>Orange</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gender</td>
<td>-1</td>
<td>1</td>
<td>-0.95</td>
<td>0.97</td>
<td>0.00</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>Royal</td>
<td>0.01</td>
<td>0.02</td>
<td>0.93</td>
<td>0.95</td>
<td>-0.01</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>Age</td>
<td>0.03</td>
<td>0.02</td>
<td>0.7</td>
<td>0.69</td>
<td>0.03</td>
<td>-0.02</td>
</tr>
<tr class="even">
<td>Food</td>
<td>0.09</td>
<td>0.01</td>
<td>0.02</td>
<td>0.01</td>
<td>0.95</td>
<td>0.97</td>
</tr>
</tbody>
</table>
<p>对于词汇表中任意单词的独热向量 <span class="math inline">\(O_i\)</span>，它的大小是 <span class="math inline">\(5\times 1\)</span> ，嵌入矩阵 <span class="math inline">\(E\)</span> 大小为 <span class="math inline">\(4\times 5\)</span> ， 那么 <span class="math inline">\(EO_i\)</span> 就可以得到词汇表中单词 <span class="math inline">\(i\)</span> 的嵌入向量。 模型在遇到 Apple 和 Orange 的时候就可以计算两个向量的余弦相似度，从而知道它们都是食物。在实践中可以使用 t-SNE 算法可视化高维特征向量，这个算法会将高维向量映射到一个二维空间中。</p>
<h3 id="余弦相似度">余弦相似度</h3>
<p>为了衡量两个单词的相似性，我们需要一种衡量两个单词的嵌入向量的方法。给定两个向量 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span>，其余弦相似度定义为： <span class="math display">\[
\text{CosineSimilarity(u, v)} = \frac {u . v} {||u||_2 ||v||_2} = cos(\theta)
\]</span> 其中分子是两个向量的点乘，分母是两个向量的二范数的乘积，<span class="math inline">\(\theta\)</span> 是两个向量形成的角度。两个向量越相似，余弦相似度就越接近于 1，不相似则取值会很小。图像如下图所示：</p>
<p><img src="/2018/08/31/word-vector-representation/cosine_sim.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosine_similarity</span><span class="params">(u, v)</span>:</span></span><br><span class="line">    distance = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the dot product between u and v (≈1 line)</span></span><br><span class="line">    dot = np.dot(u, v)</span><br><span class="line">    <span class="comment"># Compute the L2 norm of u (≈1 line)</span></span><br><span class="line">    norm_u = np.sqrt(np.sum(np.power(u,<span class="number">2</span>)))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute the L2 norm of v (≈1 line)</span></span><br><span class="line">    norm_v = np.sqrt(np.sum(np.power(v,<span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># Compute the cosine similarity defined by formula (1) (≈1 line)</span></span><br><span class="line">    cosine_similarity = np.divide(dot, norm_u * norm_v)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cosine_similarity</span><br></pre></td></tr></table></figure>
<h3 id="学习词嵌入">学习词嵌入</h3>
<p>通常在使用词嵌入的时候，可以针对自己的数据集训练（也就是学习上面表格中的嵌入矩阵 <span class="math inline">\(E\)</span>），如果数据集不是很充分也可以从网上下载训练好的词嵌入模型。在实践中通常是建立一个语言模型进行学习词嵌入（也就是说不是单独地去训练词嵌入），例如使用神经网络预测序列的下一个单词，I want a glass of orange __。 在实践中通常的做法是使用一个固定的历史窗口，例如超参数窗口大小为 4，那么就只用前面 4 个单词来预测下一个单词。嵌入矩阵也是一个参数，可以在训练过程中学习出来。如果训练集中的句子比较复杂还可以考虑上下文，即用前面四个词和后面四个词来预测中间的词。所以如果使用预训练的嵌入矩阵，那么在这个步骤就可以再训练一下，或者不训练（把它当成超参数）直接使用。</p>
<h4 id="word2vec">Word2Vec</h4>
<p>Word2Vec 算法有两种模型 Skip-grams 和 CBOW，视频中只介绍了 Skip-grams，因为它在大型语料库中表现更好。这个模型的做法是随机选择一个单词 <span class="math inline">\(O_c\)</span> 作为上下文，然后在一定的词距内随机选另一个词 <span class="math inline">\(O_t\)</span> 作为待预测的词，即目标词，然后进行监督学习。虽然不太容易预测，但是这个模型可以很好地学习出嵌入矩阵，其中 <span class="math inline">\(e_c=EO_c\)</span>，对于 10,000 个单词的词汇表，softmax 预测目标词 <span class="math inline">\(O_t\)</span> 的概率为： <span class="math display">\[
P(O_t|O_c) = \frac{e^{\theta_{t}^{T}e_{c}}}{\sum_{i=1}^{10,000}e^{\theta_{i}^{T}e_{c}}}
\]</span> 其中 <span class="math inline">\(\theta_t\)</span> 是判断输出为 <span class="math inline">\(O_t\)</span> 这个类别的参数。损失函数为： <span class="math display">\[
L(\hat y,y)=-\sum_{i=1}^{10,000}{y_{i}\log\hat y_{i}}
\]</span> 损失函数中的 <span class="math inline">\(\hat y\)</span> 和 <span class="math inline">\(y\)</span> 都是独热向量。在计算概率的时候，分母要累加所有词汇在给定词汇情况下的概率，所以词汇量比较大的时候计算量比较大，因此可以采用分级 softmax 分类器或者<strong>负采样</strong>。分级 softmax 分类器的思想是使用霍夫曼树，先判断词属于前 5000 个还是后 5000 个，然后继续分析，最后时间复杂度就从 N 变成 logN。 不过需要注意的是，在实践中使用的不是完全平衡的分类树，而且通常常用词会放在树根。详细的内容可以参考原文献[2]。</p>
<h4 id="负采样">负采样</h4>
<p>Skim-grams 其实就是学习从 <span class="math inline">\(x\)</span> 映射到 <span class="math inline">\(y\)</span> 的监督模型，只不过时间复杂度有点大。而负采样需要构造一个新的监督学习问题，即给定一对单词，例如 orange 和 juice，预测它们是否属于一对上下文-目标词。例如有一个句子：I want a glass of orange juice to go along with my cereal.</p>
<p>首先从句子中采样得到一个上下文词 orange 和一个目标词 juice，然后标记为 1；然后去字典中随机选 k （这里 k=4）个单词，标记为 0（即使 of 也出现在句子中）：</p>
<table>
<thead>
<tr class="header">
<th>Context</th>
<th>Word</th>
<th>Target?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>orange</td>
<td>juice</td>
<td>1</td>
</tr>
<tr class="even">
<td>orange</td>
<td>king</td>
<td>0</td>
</tr>
<tr class="odd">
<td>orange</td>
<td>book</td>
<td>0</td>
</tr>
<tr class="even">
<td>orange</td>
<td>the</td>
<td>0</td>
</tr>
<tr class="odd">
<td>orange</td>
<td>of</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>给定输入的上下文词 <span class="math inline">\(O_c\)</span> 和可能的目标词 <span class="math inline">\(O_t\)</span> ，定义一个逻辑回归模型，判断输出： <span class="math display">\[
P(y=1|c,t)=\sigma(\theta_t^Te_c)
\]</span> 即每个正样本都有 K 个对应的负样本来训练一个逻辑回归模型，相对而言每次迭代的成本更低，详细内容可以参考原文献[3]。在负采样的时候如果均匀采样，则学不到单词的分布，如果根据单词的频率采样又可能导致一些介词的频率很高，因此通常介于这两者之间： <span class="math display">\[
P(\omega_i)=\frac{f(\omega_i)^{\frac{3}{4}}}{\sum_{j=1}^{10,000}f(\omega_i)^{\frac{3}{4}}}
\]</span> 其中 <span class="math inline">\(f(\omega_i)\)</span> 是语料库中某个单词的词频。</p>
<h4 id="glove-词向量">GloVe 词向量</h4>
<p>GloVe 表示<strong>用于词表示的全局变量</strong>（Global vectors for word representation），假设 <span class="math inline">\(X_{ij}\)</span> 为单词 <span class="math inline">\(i\)</span> 在上下文词 <span class="math inline">\(j\)</span> 中出现的次数（即两个词出现在同一个窗口中的次数）。如果上下文词和目标词的范围定义为左右各 10 各词的话，根据定义有 <span class="math inline">\(X_{ij}=X_{ji}\)</span>，矩阵 <span class="math inline">\(X\)</span> 也叫做语料库的共现矩阵。GloVe 就是要最小化： <span class="math display">\[
\text{minimize}\sum_{i=1}^{10,000}\sum_{j=1}^{10,000}f(X_{ij})(\theta_i^Te_j+b_i+\tilde{b_j}-logX_{ij})^2
\]</span> 其中 <span class="math inline">\(b_i\)</span> 和 <span class="math inline">\(\tilde{b_j}\)</span> 是两个词向量的偏置项， 权重函数 <span class="math inline">\(f(X_{ij})\)</span> 是一个截断函数： <span class="math display">\[
f(x) =
\begin{cases}
(x/x_{max})^\alpha &amp; \text{if $x&lt;x_{max}$ } \\\
1 &amp; \text{otherwise}
\end{cases}
\]</span> 原文献中 <span class="math inline">\(\alpha\)</span> 的取值都是 0.75，而 <span class="math inline">\(x_{max}\)</span> 取值都是 100，损失函数的详细推导过程可以参考原文献[4]。</p>
<h2 id="单词类比任务">单词类比任务</h2>
<p><strong>man is to woman as king is to queen</strong>，即给定单词 a(man)、b(woman) 和 c(king)，需要找到一个单词 d 满足 <span class="math inline">\(e_b - e_a \approx e_d - e_c\)</span>。这里衡量 <span class="math inline">\(e_b - e_a\)</span> 就用余弦相似度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">complete_analogy</span><span class="params">(word_a, word_b, word_c, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="comment"># convert words to lower case</span></span><br><span class="line">    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Get the word embeddings v_a, v_b and v_c (≈1-3 lines)</span></span><br><span class="line">    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]</span><br><span class="line">    </span><br><span class="line">    words = word_to_vec_map.keys()</span><br><span class="line">    max_cosine_sim = <span class="number">-100</span>              <span class="comment"># Initialize max_cosine_sim to a large negative number</span></span><br><span class="line">    best_word = <span class="literal">None</span>                   <span class="comment"># Initialize best_word with None, it will help keep track of the word to output</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># loop over the whole word vector set</span></span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> words:        </span><br><span class="line">        <span class="comment"># to avoid best_word being one of the input words, pass on them.</span></span><br><span class="line">        <span class="keyword">if</span> w <span class="keyword">in</span> [word_a, word_b, word_c] :</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)  (≈1 line)</span></span><br><span class="line">        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># If the cosine_sim is more than the max_cosine_sim seen so far,</span></span><br><span class="line">            <span class="comment"># then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word (≈3 lines)</span></span><br><span class="line">        <span class="keyword">if</span> cosine_sim &gt; max_cosine_sim:</span><br><span class="line">            max_cosine_sim = cosine_sim</span><br><span class="line">            best_word = w</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> best_word</span><br></pre></td></tr></table></figure>
<h2 id="去偏词向量">去偏词向量</h2>
<p>首先计算一个向量 <span class="math inline">\(g = e_{woman}-e_{man}\)</span>，这个向量可以粗略地看成是性别 <strong>g</strong>ender。或者可以同时计算:</p>
<ul>
<li><p><span class="math inline">\(g_1 = e_{mother}-e_{father}\)</span></p></li>
<li><p><span class="math inline">\(g_2 = e_{girl}-e_{boy}\)</span></p></li>
</ul>
<p>最后取这三个向量的均值作为性别则会更加精确。可以通过以下代码验证我们的想法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name_list = [<span class="string">'john'</span>, <span class="string">'marie'</span>, <span class="string">'sophie'</span>, <span class="string">'ronaldo'</span>, <span class="string">'priya'</span>, <span class="string">'rahul'</span>, <span class="string">'danielle'</span>, <span class="string">'reza'</span>, <span class="string">'katy'</span>, <span class="string">'yasmin'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> name_list:</span><br><span class="line">    <span class="keyword">print</span> (w, cosine_similarity(word_to_vec_map[w], g))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List of names and their similarities with constructed vector:</span><br><span class="line">john [-0.23163356]</span><br><span class="line">marie [0.31559794]</span><br><span class="line">sophie [0.3186879]</span><br><span class="line">ronaldo [-0.31244797]</span><br><span class="line">priya [0.17632042]</span><br><span class="line">rahul [-0.16915471]</span><br><span class="line">danielle [0.24393299]</span><br><span class="line">reza [-0.0793043]</span><br><span class="line">katy [0.28310687]</span><br><span class="line">yasmin [0.23313858]</span><br></pre></td></tr></table></figure>
<p>可以看出，一些比较女性化的名字和 <span class="math inline">\(g\)</span> 的相似性大于0，比较男性化的名字和 <span class="math inline">\(g\)</span> 的相似性则小于 0。</p>
<h3 id="中和无性别单词的偏差">中和无性别单词的偏差</h3>
<p>下面是一些词和性别的相似性，虽然大部分的工程师是男性，但是这有点性别歧视了，而且这些词本身是不应该有性别之分的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">receptionist [0.33077942]</span><br><span class="line">technology [-0.13193732]</span><br><span class="line">teacher [0.17920923]</span><br><span class="line">engineer [-0.0803928]</span><br></pre></td></tr></table></figure>
<p>假如词嵌入是 50 维，则可以分为两部分：偏置方向 <span class="math inline">\(g\)</span> 和其余的 49 维 <span class="math inline">\(g_{\perp}\)</span>。其余的 49 维与性别无关，所以是正交的。下面的任务就是把向量 <span class="math inline">\(e_{receptionist}\)</span> 的 <span class="math inline">\(g\)</span> 方向置 0，得到 <span class="math inline">\(e_{receptionist}^{debiased}\)</span>。如下图所示：</p>
<p><img src="/2018/08/31/word-vector-representation/neutral.png"> <span class="math display">\[
e^{bias\\_component} = \frac{e \cdot g}{||g||_2^2} * g
\]</span></p>
<p><span class="math display">\[
e^{debiased} = e - e^{bias\\_component}
\]</span></p>
<p><span class="math inline">\(e^{bias\\_component}\)</span> 也就是 <span class="math inline">\(e\)</span> 在方向 <span class="math inline">\(g\)</span> 上的投影。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neutralize</span><span class="params">(word, g, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="comment"># Select word vector representation of "word". Use word_to_vec_map. (≈ 1 line)</span></span><br><span class="line">    e = word_to_vec_map[word]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute e_biascomponent using the formula give above. (≈ 1 line)</span></span><br><span class="line">    e_biascomponent = np.divide(np.dot(e, g), np.linalg.norm(g)**<span class="number">2</span>) * g</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Neutralize e by substracting e_biascomponent from it </span></span><br><span class="line">    <span class="comment"># e_debiased should be equal to its orthogonal projection. (≈ 1 line)</span></span><br><span class="line">    e_debiased = e - e_biascomponent</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> e_debiased</span><br></pre></td></tr></table></figure>
<h3 id="性别专用词均衡算法">性别专用词均衡算法</h3>
<p>均衡算法可以应用于两个只有性别之分的词。例如男演员 (actor) 和女演员 (actress)，可能女演员更接近保姆 (babysit)，通过对 babysit 的中和可以减少保姆和性别的关联性，但是还是不能保证这两种演员和其他词的关联性是否相同。均衡算法就可以处理这个问题，均衡算法的原理如下图所示：</p>
<p><img src="/2018/08/31/word-vector-representation/equalize.png"></p>
<p>原理就是保证这两个词到 49 维的 <span class="math inline">\(g_\perp\)</span> 的距离相等，公式参考 Bolukbasi et al., 2016： <span class="math display">\[
\mu = \frac{e_{w1} + e_{w2}}{2}
\]</span></p>
<p><span class="math display">\[
\mu_{B} = \frac {\mu \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}
\]</span></p>
<p><span class="math display">\[
\mu_{\perp} = \mu - \mu_{B}
\]</span></p>
<p><span class="math display">\[
e_{w1B} = \frac {e_{w1} \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}
\]</span></p>
<p><span class="math display">\[
e_{w2B} = \frac {e_{w2} \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}
\]</span></p>
<p><span class="math display">\[
e_{w1B}^{corrected} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{e_{\text{w1B}} - \mu_B} {|(e_{w1} - \mu_{\perp}) - \mu_B)|}
\]</span></p>
<p><span class="math display">\[
e_{w2B}^{corrected} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{e_{\text{w2B}} - \mu_B} {|(e_{w2} - \mu_{\perp}) - \mu_B)|}
\]</span></p>
<p><span class="math display">\[
e_1 = e_{w1B}^{corrected} + \mu_{\perp}
\]</span></p>
<p><span class="math display">\[
e_2 = e_{w2B}^{corrected} + \mu_{\perp}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">equalize</span><span class="params">(pair, bias_axis, word_to_vec_map)</span>:</span></span><br><span class="line">    <span class="comment"># Step 1: Select word vector representation of "word". Use word_to_vec_map. (≈ 2 lines)</span></span><br><span class="line">    w1, w2 = pair</span><br><span class="line">    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Compute the mean of e_w1 and e_w2 (≈ 1 line)</span></span><br><span class="line">    mu = (e_w1 + e_w2) / <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3: Compute the projections of mu over the bias axis and the orthogonal axis (≈ 2 lines)</span></span><br><span class="line">    mu_B = np.divide(np.dot(mu, bias_axis), np.linalg.norm(bias_axis)**<span class="number">2</span>) * bias_axis</span><br><span class="line">    mu_orth = mu - mu_B</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 4: Use equations (7) and (8) to compute e_w1B and e_w2B (≈2 lines)</span></span><br><span class="line">    e_w1B = np.divide(np.dot(e_w1, bias_axis), np.linalg.norm(bias_axis)**<span class="number">2</span>) * bias_axis</span><br><span class="line">    e_w2B = np.divide(np.dot(e_w2, bias_axis), np.linalg.norm(bias_axis)**<span class="number">2</span>) * bias_axis</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Step 5: Adjust the Bias part of e_w1B and e_w2B using the formulas (9) and (10) given above (≈2 lines)</span></span><br><span class="line">    corrected_e_w1B = np.sqrt(np.abs(<span class="number">1</span> - np.sum(mu_orth**<span class="number">2</span>))) * np.divide(e_w1B - mu_B, np.abs(e_w1 - mu_orth - mu_B))</span><br><span class="line">    corrected_e_w2B = np.sqrt(np.abs(<span class="number">1</span> - np.sum(mu_orth**<span class="number">2</span>))) * np.divide(e_w2B - mu_B, np.abs(e_w2 - mu_orth - mu_B))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 6: Debias by equalizing e1 and e2 to the sum of their corrected projections (≈2 lines)</span></span><br><span class="line">    e1 = corrected_e_w1B + mu_orth</span><br><span class="line">    e2 = corrected_e_w2B + mu_orth</span><br><span class="line">                                                                </span><br><span class="line">    <span class="keyword">return</span> e1, e2</span><br></pre></td></tr></table></figure>
<p>通过均衡算法，两个只有性别之分的词和性别的相似度应该大致成相反数的关系。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>吴恩达. DeepLearning.</li>
<li>Mikolov T, Chen K, Corrado G, et al. Efficient Estimation of Word Representations in Vector Space[J]. Computer Science, 2013.</li>
<li>Mikolov T, Sutskever I, Chen K, et al. Distributed Representations of Words and Phrases and their Compositionality[J]. 2013, 26:3111-3119.</li>
<li>Pennington J, Socher R, Manning C. Glove: Global Vectors for Word Representation[C]// Conference on Empirical Methods in Natural Language Processing. 2014:1532-1543.</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
</search>
